{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de modelos de clasificación.\n",
    "\n",
    "En esta etapa, me centraré en desarrollar y entrenar modelos de ML que sean capaces de clasificar las observaciones de mi conjunto de datos para predecir posibles futuros clientes que contraten el seguro de viajes. Para lograrlo, seleccionaré y probaré diferentes algoritmos de clasificación, como regresión logística, árboles de decisión, máquinas de vectores de soporte, entre otros, con el objetivo de encontrar el modelo que mejor se ajuste a los datos y proporcione resultados precisos y confiables para el caso de estudio.\n",
    "\n",
    "A lo largo del proceso de entrenamiento, también llevaré a cabo la validación cruzada y la optimización de hiperparámetros para garantizar que el modelo generalice bien y evite problemas como el sobreajuste o el subajuste. Una vez que haya identificado el modelo de clasificación más adecuado, procederé a evaluar su rendimiento utilizando métricas apropiadas, como precisión, exhaustividad, F1-score y matriz de confusión, antes de implementarlo en producción.\n",
    "\n",
    "Como hemos comprobado en el EDA el target tiene un desequilibrio entre las dos clases leve, lo que podría afectar negativamente el rendimiento de los modelos de clasificación. Para abordar este problema, implemento diversas técnicas de muestreo y balanceo de clases, con el fin de mejorar la precisión y robustez de los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Edad</th>\n",
       "      <th>Tipo_Empleo</th>\n",
       "      <th>Graduado_Universitario</th>\n",
       "      <th>Ingreso_Anual</th>\n",
       "      <th>Miembros_Familia</th>\n",
       "      <th>Enfermedades_Cronicas</th>\n",
       "      <th>Viajero_Frecuente</th>\n",
       "      <th>Visito_Extranjero</th>\n",
       "      <th>Seguro_Viajes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>400000</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1250000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>500000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>700000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>700000</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1500000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1750000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1150000</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>500000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1987 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Edad  Tipo_Empleo  Graduado_Universitario  Ingreso_Anual   \n",
       "ID                                                               \n",
       "0       31            0                       1         400000  \\\n",
       "1       31            1                       1        1250000   \n",
       "2       34            1                       1         500000   \n",
       "3       28            1                       1         700000   \n",
       "4       28            1                       1         700000   \n",
       "...    ...          ...                     ...            ...   \n",
       "1982    33            1                       1        1500000   \n",
       "1983    28            1                       1        1750000   \n",
       "1984    28            1                       1        1150000   \n",
       "1985    34            1                       1        1000000   \n",
       "1986    34            1                       1         500000   \n",
       "\n",
       "      Miembros_Familia  Enfermedades_Cronicas  Viajero_Frecuente   \n",
       "ID                                                                 \n",
       "0                    6                      1                  0  \\\n",
       "1                    7                      0                  0   \n",
       "2                    4                      1                  0   \n",
       "3                    3                      1                  0   \n",
       "4                    8                      1                  1   \n",
       "...                ...                    ...                ...   \n",
       "1982                 4                      0                  1   \n",
       "1983                 5                      1                  0   \n",
       "1984                 6                      1                  0   \n",
       "1985                 6                      0                  1   \n",
       "1986                 4                      0                  0   \n",
       "\n",
       "      Visito_Extranjero  Seguro_Viajes  \n",
       "ID                                      \n",
       "0                     0              0  \n",
       "1                     0              0  \n",
       "2                     0              1  \n",
       "3                     0              0  \n",
       "4                     0              0  \n",
       "...                 ...            ...  \n",
       "1982                  1              1  \n",
       "1983                  1              0  \n",
       "1984                  0              0  \n",
       "1985                  1              1  \n",
       "1986                  0              0  \n",
       "\n",
       "[1987 rows x 9 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./Travel_espanol.csv')\n",
    "\n",
    "df=df.set_index('ID')\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train y Test\n",
    "\n",
    "Divido el dataframe en los conjuntos de Train y Test, en una proporción del 80% y del 20% respectivamente, con una seed predefinida.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "\n",
    "X=df[['Edad','Tipo_Empleo','Graduado_Universitario','Ingreso_Anual','Miembros_Familia','Enfermedades_Cronicas','Viajero_Frecuente','Visito_Extranjero']]\n",
    "Y=df[['Seguro_Viajes']]\n",
    "\n",
    "validation_size = 0.2\n",
    "seed = 42\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X,Y,\n",
    "                                                                    test_size=validation_size,\n",
    "                                                                    random_state = seed)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estandarizar\n",
    "\n",
    "Para garantizar la calidad de los resultados y evitar la contaminación cruzada, estandarizo las particiones de datos de entrenamiento y prueba por separado. La estandarización me parece más adecuada, ya que es un proceso que transforma las variables numéricas para que tengan una media de 0 y una desviación estándar de 1, lo que facilita el aprendizaje y mejora el rendimiento de muchos algoritmos.\n",
    "\n",
    "Por lo tanto, elijo estandarizar los datos en lugar de escalarlos, ya que la estandarización no solo ajusta el rango de los valores, sino que también los centra alrededor de la media y considera la distribución de los datos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Inicio con la Regresión Logística, y observo que la matriz de confusión revela dificultades en identificar correctamente la clase 1 frente a la clase 0. Para enfrentar este problema, exploraré distintos algoritmos, técnicas de balanceo de clases y ajustes de hiperparámetros, buscando mejorar la identificación de ambas clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7688442211055276\n",
      "Precision: 0.7692307692307693\n",
      "Recall: 0.49645390070921985\n",
      "F1 Score: 0.603448275862069\n",
      "ROC AUC Score: 0.7073709192262052\n",
      "Predictions: [0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 0 0 1 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 1\n",
      " 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Didac\\AppData\\Local\\Temp\\ipykernel_8236\\1950573151.py:34: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  cbar.ax.set_yticklabels(cbar.ax.get_yticklabels(), color='white')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "\n",
    "log_reg.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "Y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Calcular la matriz de confusión normalizada\n",
    "c_mat = confusion_matrix(Y_test, Y_pred)\n",
    "c_mat_normalized = c_mat / c_mat.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"deep\")\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.gcf().set_facecolor('#333333')\n",
    "\n",
    "ax = sns.heatmap(c_mat_normalized, annot=True, cmap=\"crest\", cbar=True,\n",
    "                 cbar_kws={\"label\": \"confusión\", \"orientation\": \"vertical\",\n",
    "                           \"shrink\": 0.5, \"format\": \"%.2f\", \"extend\": \"neither\",\n",
    "                           \"extendfrac\": None, \"extendrect\": False, \"drawedges\": False},\n",
    "                 linewidths=1, linecolor='white', square=True,\n",
    "                 annot_kws={\"color\": \"white\", \"fontsize\": 14, \"weight\": \"bold\"})  # Modificado aquí\n",
    "\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(color='white', labelsize=10)\n",
    "cbar.ax.set_yticklabels(cbar.ax.get_yticklabels(), color='white')\n",
    "cbar.set_label(\"Confusión\", color='white')\n",
    "\n",
    "labels_x = ax.get_xticklabels()\n",
    "labels_y = ax.get_yticklabels()\n",
    "ax.set_xticklabels(labels_x, fontsize=12, color='white')\n",
    "ax.set_yticklabels(labels_y, fontsize=12, color='white')\n",
    "\n",
    "plt.xlabel('Predicciones', fontsize=14, color='white')\n",
    "plt.ylabel('Etiquetas reales', fontsize=14, color='white')\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(Y_test, Y_pred))\n",
    "print(\"Precision:\", precision_score(Y_test, Y_pred))\n",
    "print(\"Recall:\", recall_score(Y_test, Y_pred))\n",
    "print(\"F1 Score:\", f1_score(Y_test, Y_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(Y_test, Y_pred))\n",
    "print(\"Predictions:\", Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7261306532663316\n",
      "Precision: 0.6194029850746269\n",
      "Recall: 0.5886524822695035\n",
      "F1 Score: 0.6036363636363636\n",
      "ROC AUC Score: 0.6951044512514833\n",
      "Predictions: [0 1 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 1\n",
      " 1 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 1\n",
      " 0 0 0 1 1 0 1 1 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 1 1 0\n",
      " 0 1 1 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0\n",
      " 0 0 1 1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 1 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1\n",
      " 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 1\n",
      " 0 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 1 1\n",
      " 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Didac\\AppData\\Local\\Temp\\ipykernel_8236\\1324209736.py:31: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  cbar.ax.set_yticklabels(cbar.ax.get_yticklabels(), color='white')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Crear el objeto LogisticRegression con los pesos de las clases equilibrados\n",
    "log_reg = LogisticRegression(class_weight='balanced')\n",
    "Y_train = Y_train.values.ravel()\n",
    "\n",
    "log_reg.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = log_reg.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "c_mat = confusion_matrix(Y_test, Y_pred)\n",
    "c_mat_normalized = c_mat / c_mat.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"deep\")\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.gcf().set_facecolor('#333333')\n",
    "\n",
    "ax = sns.heatmap(c_mat_normalized, annot=True, cmap=\"crest\", cbar=True,\n",
    "                 cbar_kws={\"label\": \"confusión\", \"orientation\": \"vertical\",\n",
    "                           \"shrink\": 0.5, \"format\": \"%.2f\", \"extend\": \"neither\",\n",
    "                           \"extendfrac\": None, \"extendrect\": False, \"drawedges\": False},\n",
    "                 linewidths=1, linecolor='white', square=True,\n",
    "                 annot_kws={\"color\": \"white\", \"fontsize\": 14, \"weight\": \"bold\"})  # Modificado aquí\n",
    "\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(color='white', labelsize=10)\n",
    "cbar.ax.set_yticklabels(cbar.ax.get_yticklabels(), color='white')\n",
    "cbar.set_label(\"Confusión\", color='white')\n",
    "\n",
    "labels_x = ax.get_xticklabels()\n",
    "labels_y = ax.get_yticklabels()\n",
    "ax.set_xticklabels(labels_x, fontsize=12, color='white')\n",
    "ax.set_yticklabels(labels_y, fontsize=12, color='white')\n",
    "\n",
    "plt.xlabel('Predicciones', fontsize=14, color='white')\n",
    "plt.ylabel('Etiquetas reales', fontsize=14, color='white')\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(Y_test, Y_pred))\n",
    "print(\"Precision:\", precision_score(Y_test, Y_pred))\n",
    "print(\"Recall:\", recall_score(Y_test, Y_pred))\n",
    "print(\"F1 Score:\", f1_score(Y_test, Y_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(Y_test, Y_pred))\n",
    "print(\"Predictions:\", Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.00488017, 0.0051187 , 0.00463593, 0.00540221, 0.00497124,\n",
      "       0.00484526]), 'std_fit_time': array([0.00059458, 0.00037701, 0.00063165, 0.00119805, 0.00058545,\n",
      "       0.00061673]), 'mean_score_time': array([0.00088952, 0.00037253, 0.00031297, 0.00084631, 0.00048285,\n",
      "       0.00074093]), 'std_score_time': array([0.00064346, 0.00048461, 0.00047868, 0.00044049, 0.00051494,\n",
      "       0.00049704]), 'param_C': masked_array(data=[0.001, 0.01, 0.1, 1, 10, 100],\n",
      "             mask=[False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_penalty': masked_array(data=['l2', 'l2', 'l2', 'l2', 'l2', 'l2'],\n",
      "             mask=[False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'C': 0.001, 'penalty': 'l2'}, {'C': 0.01, 'penalty': 'l2'}, {'C': 0.1, 'penalty': 'l2'}, {'C': 1, 'penalty': 'l2'}, {'C': 10, 'penalty': 'l2'}, {'C': 100, 'penalty': 'l2'}], 'split0_test_score': array([0.75471698, 0.72955975, 0.72955975, 0.72955975, 0.72955975,\n",
      "       0.72955975]), 'split1_test_score': array([0.72955975, 0.81132075, 0.82389937, 0.83018868, 0.83018868,\n",
      "       0.83018868]), 'split2_test_score': array([0.71698113, 0.81132075, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.81761006]), 'split3_test_score': array([0.70440252, 0.77987421, 0.7672956 , 0.77358491, 0.77358491,\n",
      "       0.77358491]), 'split4_test_score': array([0.70440252, 0.72955975, 0.71069182, 0.72327044, 0.72327044,\n",
      "       0.72327044]), 'split5_test_score': array([0.72327044, 0.75471698, 0.74842767, 0.74213836, 0.74213836,\n",
      "       0.74213836]), 'split6_test_score': array([0.72327044, 0.77987421, 0.79245283, 0.78616352, 0.78616352,\n",
      "       0.78616352]), 'split7_test_score': array([0.72955975, 0.7672956 , 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491]), 'split8_test_score': array([0.73584906, 0.7672956 , 0.75471698, 0.74842767, 0.74842767,\n",
      "       0.74842767]), 'split9_test_score': array([0.7278481 , 0.77848101, 0.77848101, 0.77848101, 0.77848101,\n",
      "       0.77848101]), 'mean_test_score': array([0.72498607, 0.77092986, 0.769672  , 0.77030093, 0.77030093,\n",
      "       0.77030093]), 'std_test_score': array([0.01403314, 0.02681812, 0.03408639, 0.03362749, 0.03362749,\n",
      "       0.03362749]), 'rank_test_score': array([6, 1, 5, 2, 2, 2])}\n",
      "Accuracy: 0.7638190954773869\n",
      "Precision: 0.7764705882352941\n",
      "Recall: 0.46808510638297873\n",
      "F1 Score: 0.584070796460177\n",
      "ROC AUC Score: 0.6970775726467423\n",
      "Predictions: [0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 0 0 1 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "# Definición del modelo y de los parámetros a ajustar\n",
    "log_reg = LogisticRegression()\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100], \n",
    "              'penalty': ['l2']}\n",
    "\n",
    "\n",
    "# Búsqueda de hiperparámetros mediante validación cruzada\n",
    "grid_search = GridSearchCV(log_reg, param_grid, cv=10, scoring='accuracy')\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "print(grid_search.cv_results_)\n",
    "\n",
    "# Evaluación del modelo con los mejores hiperparámetros\n",
    "best_estimator = grid_search.best_estimator_\n",
    "best_estimator.fit(X_train, Y_train)\n",
    "Y_pred = best_estimator.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(Y_test, Y_pred))\n",
    "print(\"Precision:\", precision_score(Y_test, Y_pred))\n",
    "print(\"Recall:\", recall_score(Y_test, Y_pred))\n",
    "print(\"F1 Score:\", f1_score(Y_test, Y_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(Y_test, Y_pred))\n",
    "print(\"Predictions:\", Y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nivelar clases\n",
    "\n",
    "Pruebo diferentes técnicas de muestreo, como oversampling, undersampling y una combinación de ambos, para analizar si los resultados cambian y, especialmente, si se mejora el recall. Además, en aquellos modelos que lo permitan, aplicaré balanceo de pesos para ajustar la importancia de cada clase durante el proceso de entrenamiento, con el objetivo de obtener un mejor rendimiento en la clasificación. Finalmente también incorporo la opcion (Normal), es decir sin técnicas de equilibrio."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para Normal:\n",
      "{'mean_fit_time': array([0.00100069, 0.00103042, 0.00121765, 0.00106719, 0.00140042,\n",
      "       0.00110085, 0.00140066, 0.00119951, 0.00124919, 0.00159953,\n",
      "       0.00171719, 0.001337  ]), 'std_fit_time': array([4.47087181e-04, 9.00145833e-05, 3.48948422e-04, 3.50383897e-04,\n",
      "       4.89639845e-04, 2.99671613e-04, 4.92065668e-04, 3.99760968e-04,\n",
      "       5.10570314e-04, 4.89770451e-04, 4.70582837e-04, 5.24465643e-04]), 'mean_score_time': array([0.00035062, 0.00040648, 0.00040014, 0.00031023, 0.00029976,\n",
      "       0.00079894, 0.00019984, 0.00030055, 0.00050132, 0.0002002 ,\n",
      "       0.00019944, 0.00010011]), 'std_score_time': array([0.00044998, 0.00049806, 0.00049007, 0.00047437, 0.0004579 ,\n",
      "       0.00039947, 0.00039969, 0.0004591 , 0.00050134, 0.0004004 ,\n",
      "       0.00039887, 0.00030034]), 'param_classifier__C': masked_array(data=[0.001, 0.001, 0.01, 0.01, 0.1, 0.1, 1, 1, 10, 10, 100,\n",
      "                   100],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_classifier__penalty': masked_array(data=['l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
      "                   'l2', 'l1', 'l2'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'classifier__C': 0.001, 'classifier__penalty': 'l1'}, {'classifier__C': 0.001, 'classifier__penalty': 'l2'}, {'classifier__C': 0.01, 'classifier__penalty': 'l1'}, {'classifier__C': 0.01, 'classifier__penalty': 'l2'}, {'classifier__C': 0.1, 'classifier__penalty': 'l1'}, {'classifier__C': 0.1, 'classifier__penalty': 'l2'}, {'classifier__C': 1, 'classifier__penalty': 'l1'}, {'classifier__C': 1, 'classifier__penalty': 'l2'}, {'classifier__C': 10, 'classifier__penalty': 'l1'}, {'classifier__C': 10, 'classifier__penalty': 'l2'}, {'classifier__C': 100, 'classifier__penalty': 'l1'}, {'classifier__C': 100, 'classifier__penalty': 'l2'}], 'split0_test_score': array([0.64150943, 0.72955975, 0.72327044, 0.74213836, 0.72955975,\n",
      "       0.73584906, 0.72955975, 0.72955975, 0.72955975, 0.72955975,\n",
      "       0.72955975, 0.72955975]), 'split1_test_score': array([0.64150943, 0.79874214, 0.80503145, 0.81132075, 0.82389937,\n",
      "       0.83018868, 0.83018868, 0.83018868, 0.83018868, 0.83018868,\n",
      "       0.83018868, 0.83018868]), 'split2_test_score': array([0.64150943, 0.79245283, 0.80503145, 0.82389937, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81761006]), 'split3_test_score': array([0.64150943, 0.78616352, 0.79245283, 0.78616352, 0.77358491,\n",
      "       0.7672956 , 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491]), 'split4_test_score': array([0.64150943, 0.71698113, 0.72955975, 0.72955975, 0.71698113,\n",
      "       0.71698113, 0.72327044, 0.72327044, 0.72327044, 0.72327044,\n",
      "       0.72327044, 0.72327044]), 'split5_test_score': array([0.64150943, 0.74213836, 0.74213836, 0.75471698, 0.74213836,\n",
      "       0.74213836, 0.74213836, 0.74213836, 0.74213836, 0.74213836,\n",
      "       0.74213836, 0.74213836]), 'split6_test_score': array([0.64150943, 0.77358491, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.79245283, 0.79245283, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352]), 'split7_test_score': array([0.64150943, 0.76100629, 0.76100629, 0.7672956 , 0.77987421,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491]), 'split8_test_score': array([0.64150943, 0.72327044, 0.75471698, 0.74213836, 0.74842767,\n",
      "       0.74842767, 0.74842767, 0.74842767, 0.74842767, 0.74842767,\n",
      "       0.74842767, 0.74842767]), 'split9_test_score': array([0.64556962, 0.75949367, 0.76582278, 0.77848101, 0.77848101,\n",
      "       0.77848101, 0.77848101, 0.77848101, 0.77848101, 0.77848101,\n",
      "       0.77848101, 0.77848101]), 'mean_test_score': array([0.64191545, 0.7583393 , 0.76651939, 0.77218772, 0.769672  ,\n",
      "       0.77030093, 0.77092986, 0.77030093, 0.77030093, 0.77030093,\n",
      "       0.77030093, 0.77030093]), 'std_test_score': array([0.00121806, 0.028004  , 0.02833   , 0.02930524, 0.033619  ,\n",
      "       0.03421058, 0.0339753 , 0.03362749, 0.03362749, 0.03362749,\n",
      "       0.03362749, 0.03362749]), 'rank_test_score': array([12, 11, 10,  1,  9,  3,  2,  3,  3,  3,  3,  3])}\n",
      "Resultados para Balanced:\n",
      "{'mean_fit_time': array([0.00109975, 0.00100024, 0.00129955, 0.00130136, 0.00160105,\n",
      "       0.00149999, 0.00169997, 0.00150237, 0.0016    , 0.00139916,\n",
      "       0.00140007, 0.00150008]), 'std_fit_time': array([2.99955305e-04, 1.59953815e-06, 4.57270402e-04, 4.56979473e-04,\n",
      "       4.88402959e-04, 5.00059166e-04, 4.58130861e-04, 4.97667374e-04,\n",
      "       6.63169157e-04, 4.90420564e-04, 4.89482924e-04, 4.99916231e-04]), 'mean_score_time': array([0.00020025, 0.00060074, 0.0003    , 0.00039878, 0.00039999,\n",
      "       0.00030005, 0.00029993, 0.00039992, 0.00039992, 0.00050013,\n",
      "       0.00020001, 0.00040004]), 'std_score_time': array([0.0004005 , 0.00049051, 0.00045826, 0.00048842, 0.00048989,\n",
      "       0.00045833, 0.00045815, 0.0004898 , 0.0004898 , 0.00050013,\n",
      "       0.00040002, 0.00048995]), 'param_classifier__C': masked_array(data=[0.001, 0.001, 0.01, 0.01, 0.1, 0.1, 1, 1, 10, 10, 100,\n",
      "                   100],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_classifier__penalty': masked_array(data=['l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
      "                   'l2', 'l1', 'l2'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'classifier__C': 0.001, 'classifier__penalty': 'l1'}, {'classifier__C': 0.001, 'classifier__penalty': 'l2'}, {'classifier__C': 0.01, 'classifier__penalty': 'l1'}, {'classifier__C': 0.01, 'classifier__penalty': 'l2'}, {'classifier__C': 0.1, 'classifier__penalty': 'l1'}, {'classifier__C': 0.1, 'classifier__penalty': 'l2'}, {'classifier__C': 1, 'classifier__penalty': 'l1'}, {'classifier__C': 1, 'classifier__penalty': 'l2'}, {'classifier__C': 10, 'classifier__penalty': 'l1'}, {'classifier__C': 10, 'classifier__penalty': 'l2'}, {'classifier__C': 100, 'classifier__penalty': 'l1'}, {'classifier__C': 100, 'classifier__penalty': 'l2'}], 'split0_test_score': array([0.64150943, 0.66666667, 0.66666667, 0.72327044, 0.72327044,\n",
      "       0.71698113, 0.71698113, 0.71698113, 0.71698113, 0.71698113,\n",
      "       0.71698113, 0.71698113]), 'split1_test_score': array([0.64150943, 0.74842767, 0.71069182, 0.77358491, 0.76100629,\n",
      "       0.77358491, 0.7672956 , 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491]), 'split2_test_score': array([0.64150943, 0.74213836, 0.68553459, 0.76100629, 0.74213836,\n",
      "       0.74842767, 0.74213836, 0.74213836, 0.74213836, 0.74213836,\n",
      "       0.74213836, 0.74213836]), 'split3_test_score': array([0.64150943, 0.71069182, 0.71069182, 0.73584906, 0.71698113,\n",
      "       0.72955975, 0.72955975, 0.72955975, 0.72955975, 0.72955975,\n",
      "       0.72955975, 0.72955975]), 'split4_test_score': array([0.64150943, 0.66666667, 0.63522013, 0.68553459, 0.70440252,\n",
      "       0.70440252, 0.70440252, 0.70440252, 0.70440252, 0.70440252,\n",
      "       0.70440252, 0.70440252]), 'split5_test_score': array([0.64150943, 0.68553459, 0.70440252, 0.72955975, 0.74213836,\n",
      "       0.74213836, 0.74213836, 0.74213836, 0.74213836, 0.74213836,\n",
      "       0.74213836, 0.74213836]), 'split6_test_score': array([0.64150943, 0.71069182, 0.69811321, 0.73584906, 0.76100629,\n",
      "       0.72955975, 0.72955975, 0.72955975, 0.72955975, 0.72955975,\n",
      "       0.72955975, 0.72955975]), 'split7_test_score': array([0.64150943, 0.7672956 , 0.7672956 , 0.79245283, 0.7672956 ,\n",
      "       0.76100629, 0.76100629, 0.76100629, 0.76100629, 0.76100629,\n",
      "       0.76100629, 0.76100629]), 'split8_test_score': array([0.64150943, 0.71069182, 0.71069182, 0.71069182, 0.71698113,\n",
      "       0.70440252, 0.71069182, 0.71069182, 0.71069182, 0.71069182,\n",
      "       0.71069182, 0.71069182]), 'split9_test_score': array([0.64556962, 0.72151899, 0.73417722, 0.71518987, 0.73417722,\n",
      "       0.7278481 , 0.74050633, 0.7278481 , 0.73417722, 0.7278481 ,\n",
      "       0.7278481 , 0.7278481 ]), 'mean_test_score': array([0.64191545, 0.7130324 , 0.70234854, 0.73629886, 0.73693973,\n",
      "       0.7337911 , 0.73442799, 0.7337911 , 0.73442401, 0.7337911 ,\n",
      "       0.7337911 , 0.7337911 ]), 'std_test_score': array([0.00121806, 0.03191963, 0.03394746, 0.03007965, 0.02045427,\n",
      "       0.02165456, 0.01938881, 0.02052933, 0.0204337 , 0.02052933,\n",
      "       0.02052933, 0.02052933]), 'rank_test_score': array([12, 10, 11,  2,  1,  5,  3,  6,  4,  6,  6,  6])}\n",
      "Resultados para OverSampler:\n",
      "{'mean_fit_time': array([0.00149972, 0.00179965, 0.00199878, 0.0017997 , 0.00209959,\n",
      "       0.00195224, 0.00219898, 0.00199893, 0.0021003 , 0.00189943,\n",
      "       0.00190063, 0.00200045]), 'std_fit_time': array([5.00178428e-04, 3.99866498e-04, 3.89615644e-06, 3.99828245e-04,\n",
      "       2.99907546e-04, 1.43791036e-04, 3.99270289e-04, 2.38525843e-06,\n",
      "       2.99356208e-04, 3.00717814e-04, 2.98963889e-04, 2.81747821e-06]), 'mean_score_time': array([3.00168991e-04, 3.00455093e-04, 3.00049782e-04, 4.00018692e-04,\n",
      "       4.99963760e-04, 2.00057030e-04, 3.00192833e-04, 8.00728798e-04,\n",
      "       1.99842453e-04, 1.99937820e-04, 5.99479675e-04, 9.98020172e-05]), 'std_score_time': array([0.00045852, 0.00045895, 0.00045833, 0.00048992, 0.00049996,\n",
      "       0.00040011, 0.00045855, 0.00040038, 0.00039969, 0.00039988,\n",
      "       0.00048947, 0.00029941]), 'param_classifier__C': masked_array(data=[0.001, 0.001, 0.01, 0.01, 0.1, 0.1, 1, 1, 10, 10, 100,\n",
      "                   100],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_classifier__penalty': masked_array(data=['l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
      "                   'l2', 'l1', 'l2'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'classifier__C': 0.001, 'classifier__penalty': 'l1'}, {'classifier__C': 0.001, 'classifier__penalty': 'l2'}, {'classifier__C': 0.01, 'classifier__penalty': 'l1'}, {'classifier__C': 0.01, 'classifier__penalty': 'l2'}, {'classifier__C': 0.1, 'classifier__penalty': 'l1'}, {'classifier__C': 0.1, 'classifier__penalty': 'l2'}, {'classifier__C': 1, 'classifier__penalty': 'l1'}, {'classifier__C': 1, 'classifier__penalty': 'l2'}, {'classifier__C': 10, 'classifier__penalty': 'l1'}, {'classifier__C': 10, 'classifier__penalty': 'l2'}, {'classifier__C': 100, 'classifier__penalty': 'l1'}, {'classifier__C': 100, 'classifier__penalty': 'l2'}], 'split0_test_score': array([0.64150943, 0.67924528, 0.66666667, 0.72327044, 0.71698113,\n",
      "       0.72327044, 0.71698113, 0.72327044, 0.72955975, 0.71698113,\n",
      "       0.72327044, 0.71698113]), 'split1_test_score': array([0.64150943, 0.7672956 , 0.67295597, 0.7672956 , 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.75471698, 0.76100629, 0.77987421,\n",
      "       0.77987421, 0.77987421]), 'split2_test_score': array([0.64150943, 0.74842767, 0.67295597, 0.76100629, 0.74842767,\n",
      "       0.74842767, 0.74213836, 0.72955975, 0.74213836, 0.73584906,\n",
      "       0.75471698, 0.73584906]), 'split3_test_score': array([0.64150943, 0.72327044, 0.70440252, 0.72955975, 0.73584906,\n",
      "       0.72327044, 0.72327044, 0.71698113, 0.72955975, 0.71698113,\n",
      "       0.73584906, 0.72955975]), 'split4_test_score': array([0.64150943, 0.66666667, 0.63522013, 0.67924528, 0.69811321,\n",
      "       0.67295597, 0.69811321, 0.70440252, 0.71698113, 0.69811321,\n",
      "       0.70440252, 0.71698113]), 'split5_test_score': array([0.64150943, 0.71698113, 0.69811321, 0.72327044, 0.74213836,\n",
      "       0.72327044, 0.74213836, 0.72955975, 0.74213836, 0.74213836,\n",
      "       0.74213836, 0.73584906]), 'split6_test_score': array([0.64150943, 0.71069182, 0.69811321, 0.74842767, 0.7672956 ,\n",
      "       0.72327044, 0.75471698, 0.73584906, 0.73584906, 0.74842767,\n",
      "       0.73584906, 0.72327044]), 'split7_test_score': array([0.64150943, 0.7672956 , 0.75471698, 0.78616352, 0.75471698,\n",
      "       0.79874214, 0.7672956 , 0.75471698, 0.77358491, 0.77987421,\n",
      "       0.76100629, 0.7672956 ]), 'split8_test_score': array([0.64150943, 0.71069182, 0.71069182, 0.71069182, 0.70440252,\n",
      "       0.70440252, 0.69811321, 0.69811321, 0.71698113, 0.70440252,\n",
      "       0.70440252, 0.71069182]), 'split9_test_score': array([0.64556962, 0.7278481 , 0.73417722, 0.7278481 , 0.74050633,\n",
      "       0.71518987, 0.7278481 , 0.7278481 , 0.72151899, 0.75316456,\n",
      "       0.74683544, 0.74050633]), 'mean_test_score': array([0.64191545, 0.72184141, 0.69480137, 0.73567789, 0.73820158,\n",
      "       0.73063848, 0.73442003, 0.72750179, 0.73693177, 0.73758061,\n",
      "       0.73883449, 0.73568585]), 'std_test_score': array([0.00121806, 0.0316355 , 0.03286775, 0.02927137, 0.02387861,\n",
      "       0.03357137, 0.02500758, 0.01756546, 0.01766558, 0.02732934,\n",
      "       0.02265881, 0.02119241]), 'rank_test_score': array([12, 10, 11,  6,  2,  8,  7,  9,  4,  3,  1,  5])}\n",
      "Resultados para UnderSampler:\n",
      "{'mean_fit_time': array([0.00139954, 0.00142889, 0.00149875, 0.00129895, 0.00172975,\n",
      "       0.00147491, 0.00147178, 0.00150359, 0.00163538, 0.0014585 ,\n",
      "       0.00153995, 0.00149884]), 'std_fit_time': array([0.00049016, 0.00052348, 0.00043762, 0.00045854, 0.00042095,\n",
      "       0.00041101, 0.0004622 , 0.00054866, 0.00046518, 0.00048176,\n",
      "       0.00061781, 0.00050002]), 'mean_score_time': array([0.00059981, 0.00029986, 0.00040181, 0.00050092, 0.00025063,\n",
      "       0.00025089, 0.00030093, 0.00030069, 0.00040057, 0.00040064,\n",
      "       0.00050359, 0.00040035]), 'std_score_time': array([0.00048975, 0.00045804, 0.00049211, 0.00050092, 0.00040378,\n",
      "       0.00040389, 0.00040072, 0.00045932, 0.0004906 , 0.00049069,\n",
      "       0.0005037 , 0.00049033]), 'param_classifier__C': masked_array(data=[0.001, 0.001, 0.01, 0.01, 0.1, 0.1, 1, 1, 10, 10, 100,\n",
      "                   100],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_classifier__penalty': masked_array(data=['l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
      "                   'l2', 'l1', 'l2'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'classifier__C': 0.001, 'classifier__penalty': 'l1'}, {'classifier__C': 0.001, 'classifier__penalty': 'l2'}, {'classifier__C': 0.01, 'classifier__penalty': 'l1'}, {'classifier__C': 0.01, 'classifier__penalty': 'l2'}, {'classifier__C': 0.1, 'classifier__penalty': 'l1'}, {'classifier__C': 0.1, 'classifier__penalty': 'l2'}, {'classifier__C': 1, 'classifier__penalty': 'l1'}, {'classifier__C': 1, 'classifier__penalty': 'l2'}, {'classifier__C': 10, 'classifier__penalty': 'l1'}, {'classifier__C': 10, 'classifier__penalty': 'l2'}, {'classifier__C': 100, 'classifier__penalty': 'l1'}, {'classifier__C': 100, 'classifier__penalty': 'l2'}], 'split0_test_score': array([0.64150943, 0.66666667, 0.66666667, 0.6918239 , 0.70440252,\n",
      "       0.72955975, 0.71069182, 0.71069182, 0.73584906, 0.73584906,\n",
      "       0.71069182, 0.71698113]), 'split1_test_score': array([0.64150943, 0.75471698, 0.67295597, 0.77358491, 0.75471698,\n",
      "       0.7672956 , 0.76100629, 0.79245283, 0.76100629, 0.78616352,\n",
      "       0.77358491, 0.7672956 ]), 'split2_test_score': array([0.64150943, 0.74213836, 0.66037736, 0.74842767, 0.72955975,\n",
      "       0.74213836, 0.74213836, 0.73584906, 0.73584906, 0.74213836,\n",
      "       0.72327044, 0.72955975]), 'split3_test_score': array([0.64150943, 0.69811321, 0.71069182, 0.73584906, 0.71069182,\n",
      "       0.76100629, 0.72955975, 0.72327044, 0.72955975, 0.71698113,\n",
      "       0.72955975, 0.72327044]), 'split4_test_score': array([0.64150943, 0.67295597, 0.63522013, 0.68553459, 0.70440252,\n",
      "       0.67924528, 0.71069182, 0.72327044, 0.70440252, 0.69811321,\n",
      "       0.6918239 , 0.71069182]), 'split5_test_score': array([0.64150943, 0.68553459, 0.67295597, 0.73584906, 0.74213836,\n",
      "       0.74213836, 0.73584906, 0.74213836, 0.73584906, 0.72955975,\n",
      "       0.73584906, 0.72327044]), 'split6_test_score': array([0.64150943, 0.70440252, 0.72327044, 0.74842767, 0.74842767,\n",
      "       0.74213836, 0.74213836, 0.7672956 , 0.71698113, 0.72327044,\n",
      "       0.74213836, 0.72327044]), 'split7_test_score': array([0.64150943, 0.74213836, 0.7672956 , 0.77358491, 0.77987421,\n",
      "       0.77358491, 0.77358491, 0.80503145, 0.78616352, 0.79874214,\n",
      "       0.77987421, 0.74213836]), 'split8_test_score': array([0.64150943, 0.70440252, 0.67295597, 0.71698113, 0.71069182,\n",
      "       0.70440252, 0.70440252, 0.71069182, 0.70440252, 0.71069182,\n",
      "       0.70440252, 0.70440252]), 'split9_test_score': array([0.64556962, 0.70886076, 0.77848101, 0.7278481 , 0.74050633,\n",
      "       0.70253165, 0.74683544, 0.70886076, 0.70886076, 0.75949367,\n",
      "       0.73417722, 0.74050633]), 'mean_test_score': array([0.64191545, 0.70799299, 0.69608709, 0.7337911 , 0.7325412 ,\n",
      "       0.73440411, 0.73568983, 0.74195526, 0.73189237, 0.74010031,\n",
      "       0.73253722, 0.72813868]), 'std_test_score': array([0.00121806, 0.02842345, 0.04501369, 0.02830522, 0.02384818,\n",
      "       0.02913079, 0.02133226, 0.03310039, 0.02471754, 0.03084742,\n",
      "       0.02655681, 0.01716864]), 'rank_test_score': array([12, 10, 11,  5,  6,  4,  3,  1,  8,  2,  7,  9])}\n",
      "Resultados para SMOTEENN:\n",
      "{'mean_fit_time': array([0.01882381, 0.01952932, 0.0177794 , 0.01749384, 0.01851511,\n",
      "       0.0178884 , 0.02044351, 0.01793594, 0.01878643, 0.01829977,\n",
      "       0.01839364, 0.01820157]), 'std_fit_time': array([0.00097959, 0.0014344 , 0.00087355, 0.00038769, 0.00093863,\n",
      "       0.00048709, 0.00321075, 0.00042899, 0.00164733, 0.00045818,\n",
      "       0.00048236, 0.00039921]), 'mean_score_time': array([3.00002098e-04, 5.02133369e-04, 5.00679016e-04, 9.97066498e-05,\n",
      "       6.00790977e-04, 5.52201271e-04, 4.01759148e-04, 4.00233269e-04,\n",
      "       3.99899483e-04, 5.00202179e-04, 4.99939919e-04, 1.98507309e-04]), 'std_score_time': array([0.00045826, 0.00050214, 0.00050069, 0.00029912, 0.00049056,\n",
      "       0.00047303, 0.00049207, 0.00049019, 0.00048977, 0.0005002 ,\n",
      "       0.00049994, 0.00039703]), 'param_classifier__C': masked_array(data=[0.001, 0.001, 0.01, 0.01, 0.1, 0.1, 1, 1, 10, 10, 100,\n",
      "                   100],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_classifier__penalty': masked_array(data=['l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
      "                   'l2', 'l1', 'l2'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'classifier__C': 0.001, 'classifier__penalty': 'l1'}, {'classifier__C': 0.001, 'classifier__penalty': 'l2'}, {'classifier__C': 0.01, 'classifier__penalty': 'l1'}, {'classifier__C': 0.01, 'classifier__penalty': 'l2'}, {'classifier__C': 0.1, 'classifier__penalty': 'l1'}, {'classifier__C': 0.1, 'classifier__penalty': 'l2'}, {'classifier__C': 1, 'classifier__penalty': 'l1'}, {'classifier__C': 1, 'classifier__penalty': 'l2'}, {'classifier__C': 10, 'classifier__penalty': 'l1'}, {'classifier__C': 10, 'classifier__penalty': 'l2'}, {'classifier__C': 100, 'classifier__penalty': 'l1'}, {'classifier__C': 100, 'classifier__penalty': 'l2'}], 'split0_test_score': array([0.64150943, 0.63522013, 0.65408805, 0.73584906, 0.71698113,\n",
      "       0.73584906, 0.74842767, 0.71698113, 0.72327044, 0.74842767,\n",
      "       0.71698113, 0.73584906]), 'split1_test_score': array([0.64150943, 0.71698113, 0.67295597, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.77358491, 0.80503145, 0.80503145, 0.79245283,\n",
      "       0.79874214, 0.79245283]), 'split2_test_score': array([0.64150943, 0.70440252, 0.68553459, 0.74213836, 0.74213836,\n",
      "       0.74842767, 0.74213836, 0.74213836, 0.71698113, 0.72955975,\n",
      "       0.72955975, 0.74213836]), 'split3_test_score': array([0.64150943, 0.6918239 , 0.71069182, 0.73584906, 0.70440252,\n",
      "       0.71069182, 0.71069182, 0.68553459, 0.74213836, 0.74213836,\n",
      "       0.71069182, 0.6918239 ]), 'split4_test_score': array([0.64150943, 0.65408805, 0.64150943, 0.6918239 , 0.72327044,\n",
      "       0.71698113, 0.71698113, 0.72327044, 0.6918239 , 0.71069182,\n",
      "       0.71069182, 0.70440252]), 'split5_test_score': array([0.64150943, 0.70440252, 0.67295597, 0.74213836, 0.74842767,\n",
      "       0.73584906, 0.70440252, 0.73584906, 0.71069182, 0.74842767,\n",
      "       0.72955975, 0.70440252]), 'split6_test_score': array([0.64150943, 0.69811321, 0.66037736, 0.74213836, 0.74842767,\n",
      "       0.7672956 , 0.75471698, 0.72955975, 0.72955975, 0.74842767,\n",
      "       0.76100629, 0.72327044]), 'split7_test_score': array([0.64150943, 0.75471698, 0.7672956 , 0.79874214, 0.77987421,\n",
      "       0.74213836, 0.75471698, 0.74842767, 0.76100629, 0.75471698,\n",
      "       0.75471698, 0.75471698]), 'split8_test_score': array([0.64150943, 0.69811321, 0.67295597, 0.70440252, 0.69811321,\n",
      "       0.70440252, 0.69811321, 0.70440252, 0.71069182, 0.71069182,\n",
      "       0.70440252, 0.72327044]), 'split9_test_score': array([0.64556962, 0.67088608, 0.6835443 , 0.70886076, 0.72151899,\n",
      "       0.74050633, 0.71518987, 0.69620253, 0.74683544, 0.76582278,\n",
      "       0.72151899, 0.74683544]), 'mean_test_score': array([0.64191545, 0.69287477, 0.68219091, 0.7388106 , 0.73693177,\n",
      "       0.73883051, 0.73189635, 0.72873975, 0.73380304, 0.74513574,\n",
      "       0.73378712, 0.73191625]), 'std_test_score': array([0.00121806, 0.03168487, 0.03353291, 0.03189594, 0.02818951,\n",
      "       0.02372504, 0.02450734, 0.03181919, 0.03048811, 0.0232713 ,\n",
      "       0.02792316, 0.0279249 ]), 'rank_test_score': array([12, 10, 11,  3,  4,  2,  8,  9,  5,  1,  6,  7])}\n",
      "\n",
      "Resultados para Normal:\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('classifier',\n",
      "                                        LogisticRegression(solver='liblinear'))]),\n",
      "             param_grid={'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
      "                         'classifier__penalty': ['l1', 'l2']},\n",
      "             scoring='accuracy')\n",
      "Accuracy: 0.7738693467336684\n",
      "Precision: 0.7741935483870968\n",
      "Recall: 0.5106382978723404\n",
      "F1 Score: 0.6153846153846153\n",
      "ROC AUC Score: 0.7144631178077654\n",
      "Predictions: [0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 0 0 1 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 1\n",
      " 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\n",
      "Resultados para Balanced:\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('classifier',\n",
      "                                        LogisticRegression(class_weight='balanced',\n",
      "                                                           solver='liblinear'))]),\n",
      "             param_grid={'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
      "                         'classifier__penalty': ['l1', 'l2']},\n",
      "             scoring='accuracy')\n",
      "Accuracy: 0.7185929648241206\n",
      "Precision: 0.6074074074074074\n",
      "Recall: 0.5815602836879432\n",
      "F1 Score: 0.5942028985507246\n",
      "ROC AUC Score: 0.6876673013770456\n",
      "Predictions: [0 1 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 1\n",
      " 1 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1\n",
      " 0 0 0 1 1 0 1 1 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 1 1 0\n",
      " 0 1 1 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0\n",
      " 0 0 1 1 0 0 1 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 1 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1\n",
      " 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 1\n",
      " 0 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 0 1 1\n",
      " 0 0 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 1 0 0]\n",
      "\n",
      "Resultados para OverSampler:\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('sampler', RandomOverSampler()),\n",
      "                                       ('classifier',\n",
      "                                        LogisticRegression(solver='liblinear'))]),\n",
      "             param_grid={'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
      "                         'classifier__penalty': ['l1', 'l2']},\n",
      "             scoring='accuracy')\n",
      "Accuracy: 0.7236180904522613\n",
      "Precision: 0.6165413533834586\n",
      "Recall: 0.5815602836879432\n",
      "F1 Score: 0.5985401459854015\n",
      "ROC AUC Score: 0.6915583519607031\n",
      "Predictions: [0 1 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 1\n",
      " 1 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1\n",
      " 0 0 0 1 1 0 1 1 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 1 1 0\n",
      " 0 1 1 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0\n",
      " 0 0 1 1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 1 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1\n",
      " 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 1\n",
      " 0 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 1 1\n",
      " 0 0 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\n",
      "Resultados para UnderSampler:\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('sampler', RandomUnderSampler()),\n",
      "                                       ('classifier',\n",
      "                                        LogisticRegression(solver='liblinear'))]),\n",
      "             param_grid={'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
      "                         'classifier__penalty': ['l1', 'l2']},\n",
      "             scoring='accuracy')\n",
      "Accuracy: 0.7160804020100503\n",
      "Precision: 0.6\n",
      "Recall: 0.5957446808510638\n",
      "F1 Score: 0.5978647686832739\n",
      "ROC AUC Score: 0.6889229240831194\n",
      "Predictions: [0 1 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 1\n",
      " 1 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 1\n",
      " 0 0 0 1 1 0 1 1 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 1 1 0\n",
      " 0 1 1 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0\n",
      " 0 0 1 1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 1 0 1 0 1 1 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1\n",
      " 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 1 1\n",
      " 0 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 0 1 1\n",
      " 1 0 0 1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0]\n",
      "\n",
      "Resultados para SMOTEENN:\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('sampler', SMOTEENN()),\n",
      "                                       ('classifier',\n",
      "                                        LogisticRegression(solver='liblinear'))]),\n",
      "             param_grid={'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
      "                         'classifier__penalty': ['l1', 'l2']},\n",
      "             scoring='accuracy')\n",
      "Accuracy: 0.7286432160804021\n",
      "Precision: 0.6259541984732825\n",
      "Recall: 0.5815602836879432\n",
      "F1 Score: 0.6029411764705882\n",
      "ROC AUC Score: 0.6954494025443607\n",
      "Predictions: [0 1 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1\n",
      " 1 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1\n",
      " 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 1 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 1 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 1 0 1 0 1 1 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1\n",
      " 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 1 1\n",
      " 0 0 1 1 1 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 1 1 1 0 0 0 1 0 0 0 1 0 0 1 1\n",
      " 1 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression(solver='liblinear')  # Cambio el solver a 'liblinear' para admitir penalización L1\n",
    "log_reg_pesos = LogisticRegression(solver='liblinear', class_weight='balanced')  #para balancear pesos\n",
    "grid_parametros = {'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100], \n",
    "              'classifier__penalty': ['l1', 'l2']} \n",
    "\n",
    "# Creo instancias de las técnicas de muestreo\n",
    "oversampler = RandomOverSampler()\n",
    "undersampler = RandomUnderSampler()\n",
    "combinado = SMOTEENN()\n",
    "\n",
    "# Creo Pipeline para cada modificación del modelo.\n",
    "normal_pipeline = Pipeline([('classifier', log_reg)])\n",
    "balanceado_pipeline = Pipeline([('classifier', log_reg_pesos)])\n",
    "over_pipeline = ImbPipeline([('sampler', oversampler), ('classifier', log_reg)])\n",
    "under_pipeline = ImbPipeline([('sampler', undersampler), ('classifier', log_reg)])\n",
    "combinado_pipeline = ImbPipeline([('sampler', combinado), ('classifier', log_reg)])\n",
    "\n",
    "# En este diccionario, se irán guardando todos los resultados.\n",
    "resultados = {}\n",
    "\n",
    "# Bucle para iniciar la busqeuda de los hiperparámetros de la validación cruzada.\n",
    "for nombre, pipeline in [('Normal', normal_pipeline), ('Balanced', balanceado_pipeline), ('OverSampler', over_pipeline), ('UnderSampler', under_pipeline), ('SMOTEENN', combinado_pipeline)]:\n",
    "    grid_search = GridSearchCV(pipeline, grid_parametros, cv=10, scoring='accuracy')\n",
    "    grid_search.fit(X_train, Y_train)\n",
    "\n",
    "    \n",
    "    print(f\"Resultados para {nombre}:\")\n",
    "    print(grid_search.cv_results_)\n",
    "\n",
    "#Predicción con los mejores parametros.\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "    Y_pred = best_estimator.predict(X_test)\n",
    "\n",
    "    #Guardamos los resultados en el diccionraio de test y predicción.\n",
    "    resultados[nombre] = {\"GridSearchModel\": grid_search,\n",
    "                     \"Accuracy\": accuracy_score(Y_test, Y_pred),\n",
    "                     \"Precision\": precision_score(Y_test, Y_pred),\n",
    "                     \"Recall\": recall_score(Y_test, Y_pred),\n",
    "                     \"F1 Score\": f1_score(Y_test, Y_pred),\n",
    "                     \"ROC AUC Score\": roc_auc_score(Y_test, Y_pred),\n",
    "                     \"Predictions\": Y_pred}\n",
    "\n",
    "\n",
    "for nombre, metricas in resultados.items():\n",
    "    print(f\"\\nResultados para {nombre}:\")\n",
    "    for metrica, value in metricas.items():\n",
    "        print(f\"{metrica}: {value}\")\n",
    "\n",
    "for nombre, metricas in resultados.items():\n",
    "    with open(f\"Modelos/Regresion_logistica_{nombre}_mejor_modelo.pkl\", \"wb\") as f:\n",
    "        pickle.dump(metricas[\"GridSearchModel\"].best_estimator_, f)\n",
    "    \n",
    "    with open(f\"Resultados/Regresion_logistica_{nombre}_resultados.txt\", \"w\") as f:\n",
    "        for metrica, value in metricas.items():\n",
    "            if metrica != \"Predictions\": \n",
    "                f.write(f\"{metrica}: {value}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para Normal:\n",
      "{'mean_fit_time': array([0.0016032 , 0.00160007, 0.00165145, 0.0016058 , 0.00165091,\n",
      "       0.00145319, 0.00145547, 0.00181475, 0.00159795, 0.00110166,\n",
      "       0.00121334, 0.0012594 , 0.00141916, 0.00140183, 0.00114799,\n",
      "       0.00149961, 0.00195141, 0.00122199, 0.00132685, 0.00160091,\n",
      "       0.00150177, 0.00144022, 0.00143566, 0.00150068, 0.00165424,\n",
      "       0.00158284, 0.00137064, 0.00127616]), 'std_fit_time': array([0.0004345 , 0.00043372, 0.00046073, 0.00049341, 0.000449  ,\n",
      "       0.00047276, 0.00047096, 0.00031896, 0.00049086, 0.00030055,\n",
      "       0.00033119, 0.00040812, 0.00049841, 0.00049136, 0.00031757,\n",
      "       0.00049997, 0.00042537, 0.00035582, 0.00052486, 0.00053676,\n",
      "       0.00052674, 0.00046863, 0.00041514, 0.00049894, 0.00044809,\n",
      "       0.00047879, 0.00042701, 0.00045237]), 'mean_score_time': array([0.00428829, 0.00430222, 0.004512  , 0.00459507, 0.00475581,\n",
      "       0.00477381, 0.0045047 , 0.0046999 , 0.0050005 , 0.00514195,\n",
      "       0.00502493, 0.00539293, 0.00513353, 0.0050966 , 0.00543399,\n",
      "       0.00599866, 0.00567324, 0.00557365, 0.00547769, 0.0055784 ,\n",
      "       0.00585656, 0.00594521, 0.00559475, 0.00563576, 0.00580344,\n",
      "       0.00578229, 0.00604298, 0.00606298]), 'std_score_time': array([0.00059411, 0.00046287, 0.0004457 , 0.00050746, 0.00038782,\n",
      "       0.00044063, 0.00051464, 0.00049472, 0.00020382, 0.0004534 ,\n",
      "       0.00047327, 0.00046791, 0.0003773 , 0.0001862 , 0.00045398,\n",
      "       0.00068368, 0.00078429, 0.00047018, 0.0004051 , 0.00050844,\n",
      "       0.000525  , 0.00099915, 0.00043934, 0.00042269, 0.00048119,\n",
      "       0.00041977, 0.00044245, 0.00034588]), 'param_classifier__n_neighbors': masked_array(data=[3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "                   18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'classifier__n_neighbors': 3}, {'classifier__n_neighbors': 4}, {'classifier__n_neighbors': 5}, {'classifier__n_neighbors': 6}, {'classifier__n_neighbors': 7}, {'classifier__n_neighbors': 8}, {'classifier__n_neighbors': 9}, {'classifier__n_neighbors': 10}, {'classifier__n_neighbors': 11}, {'classifier__n_neighbors': 12}, {'classifier__n_neighbors': 13}, {'classifier__n_neighbors': 14}, {'classifier__n_neighbors': 15}, {'classifier__n_neighbors': 16}, {'classifier__n_neighbors': 17}, {'classifier__n_neighbors': 18}, {'classifier__n_neighbors': 19}, {'classifier__n_neighbors': 20}, {'classifier__n_neighbors': 21}, {'classifier__n_neighbors': 22}, {'classifier__n_neighbors': 23}, {'classifier__n_neighbors': 24}, {'classifier__n_neighbors': 25}, {'classifier__n_neighbors': 26}, {'classifier__n_neighbors': 27}, {'classifier__n_neighbors': 28}, {'classifier__n_neighbors': 29}, {'classifier__n_neighbors': 30}], 'split0_test_score': array([0.74842767, 0.7672956 , 0.76100629, 0.75471698, 0.74213836,\n",
      "       0.7672956 , 0.74842767, 0.74213836, 0.77358491, 0.75471698,\n",
      "       0.75471698, 0.73584906, 0.74213836, 0.74842767, 0.76100629,\n",
      "       0.74842767, 0.74213836, 0.74213836, 0.74842767, 0.74213836,\n",
      "       0.74213836, 0.73584906, 0.73584906, 0.74213836, 0.74213836,\n",
      "       0.74842767, 0.76100629, 0.74842767]), 'split1_test_score': array([0.72955975, 0.83018868, 0.79245283, 0.8490566 , 0.8427673 ,\n",
      "       0.82389937, 0.81761006, 0.8427673 , 0.8427673 , 0.83018868,\n",
      "       0.83647799, 0.83018868, 0.8490566 , 0.85534591, 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.86163522, 0.8427673 ,\n",
      "       0.85534591, 0.8427673 , 0.85534591, 0.83018868, 0.83647799,\n",
      "       0.83018868, 0.83018868, 0.83018868]), 'split2_test_score': array([0.72327044, 0.7672956 , 0.76100629, 0.79245283, 0.7672956 ,\n",
      "       0.77987421, 0.77987421, 0.7672956 , 0.77987421, 0.78616352,\n",
      "       0.78616352, 0.80503145, 0.79874214, 0.79874214, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.77987421, 0.78616352, 0.81132075,\n",
      "       0.79874214, 0.81132075, 0.81132075, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145]), 'split3_test_score': array([0.73584906, 0.7672956 , 0.77987421, 0.77987421, 0.79874214,\n",
      "       0.79245283, 0.79245283, 0.78616352, 0.79245283, 0.79245283,\n",
      "       0.78616352, 0.78616352, 0.77358491, 0.78616352, 0.77358491,\n",
      "       0.77987421, 0.7672956 , 0.7672956 , 0.77358491, 0.77987421,\n",
      "       0.77987421, 0.78616352, 0.78616352, 0.79874214, 0.79245283,\n",
      "       0.79245283, 0.79245283, 0.79245283]), 'split4_test_score': array([0.74213836, 0.75471698, 0.76100629, 0.76100629, 0.7672956 ,\n",
      "       0.74842767, 0.76100629, 0.74213836, 0.75471698, 0.76100629,\n",
      "       0.76100629, 0.75471698, 0.7672956 , 0.77358491, 0.77358491,\n",
      "       0.7672956 , 0.75471698, 0.7672956 , 0.75471698, 0.76100629,\n",
      "       0.75471698, 0.74842767, 0.74213836, 0.73584906, 0.74213836,\n",
      "       0.72955975, 0.73584906, 0.72955975]), 'split5_test_score': array([0.72955975, 0.77987421, 0.76100629, 0.78616352, 0.78616352,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.76100629, 0.76100629,\n",
      "       0.77358491, 0.7672956 , 0.77358491, 0.77358491, 0.78616352,\n",
      "       0.77987421, 0.77358491, 0.77358491, 0.77987421, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77987421, 0.77987421, 0.77987421,\n",
      "       0.77987421, 0.77987421, 0.77987421]), 'split6_test_score': array([0.80503145, 0.80503145, 0.79874214, 0.79874214, 0.77358491,\n",
      "       0.77987421, 0.77358491, 0.79245283, 0.79245283, 0.79874214,\n",
      "       0.79874214, 0.79245283, 0.80503145, 0.79874214, 0.80503145,\n",
      "       0.78616352, 0.78616352, 0.79245283, 0.79874214, 0.79245283,\n",
      "       0.80503145, 0.79245283, 0.79245283, 0.79245283, 0.78616352,\n",
      "       0.80503145, 0.81132075, 0.79874214]), 'split7_test_score': array([0.79245283, 0.80503145, 0.82389937, 0.79245283, 0.77987421,\n",
      "       0.79874214, 0.79245283, 0.79245283, 0.79245283, 0.79874214,\n",
      "       0.79245283, 0.79874214, 0.77987421, 0.79245283, 0.78616352,\n",
      "       0.79245283, 0.78616352, 0.79245283, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.79245283, 0.79245283, 0.79245283, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352]), 'split8_test_score': array([0.78616352, 0.82389937, 0.81132075, 0.80503145, 0.79874214,\n",
      "       0.79245283, 0.77358491, 0.78616352, 0.77358491, 0.78616352,\n",
      "       0.79874214, 0.79245283, 0.79245283, 0.78616352, 0.77987421,\n",
      "       0.77987421, 0.77987421, 0.77987421, 0.77358491, 0.77987421,\n",
      "       0.78616352, 0.77987421, 0.77358491, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352]), 'split9_test_score': array([0.80379747, 0.84177215, 0.82911392, 0.82911392, 0.82278481,\n",
      "       0.8164557 , 0.81012658, 0.82278481, 0.82278481, 0.82278481,\n",
      "       0.82911392, 0.82911392, 0.82278481, 0.82278481, 0.8164557 ,\n",
      "       0.82911392, 0.8164557 , 0.83544304, 0.82278481, 0.81012658,\n",
      "       0.8164557 , 0.82278481, 0.83544304, 0.83544304, 0.83544304,\n",
      "       0.82911392, 0.83544304, 0.82278481]), 'mean_test_score': array([0.75962503, 0.79424011, 0.78794284, 0.79486108, 0.78793886,\n",
      "       0.78730595, 0.78227052, 0.7847942 , 0.78856779, 0.78919672,\n",
      "       0.79171642, 0.7892007 , 0.79045458, 0.79359924, 0.79170846,\n",
      "       0.78982963, 0.78416129, 0.78794682, 0.78856779, 0.7879309 ,\n",
      "       0.78982167, 0.78856779, 0.79046254, 0.78983361, 0.78920468,\n",
      "       0.7892007 , 0.79234934, 0.78793886]), 'std_test_score': array([0.0314974 , 0.02934391, 0.02576594, 0.02701566, 0.02770924,\n",
      "       0.02140845, 0.02015383, 0.02999353, 0.02565879, 0.02407901,\n",
      "       0.02490768, 0.02856653, 0.02883837, 0.02769632, 0.02431167,\n",
      "       0.02757551, 0.02883391, 0.03052681, 0.03147442, 0.02688467,\n",
      "       0.03034649, 0.03058205, 0.03522697, 0.03055264, 0.03029698,\n",
      "       0.03018244, 0.02866439, 0.02910177]), 'rank_test_score': array([28,  2, 20,  1, 21, 24, 27, 25, 16, 15,  5, 13,  8,  3,  6, 10, 26,\n",
      "       19, 16, 23, 11, 16,  7,  9, 12, 14,  4, 21])}\n",
      "Resultados para OverSampler:\n",
      "{'mean_fit_time': array([0.00269916, 0.00219986, 0.00250573, 0.00253198, 0.00280163,\n",
      "       0.00261295, 0.0025003 , 0.00239971, 0.00269659, 0.0024986 ,\n",
      "       0.00219979, 0.00219965, 0.00219834, 0.00239825, 0.0023993 ,\n",
      "       0.00281518, 0.00241263, 0.00240571, 0.00234084, 0.00251675,\n",
      "       0.0024502 , 0.00252199, 0.00247188, 0.00230281, 0.00207248,\n",
      "       0.00267065, 0.00253482, 0.00255599]), 'std_fit_time': array([0.00045802, 0.00039919, 0.00049287, 0.00047813, 0.00039905,\n",
      "       0.00055065, 0.00049997, 0.00049001, 0.00045568, 0.00049851,\n",
      "       0.00039958, 0.00039924, 0.0003975 , 0.00048823, 0.00048888,\n",
      "       0.00100142, 0.00043721, 0.0004363 , 0.00045716, 0.0004862 ,\n",
      "       0.00056573, 0.00044916, 0.00040312, 0.00040071, 0.00030898,\n",
      "       0.00058029, 0.00047608, 0.00072665]), 'mean_score_time': array([0.00460038, 0.00469861, 0.00486798, 0.00480027, 0.00466261,\n",
      "       0.00519485, 0.00497513, 0.00487697, 0.00520401, 0.00520079,\n",
      "       0.00509861, 0.00519898, 0.00530028, 0.00550056, 0.00529931,\n",
      "       0.00606093, 0.00562105, 0.00531857, 0.00553393, 0.00537179,\n",
      "       0.00589316, 0.00560429, 0.00564516, 0.00586212, 0.00605407,\n",
      "       0.00600452, 0.00631902, 0.00627136]), 'std_score_time': array([0.00048879, 0.00045749, 0.00101425, 0.00060156, 0.00044641,\n",
      "       0.0007075 , 0.00013391, 0.00054096, 0.00039816, 0.00039916,\n",
      "       0.00030024, 0.00040029, 0.00045977, 0.00049939, 0.00045781,\n",
      "       0.00050169, 0.00060108, 0.00041492, 0.00050882, 0.00038914,\n",
      "       0.00030135, 0.00056555, 0.00042234, 0.00040207, 0.00045464,\n",
      "       0.00041415, 0.00045751, 0.00042101]), 'param_classifier__n_neighbors': masked_array(data=[3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "                   18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'classifier__n_neighbors': 3}, {'classifier__n_neighbors': 4}, {'classifier__n_neighbors': 5}, {'classifier__n_neighbors': 6}, {'classifier__n_neighbors': 7}, {'classifier__n_neighbors': 8}, {'classifier__n_neighbors': 9}, {'classifier__n_neighbors': 10}, {'classifier__n_neighbors': 11}, {'classifier__n_neighbors': 12}, {'classifier__n_neighbors': 13}, {'classifier__n_neighbors': 14}, {'classifier__n_neighbors': 15}, {'classifier__n_neighbors': 16}, {'classifier__n_neighbors': 17}, {'classifier__n_neighbors': 18}, {'classifier__n_neighbors': 19}, {'classifier__n_neighbors': 20}, {'classifier__n_neighbors': 21}, {'classifier__n_neighbors': 22}, {'classifier__n_neighbors': 23}, {'classifier__n_neighbors': 24}, {'classifier__n_neighbors': 25}, {'classifier__n_neighbors': 26}, {'classifier__n_neighbors': 27}, {'classifier__n_neighbors': 28}, {'classifier__n_neighbors': 29}, {'classifier__n_neighbors': 30}], 'split0_test_score': array([0.74213836, 0.74213836, 0.6918239 , 0.76100629, 0.72955975,\n",
      "       0.74842767, 0.74213836, 0.71698113, 0.72327044, 0.76100629,\n",
      "       0.70440252, 0.74213836, 0.71698113, 0.74213836, 0.75471698,\n",
      "       0.74213836, 0.72327044, 0.71698113, 0.72955975, 0.74842767,\n",
      "       0.71069182, 0.72327044, 0.74213836, 0.74213836, 0.75471698,\n",
      "       0.74842767, 0.74842767, 0.74213836]), 'split1_test_score': array([0.71069182, 0.75471698, 0.6918239 , 0.71698113, 0.71698113,\n",
      "       0.74842767, 0.71069182, 0.76100629, 0.77358491, 0.80503145,\n",
      "       0.74842767, 0.81132075, 0.76100629, 0.8427673 , 0.79874214,\n",
      "       0.80503145, 0.80503145, 0.83647799, 0.85534591, 0.83647799,\n",
      "       0.79874214, 0.8427673 , 0.85534591, 0.85534591, 0.85534591,\n",
      "       0.8490566 , 0.85534591, 0.86163522]), 'split2_test_score': array([0.72955975, 0.71698113, 0.71069182, 0.72327044, 0.69811321,\n",
      "       0.71698113, 0.73584906, 0.74842767, 0.73584906, 0.75471698,\n",
      "       0.74213836, 0.77358491, 0.73584906, 0.75471698, 0.74213836,\n",
      "       0.7672956 , 0.77987421, 0.73584906, 0.75471698, 0.75471698,\n",
      "       0.74842767, 0.74842767, 0.74213836, 0.74842767, 0.74213836,\n",
      "       0.73584906, 0.76100629, 0.74842767]), 'split3_test_score': array([0.77987421, 0.76100629, 0.71069182, 0.77987421, 0.77358491,\n",
      "       0.78616352, 0.76100629, 0.77987421, 0.74842767, 0.79245283,\n",
      "       0.77358491, 0.75471698, 0.71698113, 0.77358491, 0.71069182,\n",
      "       0.71069182, 0.75471698, 0.76100629, 0.72327044, 0.76100629,\n",
      "       0.7672956 , 0.74842767, 0.76100629, 0.76100629, 0.7672956 ,\n",
      "       0.74842767, 0.7672956 , 0.77358491]), 'split4_test_score': array([0.68553459, 0.74842767, 0.74842767, 0.74842767, 0.72955975,\n",
      "       0.76100629, 0.75471698, 0.7672956 , 0.72955975, 0.76100629,\n",
      "       0.73584906, 0.74842767, 0.71069182, 0.74842767, 0.74842767,\n",
      "       0.72955975, 0.71069182, 0.72955975, 0.70440252, 0.72327044,\n",
      "       0.72327044, 0.71698113, 0.74842767, 0.72955975, 0.70440252,\n",
      "       0.71069182, 0.72955975, 0.72327044]), 'split5_test_score': array([0.67295597, 0.74842767, 0.71069182, 0.7672956 , 0.71698113,\n",
      "       0.74213836, 0.71069182, 0.7672956 , 0.70440252, 0.77987421,\n",
      "       0.74842767, 0.74213836, 0.76100629, 0.75471698, 0.74842767,\n",
      "       0.73584906, 0.76100629, 0.76100629, 0.74213836, 0.76100629,\n",
      "       0.74213836, 0.7672956 , 0.77987421, 0.76100629, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.77987421]), 'split6_test_score': array([0.77358491, 0.77987421, 0.79874214, 0.81132075, 0.76100629,\n",
      "       0.75471698, 0.74213836, 0.7672956 , 0.74842767, 0.74842767,\n",
      "       0.75471698, 0.74842767, 0.73584906, 0.76100629, 0.76100629,\n",
      "       0.78616352, 0.77358491, 0.79874214, 0.77358491, 0.75471698,\n",
      "       0.77358491, 0.74213836, 0.77358491, 0.77987421, 0.7672956 ,\n",
      "       0.79874214, 0.79245283, 0.79245283]), 'split7_test_score': array([0.72327044, 0.7672956 , 0.76100629, 0.74213836, 0.75471698,\n",
      "       0.78616352, 0.74842767, 0.77358491, 0.78616352, 0.77987421,\n",
      "       0.7672956 , 0.7672956 , 0.77358491, 0.77358491, 0.80503145,\n",
      "       0.7672956 , 0.76100629, 0.76100629, 0.7672956 , 0.7672956 ,\n",
      "       0.77987421, 0.74213836, 0.7672956 , 0.76100629, 0.7672956 ,\n",
      "       0.7672956 , 0.79245283, 0.75471698]), 'split8_test_score': array([0.74213836, 0.75471698, 0.75471698, 0.79874214, 0.79245283,\n",
      "       0.79245283, 0.80503145, 0.76100629, 0.7672956 , 0.76100629,\n",
      "       0.77987421, 0.76100629, 0.76100629, 0.75471698, 0.76100629,\n",
      "       0.7672956 , 0.74842767, 0.77358491, 0.76100629, 0.77358491,\n",
      "       0.75471698, 0.7672956 , 0.74213836, 0.7672956 , 0.76100629,\n",
      "       0.77987421, 0.78616352, 0.77987421]), 'split9_test_score': array([0.78481013, 0.81012658, 0.79746835, 0.78481013, 0.7721519 ,\n",
      "       0.76582278, 0.79746835, 0.79113924, 0.79113924, 0.79746835,\n",
      "       0.79113924, 0.76582278, 0.79113924, 0.80379747, 0.78481013,\n",
      "       0.80379747, 0.75949367, 0.79113924, 0.77848101, 0.80379747,\n",
      "       0.77848101, 0.78481013, 0.77848101, 0.76582278, 0.7721519 ,\n",
      "       0.7721519 , 0.79113924, 0.79113924]), 'mean_test_score': array([0.73445586, 0.75837115, 0.73760847, 0.76338667, 0.74451079,\n",
      "       0.76023008, 0.75081602, 0.76339065, 0.75081204, 0.77408646,\n",
      "       0.75458562, 0.76148794, 0.74640952, 0.77094578, 0.76149988,\n",
      "       0.76151182, 0.75771037, 0.76653531, 0.75898018, 0.76843006,\n",
      "       0.75772232, 0.75835523, 0.76904307, 0.76714832, 0.76778123,\n",
      "       0.76966802, 0.78100072, 0.77471141]), 'std_test_score': array([0.03624478, 0.02329954, 0.03826711, 0.02955923, 0.02898208,\n",
      "       0.02218568, 0.02972378, 0.01892212, 0.02695483, 0.01858883,\n",
      "       0.02366092, 0.01954021, 0.02570857, 0.02911587, 0.02677674,\n",
      "       0.03004598, 0.02549394, 0.03382377, 0.0392103 , 0.0297238 ,\n",
      "       0.02585461, 0.03413351, 0.03215498, 0.03231807, 0.03593923,\n",
      "       0.03613881, 0.03200061, 0.03604545]), 'rank_test_score': array([28, 18, 27, 12, 26, 16, 23, 11, 24,  3, 22, 15, 25,  4, 14, 13, 21,\n",
      "       10, 17,  7, 20, 19,  6,  9,  8,  5,  1,  2])}\n",
      "Resultados para UnderSampler:\n",
      "{'mean_fit_time': array([0.00190196, 0.0019516 , 0.00180044, 0.00190027, 0.00180063,\n",
      "       0.00207837, 0.00220096, 0.00213039, 0.00200071, 0.0018007 ,\n",
      "       0.00181603, 0.00218976, 0.00169957, 0.00199795, 0.00185215,\n",
      "       0.00219703, 0.00220053, 0.00190721, 0.0019604 , 0.00203011,\n",
      "       0.00196505, 0.00214062, 0.00190094, 0.00182688, 0.00194857,\n",
      "       0.00175071, 0.00169985, 0.00195167]), 'std_fit_time': array([3.01325304e-04, 1.46772042e-04, 4.00258332e-04, 3.00035531e-04,\n",
      "       4.00353926e-04, 2.29258775e-04, 4.00128210e-04, 3.02862329e-04,\n",
      "       1.00701867e-06, 4.00508613e-04, 4.49012654e-04, 3.93434193e-04,\n",
      "       4.57665329e-04, 7.34468546e-06, 3.16830130e-04, 3.95344937e-04,\n",
      "       3.99035415e-04, 3.03278689e-04, 3.65991052e-04, 8.85958083e-05,\n",
      "       3.71562501e-04, 5.68038909e-04, 5.38549674e-04, 4.58372839e-04,\n",
      "       6.30274505e-04, 4.01885870e-04, 4.59774489e-04, 4.62864437e-04]), 'mean_score_time': array([0.00425065, 0.00435259, 0.00493634, 0.0043987 , 0.00449798,\n",
      "       0.00499885, 0.0051986 , 0.00495956, 0.004898  , 0.00509846,\n",
      "       0.00509882, 0.00520017, 0.00517278, 0.00530193, 0.00555472,\n",
      "       0.00529978, 0.00555756, 0.00536845, 0.00565784, 0.00577202,\n",
      "       0.00548038, 0.00595262, 0.00611506, 0.00579042, 0.00558655,\n",
      "       0.00525353, 0.00568905, 0.00556138]), 'std_score_time': array([4.05457712e-04, 4.50823591e-04, 7.10784185e-04, 4.90271473e-04,\n",
      "       5.00273966e-04, 4.23426295e-06, 4.00603796e-04, 1.16750560e-04,\n",
      "       3.00146494e-04, 3.00368849e-04, 5.36069031e-04, 3.99003624e-04,\n",
      "       4.22465704e-04, 4.61489378e-04, 6.57398192e-04, 4.01151803e-04,\n",
      "       6.44709491e-04, 6.29673582e-04, 4.46959439e-04, 3.92162374e-04,\n",
      "       4.51818307e-04, 1.02133825e-04, 5.87245484e-04, 5.37766123e-04,\n",
      "       4.45235127e-04, 4.97696114e-04, 4.51477686e-04, 4.54501865e-04]), 'param_classifier__n_neighbors': masked_array(data=[3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "                   18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'classifier__n_neighbors': 3}, {'classifier__n_neighbors': 4}, {'classifier__n_neighbors': 5}, {'classifier__n_neighbors': 6}, {'classifier__n_neighbors': 7}, {'classifier__n_neighbors': 8}, {'classifier__n_neighbors': 9}, {'classifier__n_neighbors': 10}, {'classifier__n_neighbors': 11}, {'classifier__n_neighbors': 12}, {'classifier__n_neighbors': 13}, {'classifier__n_neighbors': 14}, {'classifier__n_neighbors': 15}, {'classifier__n_neighbors': 16}, {'classifier__n_neighbors': 17}, {'classifier__n_neighbors': 18}, {'classifier__n_neighbors': 19}, {'classifier__n_neighbors': 20}, {'classifier__n_neighbors': 21}, {'classifier__n_neighbors': 22}, {'classifier__n_neighbors': 23}, {'classifier__n_neighbors': 24}, {'classifier__n_neighbors': 25}, {'classifier__n_neighbors': 26}, {'classifier__n_neighbors': 27}, {'classifier__n_neighbors': 28}, {'classifier__n_neighbors': 29}, {'classifier__n_neighbors': 30}], 'split0_test_score': array([0.71069182, 0.78616352, 0.74842767, 0.76100629, 0.71069182,\n",
      "       0.71698113, 0.75471698, 0.74842767, 0.74213836, 0.74842767,\n",
      "       0.72955975, 0.71698113, 0.72327044, 0.76100629, 0.74842767,\n",
      "       0.74213836, 0.73584906, 0.72327044, 0.76100629, 0.76100629,\n",
      "       0.78616352, 0.75471698, 0.75471698, 0.75471698, 0.74213836,\n",
      "       0.74842767, 0.71069182, 0.75471698]), 'split1_test_score': array([0.72327044, 0.79874214, 0.79874214, 0.80503145, 0.77987421,\n",
      "       0.83018868, 0.81132075, 0.8427673 , 0.81761006, 0.83018868,\n",
      "       0.8427673 , 0.8427673 , 0.83647799, 0.8490566 , 0.86792453,\n",
      "       0.8490566 , 0.85534591, 0.8427673 , 0.8490566 , 0.83647799,\n",
      "       0.8490566 , 0.8427673 , 0.88050314, 0.88050314, 0.8427673 ,\n",
      "       0.86792453, 0.88050314, 0.86163522]), 'split2_test_score': array([0.70440252, 0.74213836, 0.73584906, 0.77987421, 0.71698113,\n",
      "       0.76100629, 0.77358491, 0.76100629, 0.73584906, 0.76100629,\n",
      "       0.74842767, 0.76100629, 0.75471698, 0.7672956 , 0.7672956 ,\n",
      "       0.72955975, 0.72327044, 0.73584906, 0.73584906, 0.77358491,\n",
      "       0.73584906, 0.75471698, 0.73584906, 0.7672956 , 0.75471698,\n",
      "       0.76100629, 0.76100629, 0.77987421]), 'split3_test_score': array([0.74842767, 0.77987421, 0.75471698, 0.7672956 , 0.77358491,\n",
      "       0.6918239 , 0.71698113, 0.74842767, 0.72327044, 0.76100629,\n",
      "       0.7672956 , 0.7672956 , 0.74842767, 0.76100629, 0.77358491,\n",
      "       0.77987421, 0.7672956 , 0.77358491, 0.7672956 , 0.76100629,\n",
      "       0.77358491, 0.75471698, 0.74842767, 0.76100629, 0.74842767,\n",
      "       0.76100629, 0.75471698, 0.75471698]), 'split4_test_score': array([0.72955975, 0.72955975, 0.75471698, 0.75471698, 0.76100629,\n",
      "       0.74842767, 0.70440252, 0.75471698, 0.71698113, 0.74842767,\n",
      "       0.73584906, 0.74842767, 0.72327044, 0.74842767, 0.72955975,\n",
      "       0.72955975, 0.72327044, 0.74213836, 0.72955975, 0.74842767,\n",
      "       0.73584906, 0.74213836, 0.71698113, 0.73584906, 0.7672956 ,\n",
      "       0.74842767, 0.75471698, 0.74213836]), 'split5_test_score': array([0.63522013, 0.79245283, 0.74842767, 0.76100629, 0.74842767,\n",
      "       0.72955975, 0.72327044, 0.7672956 , 0.7672956 , 0.7672956 ,\n",
      "       0.7672956 , 0.76100629, 0.77358491, 0.78616352, 0.74842767,\n",
      "       0.78616352, 0.77987421, 0.7672956 , 0.79245283, 0.7672956 ,\n",
      "       0.78616352, 0.79245283, 0.78616352, 0.79874214, 0.76100629,\n",
      "       0.77358491, 0.77358491, 0.77987421]), 'split6_test_score': array([0.77358491, 0.77358491, 0.71069182, 0.78616352, 0.76100629,\n",
      "       0.78616352, 0.74842767, 0.75471698, 0.77987421, 0.79874214,\n",
      "       0.7672956 , 0.80503145, 0.77987421, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.77987421, 0.77358491, 0.77358491, 0.81132075,\n",
      "       0.79874214, 0.81761006, 0.80503145, 0.78616352, 0.80503145,\n",
      "       0.79245283, 0.78616352, 0.81132075]), 'split7_test_score': array([0.7672956 , 0.77358491, 0.79245283, 0.77987421, 0.74842767,\n",
      "       0.79245283, 0.76100629, 0.74213836, 0.74213836, 0.78616352,\n",
      "       0.75471698, 0.75471698, 0.77358491, 0.75471698, 0.71698113,\n",
      "       0.75471698, 0.74213836, 0.73584906, 0.75471698, 0.79245283,\n",
      "       0.72327044, 0.72955975, 0.77358491, 0.77358491, 0.79245283,\n",
      "       0.77987421, 0.75471698, 0.77358491]), 'split8_test_score': array([0.78616352, 0.80503145, 0.74842767, 0.77358491, 0.74213836,\n",
      "       0.77358491, 0.72955975, 0.75471698, 0.7672956 , 0.78616352,\n",
      "       0.76100629, 0.78616352, 0.77358491, 0.76100629, 0.77987421,\n",
      "       0.76100629, 0.78616352, 0.7672956 , 0.76100629, 0.78616352,\n",
      "       0.76100629, 0.78616352, 0.7672956 , 0.77358491, 0.74842767,\n",
      "       0.76100629, 0.75471698, 0.75471698]), 'split9_test_score': array([0.78481013, 0.82278481, 0.77848101, 0.80379747, 0.79113924,\n",
      "       0.81012658, 0.77848101, 0.79113924, 0.79746835, 0.8164557 ,\n",
      "       0.79746835, 0.77848101, 0.79746835, 0.79746835, 0.76582278,\n",
      "       0.79113924, 0.77848101, 0.80379747, 0.77848101, 0.77848101,\n",
      "       0.79113924, 0.78481013, 0.76582278, 0.77848101, 0.7721519 ,\n",
      "       0.77848101, 0.81012658, 0.7721519 ]), 'mean_test_score': array([0.73634265, 0.78039169, 0.75709338, 0.77723509, 0.75332776,\n",
      "       0.76403153, 0.75017515, 0.76653531, 0.75899212, 0.78038771,\n",
      "       0.76716822, 0.77218772, 0.76842608, 0.77723111, 0.76840618,\n",
      "       0.77093782, 0.76715628, 0.76654327, 0.77030093, 0.78162169,\n",
      "       0.77408248, 0.77596529, 0.77343762, 0.78099276, 0.7734416 ,\n",
      "       0.77721917, 0.77409442, 0.77847305]), 'std_test_score': array([0.04409436, 0.02657057, 0.0250666 , 0.01648567, 0.02444344,\n",
      "       0.04093776, 0.03094326, 0.02849179, 0.03104046, 0.02673988,\n",
      "       0.03094005, 0.03238307, 0.03217352, 0.02820106, 0.0391629 ,\n",
      "       0.03416079, 0.03748122, 0.0341331 , 0.0316896 , 0.02502142,\n",
      "       0.03533941, 0.03362005, 0.04277274, 0.03698053, 0.02990212,\n",
      "       0.0330573 , 0.04296532, 0.03328056]), 'rank_test_score': array([28,  3, 25,  6, 26, 23, 27, 22, 24,  4, 19, 14, 17,  7, 18, 15, 20,\n",
      "       21, 16,  1, 11,  9, 13,  2, 12,  8, 10,  5])}\n",
      "Resultados para SMOTEENN:\n",
      "{'mean_fit_time': array([0.01789968, 0.01751909, 0.01753519, 0.01767385, 0.01810811,\n",
      "       0.01854036, 0.01789708, 0.01790316, 0.01784656, 0.0180409 ,\n",
      "       0.01788647, 0.01777437, 0.01827152, 0.01780691, 0.01814268,\n",
      "       0.01809921, 0.01810024, 0.01809866, 0.01830032, 0.01809983,\n",
      "       0.01816185, 0.01787474, 0.01803906, 0.01782393, 0.01786697,\n",
      "       0.01769507, 0.0178746 , 0.01814322]), 'std_fit_time': array([0.00040726, 0.00033419, 0.00043098, 0.00045123, 0.00045476,\n",
      "       0.00195356, 0.00023456, 0.00058251, 0.00036593, 0.00057232,\n",
      "       0.00048787, 0.00049433, 0.00037473, 0.00053922, 0.00040032,\n",
      "       0.00029647, 0.00030018, 0.00030058, 0.00045871, 0.00030071,\n",
      "       0.00061584, 0.00050057, 0.00036996, 0.00036675, 0.00021935,\n",
      "       0.00038458, 0.00034787, 0.00036642]), 'mean_score_time': array([0.004124  , 0.00445962, 0.00456669, 0.0043088 , 0.00472872,\n",
      "       0.00477831, 0.00485246, 0.00475769, 0.00485065, 0.00504887,\n",
      "       0.00485325, 0.00510359, 0.00500631, 0.00517912, 0.00510228,\n",
      "       0.00549982, 0.00529835, 0.00539997, 0.00539851, 0.00589941,\n",
      "       0.00548556, 0.0058022 , 0.00538104, 0.00590718, 0.00553412,\n",
      "       0.00576181, 0.00563178, 0.00588334]), 'std_score_time': array([0.00046336, 0.00046616, 0.00046745, 0.00039409, 0.0003928 ,\n",
      "       0.00055588, 0.00045208, 0.00039987, 0.00046226, 0.00015475,\n",
      "       0.00032289, 0.00030743, 0.00022078, 0.00039408, 0.00029885,\n",
      "       0.00050176, 0.00045864, 0.00049236, 0.00049022, 0.00030025,\n",
      "       0.00045602, 0.00032149, 0.0004398 , 0.00036877, 0.00039021,\n",
      "       0.00028728, 0.00047014, 0.00017351]), 'param_classifier__n_neighbors': masked_array(data=[3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "                   18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'classifier__n_neighbors': 3}, {'classifier__n_neighbors': 4}, {'classifier__n_neighbors': 5}, {'classifier__n_neighbors': 6}, {'classifier__n_neighbors': 7}, {'classifier__n_neighbors': 8}, {'classifier__n_neighbors': 9}, {'classifier__n_neighbors': 10}, {'classifier__n_neighbors': 11}, {'classifier__n_neighbors': 12}, {'classifier__n_neighbors': 13}, {'classifier__n_neighbors': 14}, {'classifier__n_neighbors': 15}, {'classifier__n_neighbors': 16}, {'classifier__n_neighbors': 17}, {'classifier__n_neighbors': 18}, {'classifier__n_neighbors': 19}, {'classifier__n_neighbors': 20}, {'classifier__n_neighbors': 21}, {'classifier__n_neighbors': 22}, {'classifier__n_neighbors': 23}, {'classifier__n_neighbors': 24}, {'classifier__n_neighbors': 25}, {'classifier__n_neighbors': 26}, {'classifier__n_neighbors': 27}, {'classifier__n_neighbors': 28}, {'classifier__n_neighbors': 29}, {'classifier__n_neighbors': 30}], 'split0_test_score': array([0.71698113, 0.72955975, 0.72955975, 0.74842767, 0.73584906,\n",
      "       0.74842767, 0.72327044, 0.67295597, 0.69811321, 0.71069182,\n",
      "       0.77987421, 0.68553459, 0.74213836, 0.72327044, 0.75471698,\n",
      "       0.74213836, 0.70440252, 0.76100629, 0.72327044, 0.72327044,\n",
      "       0.73584906, 0.75471698, 0.73584906, 0.72955975, 0.75471698,\n",
      "       0.71698113, 0.74213836, 0.73584906]), 'split1_test_score': array([0.77358491, 0.81761006, 0.81761006, 0.81761006, 0.80503145,\n",
      "       0.82389937, 0.83018868, 0.85534591, 0.81761006, 0.82389937,\n",
      "       0.82389937, 0.83018868, 0.81761006, 0.8490566 , 0.83018868,\n",
      "       0.81761006, 0.81761006, 0.85534591, 0.8427673 , 0.86163522,\n",
      "       0.82389937, 0.86792453, 0.83018868, 0.86792453, 0.8427673 ,\n",
      "       0.8490566 , 0.86163522, 0.87421384]), 'split2_test_score': array([0.72327044, 0.74842767, 0.7672956 , 0.74842767, 0.74213836,\n",
      "       0.73584906, 0.72955975, 0.73584906, 0.76100629, 0.77358491,\n",
      "       0.74213836, 0.75471698, 0.72327044, 0.72327044, 0.74842767,\n",
      "       0.70440252, 0.72327044, 0.74213836, 0.71069182, 0.72327044,\n",
      "       0.72955975, 0.73584906, 0.75471698, 0.74213836, 0.73584906,\n",
      "       0.76100629, 0.75471698, 0.70440252]), 'split3_test_score': array([0.76100629, 0.74213836, 0.7672956 , 0.75471698, 0.73584906,\n",
      "       0.7672956 , 0.72327044, 0.7672956 , 0.74842767, 0.76100629,\n",
      "       0.73584906, 0.75471698, 0.74842767, 0.74213836, 0.75471698,\n",
      "       0.74842767, 0.74213836, 0.74842767, 0.72327044, 0.72955975,\n",
      "       0.7672956 , 0.73584906, 0.74842767, 0.7672956 , 0.7672956 ,\n",
      "       0.75471698, 0.74213836, 0.7672956 ]), 'split4_test_score': array([0.72327044, 0.71069182, 0.69811321, 0.71698113, 0.72955975,\n",
      "       0.72327044, 0.74213836, 0.74213836, 0.74213836, 0.73584906,\n",
      "       0.71698113, 0.72327044, 0.74213836, 0.73584906, 0.71698113,\n",
      "       0.72955975, 0.74213836, 0.73584906, 0.72327044, 0.72955975,\n",
      "       0.71069182, 0.75471698, 0.71698113, 0.75471698, 0.72955975,\n",
      "       0.72955975, 0.73584906, 0.73584906]), 'split5_test_score': array([0.71698113, 0.73584906, 0.74213836, 0.77987421, 0.75471698,\n",
      "       0.72955975, 0.75471698, 0.76100629, 0.77358491, 0.78616352,\n",
      "       0.76100629, 0.79245283, 0.7672956 , 0.76100629, 0.79245283,\n",
      "       0.79874214, 0.7672956 , 0.7672956 , 0.79874214, 0.76100629,\n",
      "       0.77987421, 0.79245283, 0.75471698, 0.79245283, 0.75471698,\n",
      "       0.74842767, 0.75471698, 0.77987421]), 'split6_test_score': array([0.77358491, 0.77358491, 0.72327044, 0.77987421, 0.79874214,\n",
      "       0.78616352, 0.74842767, 0.78616352, 0.75471698, 0.78616352,\n",
      "       0.75471698, 0.78616352, 0.79874214, 0.77987421, 0.75471698,\n",
      "       0.77987421, 0.75471698, 0.77358491, 0.77987421, 0.77987421,\n",
      "       0.76100629, 0.79245283, 0.77987421, 0.79874214, 0.77987421,\n",
      "       0.77987421, 0.7672956 , 0.78616352]), 'split7_test_score': array([0.72955975, 0.71069182, 0.71069182, 0.76100629, 0.77987421,\n",
      "       0.78616352, 0.76100629, 0.77987421, 0.7672956 , 0.7672956 ,\n",
      "       0.70440252, 0.78616352, 0.70440252, 0.79245283, 0.75471698,\n",
      "       0.7672956 , 0.72327044, 0.77358491, 0.74842767, 0.72955975,\n",
      "       0.75471698, 0.74842767, 0.75471698, 0.74213836, 0.72955975,\n",
      "       0.72955975, 0.73584906, 0.74213836]), 'split8_test_score': array([0.73584906, 0.76100629, 0.75471698, 0.7672956 , 0.78616352,\n",
      "       0.77987421, 0.74842767, 0.76100629, 0.74213836, 0.72327044,\n",
      "       0.7672956 , 0.78616352, 0.75471698, 0.7672956 , 0.79245283,\n",
      "       0.75471698, 0.79245283, 0.78616352, 0.74213836, 0.74842767,\n",
      "       0.75471698, 0.7672956 , 0.75471698, 0.77358491, 0.77358491,\n",
      "       0.75471698, 0.73584906, 0.74842767]), 'split9_test_score': array([0.75949367, 0.75316456, 0.75949367, 0.7721519 , 0.75949367,\n",
      "       0.75949367, 0.76582278, 0.74683544, 0.75316456, 0.78481013,\n",
      "       0.7721519 , 0.75949367, 0.7721519 , 0.77848101, 0.7721519 ,\n",
      "       0.77848101, 0.77848101, 0.79113924, 0.74050633, 0.75949367,\n",
      "       0.75949367, 0.74683544, 0.77848101, 0.79113924, 0.79113924,\n",
      "       0.77848101, 0.7721519 , 0.77848101]), 'mean_test_score': array([0.74135817, 0.74827243, 0.74701855, 0.76463657, 0.76274182,\n",
      "       0.76399968, 0.75268291, 0.76084707, 0.7558196 , 0.76527347,\n",
      "       0.75583154, 0.76588647, 0.7570894 , 0.76526948, 0.7671523 ,\n",
      "       0.76212483, 0.75457766, 0.77345355, 0.75329592, 0.75456572,\n",
      "       0.75771037, 0.7696521 , 0.76086697, 0.77596927, 0.76590638,\n",
      "       0.76023804, 0.76023406, 0.76526948]), 'std_test_score': array([0.02191902, 0.03000212, 0.03259499, 0.02498437, 0.02640733,\n",
      "       0.02955256, 0.0294372 , 0.04344043, 0.02838935, 0.0322367 ,\n",
      "       0.03221518, 0.03825827, 0.0319    , 0.03619087, 0.02960595,\n",
      "       0.03172229, 0.0330576 , 0.03224067, 0.03950741, 0.04005312,\n",
      "       0.02911559, 0.03795425, 0.02887026, 0.03801538, 0.03255194,\n",
      "       0.0354424 , 0.03601911, 0.04353388]), 'rank_test_score': array([28, 26, 27, 10, 12, 11, 25, 15, 21,  7, 20,  6, 19,  8,  4, 13, 22,\n",
      "        2, 24, 23, 18,  3, 14,  1,  5, 16, 17,  8])}\n",
      "\n",
      "Resultados para Normal:\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('classifier', KNeighborsClassifier())]),\n",
      "             param_grid={'classifier__n_neighbors': range(3, 31)},\n",
      "             scoring='accuracy')\n",
      "Accuracy: 0.7889447236180904\n",
      "Precision: 0.8275862068965517\n",
      "Recall: 0.5106382978723404\n",
      "F1 Score: 0.631578947368421\n",
      "ROC AUC Score: 0.7261362695587382\n",
      "Predictions: [0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 1 0 1 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\n",
      "Resultados para OverSampler:\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('sampler', RandomOverSampler()),\n",
      "                                       ('classifier', KNeighborsClassifier())]),\n",
      "             param_grid={'classifier__n_neighbors': range(3, 31)},\n",
      "             scoring='accuracy')\n",
      "Accuracy: 0.7562814070351759\n",
      "Precision: 0.6746031746031746\n",
      "Recall: 0.6028368794326241\n",
      "F1 Score: 0.6367041198501872\n",
      "ROC AUC Score: 0.7216519027513314\n",
      "Predictions: [0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 1 0 1 0 1 0 0 1 1\n",
      " 0 0 0 1 1 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0\n",
      " 0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 1 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0\n",
      " 1 0 0 1 0 1 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 1 1\n",
      " 0 0 0 1 1 1 1 0 1 1 0 0 1 0 0 1 1 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 1\n",
      " 0 0 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\n",
      "Resultados para UnderSampler:\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('sampler', RandomUnderSampler()),\n",
      "                                       ('classifier', KNeighborsClassifier())]),\n",
      "             param_grid={'classifier__n_neighbors': range(3, 31)},\n",
      "             scoring='accuracy')\n",
      "Accuracy: 0.7487437185929648\n",
      "Precision: 0.6589147286821705\n",
      "Recall: 0.6028368794326241\n",
      "F1 Score: 0.6296296296296295\n",
      "ROC AUC Score: 0.7158153268758449\n",
      "Predictions: [0 1 1 0 1 1 1 0 0 1 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 1 1\n",
      " 0 0 0 1 1 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 1 1 1 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 1 0 1 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 1 1\n",
      " 0 0 0 1 1 1 1 0 1 1 0 0 1 0 0 1 1 0 1 0 1 0 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\n",
      "Resultados para SMOTEENN:\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('sampler', SMOTEENN()),\n",
      "                                       ('classifier', KNeighborsClassifier())]),\n",
      "             param_grid={'classifier__n_neighbors': range(3, 31)},\n",
      "             scoring='accuracy')\n",
      "Accuracy: 0.7487437185929648\n",
      "Precision: 0.6722689075630253\n",
      "Recall: 0.5673758865248227\n",
      "F1 Score: 0.6153846153846154\n",
      "ROC AUC Score: 0.7078124568810883\n",
      "Predictions: [0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1\n",
      " 1 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 1\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 1 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0\n",
      " 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 1 1 1 0 0 0 1 0 0 0 0 1 1\n",
      " 0 0 0 1 1 1 1 0 1 1 0 0 1 0 0 1 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "k_neighbors = KNeighborsClassifier()\n",
    "grid_parametros = {'classifier__n_neighbors': range(3, 31)}\n",
    "\n",
    "oversampler = RandomOverSampler()\n",
    "undersampler = RandomUnderSampler()\n",
    "combinado = SMOTEENN()\n",
    "\n",
    "\n",
    "normal_pipeline = Pipeline([('classifier', k_neighbors)])\n",
    "over_pipeline = ImbPipeline([('sampler', oversampler), ('classifier', k_neighbors)])\n",
    "under_pipeline = ImbPipeline([('sampler', undersampler), ('classifier', k_neighbors)])\n",
    "combinado_pipeline = ImbPipeline([('sampler', combinado), ('classifier', k_neighbors)])\n",
    "\n",
    "\n",
    "resultados = {}\n",
    "\n",
    "\n",
    "for nombre, pipeline in [('Normal', normal_pipeline), ('OverSampler', over_pipeline), ('UnderSampler', under_pipeline), ('SMOTEENN', combinado_pipeline)]:\n",
    "    grid_search = GridSearchCV(pipeline, grid_parametros, cv=10, scoring='accuracy')\n",
    "    grid_search.fit(X_train, Y_train)\n",
    "\n",
    "    \n",
    "    print(f\"Resultados para {nombre}:\")\n",
    "    print(grid_search.cv_results_)\n",
    "\n",
    "\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "    Y_pred = best_estimator.predict(X_test)\n",
    "\n",
    "    resultados[nombre] = {\"GridSearchModel\": grid_search,\n",
    "                     \"Accuracy\": accuracy_score(Y_test, Y_pred),\n",
    "                     \"Precision\": precision_score(Y_test, Y_pred),\n",
    "                     \"Recall\": recall_score(Y_test, Y_pred),\n",
    "                     \"F1 Score\": f1_score(Y_test, Y_pred),\n",
    "                     \"ROC AUC Score\": roc_auc_score(Y_test, Y_pred),\n",
    "                     \"Predictions\": Y_pred}\n",
    "\n",
    "\n",
    "for nombre, metricas in resultados.items():\n",
    "    print(f\"\\nResultados para {nombre}:\")\n",
    "    for metrica, value in metricas.items():\n",
    "        print(f\"{metrica}: {value}\")\n",
    "\n",
    "for nombre, metricas in resultados.items():\n",
    "    with open(f\"Modelos/KN_{nombre}_mejor_modelo.pkl\", \"wb\") as f:\n",
    "        pickle.dump(metricas[\"GridSearchModel\"].best_estimator_, f)\n",
    "    \n",
    "    with open(f\"Resultados/KN_{nombre}_resultados.txt\", \"w\") as f:\n",
    "        for metrica, value in metricas.items():\n",
    "            if metrica != \"Predictions\": \n",
    "                f.write(f\"{metrica}: {value}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árbol de decisión\n",
    "\n",
    "Se observa que los distintos resultados por balanceo de clases dan los mismos resultados se entiende que este modelo en particular no se ve tan afectado por el desbalanceo de clases, como si ocurre en otros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para Normal:\n",
      "{'mean_fit_time': array([0.00075445, 0.00089939, 0.00076802, 0.00089943, 0.00086656,\n",
      "       0.00070014, 0.00049949, 0.00061083, 0.00085402, 0.00086842,\n",
      "       0.00070088, 0.0007508 , 0.0006    , 0.00060005, 0.00067532,\n",
      "       0.00070345, 0.00085132, 0.00099633, 0.00069966, 0.00080047,\n",
      "       0.00084977, 0.00090067, 0.00089996, 0.00095055, 0.00090051,\n",
      "       0.00089984, 0.00086515, 0.00070028, 0.00080032, 0.00080097,\n",
      "       0.00090063, 0.00099933, 0.00075037, 0.00090032, 0.00089931,\n",
      "       0.0009635 , 0.00079944, 0.00100148, 0.00105131, 0.00087798,\n",
      "       0.00093122, 0.00101025, 0.00106137, 0.00105073, 0.00123305,\n",
      "       0.00090058, 0.00108864, 0.00100007, 0.00149963, 0.00109906,\n",
      "       0.00110118, 0.0010505 , 0.00099921, 0.00109918, 0.00109978,\n",
      "       0.00115535, 0.00136333, 0.00099969, 0.00104342, 0.00100117,\n",
      "       0.0014302 , 0.00099976, 0.00103803, 0.00105126, 0.0010283 ,\n",
      "       0.00134037, 0.00139997, 0.00120139, 0.00114398, 0.00145783,\n",
      "       0.00124981, 0.00149505, 0.00134521, 0.00160072, 0.00105081,\n",
      "       0.00100026, 0.00124919, 0.00117888, 0.00130005, 0.00130014,\n",
      "       0.00129979, 0.00143371, 0.00159893, 0.00143986, 0.00125771,\n",
      "       0.00100546, 0.00160041, 0.00100052, 0.0011584 , 0.00116947,\n",
      "       0.00134761, 0.00120111, 0.00119975, 0.00099993, 0.00159993,\n",
      "       0.00130026, 0.0014009 , 0.00149961, 0.00129983, 0.00153069,\n",
      "       0.00139997, 0.00148761, 0.00139928, 0.00140016, 0.00119932,\n",
      "       0.0015003 , 0.00149894, 0.00140002, 0.00115163, 0.00130036,\n",
      "       0.00140007, 0.00130086, 0.00169969, 0.00129981, 0.00160074,\n",
      "       0.00150034, 0.00149975, 0.00160036, 0.00149963, 0.00139995,\n",
      "       0.00149899, 0.00149996, 0.00139942, 0.00149996, 0.00139112,\n",
      "       0.00129983, 0.0013001 , 0.00160067, 0.00150018, 0.00160425,\n",
      "       0.00140035, 0.0015424 , 0.00170012, 0.00149989, 0.00149984,\n",
      "       0.00150108, 0.0015002 , 0.00160019, 0.00155122, 0.00130005,\n",
      "       0.00140023, 0.00159976, 0.00132401, 0.00166223, 0.00170033,\n",
      "       0.00170016, 0.0016983 , 0.00149996, 0.0018002 , 0.00173595,\n",
      "       0.00150015, 0.00149977, 0.00150142, 0.00170057, 0.00156424,\n",
      "       0.00140011, 0.00140035, 0.00161474, 0.00152547, 0.00149951,\n",
      "       0.00162494, 0.00179963, 0.00190015, 0.00166373, 0.0018997 ,\n",
      "       0.00157163, 0.0017998 , 0.00135899, 0.00160065, 0.00160043,\n",
      "       0.00159955, 0.00159981, 0.00140085, 0.00149972, 0.00149961,\n",
      "       0.00160127, 0.0019001 , 0.00169926, 0.00180011, 0.00159976,\n",
      "       0.00190027, 0.00170035, 0.00169985, 0.00159864, 0.00190172,\n",
      "       0.00169969, 0.00195305, 0.00178823, 0.00169942, 0.00172698,\n",
      "       0.00177863, 0.00159974, 0.00180037, 0.00175066, 0.00200007,\n",
      "       0.00169985, 0.00189974, 0.0018014 , 0.00160038, 0.00171978,\n",
      "       0.00170016, 0.00185058, 0.00160143, 0.00167873, 0.0016001 ,\n",
      "       0.00153856, 0.00179932, 0.00139966, 0.00200021, 0.002     ,\n",
      "       0.00175123, 0.0019999 , 0.00179918, 0.0017978 , 0.00190058,\n",
      "       0.00170054, 0.00179968, 0.00190005, 0.00188963, 0.00169995,\n",
      "       0.00166643, 0.00170014, 0.00160322, 0.00170016, 0.00198631,\n",
      "       0.00200033, 0.00159976, 0.00190001, 0.00200059, 0.00200033,\n",
      "       0.00179789, 0.00180008, 0.00189991, 0.001671  , 0.00178671,\n",
      "       0.0016988 , 0.00139999, 0.00159991, 0.00149953, 0.00149772,\n",
      "       0.00207765, 0.00199988, 0.0018996 , 0.00200002, 0.0018986 ,\n",
      "       0.00200121, 0.00194509, 0.0018997 , 0.00186324, 0.00169966,\n",
      "       0.00169978, 0.00159979, 0.00169961, 0.00160134, 0.00169899,\n",
      "       0.00169957, 0.00200031, 0.00180042, 0.00189979, 0.00170031,\n",
      "       0.00182707, 0.00187004, 0.00175061, 0.0015007 , 0.00170031,\n",
      "       0.00167964, 0.00185075, 0.0017601 , 0.00152357, 0.00160012,\n",
      "       0.00160005, 0.00181265, 0.00199924, 0.00196917, 0.00180049,\n",
      "       0.00150032, 0.0020004 , 0.00169961, 0.00195413, 0.00190053,\n",
      "       0.00155067, 0.00158606, 0.00172901, 0.00169995, 0.00170145,\n",
      "       0.00150154, 0.00170002, 0.00158052, 0.00190053, 0.00189929,\n",
      "       0.00189989, 0.0018748 , 0.00190146, 0.00199997, 0.00190024,\n",
      "       0.00179961, 0.0019002 , 0.00160038, 0.00189962, 0.00150034,\n",
      "       0.0015996 , 0.00160086, 0.00170043, 0.00170066, 0.00189812,\n",
      "       0.0019686 , 0.00190029, 0.00140078, 0.00199943, 0.0016999 ,\n",
      "       0.00179968, 0.00159931, 0.00179973, 0.00149994, 0.00180001,\n",
      "       0.0017    , 0.00160348, 0.00140002, 0.00165   , 0.00149913]), 'std_fit_time': array([5.16457483e-04, 5.38997339e-04, 3.95015382e-04, 2.99812596e-04,\n",
      "       3.28140718e-04, 4.58351917e-04, 4.99489199e-04, 4.98933394e-04,\n",
      "       4.52168614e-04, 4.50205206e-04, 4.58842289e-04, 5.12925161e-04,\n",
      "       4.89902404e-04, 4.89941964e-04, 4.74061568e-04, 4.60565139e-04,\n",
      "       3.19934087e-04, 1.97194577e-04, 4.58041546e-04, 4.00242625e-04,\n",
      "       4.49130358e-04, 3.00238994e-04, 3.00001674e-04, 1.48475769e-04,\n",
      "       3.00198513e-04, 2.99962843e-04, 3.29148330e-04, 4.58445833e-04,\n",
      "       4.00167354e-04, 4.00491158e-04, 3.00216467e-04, 1.74306648e-06,\n",
      "       4.02820435e-04, 3.00112568e-04, 2.99774081e-04, 3.72633211e-04,\n",
      "       3.99723341e-04, 4.53402938e-06, 1.13724175e-04, 4.93769209e-04,\n",
      "       3.25310838e-04, 3.19646412e-05, 1.80462109e-04, 3.49505055e-04,\n",
      "       3.97243215e-04, 3.00209666e-04, 2.64335539e-04, 5.18986374e-06,\n",
      "       5.00561728e-04, 3.01465993e-04, 2.97503974e-04, 3.49286887e-04,\n",
      "       2.00611915e-06, 3.00767812e-04, 2.99644804e-04, 5.42726027e-04,\n",
      "       4.53828870e-04, 2.69739830e-06, 4.66676731e-04, 4.09747144e-06,\n",
      "       5.87970226e-04, 1.47376628e-06, 9.01351395e-05, 1.16466441e-04,\n",
      "       8.68732003e-05, 4.47914256e-04, 4.89856468e-04, 5.99794733e-04,\n",
      "       3.13263465e-04, 6.45284236e-04, 4.02789592e-04, 4.91478525e-04,\n",
      "       4.49530841e-04, 4.88948767e-04, 1.02688861e-04, 1.56414218e-06,\n",
      "       4.02017110e-04, 3.62235573e-04, 4.58548040e-04, 4.58232580e-04,\n",
      "       4.57993900e-04, 4.72882312e-04, 5.33185722e-04, 5.46023425e-04,\n",
      "       4.07026866e-04, 1.56877976e-05, 4.89318796e-04, 2.18058524e-06,\n",
      "       3.39024715e-04, 4.44920262e-04, 4.44543624e-04, 4.01408388e-04,\n",
      "       4.00064052e-04, 1.40646755e-06, 4.89999291e-04, 4.58511981e-04,\n",
      "       4.90901131e-04, 5.00014248e-04, 4.58326161e-04, 4.76823506e-04,\n",
      "       4.90102019e-04, 4.88993696e-04, 4.89980472e-04, 4.89796536e-04,\n",
      "       3.99141927e-04, 4.99565692e-04, 5.00922677e-04, 4.89765576e-04,\n",
      "       3.22351266e-04, 4.59542425e-04, 4.89776586e-04, 5.09261346e-04,\n",
      "       4.57840729e-04, 4.58444010e-04, 4.89980124e-04, 4.99847294e-04,\n",
      "       5.00202988e-04, 4.89814526e-04, 5.00373571e-04, 4.89971803e-04,\n",
      "       5.00158503e-04, 4.99988762e-04, 4.90009337e-04, 4.99797557e-04,\n",
      "       4.78803441e-04, 4.57439636e-04, 4.58101220e-04, 4.90507462e-04,\n",
      "       5.00822635e-04, 4.37974113e-04, 4.90566586e-04, 4.74384965e-04,\n",
      "       4.58380621e-04, 4.99964204e-04, 4.99868916e-04, 4.98686527e-04,\n",
      "       4.99844765e-04, 4.89483366e-04, 4.71987622e-04, 4.58706550e-04,\n",
      "       4.89688267e-04, 4.89912164e-04, 4.47966914e-04, 4.47131559e-04,\n",
      "       4.57793921e-04, 4.58411811e-04, 4.58460489e-04, 4.99799206e-04,\n",
      "       4.00320545e-04, 4.91535280e-04, 5.00133404e-04, 4.98750210e-04,\n",
      "       5.01600838e-04, 4.59146052e-04, 4.70593989e-04, 4.89396054e-04,\n",
      "       4.89610014e-04, 5.04178905e-04, 4.53757799e-04, 4.99679421e-04,\n",
      "       4.63991496e-04, 4.00091237e-04, 3.00154462e-04, 4.47652350e-04,\n",
      "       3.00007271e-04, 4.74483588e-04, 4.00415446e-04, 4.53460505e-04,\n",
      "       4.90148349e-04, 4.89386365e-04, 4.90710708e-04, 4.90827384e-04,\n",
      "       4.91762813e-04, 4.99845606e-04, 5.00250517e-04, 6.61572857e-04,\n",
      "       2.99908231e-04, 4.58191927e-04, 3.99911627e-04, 4.90012460e-04,\n",
      "       3.00285244e-04, 4.58695149e-04, 4.58573592e-04, 4.88868687e-04,\n",
      "       3.00604385e-04, 4.58412295e-04, 3.54413722e-04, 3.96519317e-04,\n",
      "       4.59547175e-04, 4.81785977e-04, 5.58557941e-04, 4.90962683e-04,\n",
      "       3.99633366e-04, 4.02484639e-04, 1.13066728e-06, 4.58313344e-04,\n",
      "       2.99862516e-04, 4.00999258e-04, 4.90466797e-04, 4.74708455e-04,\n",
      "       4.58203839e-04, 3.18953528e-04, 4.89385312e-04, 4.48486064e-04,\n",
      "       4.90284050e-04, 5.50676645e-04, 4.00293625e-04, 4.89863996e-04,\n",
      "       1.75929649e-06, 3.37545477e-06, 4.02520821e-04, 3.49232357e-06,\n",
      "       3.99994717e-04, 3.98695682e-04, 3.00151762e-04, 4.58147628e-04,\n",
      "       3.99521282e-04, 3.00203761e-04, 2.98212850e-04, 4.58847918e-04,\n",
      "       4.45089280e-04, 4.59242873e-04, 4.86475128e-04, 4.57997325e-04,\n",
      "       3.90770597e-05, 1.86210863e-06, 4.89866842e-04, 3.01958741e-04,\n",
      "       5.23484898e-06, 1.13843311e-06, 3.99203351e-04, 3.99790230e-04,\n",
      "       2.99999679e-04, 4.47022439e-04, 5.72278435e-04, 4.60211708e-04,\n",
      "       4.90290983e-04, 4.90272122e-04, 4.99088147e-04, 5.01874976e-04,\n",
      "       2.24738924e-04, 2.14695897e-06, 3.01250555e-04, 1.94877110e-06,\n",
      "       2.99679731e-04, 5.35466048e-06, 3.43203359e-04, 2.99933613e-04,\n",
      "       4.68932278e-04, 4.57990702e-04, 4.58376608e-04, 4.90225218e-04,\n",
      "       4.58586446e-04, 4.88186947e-04, 4.58691514e-04, 4.58080252e-04,\n",
      "       1.29910781e-06, 4.00309626e-04, 3.00117422e-04, 4.57777532e-04,\n",
      "       4.18966940e-04, 3.03602059e-04, 4.01949489e-04, 4.99347804e-04,\n",
      "       4.58043917e-04, 6.01503326e-04, 3.19444227e-04, 3.97743637e-04,\n",
      "       4.82031993e-04, 4.90154878e-04, 4.90145058e-04, 4.08164444e-04,\n",
      "       2.01516596e-06, 9.32834773e-05, 4.00345416e-04, 4.99013786e-04,\n",
      "       3.16486632e-06, 4.58210787e-04, 1.46496132e-04, 3.00209480e-04,\n",
      "       4.71696599e-04, 4.80819360e-04, 4.83113303e-04, 4.58583711e-04,\n",
      "       4.58539864e-04, 4.98756150e-04, 4.57591745e-04, 4.77345598e-04,\n",
      "       3.00365631e-04, 2.99712805e-04, 2.99987065e-04, 3.00640785e-04,\n",
      "       3.00545056e-04, 7.63311891e-07, 3.00185140e-04, 4.00736306e-04,\n",
      "       3.00248895e-04, 4.90226508e-04, 2.99904288e-04, 4.99750963e-04,\n",
      "       4.90213783e-04, 4.90759025e-04, 4.58739917e-04, 4.58745121e-04,\n",
      "       2.99447092e-04, 3.85609758e-04, 3.00161306e-04, 4.89101290e-04,\n",
      "       1.22872340e-06, 4.57876130e-04, 4.00234998e-04, 4.89542355e-04,\n",
      "       4.00317861e-04, 4.99490278e-04, 4.00820545e-04, 4.58319707e-04,\n",
      "       4.87195649e-04, 4.90251904e-04, 4.50998160e-04, 4.99679986e-04]), 'mean_score_time': array([3.47900391e-04, 3.00121307e-04, 3.98349762e-04, 4.99463081e-04,\n",
      "       4.27126884e-04, 5.00559807e-04, 5.00154495e-04, 4.46605682e-04,\n",
      "       3.01456451e-04, 3.01551819e-04, 3.99684906e-04, 3.51381302e-04,\n",
      "       4.00304794e-04, 3.99851799e-04, 2.48146057e-04, 3.63779068e-04,\n",
      "       4.02522087e-04, 4.14752960e-04, 3.99851799e-04, 3.00264359e-04,\n",
      "       4.99510765e-04, 9.95397568e-05, 1.99794769e-04, 2.99978256e-04,\n",
      "       2.00128555e-04, 3.00097466e-04, 3.99470329e-04, 3.99827957e-04,\n",
      "       3.00693512e-04, 3.99875641e-04, 1.00040436e-04, 2.99859047e-04,\n",
      "       4.00495529e-04, 5.00297546e-04, 3.00192833e-04, 4.00233269e-04,\n",
      "       3.44157219e-04, 1.00278854e-04, 3.99255753e-04, 4.07505035e-04,\n",
      "       2.00176239e-04, 5.01275063e-04, 2.99906731e-04, 5.11145592e-04,\n",
      "       5.01680374e-04, 4.10461426e-04, 3.99804115e-04, 2.99334526e-04,\n",
      "       2.00796127e-04, 4.00710106e-04, 3.99231911e-04, 2.00653076e-04,\n",
      "       2.99811363e-04, 1.99604034e-04, 4.00972366e-04, 4.11987305e-04,\n",
      "       4.24027443e-04, 0.00000000e+00, 4.66370583e-04, 1.99961662e-04,\n",
      "       3.99494171e-04, 2.99644470e-04, 7.58433342e-04, 2.50124931e-04,\n",
      "       3.00216675e-04, 6.50906563e-04, 0.00000000e+00, 4.00567055e-04,\n",
      "       6.50453568e-04, 1.40309334e-04, 6.01196289e-04, 3.99708748e-04,\n",
      "       5.01060486e-04, 2.42090225e-04, 6.50668144e-04, 9.99855995e-04,\n",
      "       5.47623634e-04, 0.00000000e+00, 5.99932671e-04, 2.99859047e-04,\n",
      "       2.00200081e-04, 6.01053238e-04, 1.99556351e-04, 4.00638580e-04,\n",
      "       4.00233269e-04, 7.09104538e-04, 3.99589539e-04, 9.99617577e-04,\n",
      "       7.00092316e-04, 4.33158875e-04, 6.02507591e-04, 3.99661064e-04,\n",
      "       0.00000000e+00, 4.99653816e-04, 3.99994850e-04, 5.00011444e-04,\n",
      "       3.00192833e-04, 2.00009346e-04, 3.99875641e-04, 3.99899483e-04,\n",
      "       1.99985504e-04, 4.00424004e-04, 4.00257111e-04, 4.00209427e-04,\n",
      "       4.00853157e-04, 4.99677658e-04, 3.00025940e-04, 2.99978256e-04,\n",
      "       4.31156158e-04, 4.00161743e-04, 3.99756432e-04, 2.50840187e-04,\n",
      "       2.00343132e-04, 5.99789619e-04, 3.99732590e-04, 3.99899483e-04,\n",
      "       4.00018692e-04, 2.99835205e-04, 4.00567055e-04, 3.99541855e-04,\n",
      "       3.00383568e-04, 4.00066376e-04, 4.00519371e-04, 2.00009346e-04,\n",
      "       4.00161743e-04, 6.00075722e-04, 3.99732590e-04, 2.00033188e-04,\n",
      "       4.99916077e-04, 3.62968445e-04, 3.99875641e-04, 2.50720978e-04,\n",
      "       3.00002098e-04, 4.00304794e-04, 2.99882889e-04, 2.98905373e-04,\n",
      "       4.99820709e-04, 2.99715996e-04, 3.00073624e-04, 5.00106812e-04,\n",
      "       2.99835205e-04, 3.00073624e-04, 3.99804115e-04, 3.00598145e-04,\n",
      "       2.99787521e-04, 4.00018692e-04, 3.01098824e-04, 4.00066376e-04,\n",
      "       3.00025940e-04, 2.99954414e-04, 4.50992584e-04, 4.00090218e-04,\n",
      "       2.99835205e-04, 2.99954414e-04, 5.00440598e-04, 3.99756432e-04,\n",
      "       5.00226021e-04, 4.51016426e-04, 3.99518013e-04, 4.00280952e-04,\n",
      "       4.00781631e-04, 3.00288200e-04, 9.99927521e-05, 3.00621986e-04,\n",
      "       2.00033188e-04, 4.00137901e-04, 3.99398804e-04, 7.17616081e-04,\n",
      "       4.99892235e-04, 3.99684906e-04, 4.00066376e-04, 4.00066376e-04,\n",
      "       5.00035286e-04, 4.00280952e-04, 3.99732590e-04, 3.98778915e-04,\n",
      "       4.00042534e-04, 5.00893593e-04, 3.99827957e-04, 4.00090218e-04,\n",
      "       2.99668312e-04, 4.99987602e-04, 3.00002098e-04, 4.01592255e-04,\n",
      "       9.98497009e-05, 2.99906731e-04, 3.60822678e-04, 4.00853157e-04,\n",
      "       2.99572945e-04, 2.99954414e-04, 1.99985504e-04, 2.99906731e-04,\n",
      "       4.99629974e-04, 3.00002098e-04, 0.00000000e+00, 3.99947166e-04,\n",
      "       2.99763680e-04, 2.99954414e-04, 3.99899483e-04, 3.99971008e-04,\n",
      "       5.00035286e-04, 1.99842453e-04, 3.99208069e-04, 2.99978256e-04,\n",
      "       4.00280952e-04, 3.99708748e-04, 2.00104713e-04, 5.00655174e-04,\n",
      "       3.00121307e-04, 2.99954414e-04, 4.99582291e-04, 0.00000000e+00,\n",
      "       5.02228737e-04, 3.01766396e-04, 3.00478935e-04, 4.99844551e-04,\n",
      "       6.00385666e-04, 4.00257111e-04, 3.00002098e-04, 3.99994850e-04,\n",
      "       3.99971008e-04, 4.00638580e-04, 3.97467613e-04, 3.99827957e-04,\n",
      "       4.01496887e-04, 3.00073624e-04, 5.99670410e-04, 2.99954414e-04,\n",
      "       3.98516655e-04, 3.00312042e-04, 3.00073624e-04, 3.00145149e-04,\n",
      "       4.99916077e-04, 5.01060486e-04, 2.99525261e-04, 3.00431252e-04,\n",
      "       4.99415398e-04, 3.99971008e-04, 3.00526619e-04, 5.00845909e-04,\n",
      "       4.98390198e-04, 4.00233269e-04, 3.99661064e-04, 9.99927521e-05,\n",
      "       2.99763680e-04, 5.00774384e-04, 3.50904465e-04, 9.99927521e-05,\n",
      "       3.97777557e-04, 4.00900841e-04, 5.00416756e-04, 4.99892235e-04,\n",
      "       2.00629234e-04, 3.98612022e-04, 3.00788879e-04, 3.00431252e-04,\n",
      "       3.99994850e-04, 6.00147247e-04, 3.00335884e-04, 3.99637222e-04,\n",
      "       6.00147247e-04, 3.00168991e-04, 5.00106812e-04, 4.99510765e-04,\n",
      "       4.00090218e-04, 3.99851799e-04, 4.00018692e-04, 3.00598145e-04,\n",
      "       4.49752808e-04, 4.00018692e-04, 4.00400162e-04, 2.50363350e-04,\n",
      "       3.00073624e-04, 4.00042534e-04, 3.99994850e-04, 6.10756874e-04,\n",
      "       2.99906731e-04, 5.00202179e-04, 2.50744820e-04, 3.00002098e-04,\n",
      "       4.00543213e-04, 4.00018692e-04, 4.00066376e-04, 2.99930573e-04,\n",
      "       2.99572945e-04, 4.98676300e-04, 2.00128555e-04, 3.99875641e-04,\n",
      "       3.99947166e-04, 6.00528717e-04, 3.00168991e-04, 4.01496887e-04,\n",
      "       5.98740578e-04, 4.00090218e-04, 2.99978256e-04, 3.99827957e-04,\n",
      "       4.99916077e-04, 5.00059128e-04, 1.00016594e-04, 4.99892235e-04,\n",
      "       4.00114059e-04, 3.99827957e-04, 3.99708748e-04, 4.50468063e-04,\n",
      "       7.01880455e-04, 2.99930573e-04, 3.99804115e-04, 6.30927086e-04,\n",
      "       4.00590897e-04, 6.00004196e-04, 4.00257111e-04, 5.00535965e-04,\n",
      "       5.00369072e-04, 5.00011444e-04, 2.99978256e-04, 2.99978256e-04,\n",
      "       3.97872925e-04, 4.00066376e-04, 2.99906731e-04, 4.00471687e-04]), 'std_score_time': array([5.45683408e-04, 4.58442882e-04, 4.87902483e-04, 4.99463883e-04,\n",
      "       5.28269876e-04, 5.00560761e-04, 5.00158366e-04, 5.61559602e-04,\n",
      "       4.60502214e-04, 4.01387372e-04, 4.89514048e-04, 4.51366329e-04,\n",
      "       4.90272548e-04, 4.89717199e-04, 3.99163427e-04, 4.70708404e-04,\n",
      "       4.93014930e-04, 5.09348562e-04, 4.89717269e-04, 4.58672203e-04,\n",
      "       4.99518815e-04, 2.98619270e-04, 3.99589553e-04, 4.58225956e-04,\n",
      "       4.00257338e-04, 4.58406529e-04, 4.89250670e-04, 4.89687443e-04,\n",
      "       4.59322755e-04, 4.89747857e-04, 3.00121307e-04, 4.58042376e-04,\n",
      "       4.90506729e-04, 5.00298164e-04, 4.58552238e-04, 4.90186025e-04,\n",
      "       5.37902932e-04, 3.00836563e-04, 4.88987336e-04, 4.99318167e-04,\n",
      "       4.00352705e-04, 5.01298841e-04, 4.58116302e-04, 5.11875644e-04,\n",
      "       5.01689423e-04, 5.03463046e-04, 4.89658601e-04, 4.57244671e-04,\n",
      "       4.01593161e-04, 4.90771937e-04, 4.88959669e-04, 4.01310246e-04,\n",
      "       4.57970134e-04, 3.99209222e-04, 4.91090614e-04, 5.49213237e-04,\n",
      "       5.23653834e-04, 0.00000000e+00, 4.94213817e-04, 3.99923328e-04,\n",
      "       4.89279564e-04, 4.57715300e-04, 5.24266533e-04, 4.02791131e-04,\n",
      "       4.58589442e-04, 4.49896041e-04, 0.00000000e+00, 5.38922049e-04,\n",
      "       4.49964129e-04, 4.20928001e-04, 4.90885202e-04, 4.89541534e-04,\n",
      "       5.01069645e-04, 4.93026646e-04, 4.49979070e-04, 2.73101172e-06,\n",
      "       5.64196553e-04, 0.00000000e+00, 4.89843200e-04, 4.58042314e-04,\n",
      "       4.00400336e-04, 4.90762659e-04, 3.99112830e-04, 4.90686708e-04,\n",
      "       4.90184193e-04, 4.64950582e-04, 4.89396295e-04, 1.07711382e-06,\n",
      "       4.58320205e-04, 5.79081073e-04, 4.91984990e-04, 4.89483284e-04,\n",
      "       0.00000000e+00, 4.99654187e-04, 4.89891959e-04, 5.00011849e-04,\n",
      "       4.58552275e-04, 4.00018696e-04, 4.89745768e-04, 4.89775135e-04,\n",
      "       3.99971008e-04, 4.90419057e-04, 4.90213806e-04, 4.90154774e-04,\n",
      "       4.90946118e-04, 4.99679280e-04, 4.58300199e-04, 4.58224802e-04,\n",
      "       5.34711742e-04, 4.90096437e-04, 4.89599783e-04, 4.04268134e-04,\n",
      "       4.00686296e-04, 4.89726759e-04, 4.89570770e-04, 4.89776029e-04,\n",
      "       4.89920917e-04, 4.58005928e-04, 4.90593713e-04, 4.89337285e-04,\n",
      "       4.58845131e-04, 4.89979578e-04, 4.90535023e-04, 4.00018696e-04,\n",
      "       4.90096333e-04, 4.89960754e-04, 4.89571815e-04, 4.00066390e-04,\n",
      "       4.99916129e-04, 3.97215158e-04, 4.89745652e-04, 4.03781418e-04,\n",
      "       4.58260853e-04, 4.90271435e-04, 4.58078745e-04, 4.56596404e-04,\n",
      "       4.99820725e-04, 4.57823862e-04, 4.58370060e-04, 5.00107032e-04,\n",
      "       4.58006077e-04, 4.58370333e-04, 4.89658892e-04, 4.59176503e-04,\n",
      "       4.57933206e-04, 4.89920859e-04, 4.59944582e-04, 4.89979683e-04,\n",
      "       4.58297247e-04, 4.58188089e-04, 4.72432526e-04, 4.90008481e-04,\n",
      "       4.58005878e-04, 4.58187953e-04, 5.00449582e-04, 4.89599702e-04,\n",
      "       5.00226923e-04, 4.72010239e-04, 4.89308211e-04, 4.90244587e-04,\n",
      "       4.90859585e-04, 4.58698129e-04, 2.99978256e-04, 4.59208610e-04,\n",
      "       4.00066390e-04, 4.90066905e-04, 4.89162229e-04, 4.72395553e-04,\n",
      "       4.99892458e-04, 4.89512677e-04, 4.89979277e-04, 4.89979312e-04,\n",
      "       5.00035441e-04, 4.90242268e-04, 4.89571339e-04, 4.88414506e-04,\n",
      "       4.89950266e-04, 5.00900111e-04, 4.89687292e-04, 4.90008620e-04,\n",
      "       4.57752799e-04, 4.99987834e-04, 4.58260803e-04, 4.91860374e-04,\n",
      "       2.99549103e-04, 4.58115111e-04, 4.54571506e-04, 4.90946453e-04,\n",
      "       4.57606230e-04, 4.58187953e-04, 3.99971023e-04, 4.58115098e-04,\n",
      "       4.99635201e-04, 4.58260890e-04, 0.00000000e+00, 4.89833315e-04,\n",
      "       4.57897192e-04, 4.58187940e-04, 4.89774891e-04, 4.89862441e-04,\n",
      "       5.00035725e-04, 3.99685034e-04, 4.88931790e-04, 4.58224405e-04,\n",
      "       4.90242732e-04, 4.89541371e-04, 4.00209601e-04, 5.00656564e-04,\n",
      "       4.58446887e-04, 4.58188263e-04, 4.99595846e-04, 0.00000000e+00,\n",
      "       5.02241108e-04, 4.60993011e-04, 4.58990976e-04, 4.99846860e-04,\n",
      "       4.90215661e-04, 4.90213481e-04, 4.58260791e-04, 4.89892411e-04,\n",
      "       4.89864959e-04, 4.90683499e-04, 4.86809643e-04, 4.89687362e-04,\n",
      "       4.91734086e-04, 4.58370581e-04, 4.89629130e-04, 4.58188089e-04,\n",
      "       4.88087220e-04, 4.58735217e-04, 4.58370160e-04, 4.58484264e-04,\n",
      "       4.99916197e-04, 5.01063338e-04, 4.57533143e-04, 4.58919220e-04,\n",
      "       4.99416417e-04, 4.89862870e-04, 4.59066331e-04, 5.00848549e-04,\n",
      "       4.98396669e-04, 4.90184448e-04, 4.89483865e-04, 2.99978256e-04,\n",
      "       4.57898930e-04, 5.00780257e-04, 4.50888715e-04, 2.99978256e-04,\n",
      "       4.87199790e-04, 4.91007852e-04, 5.00418759e-04, 4.99892742e-04,\n",
      "       4.01261447e-04, 4.88206162e-04, 4.59463003e-04, 4.58917386e-04,\n",
      "       4.89891843e-04, 4.90018311e-04, 4.58773131e-04, 4.89454364e-04,\n",
      "       4.90019993e-04, 4.58515972e-04, 5.00108169e-04, 4.99512056e-04,\n",
      "       4.90009212e-04, 4.89717211e-04, 4.89920871e-04, 4.59172814e-04,\n",
      "       4.70963497e-04, 4.89920847e-04, 4.90392780e-04, 4.03292486e-04,\n",
      "       4.58370160e-04, 4.89951345e-04, 4.89891646e-04, 4.99585058e-04,\n",
      "       4.58115135e-04, 5.00203668e-04, 4.04001475e-04, 4.58260779e-04,\n",
      "       4.90564578e-04, 4.89921103e-04, 4.89979370e-04, 4.58151633e-04,\n",
      "       4.57606900e-04, 4.98684261e-04, 4.00257238e-04, 4.89745652e-04,\n",
      "       4.89833268e-04, 4.90332879e-04, 4.58515972e-04, 4.91738582e-04,\n",
      "       4.88882247e-04, 4.90008644e-04, 4.58224368e-04, 4.89687362e-04,\n",
      "       4.99916277e-04, 5.00059132e-04, 3.00049782e-04, 4.99893572e-04,\n",
      "       4.90037810e-04, 4.89687292e-04, 4.89542265e-04, 4.71845707e-04,\n",
      "       4.59507567e-04, 4.58151695e-04, 4.89658160e-04, 5.22979281e-04,\n",
      "       4.90622162e-04, 4.89901835e-04, 4.90213899e-04, 5.00536889e-04,\n",
      "       5.00369794e-04, 5.00014202e-04, 4.58224442e-04, 4.58224393e-04,\n",
      "       4.87321111e-04, 4.89979253e-04, 4.58115098e-04, 4.90476785e-04]), 'param_classifier__max_depth': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
      "                   2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3,\n",
      "                   3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4,\n",
      "                   4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "                   6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "                   7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "                   8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
      "                   11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
      "                   12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13,\n",
      "                   13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14,\n",
      "                   14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15,\n",
      "                   15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16,\n",
      "                   16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "                   17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "                   17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
      "                   18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
      "                   19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "                   20, 20, 20, 20, 20, 20, 20, 20],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_classifier__min_samples_leaf': masked_array(data=[1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1,\n",
      "                   1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1,\n",
      "                   1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1,\n",
      "                   1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1,\n",
      "                   2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2,\n",
      "                   2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2,\n",
      "                   2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2,\n",
      "                   2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "                   5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5,\n",
      "                   5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5,\n",
      "                   5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5,\n",
      "                   5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5,\n",
      "                   10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10,\n",
      "                   10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10,\n",
      "                   10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10,\n",
      "                   10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10,\n",
      "                   1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1,\n",
      "                   1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1,\n",
      "                   1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_classifier__min_samples_split': masked_array(data=[2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'classifier__max_depth': 1, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}], 'split0_test_score': array([0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77987421, 0.77987421, 0.77987421, 0.77987421,\n",
      "       0.77987421, 0.77987421, 0.77987421, 0.77987421, 0.77987421,\n",
      "       0.77987421, 0.77987421, 0.77987421, 0.77987421, 0.77987421,\n",
      "       0.77987421, 0.77987421, 0.83018868, 0.83018868, 0.83018868,\n",
      "       0.83018868, 0.83018868, 0.83018868, 0.83018868, 0.83018868,\n",
      "       0.83018868, 0.83018868, 0.83018868, 0.83018868, 0.83018868,\n",
      "       0.83018868, 0.83018868, 0.83018868, 0.82389937, 0.82389937,\n",
      "       0.82389937, 0.82389937, 0.82389937, 0.82389937, 0.82389937,\n",
      "       0.82389937, 0.82389937, 0.82389937, 0.82389937, 0.82389937,\n",
      "       0.83018868, 0.83018868, 0.83018868, 0.83018868, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81761006, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81761006, 0.81132075, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81132075, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.79874214, 0.79245283, 0.80503145, 0.79874214,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.79245283, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.79874214, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.78616352, 0.77987421, 0.78616352,\n",
      "       0.78616352, 0.77987421, 0.77358491, 0.77987421, 0.78616352,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.79874214, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.76100629, 0.75471698,\n",
      "       0.76100629, 0.77987421, 0.7672956 , 0.7672956 , 0.77358491,\n",
      "       0.78616352, 0.80503145, 0.80503145, 0.80503145, 0.79874214,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81761006, 0.75471698,\n",
      "       0.74213836, 0.75471698, 0.77987421, 0.77358491, 0.7672956 ,\n",
      "       0.7672956 , 0.78616352, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.79874214, 0.81761006, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.74842767, 0.73584906, 0.75471698, 0.77987421, 0.75471698,\n",
      "       0.76100629, 0.7672956 , 0.78616352, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.75471698, 0.73584906, 0.75471698, 0.77358491,\n",
      "       0.7672956 , 0.76100629, 0.7672956 , 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.79874214, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.74213836, 0.72327044, 0.74213836,\n",
      "       0.77358491, 0.74842767, 0.75471698, 0.75471698, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.79874214, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.73584906, 0.72327044,\n",
      "       0.72955975, 0.77987421, 0.75471698, 0.75471698, 0.74842767,\n",
      "       0.77987421, 0.78616352, 0.78616352, 0.78616352, 0.79874214,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81761006, 0.72327044,\n",
      "       0.71698113, 0.72955975, 0.77358491, 0.75471698, 0.74842767,\n",
      "       0.74842767, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.79874214, 0.81761006, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.71698113, 0.71698113, 0.71698113, 0.76100629, 0.74842767,\n",
      "       0.73584906, 0.73584906, 0.7672956 , 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.79874214, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.72955975, 0.72955975, 0.72327044, 0.7672956 ,\n",
      "       0.76100629, 0.75471698, 0.74213836, 0.77987421, 0.79245283,\n",
      "       0.79245283, 0.79245283, 0.80503145, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.72955975, 0.72955975, 0.72327044,\n",
      "       0.77358491, 0.75471698, 0.76100629, 0.74213836, 0.77358491,\n",
      "       0.79245283, 0.79245283, 0.79245283, 0.80503145, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.71698113, 0.72955975,\n",
      "       0.72327044, 0.7672956 , 0.76100629, 0.76100629, 0.74213836,\n",
      "       0.77987421, 0.79245283, 0.79245283, 0.79245283, 0.80503145,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81761006, 0.72955975,\n",
      "       0.72327044, 0.72327044, 0.77358491, 0.75471698, 0.76100629,\n",
      "       0.74213836, 0.77358491, 0.79245283, 0.79245283, 0.79245283,\n",
      "       0.80503145, 0.81761006, 0.81761006, 0.81761006, 0.81761006]), 'split1_test_score': array([0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.88679245, 0.88679245, 0.88679245,\n",
      "       0.88679245, 0.88679245, 0.88679245, 0.88679245, 0.88679245,\n",
      "       0.88679245, 0.88679245, 0.88679245, 0.88679245, 0.88679245,\n",
      "       0.88679245, 0.88679245, 0.88679245, 0.86792453, 0.86792453,\n",
      "       0.86792453, 0.86792453, 0.86792453, 0.86792453, 0.86792453,\n",
      "       0.86792453, 0.86792453, 0.86792453, 0.86792453, 0.86792453,\n",
      "       0.88679245, 0.88679245, 0.88679245, 0.88679245, 0.87421384,\n",
      "       0.87421384, 0.86792453, 0.86792453, 0.87421384, 0.87421384,\n",
      "       0.86792453, 0.86792453, 0.86792453, 0.86792453, 0.86792453,\n",
      "       0.86792453, 0.88679245, 0.88679245, 0.88679245, 0.88679245,\n",
      "       0.86792453, 0.86792453, 0.86792453, 0.86792453, 0.86163522,\n",
      "       0.86163522, 0.86163522, 0.86792453, 0.86792453, 0.86792453,\n",
      "       0.86792453, 0.86792453, 0.88679245, 0.88679245, 0.88679245,\n",
      "       0.88679245, 0.86163522, 0.86163522, 0.86163522, 0.86792453,\n",
      "       0.86163522, 0.86163522, 0.86163522, 0.86792453, 0.86792453,\n",
      "       0.86792453, 0.86792453, 0.87421384, 0.88679245, 0.88679245,\n",
      "       0.88679245, 0.88679245, 0.85534591, 0.85534591, 0.8490566 ,\n",
      "       0.86792453, 0.8490566 , 0.8490566 , 0.8490566 , 0.86792453,\n",
      "       0.86163522, 0.85534591, 0.85534591, 0.87421384, 0.88679245,\n",
      "       0.88679245, 0.88679245, 0.88679245, 0.8490566 , 0.8490566 ,\n",
      "       0.85534591, 0.86163522, 0.85534591, 0.85534591, 0.8427673 ,\n",
      "       0.86792453, 0.85534591, 0.86163522, 0.86163522, 0.87421384,\n",
      "       0.88679245, 0.88679245, 0.88679245, 0.88679245, 0.86163522,\n",
      "       0.85534591, 0.85534591, 0.86792453, 0.8427673 , 0.8427673 ,\n",
      "       0.8490566 , 0.86792453, 0.86163522, 0.86163522, 0.85534591,\n",
      "       0.87421384, 0.88679245, 0.88679245, 0.88679245, 0.88679245,\n",
      "       0.8427673 , 0.83647799, 0.8427673 , 0.86163522, 0.83647799,\n",
      "       0.83647799, 0.83647799, 0.86792453, 0.85534591, 0.86163522,\n",
      "       0.85534591, 0.87421384, 0.88679245, 0.88679245, 0.88679245,\n",
      "       0.88679245, 0.81132075, 0.81761006, 0.83647799, 0.86163522,\n",
      "       0.83018868, 0.83018868, 0.8427673 , 0.86792453, 0.85534591,\n",
      "       0.86163522, 0.86163522, 0.87421384, 0.88679245, 0.88679245,\n",
      "       0.88679245, 0.88679245, 0.80503145, 0.81132075, 0.83647799,\n",
      "       0.86163522, 0.83018868, 0.83018868, 0.83647799, 0.86792453,\n",
      "       0.8490566 , 0.8490566 , 0.8427673 , 0.86163522, 0.88679245,\n",
      "       0.88679245, 0.88679245, 0.88679245, 0.81132075, 0.81761006,\n",
      "       0.83647799, 0.86163522, 0.83018868, 0.83018868, 0.8427673 ,\n",
      "       0.86792453, 0.8427673 , 0.8427673 , 0.8490566 , 0.86163522,\n",
      "       0.88679245, 0.88679245, 0.88679245, 0.88679245, 0.79874214,\n",
      "       0.81761006, 0.83018868, 0.86792453, 0.83018868, 0.83018868,\n",
      "       0.83647799, 0.86792453, 0.8427673 , 0.8427673 , 0.8490566 ,\n",
      "       0.86163522, 0.88679245, 0.88679245, 0.88679245, 0.88679245,\n",
      "       0.80503145, 0.81761006, 0.83018868, 0.86792453, 0.83647799,\n",
      "       0.83647799, 0.83647799, 0.86792453, 0.8490566 , 0.8490566 ,\n",
      "       0.8427673 , 0.86163522, 0.88679245, 0.88679245, 0.88679245,\n",
      "       0.88679245, 0.79874214, 0.81132075, 0.82389937, 0.86163522,\n",
      "       0.83018868, 0.83018868, 0.83018868, 0.86792453, 0.8427673 ,\n",
      "       0.8427673 , 0.8490566 , 0.86163522, 0.88679245, 0.88679245,\n",
      "       0.88679245, 0.88679245, 0.78616352, 0.81132075, 0.82389937,\n",
      "       0.86163522, 0.83647799, 0.83018868, 0.83018868, 0.86792453,\n",
      "       0.8490566 , 0.8490566 , 0.8427673 , 0.86163522, 0.88679245,\n",
      "       0.88679245, 0.88679245, 0.88679245, 0.77987421, 0.81132075,\n",
      "       0.82389937, 0.86163522, 0.83018868, 0.83018868, 0.83018868,\n",
      "       0.86792453, 0.8490566 , 0.8427673 , 0.8427673 , 0.86163522,\n",
      "       0.88679245, 0.88679245, 0.88679245, 0.88679245, 0.77987421,\n",
      "       0.81132075, 0.82389937, 0.86792453, 0.83647799, 0.83018868,\n",
      "       0.83018868, 0.86792453, 0.8490566 , 0.8427673 , 0.8490566 ,\n",
      "       0.86163522, 0.88679245, 0.88679245, 0.88679245, 0.88679245]), 'split2_test_score': array([0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79245283, 0.79245283, 0.79245283, 0.79245283,\n",
      "       0.79245283, 0.79245283, 0.79245283, 0.79245283, 0.79245283,\n",
      "       0.79245283, 0.79245283, 0.79245283, 0.79245283, 0.79245283,\n",
      "       0.79245283, 0.79245283, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.80503145, 0.81132075, 0.81132075, 0.81132075, 0.80503145,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81132075, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.81132075, 0.81761006, 0.81761006, 0.81761006, 0.81132075,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81132075, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81132075, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.81132075, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79245283, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79245283, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79245283, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.77987421,\n",
      "       0.77987421, 0.78616352, 0.79245283, 0.77987421, 0.78616352,\n",
      "       0.79874214, 0.78616352, 0.79245283, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.77358491, 0.77358491, 0.78616352,\n",
      "       0.78616352, 0.77358491, 0.77358491, 0.78616352, 0.78616352,\n",
      "       0.79245283, 0.79245283, 0.79245283, 0.79874214, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.7672956 , 0.7672956 ,\n",
      "       0.78616352, 0.77358491, 0.7672956 , 0.75471698, 0.77358491,\n",
      "       0.77358491, 0.77987421, 0.77987421, 0.77987421, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.77358491, 0.78616352, 0.77358491, 0.7672956 , 0.7672956 ,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.77987421, 0.77987421,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.77987421, 0.76100629, 0.78616352, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77987421, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.79874214, 0.78616352, 0.78616352, 0.77358491,\n",
      "       0.77358491, 0.7672956 , 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77987421, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.79245283, 0.77987421, 0.78616352,\n",
      "       0.77358491, 0.77987421, 0.7672956 , 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.77358491,\n",
      "       0.78616352, 0.77358491, 0.73584906, 0.74213836, 0.76100629,\n",
      "       0.77358491, 0.77987421, 0.77358491, 0.77987421, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.77358491,\n",
      "       0.7672956 , 0.78616352, 0.77358491, 0.72955975, 0.73584906,\n",
      "       0.76100629, 0.77358491, 0.77358491, 0.77987421, 0.77358491,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.77987421, 0.7672956 , 0.78616352, 0.77358491, 0.73584906,\n",
      "       0.74842767, 0.76100629, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77987421, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.77358491, 0.7672956 , 0.77987421, 0.77358491,\n",
      "       0.74842767, 0.74213836, 0.76100629, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.7672956 , 0.7672956 , 0.77358491,\n",
      "       0.77358491, 0.75471698, 0.74842767, 0.76100629, 0.77358491,\n",
      "       0.77987421, 0.77358491, 0.77358491, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.7672956 , 0.75471698,\n",
      "       0.77987421, 0.77358491, 0.74213836, 0.72955975, 0.75471698,\n",
      "       0.77358491, 0.77358491, 0.77987421, 0.77358491, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.77358491, 0.77987421, 0.77358491, 0.74842767, 0.74213836,\n",
      "       0.76100629, 0.77358491, 0.77987421, 0.77987421, 0.77358491,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352]), 'split3_test_score': array([0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.77987421, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.79245283, 0.79245283, 0.79245283,\n",
      "       0.78616352, 0.79245283, 0.79245283, 0.79245283, 0.78616352,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.78616352, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.77987421, 0.78616352,\n",
      "       0.79245283, 0.77987421, 0.77987421, 0.77987421, 0.79245283,\n",
      "       0.77987421, 0.77987421, 0.78616352, 0.78616352, 0.77358491,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.77358491,\n",
      "       0.77358491, 0.79874214, 0.77987421, 0.78616352, 0.78616352,\n",
      "       0.79245283, 0.77987421, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.77358491, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.75471698, 0.7672956 , 0.79245283, 0.77987421, 0.7672956 ,\n",
      "       0.77358491, 0.78616352, 0.77987421, 0.79245283, 0.78616352,\n",
      "       0.78616352, 0.77358491, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.7672956 , 0.77358491, 0.79245283, 0.79245283,\n",
      "       0.76100629, 0.77987421, 0.79874214, 0.78616352, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.77987421, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.76100629, 0.77987421, 0.79245283,\n",
      "       0.79245283, 0.77987421, 0.77987421, 0.79245283, 0.78616352,\n",
      "       0.79245283, 0.79874214, 0.79874214, 0.77987421, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.75471698, 0.7672956 ,\n",
      "       0.80503145, 0.79245283, 0.76100629, 0.77987421, 0.79245283,\n",
      "       0.78616352, 0.79245283, 0.79874214, 0.79245283, 0.77987421,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.74213836,\n",
      "       0.76100629, 0.80503145, 0.79245283, 0.7672956 , 0.77358491,\n",
      "       0.79245283, 0.78616352, 0.79874214, 0.79874214, 0.79245283,\n",
      "       0.77987421, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.73584906, 0.75471698, 0.78616352, 0.79245283, 0.76100629,\n",
      "       0.77358491, 0.79874214, 0.78616352, 0.79874214, 0.79245283,\n",
      "       0.79874214, 0.77987421, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.73584906, 0.74842767, 0.79874214, 0.79245283,\n",
      "       0.75471698, 0.7672956 , 0.79245283, 0.78616352, 0.79245283,\n",
      "       0.79245283, 0.79245283, 0.77987421, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.72955975, 0.75471698, 0.79874214,\n",
      "       0.79245283, 0.7672956 , 0.77358491, 0.79245283, 0.78616352,\n",
      "       0.79874214, 0.79874214, 0.79245283, 0.77987421, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.72955975, 0.75471698,\n",
      "       0.78616352, 0.79245283, 0.74842767, 0.77358491, 0.78616352,\n",
      "       0.78616352, 0.79245283, 0.79245283, 0.79874214, 0.77987421,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.74213836,\n",
      "       0.74213836, 0.79245283, 0.79245283, 0.7672956 , 0.7672956 ,\n",
      "       0.79874214, 0.78616352, 0.79245283, 0.79245283, 0.79245283,\n",
      "       0.77987421, 0.80503145, 0.80503145, 0.80503145, 0.80503145]), 'split4_test_score': array([0.74842767, 0.74842767, 0.74842767, 0.74842767, 0.74842767,\n",
      "       0.74842767, 0.74842767, 0.74842767, 0.74842767, 0.74842767,\n",
      "       0.74842767, 0.74842767, 0.74842767, 0.74842767, 0.74842767,\n",
      "       0.74842767, 0.74842767, 0.74842767, 0.74842767, 0.74842767,\n",
      "       0.74842767, 0.74842767, 0.74842767, 0.74842767, 0.74842767,\n",
      "       0.74842767, 0.74842767, 0.74842767, 0.74842767, 0.74842767,\n",
      "       0.74842767, 0.74842767, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.77987421, 0.77987421,\n",
      "       0.77987421, 0.77987421, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.76100629, 0.76100629, 0.7672956 , 0.78616352,\n",
      "       0.76100629, 0.76100629, 0.77358491, 0.79245283, 0.7672956 ,\n",
      "       0.7672956 , 0.7672956 , 0.7672956 , 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.75471698, 0.75471698, 0.76100629,\n",
      "       0.77987421, 0.7672956 , 0.7672956 , 0.7672956 , 0.78616352,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.77358491, 0.75471698,\n",
      "       0.76100629, 0.77987421, 0.76100629, 0.76100629, 0.7672956 ,\n",
      "       0.78616352, 0.76100629, 0.76100629, 0.76100629, 0.76100629,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.77358491,\n",
      "       0.76100629, 0.7672956 , 0.78616352, 0.76100629, 0.76100629,\n",
      "       0.7672956 , 0.78616352, 0.7672956 , 0.7672956 , 0.7672956 ,\n",
      "       0.76100629, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.76100629, 0.75471698, 0.76100629, 0.78616352, 0.75471698,\n",
      "       0.75471698, 0.76100629, 0.78616352, 0.7672956 , 0.7672956 ,\n",
      "       0.7672956 , 0.76100629, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.76100629, 0.75471698, 0.76100629, 0.78616352,\n",
      "       0.75471698, 0.75471698, 0.76100629, 0.78616352, 0.7672956 ,\n",
      "       0.7672956 , 0.7672956 , 0.76100629, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.7672956 , 0.76100629, 0.76100629,\n",
      "       0.78616352, 0.75471698, 0.75471698, 0.76100629, 0.78616352,\n",
      "       0.7672956 , 0.7672956 , 0.7672956 , 0.76100629, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.75471698, 0.75471698,\n",
      "       0.76100629, 0.78616352, 0.75471698, 0.75471698, 0.76100629,\n",
      "       0.78616352, 0.7672956 , 0.7672956 , 0.7672956 , 0.76100629,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.76100629,\n",
      "       0.74842767, 0.76100629, 0.78616352, 0.75471698, 0.75471698,\n",
      "       0.76100629, 0.78616352, 0.7672956 , 0.7672956 , 0.7672956 ,\n",
      "       0.76100629, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.75471698, 0.75471698, 0.76100629, 0.78616352, 0.75471698,\n",
      "       0.75471698, 0.76100629, 0.78616352, 0.7672956 , 0.7672956 ,\n",
      "       0.7672956 , 0.76100629, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.7672956 , 0.75471698, 0.76100629, 0.78616352,\n",
      "       0.75471698, 0.75471698, 0.76100629, 0.78616352, 0.7672956 ,\n",
      "       0.7672956 , 0.7672956 , 0.76100629, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.7672956 , 0.75471698, 0.76100629,\n",
      "       0.78616352, 0.75471698, 0.75471698, 0.76100629, 0.78616352,\n",
      "       0.7672956 , 0.7672956 , 0.7672956 , 0.76100629, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.76100629, 0.75471698,\n",
      "       0.76100629, 0.78616352, 0.75471698, 0.75471698, 0.76100629,\n",
      "       0.78616352, 0.7672956 , 0.7672956 , 0.7672956 , 0.76100629,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.75471698,\n",
      "       0.75471698, 0.76100629, 0.78616352, 0.75471698, 0.75471698,\n",
      "       0.76100629, 0.78616352, 0.7672956 , 0.7672956 , 0.7672956 ,\n",
      "       0.76100629, 0.78616352, 0.78616352, 0.78616352, 0.78616352]), 'split5_test_score': array([0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 ,\n",
      "       0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 ,\n",
      "       0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 ,\n",
      "       0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 ,\n",
      "       0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 ,\n",
      "       0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 ,\n",
      "       0.7672956 , 0.7672956 , 0.82389937, 0.82389937, 0.82389937,\n",
      "       0.81761006, 0.82389937, 0.82389937, 0.82389937, 0.81761006,\n",
      "       0.82389937, 0.82389937, 0.82389937, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.82389937, 0.82389937,\n",
      "       0.82389937, 0.81761006, 0.82389937, 0.82389937, 0.82389937,\n",
      "       0.81761006, 0.82389937, 0.82389937, 0.82389937, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81761006, 0.82389937,\n",
      "       0.82389937, 0.82389937, 0.81761006, 0.82389937, 0.82389937,\n",
      "       0.82389937, 0.81761006, 0.82389937, 0.82389937, 0.82389937,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.81132075, 0.82389937, 0.82389937, 0.82389937, 0.82389937,\n",
      "       0.82389937, 0.82389937, 0.82389937, 0.82389937, 0.82389937,\n",
      "       0.82389937, 0.81761006, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.82389937, 0.82389937,\n",
      "       0.83018868, 0.83018868, 0.82389937, 0.82389937, 0.83018868,\n",
      "       0.82389937, 0.83018868, 0.81761006, 0.82389937, 0.82389937,\n",
      "       0.82389937, 0.82389937, 0.79874214, 0.79245283, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.81132075, 0.80503145, 0.80503145,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79245283, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.79245283, 0.79245283,\n",
      "       0.79245283, 0.79245283, 0.79874214, 0.80503145, 0.79245283,\n",
      "       0.79245283, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.77358491,\n",
      "       0.76100629, 0.77358491, 0.77987421, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.79245283, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79245283, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.76100629, 0.76100629, 0.7672956 , 0.77358491, 0.79874214,\n",
      "       0.78616352, 0.77987421, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.77987421, 0.77358491, 0.7672956 , 0.77358491,\n",
      "       0.79245283, 0.79874214, 0.77358491, 0.78616352, 0.77987421,\n",
      "       0.77987421, 0.77987421, 0.78616352, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.76100629, 0.75471698, 0.75471698,\n",
      "       0.77358491, 0.78616352, 0.80503145, 0.77358491, 0.78616352,\n",
      "       0.77987421, 0.77987421, 0.77987421, 0.78616352, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.74213836, 0.75471698,\n",
      "       0.74842767, 0.77358491, 0.77987421, 0.79245283, 0.7672956 ,\n",
      "       0.78616352, 0.77987421, 0.77987421, 0.77987421, 0.77987421,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.75471698,\n",
      "       0.75471698, 0.75471698, 0.77358491, 0.79245283, 0.79874214,\n",
      "       0.77358491, 0.78616352, 0.77987421, 0.77987421, 0.77987421,\n",
      "       0.77987421, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.75471698, 0.74842767, 0.74842767, 0.77358491, 0.78616352,\n",
      "       0.79874214, 0.7672956 , 0.78616352, 0.77987421, 0.77987421,\n",
      "       0.77987421, 0.78616352, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.74842767, 0.75471698, 0.74842767, 0.77358491,\n",
      "       0.77987421, 0.79874214, 0.7672956 , 0.78616352, 0.77987421,\n",
      "       0.77987421, 0.77987421, 0.78616352, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.72327044, 0.74213836, 0.74842767,\n",
      "       0.77358491, 0.79245283, 0.79245283, 0.7672956 , 0.78616352,\n",
      "       0.77987421, 0.77987421, 0.77987421, 0.77987421, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.74213836, 0.74213836,\n",
      "       0.74842767, 0.77358491, 0.77987421, 0.79874214, 0.7672956 ,\n",
      "       0.78616352, 0.77987421, 0.77987421, 0.77987421, 0.77987421,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.73584906,\n",
      "       0.74842767, 0.74842767, 0.77358491, 0.78616352, 0.79874214,\n",
      "       0.7672956 , 0.78616352, 0.77987421, 0.77987421, 0.77987421,\n",
      "       0.78616352, 0.81132075, 0.81132075, 0.81132075, 0.81132075]), 'split6_test_score': array([0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.83647799,\n",
      "       0.83647799, 0.8427673 , 0.8427673 , 0.83647799, 0.83647799,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.82389937, 0.82389937, 0.83647799, 0.83647799, 0.82389937,\n",
      "       0.82389937, 0.83647799, 0.83647799, 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.82389937, 0.82389937, 0.83647799, 0.83647799,\n",
      "       0.82389937, 0.82389937, 0.83647799, 0.83647799, 0.83647799,\n",
      "       0.83647799, 0.83647799, 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.82389937, 0.82389937, 0.83647799,\n",
      "       0.83647799, 0.81761006, 0.82389937, 0.83647799, 0.83647799,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.83647799, 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.82389937, 0.82389937,\n",
      "       0.83647799, 0.83647799, 0.82389937, 0.83018868, 0.8427673 ,\n",
      "       0.83647799, 0.81761006, 0.81761006, 0.81761006, 0.83647799,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.79874214,\n",
      "       0.79245283, 0.81132075, 0.82389937, 0.78616352, 0.78616352,\n",
      "       0.82389937, 0.82389937, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.82389937, 0.83018868, 0.83018868, 0.83018868, 0.83018868,\n",
      "       0.79245283, 0.79245283, 0.79245283, 0.82389937, 0.79245283,\n",
      "       0.78616352, 0.79245283, 0.82389937, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.82389937, 0.83018868, 0.83018868, 0.83018868,\n",
      "       0.83018868, 0.78616352, 0.80503145, 0.78616352, 0.82389937,\n",
      "       0.79874214, 0.80503145, 0.79245283, 0.82389937, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.82389937, 0.83018868, 0.83018868,\n",
      "       0.83018868, 0.83018868, 0.77987421, 0.79874214, 0.77987421,\n",
      "       0.81761006, 0.79245283, 0.79874214, 0.78616352, 0.81761006,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.81761006, 0.83018868,\n",
      "       0.83018868, 0.83018868, 0.83018868, 0.78616352, 0.80503145,\n",
      "       0.79245283, 0.81761006, 0.81132075, 0.80503145, 0.81132075,\n",
      "       0.81761006, 0.79245283, 0.79245283, 0.79245283, 0.81761006,\n",
      "       0.83018868, 0.83018868, 0.83018868, 0.83018868, 0.77987421,\n",
      "       0.80503145, 0.79245283, 0.81761006, 0.80503145, 0.80503145,\n",
      "       0.79874214, 0.81761006, 0.79245283, 0.79245283, 0.79245283,\n",
      "       0.81761006, 0.83018868, 0.83018868, 0.83018868, 0.83018868,\n",
      "       0.79245283, 0.80503145, 0.79874214, 0.81761006, 0.80503145,\n",
      "       0.80503145, 0.78616352, 0.81761006, 0.79245283, 0.79245283,\n",
      "       0.79245283, 0.81761006, 0.83018868, 0.83018868, 0.83018868,\n",
      "       0.83018868, 0.78616352, 0.80503145, 0.78616352, 0.81761006,\n",
      "       0.80503145, 0.81132075, 0.80503145, 0.81761006, 0.79245283,\n",
      "       0.79245283, 0.79245283, 0.81761006, 0.83018868, 0.83018868,\n",
      "       0.83018868, 0.83018868, 0.78616352, 0.79245283, 0.78616352,\n",
      "       0.81761006, 0.81761006, 0.80503145, 0.79245283, 0.81761006,\n",
      "       0.79245283, 0.79245283, 0.79245283, 0.81761006, 0.83018868,\n",
      "       0.83018868, 0.83018868, 0.83018868, 0.77358491, 0.79245283,\n",
      "       0.77987421, 0.81761006, 0.81132075, 0.80503145, 0.79874214,\n",
      "       0.81761006, 0.79245283, 0.79245283, 0.79245283, 0.81761006,\n",
      "       0.83018868, 0.83018868, 0.83018868, 0.83018868, 0.79245283,\n",
      "       0.80503145, 0.80503145, 0.81761006, 0.81132075, 0.80503145,\n",
      "       0.79245283, 0.81761006, 0.79245283, 0.79245283, 0.79245283,\n",
      "       0.81761006, 0.83018868, 0.83018868, 0.83018868, 0.83018868]), 'split7_test_score': array([0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77987421, 0.77987421, 0.77987421, 0.77987421,\n",
      "       0.77987421, 0.77987421, 0.77987421, 0.77987421, 0.77987421,\n",
      "       0.77987421, 0.77987421, 0.77987421, 0.77987421, 0.77987421,\n",
      "       0.77987421, 0.77987421, 0.82389937, 0.82389937, 0.82389937,\n",
      "       0.81761006, 0.82389937, 0.82389937, 0.82389937, 0.81761006,\n",
      "       0.82389937, 0.82389937, 0.82389937, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.82389937, 0.81761006, 0.81761006, 0.81761006, 0.82389937,\n",
      "       0.81761006, 0.82389937, 0.82389937, 0.82389937, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.82389937, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.82389937, 0.81761006, 0.82389937, 0.82389937, 0.82389937,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.79874214, 0.79874214, 0.80503145, 0.80503145, 0.81761006,\n",
      "       0.81761006, 0.82389937, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.77987421, 0.77987421, 0.78616352, 0.79874214,\n",
      "       0.78616352, 0.78616352, 0.79245283, 0.79874214, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.79245283, 0.77987421, 0.77358491,\n",
      "       0.79245283, 0.81132075, 0.80503145, 0.79874214, 0.79874214,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.77358491, 0.77358491,\n",
      "       0.76100629, 0.77987421, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.80503145, 0.81132075, 0.80503145, 0.81132075,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81761006, 0.78616352,\n",
      "       0.79245283, 0.76100629, 0.78616352, 0.79245283, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.81132075, 0.81761006, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.77358491, 0.77987421, 0.76100629, 0.77987421, 0.78616352,\n",
      "       0.79245283, 0.78616352, 0.78616352, 0.81132075, 0.80503145,\n",
      "       0.81132075, 0.81132075, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.79245283, 0.78616352, 0.76100629, 0.78616352,\n",
      "       0.78616352, 0.79874214, 0.78616352, 0.78616352, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.81132075, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.77358491, 0.77987421, 0.75471698,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.77987421, 0.78616352,\n",
      "       0.81132075, 0.80503145, 0.81132075, 0.81132075, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.77358491, 0.76100629,\n",
      "       0.76100629, 0.78616352, 0.78616352, 0.79245283, 0.77987421,\n",
      "       0.78616352, 0.81132075, 0.81132075, 0.80503145, 0.81132075,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81761006, 0.7672956 ,\n",
      "       0.77987421, 0.76100629, 0.77987421, 0.78616352, 0.79245283,\n",
      "       0.77987421, 0.78616352, 0.81132075, 0.81132075, 0.80503145,\n",
      "       0.81132075, 0.81761006, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.7672956 , 0.78616352, 0.75471698, 0.77987421, 0.77987421,\n",
      "       0.79245283, 0.77987421, 0.78616352, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.72955975, 0.79245283, 0.76100629, 0.77987421,\n",
      "       0.77987421, 0.79245283, 0.77987421, 0.78616352, 0.80503145,\n",
      "       0.80503145, 0.81132075, 0.81132075, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.74213836, 0.77987421, 0.76100629,\n",
      "       0.77987421, 0.77987421, 0.78616352, 0.77987421, 0.78616352,\n",
      "       0.80503145, 0.81132075, 0.80503145, 0.81132075, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.74213836, 0.78616352,\n",
      "       0.75471698, 0.78616352, 0.77987421, 0.79245283, 0.77987421,\n",
      "       0.78616352, 0.80503145, 0.81132075, 0.80503145, 0.81132075,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81761006, 0.72327044,\n",
      "       0.78616352, 0.76100629, 0.77987421, 0.77987421, 0.78616352,\n",
      "       0.77987421, 0.78616352, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.81132075, 0.81761006, 0.81761006, 0.81761006, 0.81761006]), 'split8_test_score': array([0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 , 0.85534591,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.83647799, 0.8427673 , 0.8427673 , 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.83018868, 0.83647799, 0.8427673 , 0.8490566 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8490566 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.83018868, 0.83647799, 0.8427673 ,\n",
      "       0.8490566 , 0.83647799, 0.83647799, 0.83647799, 0.8427673 ,\n",
      "       0.83647799, 0.83647799, 0.8427673 , 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.83647799, 0.83018868,\n",
      "       0.83018868, 0.83647799, 0.8490566 , 0.8490566 , 0.83647799,\n",
      "       0.8427673 , 0.8427673 , 0.83647799, 0.83647799, 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 , 0.83018868,\n",
      "       0.82389937, 0.83018868, 0.83647799, 0.8427673 , 0.8427673 ,\n",
      "       0.83647799, 0.8427673 , 0.83647799, 0.8427673 , 0.83647799,\n",
      "       0.8427673 , 0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.83018868, 0.82389937, 0.83018868, 0.8427673 , 0.83647799,\n",
      "       0.83647799, 0.83647799, 0.8427673 , 0.8427673 , 0.83647799,\n",
      "       0.8427673 , 0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.81761006, 0.81761006, 0.82389937, 0.8427673 ,\n",
      "       0.83647799, 0.83647799, 0.83647799, 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.83647799, 0.8427673 , 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.82389937, 0.81761006, 0.82389937,\n",
      "       0.8427673 , 0.83647799, 0.82389937, 0.83647799, 0.8427673 ,\n",
      "       0.83647799, 0.83647799, 0.8427673 , 0.8427673 , 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.80503145, 0.82389937,\n",
      "       0.82389937, 0.8427673 , 0.83647799, 0.83018868, 0.83647799,\n",
      "       0.8427673 , 0.83647799, 0.83647799, 0.83647799, 0.8427673 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 , 0.79245283,\n",
      "       0.81132075, 0.81761006, 0.8427673 , 0.83018868, 0.82389937,\n",
      "       0.83647799, 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.78616352, 0.80503145, 0.81132075, 0.8427673 , 0.83018868,\n",
      "       0.82389937, 0.83018868, 0.8427673 , 0.83647799, 0.83647799,\n",
      "       0.83018868, 0.8427673 , 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.79245283, 0.80503145, 0.81132075, 0.8427673 ,\n",
      "       0.82389937, 0.83018868, 0.83018868, 0.8427673 , 0.83018868,\n",
      "       0.83018868, 0.83647799, 0.8427673 , 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.76100629, 0.80503145, 0.81132075,\n",
      "       0.8427673 , 0.82389937, 0.81761006, 0.83018868, 0.8427673 ,\n",
      "       0.83018868, 0.83647799, 0.83018868, 0.8427673 , 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.79245283, 0.80503145,\n",
      "       0.81132075, 0.8427673 , 0.81761006, 0.83018868, 0.83018868,\n",
      "       0.8427673 , 0.83647799, 0.83647799, 0.83647799, 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 , 0.77358491,\n",
      "       0.80503145, 0.81132075, 0.8427673 , 0.81761006, 0.81761006,\n",
      "       0.83018868, 0.8427673 , 0.83018868, 0.83647799, 0.83018868,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 ]), 'split9_test_score': array([0.80379747, 0.80379747, 0.80379747, 0.80379747, 0.80379747,\n",
      "       0.80379747, 0.80379747, 0.80379747, 0.80379747, 0.80379747,\n",
      "       0.80379747, 0.80379747, 0.80379747, 0.80379747, 0.80379747,\n",
      "       0.80379747, 0.79746835, 0.79746835, 0.79746835, 0.79746835,\n",
      "       0.79746835, 0.79746835, 0.79746835, 0.79746835, 0.79746835,\n",
      "       0.79746835, 0.79746835, 0.79746835, 0.79746835, 0.79746835,\n",
      "       0.79746835, 0.79746835, 0.86075949, 0.86075949, 0.86075949,\n",
      "       0.84810127, 0.86075949, 0.86075949, 0.86075949, 0.84810127,\n",
      "       0.86075949, 0.86075949, 0.86075949, 0.84810127, 0.84810127,\n",
      "       0.84810127, 0.84810127, 0.84810127, 0.86708861, 0.86708861,\n",
      "       0.86708861, 0.85443038, 0.86708861, 0.86708861, 0.86708861,\n",
      "       0.85443038, 0.86075949, 0.86075949, 0.86075949, 0.84810127,\n",
      "       0.84810127, 0.84810127, 0.84810127, 0.84810127, 0.86708861,\n",
      "       0.86075949, 0.86708861, 0.85443038, 0.86708861, 0.86075949,\n",
      "       0.86708861, 0.85443038, 0.86075949, 0.86075949, 0.86075949,\n",
      "       0.84810127, 0.84810127, 0.84810127, 0.84810127, 0.84810127,\n",
      "       0.86708861, 0.86075949, 0.86708861, 0.85443038, 0.86708861,\n",
      "       0.86075949, 0.86708861, 0.85443038, 0.86075949, 0.86075949,\n",
      "       0.86075949, 0.84810127, 0.84810127, 0.84810127, 0.84810127,\n",
      "       0.84810127, 0.86075949, 0.85443038, 0.86708861, 0.85443038,\n",
      "       0.86708861, 0.86075949, 0.86708861, 0.85443038, 0.85443038,\n",
      "       0.85443038, 0.86075949, 0.84177215, 0.84810127, 0.84810127,\n",
      "       0.84810127, 0.84810127, 0.85443038, 0.84810127, 0.86075949,\n",
      "       0.85443038, 0.86075949, 0.85443038, 0.86075949, 0.85443038,\n",
      "       0.84810127, 0.84810127, 0.84810127, 0.84177215, 0.84177215,\n",
      "       0.84177215, 0.84177215, 0.84177215, 0.84177215, 0.82911392,\n",
      "       0.84810127, 0.84177215, 0.85443038, 0.84810127, 0.85443038,\n",
      "       0.85443038, 0.84810127, 0.84810127, 0.84810127, 0.84177215,\n",
      "       0.84177215, 0.84177215, 0.84177215, 0.84177215, 0.84177215,\n",
      "       0.82911392, 0.84810127, 0.84177215, 0.85443038, 0.84810127,\n",
      "       0.85443038, 0.85443038, 0.84177215, 0.84177215, 0.84177215,\n",
      "       0.83544304, 0.84177215, 0.84177215, 0.84177215, 0.84177215,\n",
      "       0.82911392, 0.82911392, 0.84810127, 0.83544304, 0.84810127,\n",
      "       0.84810127, 0.86075949, 0.85443038, 0.82278481, 0.82278481,\n",
      "       0.82278481, 0.82278481, 0.82911392, 0.82911392, 0.82911392,\n",
      "       0.82911392, 0.82278481, 0.82278481, 0.84177215, 0.83544304,\n",
      "       0.84177215, 0.84177215, 0.84810127, 0.85443038, 0.8164557 ,\n",
      "       0.8164557 , 0.8164557 , 0.82911392, 0.82911392, 0.82911392,\n",
      "       0.82911392, 0.82911392, 0.82278481, 0.8164557 , 0.83544304,\n",
      "       0.84177215, 0.83544304, 0.83544304, 0.84810127, 0.85443038,\n",
      "       0.8164557 , 0.8164557 , 0.8164557 , 0.82911392, 0.82911392,\n",
      "       0.82911392, 0.82911392, 0.82911392, 0.80379747, 0.79746835,\n",
      "       0.82278481, 0.84177215, 0.82911392, 0.82911392, 0.83544304,\n",
      "       0.85443038, 0.8164557 , 0.8164557 , 0.8164557 , 0.82911392,\n",
      "       0.82911392, 0.82911392, 0.82911392, 0.82911392, 0.80379747,\n",
      "       0.79746835, 0.82278481, 0.84177215, 0.82911392, 0.82911392,\n",
      "       0.84177215, 0.85443038, 0.8164557 , 0.8164557 , 0.8164557 ,\n",
      "       0.82278481, 0.82911392, 0.82911392, 0.82911392, 0.82911392,\n",
      "       0.79746835, 0.80379747, 0.82278481, 0.84177215, 0.82911392,\n",
      "       0.82911392, 0.84177215, 0.85443038, 0.8164557 , 0.8164557 ,\n",
      "       0.8164557 , 0.82278481, 0.82911392, 0.82911392, 0.82911392,\n",
      "       0.82911392, 0.79746835, 0.79746835, 0.82911392, 0.83544304,\n",
      "       0.82911392, 0.82911392, 0.83544304, 0.85443038, 0.8164557 ,\n",
      "       0.8164557 , 0.8164557 , 0.82911392, 0.82911392, 0.82911392,\n",
      "       0.82911392, 0.82911392, 0.79746835, 0.79746835, 0.82278481,\n",
      "       0.83544304, 0.82911392, 0.82911392, 0.84177215, 0.85443038,\n",
      "       0.8164557 , 0.8164557 , 0.8164557 , 0.82278481, 0.82911392,\n",
      "       0.82911392, 0.82911392, 0.82911392, 0.8164557 , 0.80379747,\n",
      "       0.82911392, 0.83544304, 0.82911392, 0.82911392, 0.83544304,\n",
      "       0.85443038, 0.8164557 , 0.8164557 , 0.8164557 , 0.82278481,\n",
      "       0.82911392, 0.82911392, 0.82911392, 0.82911392, 0.81012658,\n",
      "       0.80379747, 0.82911392, 0.84177215, 0.82911392, 0.82911392,\n",
      "       0.83544304, 0.85443038, 0.8164557 , 0.8164557 , 0.8164557 ,\n",
      "       0.82278481, 0.82911392, 0.82911392, 0.82911392, 0.82911392]), 'mean_test_score': array([0.78478226, 0.78478226, 0.78478226, 0.78478226, 0.78478226,\n",
      "       0.78478226, 0.78478226, 0.78478226, 0.78478226, 0.78478226,\n",
      "       0.78478226, 0.78478226, 0.78478226, 0.78478226, 0.78478226,\n",
      "       0.78478226, 0.78540721, 0.78540721, 0.78540721, 0.78540721,\n",
      "       0.78540721, 0.78540721, 0.78540721, 0.78540721, 0.78540721,\n",
      "       0.78540721, 0.78540721, 0.78540721, 0.78540721, 0.78540721,\n",
      "       0.78540721, 0.78540721, 0.83324576, 0.83324576, 0.83324576,\n",
      "       0.83009315, 0.83324576, 0.83324576, 0.83324576, 0.83009315,\n",
      "       0.83324576, 0.83324576, 0.83324576, 0.83009315, 0.83009315,\n",
      "       0.83009315, 0.83009315, 0.83009315, 0.83199188, 0.83199188,\n",
      "       0.83262081, 0.8294682 , 0.83199188, 0.83199188, 0.83262081,\n",
      "       0.8294682 , 0.8319879 , 0.8319879 , 0.8319879 , 0.82883528,\n",
      "       0.83009315, 0.83009315, 0.83009315, 0.83009315, 0.83073402,\n",
      "       0.82947218, 0.83073402, 0.8275814 , 0.83073402, 0.83010111,\n",
      "       0.83136295, 0.82821033, 0.83010111, 0.83010111, 0.83010111,\n",
      "       0.82757742, 0.82883528, 0.82883528, 0.82883528, 0.82883528,\n",
      "       0.82192899, 0.82318287, 0.82570257, 0.82443675, 0.8263315 ,\n",
      "       0.82569859, 0.82884723, 0.82632354, 0.82569859, 0.82569859,\n",
      "       0.82569859, 0.82317491, 0.82694849, 0.82694849, 0.82694849,\n",
      "       0.82694849, 0.81060425, 0.80997134, 0.81626861, 0.81814744,\n",
      "       0.81186609, 0.81249104, 0.81626861, 0.81814744, 0.81877637,\n",
      "       0.8194053 , 0.81940928, 0.81813948, 0.82757742, 0.82757742,\n",
      "       0.82757742, 0.82757742, 0.80619775, 0.80367805, 0.80934639,\n",
      "       0.81437386, 0.80934639, 0.80871348, 0.81123318, 0.81500279,\n",
      "       0.81436988, 0.81374094, 0.81436988, 0.81625269, 0.82568665,\n",
      "       0.82568665, 0.82568665, 0.82568665, 0.79990049, 0.79611894,\n",
      "       0.80242019, 0.80618979, 0.80431096, 0.80367805, 0.80619775,\n",
      "       0.81060027, 0.80933843, 0.81059629, 0.80996736, 0.81310803,\n",
      "       0.82442879, 0.82442879, 0.82442879, 0.82442879, 0.79801369,\n",
      "       0.79045856, 0.7986466 , 0.80556086, 0.79927952, 0.79738874,\n",
      "       0.80368203, 0.80934241, 0.80807659, 0.80933445, 0.80807659,\n",
      "       0.8099594 , 0.82317093, 0.82317093, 0.82317093, 0.82317093,\n",
      "       0.78731391, 0.78416925, 0.79361516, 0.80367009, 0.79487302,\n",
      "       0.79487302, 0.79802563, 0.80871348, 0.80554892, 0.80429106,\n",
      "       0.80554892, 0.80869358, 0.8219051 , 0.8219051 , 0.8219051 ,\n",
      "       0.8219051 , 0.78919672, 0.78730993, 0.79109545, 0.80492795,\n",
      "       0.79424011, 0.79738476, 0.79801767, 0.80934241, 0.80302922,\n",
      "       0.80365815, 0.80365815, 0.80932649, 0.8219051 , 0.8219051 ,\n",
      "       0.8219051 , 0.8219051 , 0.78290741, 0.7822745 , 0.78668896,\n",
      "       0.80493193, 0.79297827, 0.7936072 , 0.79424409, 0.80871348,\n",
      "       0.80114242, 0.80114242, 0.80177136, 0.80743969, 0.8219051 ,\n",
      "       0.8219051 , 0.8219051 , 0.8219051 , 0.7753483 , 0.77786004,\n",
      "       0.786681  , 0.80556086, 0.78794284, 0.79108749, 0.7936072 ,\n",
      "       0.80808455, 0.80051349, 0.80051349, 0.80051349, 0.80681076,\n",
      "       0.8219051 , 0.8219051 , 0.8219051 , 0.8219051 , 0.76968792,\n",
      "       0.77597325, 0.78605207, 0.80493193, 0.78794284, 0.7892007 ,\n",
      "       0.79298225, 0.80871348, 0.80114242, 0.80177136, 0.80051349,\n",
      "       0.80617785, 0.8219051 , 0.8219051 , 0.8219051 , 0.8219051 ,\n",
      "       0.76905501, 0.77597723, 0.78164955, 0.80367407, 0.78668498,\n",
      "       0.78982963, 0.78983759, 0.80682669, 0.80114242, 0.80051349,\n",
      "       0.80051349, 0.80680678, 0.8219051 , 0.8219051 , 0.8219051 ,\n",
      "       0.8219051 , 0.76591036, 0.77660218, 0.78228246, 0.80304116,\n",
      "       0.78668498, 0.79108749, 0.79046254, 0.80808455, 0.79925563,\n",
      "       0.79925563, 0.80114242, 0.80806863, 0.8219051 , 0.8219051 ,\n",
      "       0.8219051 , 0.8219051 , 0.75899212, 0.77345753, 0.78102062,\n",
      "       0.80367009, 0.79108749, 0.78982963, 0.78983759, 0.80745562,\n",
      "       0.80114242, 0.80177136, 0.79925563, 0.80680678, 0.8219051 ,\n",
      "       0.8219051 , 0.8219051 , 0.8219051 , 0.76214871, 0.77346151,\n",
      "       0.77976674, 0.80367009, 0.78542712, 0.79045856, 0.78857575,\n",
      "       0.80808455, 0.80051349, 0.80114242, 0.80051349, 0.80743571,\n",
      "       0.8219051 , 0.8219051 , 0.8219051 , 0.8219051 , 0.76277366,\n",
      "       0.7753483 , 0.78354032, 0.80493193, 0.78857177, 0.7892007 ,\n",
      "       0.78983361, 0.80745562, 0.80051349, 0.80051349, 0.79988456,\n",
      "       0.80806464, 0.8219051 , 0.8219051 , 0.8219051 , 0.8219051 ]), 'std_test_score': array([0.0180514 , 0.0180514 , 0.0180514 , 0.0180514 , 0.0180514 ,\n",
      "       0.0180514 , 0.0180514 , 0.0180514 , 0.0180514 , 0.0180514 ,\n",
      "       0.0180514 , 0.0180514 , 0.0180514 , 0.0180514 , 0.0180514 ,\n",
      "       0.0180514 , 0.01734827, 0.01734827, 0.01734827, 0.01734827,\n",
      "       0.01734827, 0.01734827, 0.01734827, 0.01734827, 0.01734827,\n",
      "       0.01734827, 0.01734827, 0.01734827, 0.01734827, 0.01734827,\n",
      "       0.01734827, 0.01734827, 0.02572199, 0.02572199, 0.02572199,\n",
      "       0.02571007, 0.02572199, 0.02572199, 0.02572199, 0.02571007,\n",
      "       0.02572199, 0.02572199, 0.02572199, 0.02571007, 0.02571007,\n",
      "       0.02571007, 0.02571007, 0.02571007, 0.02220052, 0.02220052,\n",
      "       0.02187082, 0.02120956, 0.02220052, 0.02220052, 0.02187082,\n",
      "       0.02120956, 0.0209358 , 0.0209358 , 0.0209358 , 0.02053906,\n",
      "       0.02571007, 0.02571007, 0.02571007, 0.02571007, 0.02510589,\n",
      "       0.02365793, 0.02347754, 0.02260112, 0.02381212, 0.02290423,\n",
      "       0.02268289, 0.02186538, 0.02129328, 0.02129328, 0.02129328,\n",
      "       0.02117806, 0.0259809 , 0.0259809 , 0.0259809 , 0.0259809 ,\n",
      "       0.02548337, 0.02461834, 0.02534013, 0.02480034, 0.02325016,\n",
      "       0.02219423, 0.0228474 , 0.02345497, 0.02642483, 0.02642483,\n",
      "       0.02642483, 0.0265104 , 0.02822894, 0.02822894, 0.02822894,\n",
      "       0.02822894, 0.03235553, 0.03216309, 0.03324637, 0.03063102,\n",
      "       0.03593997, 0.03395325, 0.03252467, 0.03050161, 0.03118955,\n",
      "       0.02992941, 0.0319613 , 0.03155255, 0.02808356, 0.02808356,\n",
      "       0.02808356, 0.02808356, 0.03190534, 0.03288733, 0.03326836,\n",
      "       0.03210793, 0.030411  , 0.03031059, 0.03040993, 0.03045972,\n",
      "       0.0256901 , 0.0245782 , 0.02522396, 0.03070145, 0.02807513,\n",
      "       0.02807513, 0.02807513, 0.02807513, 0.03240493, 0.03271533,\n",
      "       0.03525227, 0.03193254, 0.03616001, 0.03717792, 0.03215234,\n",
      "       0.03368463, 0.03004465, 0.02983729, 0.02988164, 0.03436951,\n",
      "       0.02949979, 0.02949979, 0.02949979, 0.02949979, 0.03308174,\n",
      "       0.03386739, 0.03453915, 0.032011  , 0.03245721, 0.0321389 ,\n",
      "       0.032268  , 0.03292101, 0.02873753, 0.02871435, 0.02688869,\n",
      "       0.03281561, 0.02895416, 0.02895416, 0.02895416, 0.02895416,\n",
      "       0.03299953, 0.03313883, 0.03333614, 0.03181625, 0.03290986,\n",
      "       0.03180973, 0.03232146, 0.03329561, 0.02697083, 0.02768936,\n",
      "       0.02667589, 0.03313562, 0.02838436, 0.02838436, 0.02838436,\n",
      "       0.02838436, 0.02255214, 0.02738361, 0.03074871, 0.03121796,\n",
      "       0.03040318, 0.0299878 , 0.03109616, 0.03280064, 0.0273629 ,\n",
      "       0.02860237, 0.02718427, 0.03213082, 0.02838436, 0.02838436,\n",
      "       0.02838436, 0.02838436, 0.02610059, 0.02870948, 0.03318016,\n",
      "       0.03157983, 0.02994223, 0.02850288, 0.03203708, 0.03257501,\n",
      "       0.02558411, 0.025273  , 0.02528369, 0.02944551, 0.02838436,\n",
      "       0.02838436, 0.02838436, 0.02838436, 0.02595362, 0.03047559,\n",
      "       0.03403423, 0.0310067 , 0.03478143, 0.03141554, 0.03371599,\n",
      "       0.0330614 , 0.02396046, 0.02445071, 0.02493131, 0.02995598,\n",
      "       0.02838436, 0.02838436, 0.02838436, 0.02838436, 0.02421483,\n",
      "       0.03048717, 0.03181555, 0.0331682 , 0.03409225, 0.03281939,\n",
      "       0.03282649, 0.03257501, 0.02542903, 0.02480991, 0.02647038,\n",
      "       0.02954207, 0.02838436, 0.02838436, 0.02838436, 0.02838436,\n",
      "       0.02699521, 0.03085158, 0.03420329, 0.03454316, 0.03504945,\n",
      "       0.03364862, 0.03431936, 0.03432587, 0.02558411, 0.02571236,\n",
      "       0.02294858, 0.02903804, 0.02838436, 0.02838436, 0.02838436,\n",
      "       0.02838436, 0.02664846, 0.02749508, 0.03254854, 0.03196924,\n",
      "       0.03110303, 0.032529  , 0.03180437, 0.0330614 , 0.02318237,\n",
      "       0.02318237, 0.02542903, 0.02931992, 0.02838436, 0.02838436,\n",
      "       0.02838436, 0.02838436, 0.02528153, 0.02656566, 0.03177303,\n",
      "       0.03131501, 0.0315412 , 0.02870013, 0.03242285, 0.03364671,\n",
      "       0.02365615, 0.02528369, 0.02318237, 0.02944386, 0.02838436,\n",
      "       0.02838436, 0.02838436, 0.02838436, 0.02871122, 0.02799079,\n",
      "       0.03251591, 0.03156662, 0.03234562, 0.03327829, 0.03218769,\n",
      "       0.0330614 , 0.02524663, 0.02365615, 0.02396046, 0.0302611 ,\n",
      "       0.02838436, 0.02838436, 0.02838436, 0.02838436, 0.02821148,\n",
      "       0.02991823, 0.03303517, 0.0331682 , 0.03120477, 0.03018244,\n",
      "       0.03157138, 0.03364671, 0.0237948 , 0.02345998, 0.02440725,\n",
      "       0.02974266, 0.02838436, 0.02838436, 0.02838436, 0.02838436]), 'rank_test_score': array([283, 283, 283, 283, 283, 283, 283, 283, 283, 283, 283, 283, 283,\n",
      "       283, 283, 283, 267, 267, 267, 267, 267, 267, 267, 267, 267, 267,\n",
      "       267, 267, 267, 267, 267, 267,   1,   1,   1,  27,   1,   1,   1,\n",
      "        27,   1,   1,   1,  27,  27,  27,  27,  27,  12,  12,  10,  39,\n",
      "        12,  12,  10,  39,  16,  16,  16,  42,  27,  27,  27,  27,  20,\n",
      "        38,  20,  48,  20,  23,  19,  47,  23,  23,  23,  49,  42,  42,\n",
      "        42,  42,  80,  74,  60,  69,  58,  64,  41,  59,  61,  61,  61,\n",
      "        75,  54,  54,  54,  54, 139, 142, 127, 124, 137, 136, 127, 125,\n",
      "       123, 122, 121, 126,  49,  49,  49,  49, 173, 187, 145, 131, 145,\n",
      "       152, 138, 130, 132, 134, 132, 129,  65,  65,  65,  65, 218, 230,\n",
      "       197, 174, 184, 187, 172, 140, 149, 141, 143, 135,  70,  70,  70,\n",
      "        70, 227, 245, 224, 177, 220, 228, 186, 147, 160, 150, 160, 144,\n",
      "        76,  76,  76,  76, 259, 299, 235, 190, 231, 231, 225, 152, 178,\n",
      "       185, 178, 156,  81,  81,  81,  81, 254, 260, 240, 183, 234, 229,\n",
      "       226, 147, 196, 193, 193, 151,  81,  81,  81,  81, 301, 303, 261,\n",
      "       180, 239, 236, 233, 152, 201, 201, 198, 166,  81,  81,  81,  81,\n",
      "       311, 307, 264, 176, 258, 242, 237, 157, 208, 208, 208, 169,  81,\n",
      "        81,  81,  81, 315, 310, 265, 180, 257, 252, 238, 152, 201, 198,\n",
      "       208, 175,  81,  81,  81,  81, 316, 309, 304, 189, 263, 250, 247,\n",
      "       168, 201, 208, 208, 170,  81,  81,  81,  81, 317, 308, 302, 195,\n",
      "       262, 242, 244, 157, 221, 221, 201, 162,  81,  81,  81,  81, 320,\n",
      "       314, 305, 190, 241, 250, 248, 164, 201, 198, 221, 170,  81,  81,\n",
      "        81,  81, 319, 313, 306, 190, 266, 245, 255, 157, 208, 201, 208,\n",
      "       167,  81,  81,  81,  81, 318, 311, 300, 180, 256, 252, 249, 164,\n",
      "       208, 208, 219, 163,  81,  81,  81,  81])}\n",
      "Resultados para Balanced:\n",
      "{'mean_fit_time': array([0.00099897, 0.00099981, 0.00110066, 0.00100007, 0.0010983 ,\n",
      "       0.0010005 , 0.0010006 , 0.00100172, 0.00119996, 0.00120003,\n",
      "       0.00099983, 0.00099869, 0.00120077, 0.00110011, 0.00110037,\n",
      "       0.0010998 , 0.00140016, 0.00110145, 0.00100036, 0.00159998,\n",
      "       0.00169981, 0.00148411, 0.00140018, 0.00169978, 0.00099995,\n",
      "       0.00109851, 0.00100048, 0.00139976, 0.00109932, 0.00100043,\n",
      "       0.00149903, 0.00150068, 0.00159936, 0.00099959, 0.00150046,\n",
      "       0.00119929, 0.00129869, 0.001403  , 0.00120001, 0.00130041,\n",
      "       0.00129888, 0.00129938, 0.00130043, 0.00130048, 0.00130045,\n",
      "       0.00109978, 0.00140116, 0.00139985, 0.00140011, 0.00142457,\n",
      "       0.00167422, 0.00140026, 0.0015008 , 0.0013514 , 0.00149879,\n",
      "       0.00140102, 0.00159972, 0.00139904, 0.00160208, 0.0015866 ,\n",
      "       0.00152788, 0.00135505, 0.00150092, 0.00137873, 0.00169933,\n",
      "       0.00159774, 0.00170035, 0.0016978 , 0.00155039, 0.00160007,\n",
      "       0.00154514, 0.00140078, 0.00159459, 0.0016988 , 0.00155227,\n",
      "       0.00160089, 0.00170078, 0.00159707, 0.00154996, 0.00159929,\n",
      "       0.00169764, 0.00185034, 0.00175192, 0.00190012, 0.00169809,\n",
      "       0.00170257, 0.0016001 , 0.00196931, 0.00160012, 0.00167427,\n",
      "       0.00159922, 0.00157855, 0.001845  , 0.00190098, 0.00180051,\n",
      "       0.00159962, 0.00200043, 0.0018995 , 0.00189869, 0.00189905,\n",
      "       0.0018517 , 0.00176563, 0.00199983, 0.00180035, 0.00189924,\n",
      "       0.00206938, 0.00210011, 0.00170035, 0.00199935, 0.00168672,\n",
      "       0.00169981, 0.00189922, 0.00200028, 0.002     , 0.00189986,\n",
      "       0.00172591, 0.00200033, 0.00202301, 0.00188785, 0.00190015,\n",
      "       0.00180094, 0.00179946, 0.00199633, 0.0020005 , 0.00179999,\n",
      "       0.00189989, 0.00180061, 0.00200062, 0.00219944, 0.00199926,\n",
      "       0.00198476, 0.00191088, 0.00199988, 0.00199952, 0.00199983,\n",
      "       0.00199885, 0.00200095, 0.00199864, 0.00195112, 0.00195093,\n",
      "       0.00180061, 0.00184927, 0.00191374, 0.00211565, 0.00219946,\n",
      "       0.00227871, 0.00240018, 0.00223434, 0.00258307, 0.0025279 ,\n",
      "       0.00252562, 0.00220768, 0.0024008 , 0.00215018, 0.00234365,\n",
      "       0.00229931, 0.00227852, 0.00226266, 0.00220976, 0.00229888,\n",
      "       0.00247421, 0.00227613, 0.00238433, 0.00236936, 0.00253813,\n",
      "       0.00283031, 0.00237849, 0.00245171, 0.00210013, 0.00230064,\n",
      "       0.00250258, 0.00239995, 0.00218377, 0.0022368 , 0.00210001,\n",
      "       0.00200052, 0.00236897, 0.00230017, 0.0022563 , 0.00220046,\n",
      "       0.00231717, 0.00275187, 0.002249  , 0.00239742, 0.00231328,\n",
      "       0.00239923, 0.0023011 , 0.00240059, 0.00215027, 0.00210042,\n",
      "       0.00224159, 0.00203001, 0.00260136, 0.00239885, 0.00240052,\n",
      "       0.00251598, 0.00236411, 0.00255892, 0.00251539, 0.00226424,\n",
      "       0.00285654, 0.00238783, 0.00231683, 0.00223572, 0.00238075,\n",
      "       0.00216711, 0.00226357, 0.00201843, 0.00268281, 0.00240011,\n",
      "       0.00229986, 0.00200038, 0.00239749, 0.00240033, 0.00209959,\n",
      "       0.00202689, 0.00219984, 0.00207171, 0.00239954, 0.00259969,\n",
      "       0.00200052, 0.00210018, 0.00250154, 0.00200009, 0.00250092,\n",
      "       0.00249801, 0.00262456, 0.00255861, 0.00231128, 0.00230057,\n",
      "       0.00220025, 0.00215819, 0.0022541 , 0.00231154, 0.00248795,\n",
      "       0.00240021, 0.0019726 , 0.00192945, 0.00197945, 0.00231953,\n",
      "       0.00264955, 0.00254865, 0.00230072, 0.00205357, 0.00257897,\n",
      "       0.00259516, 0.00243411, 0.00226698, 0.00245938, 0.00223999,\n",
      "       0.00219829, 0.00220084, 0.00219979, 0.00199964, 0.0022994 ,\n",
      "       0.0020575 , 0.00252738, 0.00241182, 0.00250092, 0.00229912,\n",
      "       0.00249717, 0.00277703, 0.00260081, 0.00219285, 0.00240035,\n",
      "       0.00245886, 0.00259249, 0.00229967, 0.0024224 , 0.00225334,\n",
      "       0.00217664, 0.00205197, 0.00280151, 0.00278089, 0.00249999,\n",
      "       0.00229993, 0.00239975, 0.00260084, 0.00249929, 0.00200143,\n",
      "       0.0020999 , 0.00259969, 0.00230103, 0.00244665, 0.00200005,\n",
      "       0.00223868, 0.00195887, 0.00193822, 0.00270026, 0.00256498,\n",
      "       0.00239909, 0.00199966, 0.00216718, 0.00238895, 0.00255108,\n",
      "       0.00240014, 0.00219667, 0.00247345, 0.00202444, 0.00239961,\n",
      "       0.00216796, 0.00200033, 0.00210102, 0.00200083, 0.00259752,\n",
      "       0.00250001, 0.00250185, 0.00246801, 0.00236423, 0.00240166,\n",
      "       0.00230281, 0.00199981, 0.00280008, 0.00231254, 0.00230103,\n",
      "       0.00200102, 0.0020993 , 0.00210018, 0.00200138, 0.00209997]), 'std_fit_time': array([2.66560075e-06, 2.55953199e-06, 2.99737828e-04, 2.21408592e-06,\n",
      "       3.00374411e-04, 2.11964710e-06, 3.08620856e-06, 4.05627016e-06,\n",
      "       4.00426158e-04, 4.01465145e-04, 7.08869398e-07, 1.91270553e-06,\n",
      "       3.98833056e-04, 2.99919557e-04, 3.01914090e-04, 3.00033682e-04,\n",
      "       4.89892736e-04, 2.99182920e-04, 4.00486443e-06, 4.89700952e-04,\n",
      "       4.58804431e-04, 4.85623669e-04, 4.90366242e-04, 4.57385650e-04,\n",
      "       4.13427716e-06, 3.00359878e-04, 1.84385598e-06, 4.89737738e-04,\n",
      "       3.00020553e-04, 2.79560399e-06, 4.98870070e-04, 4.99471936e-04,\n",
      "       4.90075253e-04, 1.91389391e-06, 4.99966594e-04, 3.98861055e-04,\n",
      "       4.58803008e-04, 4.93034279e-04, 4.00285010e-04, 4.57536622e-04,\n",
      "       4.58436876e-04, 4.59351072e-04, 4.57884408e-04, 4.58789847e-04,\n",
      "       4.59171050e-04, 2.99235887e-04, 4.91571707e-04, 4.89569261e-04,\n",
      "       4.89891010e-04, 4.75333531e-04, 4.46080509e-04, 4.89474115e-04,\n",
      "       4.99348983e-04, 4.51258036e-04, 4.99542663e-04, 4.89296396e-04,\n",
      "       4.89837571e-04, 4.90858786e-04, 4.90059089e-04, 4.77273087e-04,\n",
      "       4.80776515e-04, 3.92178362e-04, 5.00184178e-04, 4.69634976e-04,\n",
      "       4.59533715e-04, 4.89063612e-04, 4.58540020e-04, 4.58342420e-04,\n",
      "       4.71131652e-04, 4.87494426e-04, 4.71740905e-04, 4.89971400e-04,\n",
      "       4.95397433e-04, 4.57576774e-04, 4.73069350e-04, 4.90051398e-04,\n",
      "       4.57790930e-04, 4.93516705e-04, 4.70462593e-04, 4.89623089e-04,\n",
      "       4.57454247e-04, 3.18864513e-04, 4.01529130e-04, 2.99940523e-04,\n",
      "       4.61189631e-04, 4.58365810e-04, 4.90381998e-04, 9.22763960e-05,\n",
      "       4.91281175e-04, 4.48134243e-04, 4.90747244e-04, 4.75999328e-04,\n",
      "       4.46209225e-04, 3.00376263e-04, 4.01073917e-04, 4.89788041e-04,\n",
      "       4.47310264e-04, 3.00025365e-04, 2.99631928e-04, 2.98089703e-04,\n",
      "       3.18791411e-04, 5.36062479e-04, 2.07971530e-06, 3.99914270e-04,\n",
      "       3.00017967e-04, 2.03893311e-04, 3.00212700e-04, 4.58537640e-04,\n",
      "       2.20185721e-06, 4.64236107e-04, 4.58283666e-04, 2.99697625e-04,\n",
      "       1.72190381e-06, 9.89939665e-07, 2.99667253e-04, 4.80802298e-04,\n",
      "       2.18253946e-06, 6.55165796e-05, 2.97988981e-04, 3.00314011e-04,\n",
      "       3.29465648e-04, 3.99653338e-04, 1.22087075e-05, 4.27966330e-06,\n",
      "       4.00151036e-04, 2.99115051e-04, 3.99389977e-04, 4.45851091e-04,\n",
      "       4.00293852e-04, 1.31130219e-06, 4.50617485e-05, 3.05135262e-04,\n",
      "       1.52084145e-06, 1.16410786e-06, 1.70081204e-06, 2.95639038e-06,\n",
      "       2.34863479e-06, 2.03830456e-06, 1.47426421e-04, 3.51570501e-04,\n",
      "       3.99867166e-04, 3.18465812e-04, 3.07623831e-04, 2.97797634e-04,\n",
      "       3.98795037e-04, 4.74830891e-04, 4.89720321e-04, 3.90774353e-04,\n",
      "       4.70443790e-04, 4.79925014e-04, 4.00888257e-04, 3.98333207e-04,\n",
      "       4.91265923e-04, 5.50463800e-04, 4.61746377e-04, 4.58001036e-04,\n",
      "       4.18318300e-04, 3.56843311e-04, 4.65003595e-04, 4.59061397e-04,\n",
      "       4.79540401e-04, 4.21723754e-04, 4.73997173e-04, 5.59408649e-04,\n",
      "       4.83627878e-04, 5.90843753e-04, 4.65938648e-04, 5.64095091e-04,\n",
      "       3.01403317e-04, 4.54815523e-04, 5.49165420e-04, 4.89522760e-04,\n",
      "       3.69192893e-04, 3.97157263e-04, 2.99923019e-04, 1.08106461e-06,\n",
      "       4.77068211e-04, 4.57954047e-04, 4.08015477e-04, 4.00261698e-04,\n",
      "       9.14273337e-04, 8.43653821e-04, 4.04998701e-04, 4.86773232e-04,\n",
      "       4.52176247e-04, 4.88990187e-04, 5.08508704e-04, 4.90116335e-04,\n",
      "       6.31693789e-04, 3.00194002e-04, 3.81963878e-04, 8.90675938e-05,\n",
      "       4.92658179e-04, 4.90227842e-04, 4.89787939e-04, 4.86065388e-04,\n",
      "       4.55413860e-04, 4.74003064e-04, 5.17313500e-04, 4.45586790e-04,\n",
      "       9.48228509e-04, 5.45598433e-04, 4.48394960e-04, 4.06815796e-04,\n",
      "       4.33934733e-04, 3.90412957e-04, 3.81763084e-04, 1.74774819e-04,\n",
      "       4.17126387e-04, 4.90117645e-04, 4.58531333e-04, 3.21432105e-06,\n",
      "       4.91158242e-04, 4.90237881e-04, 2.99995440e-04, 7.55909630e-05,\n",
      "       4.00032285e-04, 2.09797897e-04, 4.88890225e-04, 4.89141308e-04,\n",
      "       1.73505835e-06, 2.98761917e-04, 4.98115628e-04, 2.10565588e-06,\n",
      "       5.00586072e-04, 5.00941335e-04, 4.07975291e-04, 5.22638217e-04,\n",
      "       4.42546139e-04, 4.57384007e-04, 3.99417164e-04, 3.29957316e-04,\n",
      "       3.98475544e-04, 4.53368975e-04, 4.84293279e-04, 4.91855932e-04,\n",
      "       2.30476740e-04, 1.52927745e-04, 6.71286298e-05, 4.93556736e-04,\n",
      "       5.49072822e-04, 4.73225503e-04, 4.59213747e-04, 8.49348157e-04,\n",
      "       4.77274777e-04, 4.83296119e-04, 4.72385515e-04, 4.15949309e-04,\n",
      "       4.74305672e-04, 3.74124514e-04, 4.00851464e-04, 3.99315064e-04,\n",
      "       3.99460965e-04, 1.75347099e-06, 4.58981887e-04, 1.74228585e-04,\n",
      "       5.32100331e-04, 5.04629112e-04, 4.99790040e-04, 4.58332515e-04,\n",
      "       4.97585703e-04, 5.60986272e-04, 4.90797269e-04, 4.06418219e-04,\n",
      "       4.89246390e-04, 4.72964725e-04, 4.69660565e-04, 4.83453955e-04,\n",
      "       4.94659651e-04, 5.78379196e-04, 3.06165518e-04, 1.61011648e-04,\n",
      "       4.00005576e-04, 5.60611775e-04, 5.00086298e-04, 4.58999498e-04,\n",
      "       4.91043818e-04, 4.89536910e-04, 4.99825122e-04, 8.12388349e-06,\n",
      "       2.99424960e-04, 4.91136503e-04, 4.58448561e-04, 4.78713374e-04,\n",
      "       2.30367133e-06, 5.72324592e-04, 4.20413026e-04, 3.20988171e-04,\n",
      "       4.55670938e-04, 4.74329291e-04, 4.90813368e-04, 3.00407410e-06,\n",
      "       3.41148609e-04, 4.74029093e-04, 4.72885110e-04, 4.89201327e-04,\n",
      "       3.95640159e-04, 4.81890004e-04, 7.48706810e-05, 4.90282612e-04,\n",
      "       3.42959262e-04, 2.08667340e-06, 2.99284328e-04, 4.26022713e-06,\n",
      "       4.89898431e-04, 5.00250313e-04, 5.00440748e-04, 5.00597268e-04,\n",
      "       4.41720580e-04, 4.87927872e-04, 4.58975668e-04, 1.35626437e-06,\n",
      "       4.00210967e-04, 4.50989489e-04, 4.57785189e-04, 4.47941477e-04,\n",
      "       3.00004845e-04, 2.98253100e-04, 2.10619572e-06, 2.98833897e-04]), 'mean_score_time': array([3.99827957e-04, 5.00893593e-04, 2.99620628e-04, 3.99971008e-04,\n",
      "       2.00104713e-04, 4.99773026e-04, 4.49538231e-04, 2.99572945e-04,\n",
      "       1.99985504e-04, 5.00011444e-04, 4.00066376e-04, 5.00082970e-04,\n",
      "       2.99715996e-04, 2.99739838e-04, 1.99770927e-04, 4.00781631e-04,\n",
      "       2.99763680e-04, 7.98583031e-04, 1.98984146e-04, 0.00000000e+00,\n",
      "       2.00200081e-04, 0.00000000e+00, 9.98258591e-05, 2.99715996e-04,\n",
      "       9.00006294e-04, 9.01484489e-04, 4.99486923e-04, 0.00000000e+00,\n",
      "       7.00664520e-04, 0.00000000e+00, 5.00607491e-04, 3.99899483e-04,\n",
      "       2.00581551e-04, 5.00059128e-04, 3.00168991e-04, 5.99956512e-04,\n",
      "       0.00000000e+00, 4.99486923e-04, 2.99692154e-04, 4.00090218e-04,\n",
      "       4.00614738e-04, 5.00464439e-04, 2.99859047e-04, 4.99820709e-04,\n",
      "       9.96828079e-05, 3.99923325e-04, 2.99453735e-04, 3.99637222e-04,\n",
      "       3.99231911e-04, 6.00433350e-04, 3.00288200e-04, 3.99708748e-04,\n",
      "       3.99494171e-04, 5.18274307e-04, 3.00431252e-04, 4.99105453e-04,\n",
      "       3.00645828e-04, 2.99906731e-04, 2.99119949e-04, 4.00137901e-04,\n",
      "       3.83853912e-04, 4.86469269e-04, 3.99494171e-04, 3.00121307e-04,\n",
      "       2.99763680e-04, 4.01973724e-04, 4.00066376e-04, 4.01091576e-04,\n",
      "       4.00424004e-04, 4.00209427e-04, 3.50236893e-04, 3.99398804e-04,\n",
      "       4.00638580e-04, 3.01146507e-04, 4.21571732e-04, 3.99780273e-04,\n",
      "       5.00273705e-04, 4.21094894e-04, 3.01361084e-04, 4.01067734e-04,\n",
      "       3.01504135e-04, 3.00121307e-04, 1.99460983e-04, 3.00025940e-04,\n",
      "       4.00495529e-04, 2.99358368e-04, 4.99796867e-04, 3.00383568e-04,\n",
      "       4.99606133e-04, 4.21881676e-04, 3.99589539e-04, 4.00018692e-04,\n",
      "       4.02021408e-04, 3.99518013e-04, 2.99572945e-04, 4.99868393e-04,\n",
      "       3.99613380e-04, 4.00590897e-04, 2.00009346e-04, 3.99446487e-04,\n",
      "       5.24711609e-04, 4.00590897e-04, 1.99961662e-04, 4.00424004e-04,\n",
      "       2.00319290e-04, 2.99620628e-04, 1.99937820e-04, 3.99923325e-04,\n",
      "       4.00376320e-04, 4.50086594e-04, 2.99811363e-04, 6.00814819e-04,\n",
      "       5.00035286e-04, 3.00097466e-04, 5.00464439e-04, 4.99701500e-04,\n",
      "       4.99629974e-04, 2.99644470e-04, 4.00519371e-04, 3.44371796e-04,\n",
      "       6.00481033e-04, 5.00679016e-04, 1.99913979e-04, 3.00025940e-04,\n",
      "       5.00178337e-04, 2.99811363e-04, 4.99248505e-04, 4.99439240e-04,\n",
      "       2.00223923e-04, 5.00750542e-04, 5.50556183e-04, 3.99923325e-04,\n",
      "       6.00051880e-04, 4.00590897e-04, 4.00543213e-04, 4.01210785e-04,\n",
      "       2.99930573e-04, 3.00717354e-04, 5.00273705e-04, 3.99923325e-04,\n",
      "       3.99661064e-04, 3.99875641e-04, 4.00066376e-04, 5.07354736e-04,\n",
      "       6.00218773e-04, 4.00638580e-04, 2.99787521e-04, 4.01115417e-04,\n",
      "       4.46844101e-04, 6.43491745e-04, 6.28662109e-04, 3.99565697e-04,\n",
      "       3.00836563e-04, 3.16739082e-04, 6.17742538e-04, 6.00886345e-04,\n",
      "       3.04865837e-04, 5.00750542e-04, 5.03087044e-04, 3.00598145e-04,\n",
      "       3.00121307e-04, 7.05432892e-04, 3.99994850e-04, 5.98692894e-04,\n",
      "       4.51278687e-04, 5.10358810e-04, 6.99305534e-04, 5.99360466e-04,\n",
      "       2.99549103e-04, 2.00486183e-04, 3.00097466e-04, 1.00064278e-04,\n",
      "       2.99859047e-04, 7.00449944e-04, 6.00099564e-04, 5.99598885e-04,\n",
      "       4.50539589e-04, 6.99973106e-04, 3.99827957e-04, 3.99994850e-04,\n",
      "       6.49714470e-04, 6.00528717e-04, 7.34949112e-04, 1.99985504e-04,\n",
      "       7.50422478e-04, 5.01775742e-04, 4.00590897e-04, 5.99718094e-04,\n",
      "       5.47838211e-04, 5.99360466e-04, 9.94205475e-05, 5.50317764e-04,\n",
      "       2.00009346e-04, 5.00726700e-04, 2.99835205e-04, 4.50515747e-04,\n",
      "       5.00822067e-04, 3.00002098e-04, 5.99694252e-04, 7.23600388e-04,\n",
      "       4.99987602e-04, 5.52272797e-04, 6.92224503e-04, 4.29701805e-04,\n",
      "       1.50585175e-04, 4.02927399e-04, 2.53987312e-04, 5.00273705e-04,\n",
      "       3.50880623e-04, 4.00090218e-04, 1.99937820e-04, 6.99853897e-04,\n",
      "       6.00314140e-04, 2.99954414e-04, 6.00695610e-04, 5.15842438e-04,\n",
      "       4.99939919e-04, 9.97066498e-05, 9.99689102e-05, 0.00000000e+00,\n",
      "       4.99796867e-04, 4.99916077e-04, 4.98366356e-04, 4.00424004e-04,\n",
      "       3.99637222e-04, 5.00631332e-04, 9.98258591e-05, 1.99866295e-04,\n",
      "       5.28526306e-04, 6.06608391e-04, 2.99811363e-04, 4.00114059e-04,\n",
      "       5.33270836e-04, 7.49778748e-04, 6.49738312e-04, 1.50251389e-04,\n",
      "       7.48872757e-04, 6.01816177e-04, 5.98454475e-04, 3.01289558e-04,\n",
      "       5.50150871e-04, 3.50070000e-04, 4.99629974e-04, 1.00111961e-04,\n",
      "       5.19824028e-04, 6.05416298e-04, 3.99994850e-04, 2.99668312e-04,\n",
      "       2.00605392e-04, 1.99747086e-04, 3.99565697e-04, 4.13203239e-04,\n",
      "       1.99890137e-04, 1.99961662e-04, 1.00302696e-04, 6.99734688e-04,\n",
      "       6.50429726e-04, 5.99288940e-04, 4.00400162e-04, 4.00018692e-04,\n",
      "       4.02808189e-04, 3.00002098e-04, 6.10256195e-04, 5.00726700e-04,\n",
      "       3.99351120e-04, 3.01218033e-04, 5.00941277e-04, 8.01229477e-04,\n",
      "       5.29050827e-04, 3.00383568e-04, 6.01315498e-04, 6.13760948e-04,\n",
      "       4.05049324e-04, 2.99692154e-04, 2.99692154e-04, 7.00378418e-04,\n",
      "       3.99851799e-04, 2.99453735e-04, 4.00495529e-04, 9.99927521e-05,\n",
      "       6.01291656e-04, 2.99644470e-04, 5.99026680e-04, 4.99534607e-04,\n",
      "       6.99496269e-04, 5.00965118e-04, 2.40206718e-04, 3.32856178e-04,\n",
      "       4.99343872e-04, 4.99868393e-04, 4.01210785e-04, 7.99942017e-04,\n",
      "       5.99527359e-04, 4.98938560e-04, 2.99620628e-04, 0.00000000e+00,\n",
      "       2.00009346e-04, 9.98020172e-05, 8.00251961e-04, 3.00407410e-04,\n",
      "       5.99837303e-04, 3.00216675e-04, 5.98812103e-04, 6.98471069e-04,\n",
      "       4.00924683e-04, 5.00035286e-04, 4.98914719e-04, 3.99851799e-04,\n",
      "       4.37188148e-04, 4.98914719e-04, 4.00924683e-04, 1.00040436e-03,\n",
      "       1.99818611e-04, 4.01854515e-04, 6.01458549e-04, 6.32524490e-04,\n",
      "       4.00471687e-04, 5.00035286e-04, 4.99367714e-04, 5.99622726e-04]), 'std_score_time': array([4.89687594e-04, 5.00897842e-04, 4.57679014e-04, 4.89865609e-04,\n",
      "       4.00209516e-04, 4.99775535e-04, 4.70813847e-04, 4.57606254e-04,\n",
      "       3.99971236e-04, 5.00012724e-04, 4.89979370e-04, 5.00085345e-04,\n",
      "       4.57824123e-04, 4.57863062e-04, 3.99541887e-04, 4.90862688e-04,\n",
      "       4.57896671e-04, 3.99311252e-04, 3.97974591e-04, 0.00000000e+00,\n",
      "       4.00400591e-04, 0.00000000e+00, 2.99477577e-04, 4.57825190e-04,\n",
      "       3.00030234e-04, 3.00567910e-04, 4.99488755e-04, 0.00000000e+00,\n",
      "       4.58695286e-04, 0.00000000e+00, 5.00610041e-04, 4.89775205e-04,\n",
      "       4.01167441e-04, 5.00061792e-04, 4.58517100e-04, 4.89868034e-04,\n",
      "       0.00000000e+00, 4.99493979e-04, 4.57788482e-04, 4.90015325e-04,\n",
      "       4.90651662e-04, 5.00469305e-04, 4.58047749e-04, 4.99823318e-04,\n",
      "       2.99048424e-04, 4.89807203e-04, 4.57424644e-04, 4.89454387e-04,\n",
      "       4.88960832e-04, 4.90263542e-04, 4.58709815e-04, 4.89541986e-04,\n",
      "       4.89279773e-04, 5.20814511e-04, 4.58918303e-04, 4.99110583e-04,\n",
      "       4.59247930e-04, 4.58115135e-04, 4.56914850e-04, 4.90084848e-04,\n",
      "       4.72324199e-04, 5.23306679e-04, 4.89279982e-04, 4.58443465e-04,\n",
      "       4.57896584e-04, 4.92333904e-04, 4.89979532e-04, 4.91252408e-04,\n",
      "       4.90418814e-04, 4.90161001e-04, 4.49924501e-04, 4.89163112e-04,\n",
      "       4.90683835e-04, 4.60008892e-04, 5.19636636e-04, 4.89630430e-04,\n",
      "       5.00276313e-04, 5.19085912e-04, 4.60337948e-04, 4.91206535e-04,\n",
      "       4.60566977e-04, 4.58444407e-04, 3.98923691e-04, 4.58299430e-04,\n",
      "       4.90507401e-04, 4.57279379e-04, 4.99798899e-04, 4.58845775e-04,\n",
      "       4.99607919e-04, 5.20122098e-04, 4.89396179e-04, 4.89921729e-04,\n",
      "       4.92411079e-04, 4.89308629e-04, 4.57605907e-04, 4.99871024e-04,\n",
      "       4.89425116e-04, 4.90623007e-04, 4.00018696e-04, 4.89221088e-04,\n",
      "       5.29220495e-04, 4.90624630e-04, 3.99923328e-04, 4.90419347e-04,\n",
      "       4.00641773e-04, 4.57679200e-04, 3.99875641e-04, 4.89804047e-04,\n",
      "       4.90361329e-04, 4.71451442e-04, 4.57969637e-04, 4.90567046e-04,\n",
      "       5.00038237e-04, 4.58407000e-04, 5.00466318e-04, 4.99701937e-04,\n",
      "       4.99631117e-04, 4.57715002e-04, 4.90535649e-04, 5.38380069e-04,\n",
      "       4.90299112e-04, 5.00681412e-04, 3.99827989e-04, 4.58297198e-04,\n",
      "       5.00180603e-04, 4.57969501e-04, 4.99249347e-04, 4.99441306e-04,\n",
      "       4.00448073e-04, 5.00751230e-04, 4.71805427e-04, 4.89804325e-04,\n",
      "       4.89941441e-04, 4.90622811e-04, 4.90564497e-04, 4.91388081e-04,\n",
      "       4.58151720e-04, 4.59354587e-04, 5.00274677e-04, 4.89804058e-04,\n",
      "       4.89484759e-04, 4.89745687e-04, 4.89980495e-04, 5.07795832e-04,\n",
      "       4.90080953e-04, 4.90681610e-04, 4.57933020e-04, 4.91274476e-04,\n",
      "       5.61615779e-04, 5.39988492e-04, 5.18534131e-04, 4.89366205e-04,\n",
      "       4.59536826e-04, 4.85783308e-04, 5.07536901e-04, 4.90626220e-04,\n",
      "       4.65843548e-04, 5.00753511e-04, 6.72906445e-04, 4.59172691e-04,\n",
      "       4.58446230e-04, 4.62376859e-04, 4.89892295e-04, 4.88831787e-04,\n",
      "       4.72517316e-04, 5.11087351e-04, 4.57804219e-04, 4.89376461e-04,\n",
      "       4.57570651e-04, 4.00973929e-04, 4.58406715e-04, 3.00192833e-04,\n",
      "       4.58042314e-04, 4.58564250e-04, 4.89979532e-04, 4.89571086e-04,\n",
      "       4.71853824e-04, 4.58240167e-04, 4.89687548e-04, 4.89891866e-04,\n",
      "       4.49310644e-04, 4.90332299e-04, 4.90678923e-04, 3.99971008e-04,\n",
      "       4.02880746e-04, 5.01780991e-04, 4.90622231e-04, 4.89668060e-04,\n",
      "       5.63508975e-04, 4.89377751e-04, 2.98261642e-04, 4.71553013e-04,\n",
      "       4.00018696e-04, 5.00728500e-04, 4.58005841e-04, 4.71876160e-04,\n",
      "       5.00831867e-04, 4.58260779e-04, 4.89650993e-04, 4.78397237e-04,\n",
      "       4.99988130e-04, 4.73378299e-04, 4.96851416e-04, 5.32846120e-04,\n",
      "       3.20862431e-04, 4.93525042e-04, 4.09932832e-04, 5.00276972e-04,\n",
      "       4.50789024e-04, 4.90009862e-04, 3.99875698e-04, 4.58165234e-04,\n",
      "       4.90155959e-04, 4.58190384e-04, 4.90469336e-04, 5.17738845e-04,\n",
      "       4.99940401e-04, 2.99119949e-04, 2.99906731e-04, 0.00000000e+00,\n",
      "       4.99799376e-04, 4.99916766e-04, 4.98375214e-04, 4.90418825e-04,\n",
      "       4.89454120e-04, 5.00633610e-04, 2.99477577e-04, 3.99732679e-04,\n",
      "       5.35067151e-04, 4.95694428e-04, 4.57969550e-04, 4.90038530e-04,\n",
      "       5.40712944e-04, 4.02425897e-04, 4.49353965e-04, 3.20235912e-04,\n",
      "       5.01253854e-04, 4.91390001e-04, 4.88636996e-04, 4.60231075e-04,\n",
      "       4.71419652e-04, 4.49604874e-04, 4.99632744e-04, 3.00335884e-04,\n",
      "       4.50597239e-04, 4.94684081e-04, 4.89892748e-04, 4.57751024e-04,\n",
      "       4.01213562e-04, 3.99495324e-04, 4.89366309e-04, 5.07479604e-04,\n",
      "       3.99780330e-04, 3.99923328e-04, 3.00908089e-04, 4.58084238e-04,\n",
      "       4.49863278e-04, 4.89319028e-04, 4.90388653e-04, 4.89920859e-04,\n",
      "       4.93363078e-04, 4.58261845e-04, 4.99051744e-04, 5.00729227e-04,\n",
      "       4.89104892e-04, 4.60126303e-04, 5.00945071e-04, 4.00623376e-04,\n",
      "       5.34954276e-04, 4.58848265e-04, 4.90981782e-04, 6.94810393e-04,\n",
      "       4.96287174e-04, 4.57787935e-04, 4.57788084e-04, 4.58509900e-04,\n",
      "       4.89716503e-04, 4.57424010e-04, 4.90506983e-04, 2.99978256e-04,\n",
      "       4.90957255e-04, 4.57716157e-04, 4.89108533e-04, 4.99535581e-04,\n",
      "       4.57934152e-04, 5.00970367e-04, 4.88798736e-04, 5.15529891e-04,\n",
      "       4.99344662e-04, 4.99872491e-04, 4.91384703e-04, 3.99973296e-04,\n",
      "       4.89513781e-04, 4.98942623e-04, 4.57679200e-04, 0.00000000e+00,\n",
      "       4.00018696e-04, 2.99406052e-04, 4.00142018e-04, 4.58880282e-04,\n",
      "       4.89765681e-04, 4.58590595e-04, 4.88932569e-04, 4.57267719e-04,\n",
      "       4.91033655e-04, 5.00035566e-04, 4.98925296e-04, 4.89716479e-04,\n",
      "       5.45009551e-04, 4.98915430e-04, 4.91035461e-04, 8.98430046e-07,\n",
      "       3.99637823e-04, 4.92175740e-04, 4.91095247e-04, 5.25046161e-04,\n",
      "       4.90477110e-04, 5.00035907e-04, 4.99369615e-04, 4.89593107e-04]), 'param_classifier__max_depth': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
      "                   2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3,\n",
      "                   3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4,\n",
      "                   4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "                   6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "                   7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "                   8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
      "                   11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
      "                   12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13,\n",
      "                   13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14,\n",
      "                   14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15,\n",
      "                   15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16,\n",
      "                   16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "                   17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "                   17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
      "                   18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
      "                   19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "                   20, 20, 20, 20, 20, 20, 20, 20],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_classifier__min_samples_leaf': masked_array(data=[1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1,\n",
      "                   1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1,\n",
      "                   1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1,\n",
      "                   1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1,\n",
      "                   2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2,\n",
      "                   2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2,\n",
      "                   2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2,\n",
      "                   2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "                   5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5,\n",
      "                   5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5,\n",
      "                   5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5,\n",
      "                   5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5,\n",
      "                   10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10,\n",
      "                   10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10,\n",
      "                   10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10,\n",
      "                   10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10,\n",
      "                   1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1,\n",
      "                   1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1,\n",
      "                   1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_classifier__min_samples_split': masked_array(data=[2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'classifier__max_depth': 1, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}], 'split0_test_score': array([0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.74213836, 0.74213836, 0.74213836, 0.74213836,\n",
      "       0.74213836, 0.74213836, 0.74213836, 0.74213836, 0.74213836,\n",
      "       0.74213836, 0.74213836, 0.74213836, 0.74213836, 0.74213836,\n",
      "       0.74213836, 0.74213836, 0.83018868, 0.83018868, 0.83018868,\n",
      "       0.82389937, 0.83018868, 0.83018868, 0.83018868, 0.82389937,\n",
      "       0.83018868, 0.83018868, 0.83018868, 0.82389937, 0.82389937,\n",
      "       0.82389937, 0.82389937, 0.82389937, 0.82389937, 0.82389937,\n",
      "       0.81761006, 0.81761006, 0.82389937, 0.82389937, 0.82389937,\n",
      "       0.81761006, 0.82389937, 0.83018868, 0.82389937, 0.82389937,\n",
      "       0.82389937, 0.82389937, 0.82389937, 0.82389937, 0.81132075,\n",
      "       0.79874214, 0.80503145, 0.79874214, 0.80503145, 0.79874214,\n",
      "       0.80503145, 0.79874214, 0.80503145, 0.81132075, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.81132075, 0.80503145, 0.80503145, 0.80503145, 0.79245283,\n",
      "       0.80503145, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79245283, 0.79245283, 0.79245283, 0.79245283, 0.79245283,\n",
      "       0.79245283, 0.79874214, 0.78616352, 0.78616352, 0.79874214,\n",
      "       0.78616352, 0.77987421, 0.79245283, 0.79245283, 0.79245283,\n",
      "       0.78616352, 0.79245283, 0.79245283, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79245283, 0.79245283,\n",
      "       0.79245283, 0.77987421, 0.78616352, 0.79245283, 0.77987421,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.7672956 , 0.76100629,\n",
      "       0.7672956 , 0.77987421, 0.77358491, 0.7672956 , 0.77987421,\n",
      "       0.77358491, 0.77987421, 0.77987421, 0.78616352, 0.77987421,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.76100629,\n",
      "       0.75471698, 0.77358491, 0.77358491, 0.74842767, 0.73584906,\n",
      "       0.74842767, 0.7672956 , 0.7672956 , 0.77358491, 0.77358491,\n",
      "       0.77987421, 0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 ,\n",
      "       0.73584906, 0.72955975, 0.74842767, 0.7672956 , 0.74842767,\n",
      "       0.74213836, 0.74213836, 0.75471698, 0.74842767, 0.74842767,\n",
      "       0.74213836, 0.75471698, 0.76100629, 0.76100629, 0.75471698,\n",
      "       0.76100629, 0.72327044, 0.72955975, 0.73584906, 0.75471698,\n",
      "       0.72955975, 0.73584906, 0.72955975, 0.74213836, 0.74842767,\n",
      "       0.74842767, 0.74842767, 0.75471698, 0.7672956 , 0.7672956 ,\n",
      "       0.7672956 , 0.7672956 , 0.73584906, 0.74842767, 0.72955975,\n",
      "       0.74842767, 0.71069182, 0.72955975, 0.71069182, 0.74213836,\n",
      "       0.74842767, 0.74842767, 0.75471698, 0.75471698, 0.7672956 ,\n",
      "       0.7672956 , 0.7672956 , 0.76100629, 0.72327044, 0.74842767,\n",
      "       0.73584906, 0.74842767, 0.71698113, 0.72327044, 0.70440252,\n",
      "       0.73584906, 0.74213836, 0.74213836, 0.74213836, 0.74842767,\n",
      "       0.7672956 , 0.7672956 , 0.7672956 , 0.76100629, 0.72327044,\n",
      "       0.74213836, 0.72955975, 0.74213836, 0.73584906, 0.73584906,\n",
      "       0.72327044, 0.73584906, 0.74213836, 0.74213836, 0.73584906,\n",
      "       0.72955975, 0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 ,\n",
      "       0.71698113, 0.72327044, 0.71698113, 0.72955975, 0.70440252,\n",
      "       0.69811321, 0.70440252, 0.72327044, 0.74213836, 0.73584906,\n",
      "       0.73584906, 0.72955975, 0.76100629, 0.76100629, 0.7672956 ,\n",
      "       0.76100629, 0.73584906, 0.74213836, 0.72327044, 0.74213836,\n",
      "       0.71698113, 0.72327044, 0.71698113, 0.72955975, 0.74213836,\n",
      "       0.74213836, 0.74842767, 0.73584906, 0.7672956 , 0.7672956 ,\n",
      "       0.76100629, 0.7672956 , 0.71069182, 0.72955975, 0.71069182,\n",
      "       0.74213836, 0.68553459, 0.71069182, 0.6918239 , 0.72955975,\n",
      "       0.72955975, 0.72955975, 0.72955975, 0.73584906, 0.7672956 ,\n",
      "       0.7672956 , 0.7672956 , 0.76100629, 0.71698113, 0.74842767,\n",
      "       0.71069182, 0.74213836, 0.71698113, 0.72327044, 0.69811321,\n",
      "       0.72955975, 0.72327044, 0.72327044, 0.72327044, 0.73584906,\n",
      "       0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 , 0.71698113,\n",
      "       0.75471698, 0.71698113, 0.74213836, 0.71698113, 0.71698113,\n",
      "       0.69811321, 0.72955975, 0.72955975, 0.72955975, 0.72327044,\n",
      "       0.73584906, 0.7672956 , 0.7672956 , 0.7672956 , 0.76100629]), 'split1_test_score': array([0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.88679245, 0.88679245, 0.88679245,\n",
      "       0.88050314, 0.88679245, 0.88679245, 0.88679245, 0.88050314,\n",
      "       0.88679245, 0.88679245, 0.88679245, 0.88050314, 0.88050314,\n",
      "       0.88050314, 0.88050314, 0.88050314, 0.88679245, 0.88050314,\n",
      "       0.88050314, 0.88050314, 0.88050314, 0.88679245, 0.88050314,\n",
      "       0.88050314, 0.88050314, 0.88050314, 0.88050314, 0.88050314,\n",
      "       0.88050314, 0.88050314, 0.88050314, 0.88050314, 0.86792453,\n",
      "       0.86792453, 0.87421384, 0.87421384, 0.86792453, 0.86792453,\n",
      "       0.88050314, 0.87421384, 0.87421384, 0.87421384, 0.87421384,\n",
      "       0.87421384, 0.87421384, 0.87421384, 0.87421384, 0.87421384,\n",
      "       0.86163522, 0.85534591, 0.87421384, 0.87421384, 0.85534591,\n",
      "       0.8490566 , 0.87421384, 0.87421384, 0.87421384, 0.87421384,\n",
      "       0.87421384, 0.87421384, 0.87421384, 0.87421384, 0.87421384,\n",
      "       0.87421384, 0.8427673 , 0.8427673 , 0.85534591, 0.86163522,\n",
      "       0.8427673 , 0.83647799, 0.85534591, 0.86163522, 0.86792453,\n",
      "       0.86792453, 0.86792453, 0.86792453, 0.86163522, 0.86163522,\n",
      "       0.86163522, 0.86163522, 0.8490566 , 0.8490566 , 0.86792453,\n",
      "       0.86163522, 0.8490566 , 0.8427673 , 0.86792453, 0.86163522,\n",
      "       0.86163522, 0.86163522, 0.86163522, 0.86163522, 0.86163522,\n",
      "       0.86163522, 0.86163522, 0.86163522, 0.81761006, 0.81761006,\n",
      "       0.83647799, 0.83647799, 0.81761006, 0.81132075, 0.83647799,\n",
      "       0.83647799, 0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.80503145,\n",
      "       0.80503145, 0.82389937, 0.83018868, 0.79874214, 0.81132075,\n",
      "       0.82389937, 0.83018868, 0.83647799, 0.83647799, 0.83647799,\n",
      "       0.83647799, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.77358491, 0.77358491, 0.79245283, 0.79874214, 0.77987421,\n",
      "       0.77358491, 0.79245283, 0.79874214, 0.80503145, 0.80503145,\n",
      "       0.79874214, 0.81132075, 0.83018868, 0.83018868, 0.83018868,\n",
      "       0.83018868, 0.7672956 , 0.77987421, 0.79874214, 0.81132075,\n",
      "       0.76100629, 0.77358491, 0.80503145, 0.81132075, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.82389937, 0.82389937, 0.80503145,\n",
      "       0.80503145, 0.82389937, 0.74213836, 0.74842767, 0.77987421,\n",
      "       0.78616352, 0.76100629, 0.7672956 , 0.78616352, 0.78616352,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.81132075, 0.80503145,\n",
      "       0.81132075, 0.81132075, 0.80503145, 0.74213836, 0.76100629,\n",
      "       0.78616352, 0.79245283, 0.7672956 , 0.77358491, 0.79245283,\n",
      "       0.79245283, 0.80503145, 0.80503145, 0.80503145, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.76100629,\n",
      "       0.7672956 , 0.79874214, 0.79874214, 0.75471698, 0.77358491,\n",
      "       0.79874214, 0.79874214, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81761006, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.74213836, 0.73584906, 0.79874214, 0.79874214, 0.74842767,\n",
      "       0.75471698, 0.80503145, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.80503145, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.72955975, 0.73584906, 0.78616352, 0.79874214,\n",
      "       0.74213836, 0.74213836, 0.79245283, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.80503145, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.72955975, 0.72955975, 0.76100629,\n",
      "       0.79874214, 0.73584906, 0.74842767, 0.77358491, 0.79874214,\n",
      "       0.77987421, 0.77987421, 0.77987421, 0.80503145, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.73584906, 0.74213836,\n",
      "       0.7672956 , 0.79874214, 0.74213836, 0.72955975, 0.77358491,\n",
      "       0.79874214, 0.77358491, 0.77987421, 0.77987421, 0.80503145,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.73584906,\n",
      "       0.73584906, 0.7672956 , 0.79874214, 0.73584906, 0.73584906,\n",
      "       0.77358491, 0.79874214, 0.77987421, 0.77987421, 0.77987421,\n",
      "       0.80503145, 0.81132075, 0.81132075, 0.81132075, 0.81132075]), 'split2_test_score': array([0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.71698113, 0.71698113, 0.71698113, 0.71698113,\n",
      "       0.71698113, 0.71698113, 0.71698113, 0.71698113, 0.71698113,\n",
      "       0.71698113, 0.71698113, 0.71698113, 0.71698113, 0.71698113,\n",
      "       0.71698113, 0.71698113, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.80503145,\n",
      "       0.80503145, 0.79874214, 0.79874214, 0.80503145, 0.80503145,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.77987421, 0.77987421, 0.77358491, 0.77358491, 0.77987421,\n",
      "       0.77987421, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77987421, 0.77987421, 0.77987421,\n",
      "       0.77987421, 0.78616352, 0.78616352, 0.77987421, 0.77358491,\n",
      "       0.77987421, 0.77987421, 0.77987421, 0.77358491, 0.77987421,\n",
      "       0.77987421, 0.77987421, 0.77358491, 0.77987421, 0.77987421,\n",
      "       0.77987421, 0.77987421, 0.7672956 , 0.7672956 , 0.78616352,\n",
      "       0.77358491, 0.7672956 , 0.7672956 , 0.78616352, 0.77358491,\n",
      "       0.77987421, 0.77987421, 0.77987421, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.72327044, 0.71698113,\n",
      "       0.74213836, 0.72955975, 0.72327044, 0.71698113, 0.74213836,\n",
      "       0.72955975, 0.76100629, 0.76100629, 0.76100629, 0.75471698,\n",
      "       0.74842767, 0.74842767, 0.74842767, 0.74213836, 0.71698113,\n",
      "       0.71069182, 0.74842767, 0.72955975, 0.72955975, 0.72327044,\n",
      "       0.75471698, 0.73584906, 0.7672956 , 0.7672956 , 0.76100629,\n",
      "       0.75471698, 0.73584906, 0.73584906, 0.74213836, 0.74213836,\n",
      "       0.72955975, 0.71698113, 0.74842767, 0.73584906, 0.72955975,\n",
      "       0.71698113, 0.74842767, 0.73584906, 0.75471698, 0.74842767,\n",
      "       0.74842767, 0.74842767, 0.73584906, 0.73584906, 0.73584906,\n",
      "       0.74213836, 0.72955975, 0.73584906, 0.74213836, 0.72955975,\n",
      "       0.72955975, 0.71698113, 0.74213836, 0.72955975, 0.74842767,\n",
      "       0.74842767, 0.74213836, 0.74213836, 0.73584906, 0.74213836,\n",
      "       0.74213836, 0.73584906, 0.73584906, 0.74213836, 0.74842767,\n",
      "       0.73584906, 0.73584906, 0.71698113, 0.74213836, 0.72955975,\n",
      "       0.74842767, 0.74842767, 0.74213836, 0.74213836, 0.73584906,\n",
      "       0.74213836, 0.73584906, 0.73584906, 0.72327044, 0.71698113,\n",
      "       0.72955975, 0.72327044, 0.71698113, 0.6918239 , 0.72327044,\n",
      "       0.72955975, 0.74842767, 0.74213836, 0.74842767, 0.74213836,\n",
      "       0.74213836, 0.73584906, 0.73584906, 0.73584906, 0.72955975,\n",
      "       0.72955975, 0.73584906, 0.72327044, 0.70440252, 0.69811321,\n",
      "       0.71698113, 0.72955975, 0.75471698, 0.75471698, 0.74842767,\n",
      "       0.74842767, 0.74213836, 0.74213836, 0.73584906, 0.74213836,\n",
      "       0.72955975, 0.72327044, 0.74213836, 0.72955975, 0.71698113,\n",
      "       0.71069182, 0.72327044, 0.73584906, 0.75471698, 0.75471698,\n",
      "       0.75471698, 0.74842767, 0.74213836, 0.73584906, 0.73584906,\n",
      "       0.74213836, 0.71698113, 0.72955975, 0.74213836, 0.72955975,\n",
      "       0.71069182, 0.70440252, 0.72955975, 0.73584906, 0.75471698,\n",
      "       0.74842767, 0.74842767, 0.74842767, 0.74213836, 0.74213836,\n",
      "       0.73584906, 0.73584906, 0.71698113, 0.72327044, 0.74213836,\n",
      "       0.72955975, 0.71069182, 0.71698113, 0.72955975, 0.73584906,\n",
      "       0.74842767, 0.74842767, 0.74842767, 0.74842767, 0.73584906,\n",
      "       0.73584906, 0.74213836, 0.73584906, 0.71698113, 0.74213836,\n",
      "       0.76100629, 0.72955975, 0.72955975, 0.70440252, 0.73584906,\n",
      "       0.73584906, 0.74842767, 0.75471698, 0.75471698, 0.74842767,\n",
      "       0.73584906, 0.73584906, 0.74213836, 0.74213836, 0.72327044,\n",
      "       0.73584906, 0.75471698, 0.72955975, 0.72955975, 0.71069182,\n",
      "       0.73584906, 0.73584906, 0.74842767, 0.75471698, 0.75471698,\n",
      "       0.74842767, 0.74213836, 0.73584906, 0.73584906, 0.73584906]), 'split3_test_score': array([0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.71069182, 0.71069182, 0.71069182, 0.71069182,\n",
      "       0.71069182, 0.71069182, 0.71069182, 0.71069182, 0.71069182,\n",
      "       0.71069182, 0.71069182, 0.71069182, 0.71069182, 0.71069182,\n",
      "       0.71069182, 0.71069182, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.77987421, 0.77987421,\n",
      "       0.77987421, 0.77987421, 0.79245283, 0.79245283, 0.79245283,\n",
      "       0.79245283, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.79245283, 0.79245283,\n",
      "       0.79245283, 0.79245283, 0.77987421, 0.77987421, 0.77987421,\n",
      "       0.77987421, 0.78616352, 0.78616352, 0.78616352, 0.77987421,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77987421,\n",
      "       0.77987421, 0.77987421, 0.77987421, 0.74842767, 0.74842767,\n",
      "       0.74842767, 0.74213836, 0.76100629, 0.76100629, 0.75471698,\n",
      "       0.74213836, 0.74842767, 0.74842767, 0.74842767, 0.74842767,\n",
      "       0.75471698, 0.75471698, 0.75471698, 0.75471698, 0.74842767,\n",
      "       0.75471698, 0.75471698, 0.72955975, 0.7672956 , 0.76100629,\n",
      "       0.75471698, 0.72955975, 0.74842767, 0.74213836, 0.74213836,\n",
      "       0.74842767, 0.76100629, 0.7672956 , 0.7672956 , 0.76100629,\n",
      "       0.77987421, 0.77358491, 0.76100629, 0.75471698, 0.77987421,\n",
      "       0.77987421, 0.7672956 , 0.75471698, 0.78616352, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.75471698, 0.75471698, 0.75471698,\n",
      "       0.75471698, 0.7672956 , 0.75471698, 0.75471698, 0.74842767,\n",
      "       0.77358491, 0.7672956 , 0.7672956 , 0.75471698, 0.79245283,\n",
      "       0.79245283, 0.79245283, 0.7672956 , 0.75471698, 0.7672956 ,\n",
      "       0.75471698, 0.75471698, 0.77987421, 0.78616352, 0.7672956 ,\n",
      "       0.75471698, 0.76100629, 0.75471698, 0.76100629, 0.74842767,\n",
      "       0.77987421, 0.77987421, 0.77987421, 0.75471698, 0.75471698,\n",
      "       0.75471698, 0.75471698, 0.7672956 , 0.77987421, 0.76100629,\n",
      "       0.75471698, 0.73584906, 0.75471698, 0.75471698, 0.78616352,\n",
      "       0.75471698, 0.79245283, 0.79245283, 0.79245283, 0.75471698,\n",
      "       0.7672956 , 0.75471698, 0.7672956 , 0.75471698, 0.74842767,\n",
      "       0.74213836, 0.74842767, 0.73584906, 0.74842767, 0.74213836,\n",
      "       0.76100629, 0.75471698, 0.79245283, 0.79245283, 0.79245283,\n",
      "       0.7672956 , 0.75471698, 0.75471698, 0.75471698, 0.7672956 ,\n",
      "       0.74213836, 0.72955975, 0.72955975, 0.73584906, 0.72955975,\n",
      "       0.72327044, 0.73584906, 0.75471698, 0.77987421, 0.77987421,\n",
      "       0.77987421, 0.7672956 , 0.7672956 , 0.75471698, 0.75471698,\n",
      "       0.7672956 , 0.76100629, 0.73584906, 0.74213836, 0.73584906,\n",
      "       0.74213836, 0.73584906, 0.73584906, 0.75471698, 0.77987421,\n",
      "       0.77987421, 0.77987421, 0.75471698, 0.7672956 , 0.7672956 ,\n",
      "       0.7672956 , 0.7672956 , 0.76100629, 0.73584906, 0.72955975,\n",
      "       0.73584906, 0.72955975, 0.72955975, 0.73584906, 0.75471698,\n",
      "       0.77987421, 0.77987421, 0.77987421, 0.7672956 , 0.7672956 ,\n",
      "       0.75471698, 0.75471698, 0.7672956 , 0.76100629, 0.72955975,\n",
      "       0.73584906, 0.73584906, 0.72955975, 0.72955975, 0.72955975,\n",
      "       0.75471698, 0.77987421, 0.77987421, 0.77987421, 0.75471698,\n",
      "       0.75471698, 0.7672956 , 0.75471698, 0.7672956 , 0.7672956 ,\n",
      "       0.74213836, 0.72327044, 0.73584906, 0.72327044, 0.72327044,\n",
      "       0.72955975, 0.75471698, 0.77987421, 0.77987421, 0.77987421,\n",
      "       0.7672956 , 0.7672956 , 0.7672956 , 0.75471698, 0.75471698]), 'split4_test_score': array([0.74842767, 0.74842767, 0.74842767, 0.74842767, 0.74842767,\n",
      "       0.74842767, 0.74842767, 0.74842767, 0.74842767, 0.74842767,\n",
      "       0.74842767, 0.74842767, 0.74842767, 0.74842767, 0.74842767,\n",
      "       0.74842767, 0.72955975, 0.72955975, 0.72955975, 0.72955975,\n",
      "       0.72955975, 0.72955975, 0.72955975, 0.72955975, 0.72955975,\n",
      "       0.72955975, 0.72955975, 0.72955975, 0.72955975, 0.72955975,\n",
      "       0.72955975, 0.72955975, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.76100629,\n",
      "       0.76100629, 0.75471698, 0.75471698, 0.7672956 , 0.7672956 ,\n",
      "       0.76100629, 0.76100629, 0.76100629, 0.76100629, 0.76100629,\n",
      "       0.76100629, 0.76100629, 0.76100629, 0.76100629, 0.76100629,\n",
      "       0.77987421, 0.77987421, 0.77358491, 0.77358491, 0.77987421,\n",
      "       0.77987421, 0.77987421, 0.77987421, 0.76100629, 0.76100629,\n",
      "       0.76100629, 0.76100629, 0.7672956 , 0.7672956 , 0.7672956 ,\n",
      "       0.7672956 , 0.76100629, 0.76100629, 0.76100629, 0.76100629,\n",
      "       0.76100629, 0.76100629, 0.7672956 , 0.7672956 , 0.74842767,\n",
      "       0.74842767, 0.74842767, 0.74842767, 0.76100629, 0.76100629,\n",
      "       0.76100629, 0.76100629, 0.70440252, 0.72327044, 0.72327044,\n",
      "       0.71698113, 0.71698113, 0.72955975, 0.71698113, 0.72327044,\n",
      "       0.72955975, 0.72955975, 0.72955975, 0.72955975, 0.74213836,\n",
      "       0.74213836, 0.74213836, 0.74213836, 0.71698113, 0.71069182,\n",
      "       0.71069182, 0.71069182, 0.71698113, 0.71698113, 0.71698113,\n",
      "       0.71069182, 0.71698113, 0.71698113, 0.71698113, 0.71069182,\n",
      "       0.72955975, 0.72955975, 0.72955975, 0.72955975, 0.74842767,\n",
      "       0.73584906, 0.73584906, 0.71069182, 0.73584906, 0.74842767,\n",
      "       0.74213836, 0.71069182, 0.71698113, 0.71698113, 0.71698113,\n",
      "       0.70440252, 0.72955975, 0.72955975, 0.72955975, 0.72955975,\n",
      "       0.76100629, 0.74213836, 0.72955975, 0.71069182, 0.72955975,\n",
      "       0.72327044, 0.72955975, 0.70440252, 0.71698113, 0.71698113,\n",
      "       0.71698113, 0.70440252, 0.72955975, 0.72955975, 0.72955975,\n",
      "       0.72955975, 0.74842767, 0.73584906, 0.72955975, 0.71069182,\n",
      "       0.73584906, 0.73584906, 0.72955975, 0.70440252, 0.69811321,\n",
      "       0.69811321, 0.69811321, 0.70440252, 0.71069182, 0.71069182,\n",
      "       0.71069182, 0.71069182, 0.72955975, 0.73584906, 0.72327044,\n",
      "       0.71069182, 0.71069182, 0.72955975, 0.71698113, 0.70440252,\n",
      "       0.69811321, 0.69811321, 0.69811321, 0.70440252, 0.71069182,\n",
      "       0.71069182, 0.71069182, 0.71069182, 0.72327044, 0.71698113,\n",
      "       0.69811321, 0.68553459, 0.71698113, 0.71698113, 0.71698113,\n",
      "       0.69811321, 0.67924528, 0.67924528, 0.6918239 , 0.68553459,\n",
      "       0.70440252, 0.70440252, 0.70440252, 0.70440252, 0.72955975,\n",
      "       0.72327044, 0.6918239 , 0.69811321, 0.72327044, 0.74213836,\n",
      "       0.71698113, 0.69811321, 0.6918239 , 0.6918239 , 0.6918239 ,\n",
      "       0.69811321, 0.70440252, 0.70440252, 0.70440252, 0.70440252,\n",
      "       0.72955975, 0.73584906, 0.70440252, 0.68553459, 0.73584906,\n",
      "       0.72955975, 0.71069182, 0.69811321, 0.67924528, 0.6918239 ,\n",
      "       0.67924528, 0.68553459, 0.70440252, 0.70440252, 0.70440252,\n",
      "       0.70440252, 0.72955975, 0.74213836, 0.70440252, 0.68553459,\n",
      "       0.71698113, 0.73584906, 0.71069182, 0.69811321, 0.67924528,\n",
      "       0.6918239 , 0.6918239 , 0.69811321, 0.70440252, 0.70440252,\n",
      "       0.70440252, 0.70440252, 0.72327044, 0.72955975, 0.70440252,\n",
      "       0.69811321, 0.72327044, 0.74213836, 0.71069182, 0.69811321,\n",
      "       0.67924528, 0.67924528, 0.67924528, 0.68553459, 0.70440252,\n",
      "       0.70440252, 0.70440252, 0.70440252, 0.71069182, 0.72955975,\n",
      "       0.71069182, 0.69811321, 0.71698113, 0.72327044, 0.71069182,\n",
      "       0.69811321, 0.6918239 , 0.67924528, 0.67924528, 0.68553459,\n",
      "       0.70440252, 0.70440252, 0.70440252, 0.70440252, 0.72327044,\n",
      "       0.72327044, 0.71069182, 0.68553459, 0.71698113, 0.72327044,\n",
      "       0.70440252, 0.69811321, 0.67924528, 0.6918239 , 0.6918239 ,\n",
      "       0.69811321, 0.70440252, 0.70440252, 0.70440252, 0.70440252]), 'split5_test_score': array([0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 ,\n",
      "       0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 ,\n",
      "       0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 ,\n",
      "       0.7672956 , 0.71698113, 0.71698113, 0.71698113, 0.71698113,\n",
      "       0.71698113, 0.71698113, 0.71698113, 0.71698113, 0.71698113,\n",
      "       0.71698113, 0.71698113, 0.71698113, 0.71698113, 0.71698113,\n",
      "       0.71698113, 0.71698113, 0.82389937, 0.82389937, 0.82389937,\n",
      "       0.81761006, 0.82389937, 0.82389937, 0.82389937, 0.81761006,\n",
      "       0.82389937, 0.82389937, 0.82389937, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81132075, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.81132075, 0.82389937, 0.82389937, 0.82389937, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81761006, 0.81132075,\n",
      "       0.80503145, 0.80503145, 0.79874214, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.79874214, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.80503145, 0.81761006, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.79874214, 0.79245283, 0.78616352, 0.77987421, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.77987421, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79245283, 0.77987421, 0.77987421, 0.77987421,\n",
      "       0.77987421, 0.74213836, 0.72327044, 0.72327044, 0.71698113,\n",
      "       0.74213836, 0.73584906, 0.72327044, 0.71698113, 0.77987421,\n",
      "       0.77987421, 0.77987421, 0.77358491, 0.7672956 , 0.7672956 ,\n",
      "       0.7672956 , 0.7672956 , 0.79874214, 0.77987421, 0.77358491,\n",
      "       0.7672956 , 0.79245283, 0.78616352, 0.77358491, 0.7672956 ,\n",
      "       0.77987421, 0.77987421, 0.77987421, 0.77987421, 0.77987421,\n",
      "       0.77987421, 0.77987421, 0.77987421, 0.76100629, 0.74213836,\n",
      "       0.74213836, 0.75471698, 0.76100629, 0.75471698, 0.74213836,\n",
      "       0.75471698, 0.75471698, 0.75471698, 0.75471698, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.7672956 ,\n",
      "       0.74213836, 0.73584906, 0.74842767, 0.77358491, 0.76100629,\n",
      "       0.74213836, 0.75471698, 0.75471698, 0.75471698, 0.75471698,\n",
      "       0.7672956 , 0.74213836, 0.74213836, 0.74213836, 0.74213836,\n",
      "       0.74213836, 0.74213836, 0.71698113, 0.72955975, 0.74213836,\n",
      "       0.75471698, 0.71069182, 0.72955975, 0.74213836, 0.74213836,\n",
      "       0.74213836, 0.76100629, 0.74213836, 0.74213836, 0.74213836,\n",
      "       0.74213836, 0.74842767, 0.74213836, 0.71069182, 0.72955975,\n",
      "       0.74842767, 0.75471698, 0.71069182, 0.72955975, 0.73584906,\n",
      "       0.73584906, 0.73584906, 0.75471698, 0.74213836, 0.74213836,\n",
      "       0.74213836, 0.74213836, 0.72327044, 0.71069182, 0.68553459,\n",
      "       0.72955975, 0.74213836, 0.75471698, 0.70440252, 0.72955975,\n",
      "       0.72955975, 0.71698113, 0.72327044, 0.75471698, 0.74213836,\n",
      "       0.74213836, 0.74213836, 0.74213836, 0.72955975, 0.72955975,\n",
      "       0.67295597, 0.73584906, 0.72955975, 0.76100629, 0.71069182,\n",
      "       0.73584906, 0.72955975, 0.72955975, 0.72955975, 0.75471698,\n",
      "       0.74213836, 0.74213836, 0.74213836, 0.74213836, 0.69811321,\n",
      "       0.6918239 , 0.67924528, 0.71698113, 0.70440252, 0.73584906,\n",
      "       0.6918239 , 0.72955975, 0.72955975, 0.72327044, 0.72327044,\n",
      "       0.75471698, 0.74213836, 0.74213836, 0.74213836, 0.74213836,\n",
      "       0.70440252, 0.67924528, 0.65408805, 0.72327044, 0.70440252,\n",
      "       0.73584906, 0.66666667, 0.71069182, 0.72327044, 0.71698113,\n",
      "       0.72955975, 0.75471698, 0.74213836, 0.74213836, 0.74213836,\n",
      "       0.74213836, 0.69811321, 0.67924528, 0.65408805, 0.71069182,\n",
      "       0.70440252, 0.72327044, 0.6918239 , 0.72327044, 0.72955975,\n",
      "       0.72955975, 0.72327044, 0.75471698, 0.74213836, 0.74213836,\n",
      "       0.74213836, 0.74213836, 0.6918239 , 0.68553459, 0.67295597,\n",
      "       0.72327044, 0.70440252, 0.70440252, 0.66666667, 0.71069182,\n",
      "       0.72955975, 0.72327044, 0.72327044, 0.75471698, 0.74213836,\n",
      "       0.74213836, 0.74213836, 0.74213836, 0.68553459, 0.67924528,\n",
      "       0.67295597, 0.71069182, 0.70440252, 0.70440252, 0.6918239 ,\n",
      "       0.71069182, 0.72327044, 0.72327044, 0.72955975, 0.75471698,\n",
      "       0.74213836, 0.74213836, 0.74213836, 0.74213836, 0.6918239 ,\n",
      "       0.68553459, 0.66666667, 0.71069182, 0.71069182, 0.70440252,\n",
      "       0.66666667, 0.71069182, 0.72955975, 0.72955975, 0.72955975,\n",
      "       0.75471698, 0.74213836, 0.74213836, 0.74213836, 0.74213836]), 'split6_test_score': array([0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.77987421, 0.77987421, 0.77987421, 0.77987421,\n",
      "       0.77987421, 0.77987421, 0.77987421, 0.77987421, 0.77987421,\n",
      "       0.77987421, 0.77987421, 0.77987421, 0.77987421, 0.77987421,\n",
      "       0.77987421, 0.77987421, 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.83647799,\n",
      "       0.83647799, 0.8427673 , 0.8427673 , 0.83647799, 0.83647799,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.83647799, 0.83647799, 0.8427673 , 0.8427673 , 0.83647799,\n",
      "       0.83647799, 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.82389937, 0.83018868, 0.83647799, 0.8427673 ,\n",
      "       0.83018868, 0.83018868, 0.83647799, 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.83018868, 0.83018868,\n",
      "       0.83018868, 0.83018868, 0.79874214, 0.79874214, 0.80503145,\n",
      "       0.81132075, 0.79874214, 0.79874214, 0.80503145, 0.81132075,\n",
      "       0.83018868, 0.83018868, 0.83018868, 0.83647799, 0.83018868,\n",
      "       0.83018868, 0.83018868, 0.83018868, 0.79245283, 0.79874214,\n",
      "       0.81761006, 0.82389937, 0.79874214, 0.79874214, 0.81761006,\n",
      "       0.82389937, 0.83018868, 0.83647799, 0.83647799, 0.8427673 ,\n",
      "       0.83018868, 0.83018868, 0.83018868, 0.83018868, 0.74213836,\n",
      "       0.74213836, 0.75471698, 0.7672956 , 0.74213836, 0.74213836,\n",
      "       0.76100629, 0.77987421, 0.77987421, 0.77987421, 0.77358491,\n",
      "       0.78616352, 0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 ,\n",
      "       0.74842767, 0.73584906, 0.74842767, 0.7672956 , 0.72955975,\n",
      "       0.73584906, 0.75471698, 0.75471698, 0.74842767, 0.74842767,\n",
      "       0.74842767, 0.7672956 , 0.75471698, 0.75471698, 0.75471698,\n",
      "       0.75471698, 0.75471698, 0.74842767, 0.72955975, 0.74842767,\n",
      "       0.73584906, 0.73584906, 0.73584906, 0.74842767, 0.73584906,\n",
      "       0.73584906, 0.73584906, 0.75471698, 0.74842767, 0.74842767,\n",
      "       0.74842767, 0.74842767, 0.74842767, 0.74842767, 0.74213836,\n",
      "       0.74842767, 0.73584906, 0.73584906, 0.74842767, 0.74842767,\n",
      "       0.74213836, 0.73584906, 0.73584906, 0.75471698, 0.74842767,\n",
      "       0.74842767, 0.74842767, 0.74842767, 0.74213836, 0.74842767,\n",
      "       0.74213836, 0.75471698, 0.72955975, 0.73584906, 0.74842767,\n",
      "       0.74213836, 0.71698113, 0.71698113, 0.71698113, 0.74842767,\n",
      "       0.74842767, 0.74842767, 0.74842767, 0.74842767, 0.74842767,\n",
      "       0.74842767, 0.74213836, 0.74213836, 0.74842767, 0.75471698,\n",
      "       0.74842767, 0.74213836, 0.71698113, 0.71698113, 0.71698113,\n",
      "       0.74842767, 0.74842767, 0.74842767, 0.74842767, 0.74842767,\n",
      "       0.76100629, 0.7672956 , 0.74213836, 0.74213836, 0.72955975,\n",
      "       0.74213836, 0.74213836, 0.75471698, 0.71698113, 0.72327044,\n",
      "       0.71698113, 0.74842767, 0.74842767, 0.74842767, 0.74842767,\n",
      "       0.74842767, 0.72327044, 0.73584906, 0.71698113, 0.75471698,\n",
      "       0.71069182, 0.72327044, 0.72327044, 0.74213836, 0.71698113,\n",
      "       0.71698113, 0.71698113, 0.74842767, 0.74842767, 0.74842767,\n",
      "       0.74842767, 0.74842767, 0.72955975, 0.74842767, 0.71698113,\n",
      "       0.75471698, 0.70440252, 0.73584906, 0.72327044, 0.75471698,\n",
      "       0.71698113, 0.71698113, 0.71698113, 0.74842767, 0.74842767,\n",
      "       0.74842767, 0.74842767, 0.74842767, 0.72955975, 0.74213836,\n",
      "       0.71698113, 0.75471698, 0.71698113, 0.71698113, 0.72327044,\n",
      "       0.74213836, 0.71698113, 0.71698113, 0.71698113, 0.74842767,\n",
      "       0.74842767, 0.74842767, 0.74842767, 0.74842767, 0.74842767,\n",
      "       0.74842767, 0.71698113, 0.75471698, 0.70440252, 0.71698113,\n",
      "       0.72327044, 0.75471698, 0.71698113, 0.72327044, 0.71698113,\n",
      "       0.74842767, 0.74842767, 0.74842767, 0.74842767, 0.74842767]), 'split7_test_score': array([0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.82389937, 0.82389937, 0.82389937,\n",
      "       0.81132075, 0.82389937, 0.82389937, 0.82389937, 0.81132075,\n",
      "       0.82389937, 0.82389937, 0.82389937, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81761006, 0.81761006,\n",
      "       0.82389937, 0.81132075, 0.81761006, 0.81761006, 0.82389937,\n",
      "       0.81132075, 0.82389937, 0.82389937, 0.82389937, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.80503145, 0.81132075, 0.79874214, 0.80503145, 0.80503145,\n",
      "       0.81132075, 0.79874214, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.81132075, 0.80503145, 0.81132075, 0.80503145, 0.81132075,\n",
      "       0.81132075, 0.81761006, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.79245283, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.78616352, 0.77987421, 0.78616352, 0.79245283,\n",
      "       0.79245283, 0.79245283, 0.79874214, 0.79245283, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.7672956 , 0.7672956 , 0.7672956 ,\n",
      "       0.7672956 , 0.7672956 , 0.7672956 , 0.76100629, 0.7672956 ,\n",
      "       0.78616352, 0.77358491, 0.77358491, 0.77987421, 0.78616352,\n",
      "       0.77987421, 0.77987421, 0.77987421, 0.7672956 , 0.75471698,\n",
      "       0.75471698, 0.75471698, 0.75471698, 0.69811321, 0.71069182,\n",
      "       0.70440252, 0.72327044, 0.71698113, 0.72327044, 0.71698113,\n",
      "       0.72327044, 0.72327044, 0.72327044, 0.72327044, 0.73584906,\n",
      "       0.72955975, 0.72955975, 0.72955975, 0.72955975, 0.74213836,\n",
      "       0.72955975, 0.72955975, 0.73584906, 0.74213836, 0.74213836,\n",
      "       0.74213836, 0.73584906, 0.75471698, 0.76100629, 0.76100629,\n",
      "       0.72327044, 0.71069182, 0.71069182, 0.71069182, 0.71069182,\n",
      "       0.72327044, 0.71698113, 0.71698113, 0.74213836, 0.72327044,\n",
      "       0.72955975, 0.72327044, 0.74213836, 0.72327044, 0.72327044,\n",
      "       0.72955975, 0.72327044, 0.71069182, 0.71069182, 0.71069182,\n",
      "       0.71069182, 0.71698113, 0.71698113, 0.70440252, 0.74213836,\n",
      "       0.72327044, 0.72327044, 0.71069182, 0.74213836, 0.72955975,\n",
      "       0.72327044, 0.72955975, 0.72327044, 0.71069182, 0.71069182,\n",
      "       0.71069182, 0.71069182, 0.72327044, 0.71698113, 0.71698113,\n",
      "       0.73584906, 0.71698113, 0.72955975, 0.72955975, 0.73584906,\n",
      "       0.72327044, 0.72327044, 0.72327044, 0.72327044, 0.71069182,\n",
      "       0.71069182, 0.71069182, 0.71069182, 0.73584906, 0.71698113,\n",
      "       0.72327044, 0.73584906, 0.71698113, 0.72327044, 0.72327044,\n",
      "       0.73584906, 0.72955975, 0.72327044, 0.72327044, 0.72327044,\n",
      "       0.71069182, 0.71069182, 0.71069182, 0.71069182, 0.76100629,\n",
      "       0.73584906, 0.73584906, 0.73584906, 0.72955975, 0.72955975,\n",
      "       0.73584906, 0.73584906, 0.72327044, 0.72327044, 0.72327044,\n",
      "       0.72327044, 0.71069182, 0.71069182, 0.71069182, 0.71069182,\n",
      "       0.74213836, 0.74842767, 0.73584906, 0.73584906, 0.72955975,\n",
      "       0.73584906, 0.74213836, 0.73584906, 0.72327044, 0.72327044,\n",
      "       0.72955975, 0.72955975, 0.71069182, 0.71069182, 0.71069182,\n",
      "       0.71069182, 0.75471698, 0.73584906, 0.73584906, 0.73584906,\n",
      "       0.71698113, 0.72955975, 0.73584906, 0.73584906, 0.72327044,\n",
      "       0.72327044, 0.72327044, 0.72955975, 0.71069182, 0.71069182,\n",
      "       0.71069182, 0.71069182, 0.75471698, 0.74213836, 0.73584906,\n",
      "       0.73584906, 0.71069182, 0.72327044, 0.72955975, 0.73584906,\n",
      "       0.72327044, 0.72327044, 0.72327044, 0.72955975, 0.71069182,\n",
      "       0.71069182, 0.71069182, 0.71069182, 0.76100629, 0.73584906,\n",
      "       0.73584906, 0.73584906, 0.71698113, 0.72955975, 0.72955975,\n",
      "       0.73584906, 0.72327044, 0.72327044, 0.72327044, 0.72955975,\n",
      "       0.71069182, 0.71069182, 0.71069182, 0.71069182, 0.73584906,\n",
      "       0.72327044, 0.72955975, 0.73584906, 0.72327044, 0.72327044,\n",
      "       0.72955975, 0.73584906, 0.72955975, 0.72955975, 0.72327044,\n",
      "       0.72327044, 0.71069182, 0.71069182, 0.71069182, 0.71069182]), 'split8_test_score': array([0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 ,\n",
      "       0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 ,\n",
      "       0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 ,\n",
      "       0.7672956 , 0.7672956 , 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.83018868, 0.83018868,\n",
      "       0.83018868, 0.83018868, 0.83018868, 0.83018868, 0.83018868,\n",
      "       0.83018868, 0.83018868, 0.83018868, 0.83018868, 0.83018868,\n",
      "       0.83018868, 0.83018868, 0.83018868, 0.83018868, 0.85534591,\n",
      "       0.8490566 , 0.8490566 , 0.83018868, 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.83018868, 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.83018868, 0.83018868, 0.83018868, 0.83018868, 0.83018868,\n",
      "       0.82389937, 0.83018868, 0.83018868, 0.82389937, 0.82389937,\n",
      "       0.82389937, 0.82389937, 0.82389937, 0.83647799, 0.83647799,\n",
      "       0.83647799, 0.82389937, 0.82389937, 0.82389937, 0.82389937,\n",
      "       0.82389937, 0.81761006, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.82389937, 0.82389937, 0.82389937, 0.81132075, 0.82389937,\n",
      "       0.82389937, 0.82389937, 0.81132075, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81132075, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.83018868, 0.83018868, 0.83018868, 0.81761006,\n",
      "       0.83647799, 0.83647799, 0.83647799, 0.82389937, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.79874214, 0.80503145,\n",
      "       0.79245283, 0.79245283, 0.82389937, 0.82389937, 0.81761006,\n",
      "       0.79874214, 0.81761006, 0.81761006, 0.81761006, 0.80503145,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.82389937,\n",
      "       0.82389937, 0.81132075, 0.78616352, 0.83018868, 0.82389937,\n",
      "       0.82389937, 0.79874214, 0.82389937, 0.82389937, 0.82389937,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.83018868, 0.83018868, 0.82389937, 0.79874214, 0.81761006,\n",
      "       0.82389937, 0.83018868, 0.80503145, 0.83018868, 0.83018868,\n",
      "       0.83018868, 0.81132075, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.81132075, 0.81132075, 0.81132075, 0.79245283,\n",
      "       0.81761006, 0.81761006, 0.81132075, 0.79874214, 0.82389937,\n",
      "       0.82389937, 0.82389937, 0.80503145, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.77987421, 0.81132075, 0.80503145,\n",
      "       0.77987421, 0.79245283, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.82389937, 0.82389937, 0.82389937, 0.80503145, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.78616352, 0.81132075,\n",
      "       0.80503145, 0.77987421, 0.80503145, 0.81761006, 0.79874214,\n",
      "       0.78616352, 0.82389937, 0.82389937, 0.82389937, 0.80503145,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.74842767,\n",
      "       0.79874214, 0.77987421, 0.7672956 , 0.79245283, 0.78616352,\n",
      "       0.77358491, 0.77358491, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.78616352, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.74842767, 0.79874214, 0.79245283, 0.7672956 , 0.79245283,\n",
      "       0.80503145, 0.78616352, 0.77358491, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.78616352, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.7672956 , 0.81132075, 0.79245283, 0.76100629,\n",
      "       0.78616352, 0.79245283, 0.78616352, 0.7672956 , 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.78616352, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.74842767, 0.77358491, 0.79245283,\n",
      "       0.7672956 , 0.78616352, 0.77987421, 0.78616352, 0.77358491,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.78616352, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.74842767, 0.78616352,\n",
      "       0.79245283, 0.76100629, 0.77987421, 0.78616352, 0.78616352,\n",
      "       0.77358491, 0.81761006, 0.81761006, 0.81761006, 0.78616352,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.74213836,\n",
      "       0.78616352, 0.79245283, 0.76100629, 0.77358491, 0.77987421,\n",
      "       0.78616352, 0.77358491, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.78616352, 0.80503145, 0.80503145, 0.80503145, 0.80503145]), 'split9_test_score': array([0.80379747, 0.80379747, 0.80379747, 0.80379747, 0.80379747,\n",
      "       0.80379747, 0.80379747, 0.80379747, 0.80379747, 0.80379747,\n",
      "       0.80379747, 0.80379747, 0.80379747, 0.80379747, 0.80379747,\n",
      "       0.80379747, 0.74683544, 0.74683544, 0.74683544, 0.74683544,\n",
      "       0.74683544, 0.74683544, 0.74683544, 0.74683544, 0.74683544,\n",
      "       0.74683544, 0.74683544, 0.74683544, 0.74683544, 0.74683544,\n",
      "       0.74683544, 0.74683544, 0.86075949, 0.86075949, 0.86075949,\n",
      "       0.85443038, 0.86075949, 0.86075949, 0.86075949, 0.85443038,\n",
      "       0.86075949, 0.86075949, 0.86075949, 0.85443038, 0.85443038,\n",
      "       0.85443038, 0.85443038, 0.85443038, 0.86075949, 0.86075949,\n",
      "       0.86075949, 0.85443038, 0.86075949, 0.86075949, 0.86075949,\n",
      "       0.85443038, 0.86075949, 0.86075949, 0.86075949, 0.85443038,\n",
      "       0.85443038, 0.85443038, 0.85443038, 0.85443038, 0.86708861,\n",
      "       0.85443038, 0.85443038, 0.84810127, 0.86708861, 0.85443038,\n",
      "       0.85443038, 0.84810127, 0.85443038, 0.85443038, 0.85443038,\n",
      "       0.84810127, 0.84810127, 0.84810127, 0.84810127, 0.84810127,\n",
      "       0.86075949, 0.84810127, 0.85443038, 0.84810127, 0.86075949,\n",
      "       0.84810127, 0.85443038, 0.84810127, 0.85443038, 0.85443038,\n",
      "       0.85443038, 0.84810127, 0.84810127, 0.84810127, 0.84810127,\n",
      "       0.84810127, 0.86075949, 0.84810127, 0.85443038, 0.84810127,\n",
      "       0.86075949, 0.84810127, 0.85443038, 0.84810127, 0.83544304,\n",
      "       0.83544304, 0.83544304, 0.83544304, 0.83544304, 0.83544304,\n",
      "       0.83544304, 0.83544304, 0.83544304, 0.82911392, 0.83544304,\n",
      "       0.84177215, 0.84177215, 0.82911392, 0.83544304, 0.84177215,\n",
      "       0.84810127, 0.84810127, 0.84810127, 0.84810127, 0.8164557 ,\n",
      "       0.8164557 , 0.8164557 , 0.8164557 , 0.76582278, 0.75316456,\n",
      "       0.76582278, 0.7721519 , 0.76582278, 0.75316456, 0.76582278,\n",
      "       0.7721519 , 0.8164557 , 0.8164557 , 0.8164557 , 0.8164557 ,\n",
      "       0.75316456, 0.77848101, 0.75316456, 0.77848101, 0.80379747,\n",
      "       0.79113924, 0.79746835, 0.80379747, 0.8164557 , 0.80379747,\n",
      "       0.80379747, 0.8164557 , 0.7721519 , 0.7721519 , 0.7721519 ,\n",
      "       0.77848101, 0.75949367, 0.78481013, 0.78481013, 0.78481013,\n",
      "       0.7721519 , 0.75316456, 0.75949367, 0.76582278, 0.78481013,\n",
      "       0.7721519 , 0.7721519 , 0.78481013, 0.76582278, 0.76582278,\n",
      "       0.76582278, 0.78481013, 0.78481013, 0.79113924, 0.79113924,\n",
      "       0.79113924, 0.80379747, 0.78481013, 0.79113924, 0.79113924,\n",
      "       0.80379747, 0.78481013, 0.78481013, 0.80379747, 0.76582278,\n",
      "       0.76582278, 0.76582278, 0.78481013, 0.78481013, 0.79113924,\n",
      "       0.79113924, 0.78481013, 0.79113924, 0.76582278, 0.77848101,\n",
      "       0.78481013, 0.80379747, 0.79113924, 0.78481013, 0.79746835,\n",
      "       0.76582278, 0.76582278, 0.76582278, 0.78481013, 0.78481013,\n",
      "       0.78481013, 0.79113924, 0.78481013, 0.78481013, 0.76582278,\n",
      "       0.7721519 , 0.78481013, 0.78481013, 0.7721519 , 0.76582278,\n",
      "       0.79746835, 0.76582278, 0.76582278, 0.76582278, 0.78481013,\n",
      "       0.78481013, 0.78481013, 0.78481013, 0.79113924, 0.79746835,\n",
      "       0.76582278, 0.7721519 , 0.77848101, 0.77848101, 0.7721519 ,\n",
      "       0.76582278, 0.79746835, 0.76582278, 0.76582278, 0.76582278,\n",
      "       0.78481013, 0.78481013, 0.78481013, 0.78481013, 0.79113924,\n",
      "       0.79113924, 0.75949367, 0.7721519 , 0.78481013, 0.78481013,\n",
      "       0.7721519 , 0.76582278, 0.79746835, 0.74683544, 0.74683544,\n",
      "       0.74683544, 0.78481013, 0.78481013, 0.78481013, 0.78481013,\n",
      "       0.78481013, 0.78481013, 0.75949367, 0.7721519 , 0.77848101,\n",
      "       0.78481013, 0.76582278, 0.76582278, 0.79746835, 0.74683544,\n",
      "       0.74683544, 0.74683544, 0.78481013, 0.78481013, 0.79113924,\n",
      "       0.78481013, 0.78481013, 0.78481013, 0.75949367, 0.7721519 ,\n",
      "       0.77848101, 0.7721519 , 0.76582278, 0.76582278, 0.79746835,\n",
      "       0.74683544, 0.74683544, 0.74050633, 0.78481013, 0.79113924,\n",
      "       0.78481013, 0.79113924, 0.78481013, 0.78481013, 0.76582278,\n",
      "       0.77848101, 0.77848101, 0.77848101, 0.7721519 , 0.76582278,\n",
      "       0.79746835, 0.74683544, 0.74683544, 0.74683544, 0.78481013,\n",
      "       0.79113924, 0.78481013, 0.78481013, 0.79113924, 0.78481013,\n",
      "       0.76582278, 0.77848101, 0.77848101, 0.7721519 , 0.7721519 ,\n",
      "       0.76582278, 0.79746835, 0.74683544, 0.74683544, 0.74683544,\n",
      "       0.78481013, 0.79113924, 0.78481013, 0.79113924, 0.79113924]), 'mean_test_score': array([0.78478226, 0.78478226, 0.78478226, 0.78478226, 0.78478226,\n",
      "       0.78478226, 0.78478226, 0.78478226, 0.78478226, 0.78478226,\n",
      "       0.78478226, 0.78478226, 0.78478226, 0.78478226, 0.78478226,\n",
      "       0.78478226, 0.74952631, 0.74952631, 0.74952631, 0.74952631,\n",
      "       0.74952631, 0.74952631, 0.74952631, 0.74952631, 0.74952631,\n",
      "       0.74952631, 0.74952631, 0.74952631, 0.74952631, 0.74952631,\n",
      "       0.74952631, 0.74952631, 0.83324576, 0.83324576, 0.83324576,\n",
      "       0.8294682 , 0.83324576, 0.83324576, 0.83324576, 0.8294682 ,\n",
      "       0.83324576, 0.83324576, 0.83324576, 0.8294682 , 0.8294682 ,\n",
      "       0.8294682 , 0.8294682 , 0.8294682 , 0.82947218, 0.82884324,\n",
      "       0.82884324, 0.82632354, 0.82884324, 0.82947218, 0.82947218,\n",
      "       0.82632354, 0.83010111, 0.83073004, 0.83010111, 0.8275814 ,\n",
      "       0.8275814 , 0.8275814 , 0.8275814 , 0.8275814 , 0.82318685,\n",
      "       0.81877637, 0.82003423, 0.81499881, 0.82130006, 0.8194053 ,\n",
      "       0.82129209, 0.81562774, 0.82066316, 0.82129209, 0.82066316,\n",
      "       0.8168856 , 0.81814346, 0.81814346, 0.81814346, 0.81814346,\n",
      "       0.81500677, 0.81185415, 0.81374492, 0.81122522, 0.81123318,\n",
      "       0.81059629, 0.81374492, 0.81122522, 0.81248706, 0.81248706,\n",
      "       0.81185813, 0.80808057, 0.80996736, 0.80996736, 0.80996736,\n",
      "       0.80996736, 0.80054136, 0.79550195, 0.79802165, 0.79927554,\n",
      "       0.80054136, 0.79738874, 0.80179524, 0.79927554, 0.80304116,\n",
      "       0.80241223, 0.80304116, 0.79989651, 0.80115437, 0.80115437,\n",
      "       0.80115437, 0.80115437, 0.79109147, 0.78982963, 0.79486506,\n",
      "       0.79486904, 0.79361118, 0.79297429, 0.79738078, 0.79424011,\n",
      "       0.8005334 , 0.8005334 , 0.8005334 , 0.79801767, 0.79422419,\n",
      "       0.79422419, 0.79422419, 0.79422419, 0.75897222, 0.75644853,\n",
      "       0.7627458 , 0.76652337, 0.76589045, 0.76273784, 0.76903511,\n",
      "       0.76652337, 0.77975878, 0.78038771, 0.78101664, 0.78164557,\n",
      "       0.77594539, 0.77847703, 0.77594539, 0.7778481 , 0.76591434,\n",
      "       0.75898814, 0.76653929, 0.76151182, 0.76843802, 0.76528541,\n",
      "       0.76968792, 0.7659223 , 0.77218374, 0.77281267, 0.77155481,\n",
      "       0.76841414, 0.7583393 , 0.76149988, 0.76212881, 0.76149988,\n",
      "       0.75960513, 0.75141708, 0.75456572, 0.75708542, 0.75646843,\n",
      "       0.75520261, 0.7570894 , 0.75646843, 0.76211687, 0.76023008,\n",
      "       0.75960115, 0.7640156 , 0.76087095, 0.76150386, 0.76087493,\n",
      "       0.76213279, 0.75710931, 0.75395271, 0.75081204, 0.75584348,\n",
      "       0.75585144, 0.75458164, 0.75269485, 0.75648038, 0.75960115,\n",
      "       0.75897222, 0.75897222, 0.76149988, 0.7577263 , 0.75835921,\n",
      "       0.75710135, 0.7577263 , 0.74892524, 0.75142505, 0.74765942,\n",
      "       0.75143699, 0.74704641, 0.75081204, 0.74829233, 0.75207388,\n",
      "       0.75645649, 0.7545697 , 0.75519863, 0.75898416, 0.7558395 ,\n",
      "       0.75709736, 0.75710135, 0.75646843, 0.74703447, 0.74765146,\n",
      "       0.74199506, 0.7476634 , 0.74388982, 0.74702651, 0.74702253,\n",
      "       0.75081602, 0.75331184, 0.75205398, 0.75394077, 0.7558395 ,\n",
      "       0.7577263 , 0.7558395 , 0.75709736, 0.75584348, 0.74452671,\n",
      "       0.74450681, 0.74136613, 0.74388584, 0.74199904, 0.74702651,\n",
      "       0.74324895, 0.74955816, 0.75331184, 0.75268291, 0.75142505,\n",
      "       0.7558395 , 0.75646843, 0.75646843, 0.7558395 , 0.75835921,\n",
      "       0.74074914, 0.74010031, 0.73885041, 0.74326089, 0.73760051,\n",
      "       0.7407372 , 0.7382175 , 0.74830029, 0.74826845, 0.74889738,\n",
      "       0.74889738, 0.75395271, 0.7577263 , 0.7558395 , 0.75646843,\n",
      "       0.7577263 , 0.74011623, 0.74072924, 0.73696362, 0.74325691,\n",
      "       0.73319799, 0.73758857, 0.73884643, 0.74830029, 0.74889738,\n",
      "       0.74952631, 0.74952631, 0.75458164, 0.75835523, 0.75898814,\n",
      "       0.75709736, 0.7577263 , 0.73508479, 0.73569779, 0.73381896,\n",
      "       0.74640156, 0.72627179, 0.73570178, 0.73129926, 0.74892923,\n",
      "       0.7451238 , 0.74449487, 0.74386195, 0.75458164, 0.75835921,\n",
      "       0.75646843, 0.75773028, 0.75709736, 0.73508479, 0.74010429,\n",
      "       0.73822546, 0.74451477, 0.73319401, 0.73193217, 0.73444391,\n",
      "       0.74767136, 0.74449487, 0.74449487, 0.7451238 , 0.75332378,\n",
      "       0.75710135, 0.7577263 , 0.75709736, 0.75898814, 0.73697158,\n",
      "       0.74010429, 0.73570974, 0.74325691, 0.73067431, 0.73067431,\n",
      "       0.73129926, 0.74892923, 0.74575273, 0.74826845, 0.74638166,\n",
      "       0.75521057, 0.75898814, 0.7577263 , 0.75710135, 0.75647241]), 'std_test_score': array([0.0180514 , 0.0180514 , 0.0180514 , 0.0180514 , 0.0180514 ,\n",
      "       0.0180514 , 0.0180514 , 0.0180514 , 0.0180514 , 0.0180514 ,\n",
      "       0.0180514 , 0.0180514 , 0.0180514 , 0.0180514 , 0.0180514 ,\n",
      "       0.0180514 , 0.03117867, 0.03117867, 0.03117867, 0.03117867,\n",
      "       0.03117867, 0.03117867, 0.03117867, 0.03117867, 0.03117867,\n",
      "       0.03117867, 0.03117867, 0.03117867, 0.03117867, 0.03117867,\n",
      "       0.03117867, 0.03117867, 0.02572199, 0.02572199, 0.02572199,\n",
      "       0.0248189 , 0.02572199, 0.02572199, 0.02572199, 0.0248189 ,\n",
      "       0.02572199, 0.02572199, 0.02572199, 0.0248189 , 0.0248189 ,\n",
      "       0.0248189 , 0.0248189 , 0.0248189 , 0.02573989, 0.02437213,\n",
      "       0.02437213, 0.02444591, 0.02437213, 0.02573989, 0.02415432,\n",
      "       0.02444591, 0.02391799, 0.02382917, 0.02391799, 0.02396037,\n",
      "       0.02396037, 0.02396037, 0.02396037, 0.02396037, 0.03176123,\n",
      "       0.03067806, 0.0330885 , 0.03224031, 0.03083999, 0.02953027,\n",
      "       0.03297223, 0.03109938, 0.03112526, 0.03086551, 0.03112526,\n",
      "       0.03051264, 0.03025622, 0.03025622, 0.03025622, 0.03025622,\n",
      "       0.0289825 , 0.02706072, 0.03354611, 0.03317263, 0.02961921,\n",
      "       0.0261644 , 0.03283101, 0.03269218, 0.03566871, 0.03566871,\n",
      "       0.03595979, 0.03516089, 0.03350125, 0.03350125, 0.03350125,\n",
      "       0.03350125, 0.03441442, 0.03656131, 0.03979049, 0.04174323,\n",
      "       0.03565634, 0.03428277, 0.03937953, 0.04126672, 0.03548753,\n",
      "       0.03572455, 0.03548753, 0.03633215, 0.03222811, 0.03222811,\n",
      "       0.03222811, 0.03222811, 0.03832118, 0.03446168, 0.03774907,\n",
      "       0.03877079, 0.03737533, 0.03224826, 0.03895229, 0.0378241 ,\n",
      "       0.03926571, 0.03926571, 0.03926571, 0.03999822, 0.03472086,\n",
      "       0.03472086, 0.03472086, 0.03472086, 0.03621356, 0.03733026,\n",
      "       0.04065353, 0.0401948 , 0.03718442, 0.03649948, 0.04057895,\n",
      "       0.04048895, 0.04383733, 0.0445949 , 0.04462756, 0.04366601,\n",
      "       0.03846946, 0.03771255, 0.03846946, 0.03825695, 0.03238852,\n",
      "       0.03421322, 0.03187576, 0.03570129, 0.03379689, 0.03325983,\n",
      "       0.03208393, 0.03776834, 0.03337221, 0.03356989, 0.03363516,\n",
      "       0.03639367, 0.02897588, 0.03011411, 0.02963367, 0.02958404,\n",
      "       0.02994161, 0.0323339 , 0.03141955, 0.02710247, 0.03030108,\n",
      "       0.03104302, 0.03359114, 0.03003886, 0.03382658, 0.03330568,\n",
      "       0.03213629, 0.03250029, 0.03446634, 0.03495477, 0.0350146 ,\n",
      "       0.03454166, 0.02999495, 0.02775479, 0.03544862, 0.030632  ,\n",
      "       0.03123032, 0.02975911, 0.03523476, 0.03416624, 0.03831254,\n",
      "       0.03884841, 0.03854174, 0.03405898, 0.03482511, 0.03195709,\n",
      "       0.03182788, 0.03482511, 0.0240361 , 0.02864077, 0.03379207,\n",
      "       0.02404578, 0.03081277, 0.0263613 , 0.03191224, 0.03012568,\n",
      "       0.03620332, 0.03758422, 0.03710476, 0.03183975, 0.0315455 ,\n",
      "       0.03222078, 0.03316679, 0.03157952, 0.02491815, 0.02809128,\n",
      "       0.0377237 , 0.03057382, 0.03063469, 0.03431755, 0.03434162,\n",
      "       0.0302514 , 0.04174788, 0.04225204, 0.04007261, 0.03555411,\n",
      "       0.03331582, 0.03349172, 0.03366172, 0.03393992, 0.02538835,\n",
      "       0.02732509, 0.03505254, 0.028519  , 0.02737012, 0.02433668,\n",
      "       0.03054491, 0.03032447, 0.03797716, 0.03841486, 0.03863594,\n",
      "       0.03301592, 0.03316791, 0.03316791, 0.03349172, 0.03387968,\n",
      "       0.02269508, 0.0300682 , 0.04066418, 0.03098498, 0.02860272,\n",
      "       0.02918111, 0.03847777, 0.03248575, 0.03927962, 0.03736761,\n",
      "       0.03871928, 0.03272536, 0.03402074, 0.03419301, 0.03433979,\n",
      "       0.03402074, 0.02492026, 0.03056066, 0.03912555, 0.03075173,\n",
      "       0.02874059, 0.0236956 , 0.031095  , 0.03034527, 0.03892306,\n",
      "       0.03676739, 0.03708874, 0.02949208, 0.03413351, 0.03467259,\n",
      "       0.03435954, 0.03448268, 0.02588993, 0.02233617, 0.03335563,\n",
      "       0.02768696, 0.02984136, 0.02282487, 0.03498799, 0.03205308,\n",
      "       0.03711782, 0.03742819, 0.03743678, 0.0323083 , 0.03502775,\n",
      "       0.03433979, 0.03457643, 0.03435954, 0.02780526, 0.02609384,\n",
      "       0.03487704, 0.02854287, 0.02493341, 0.02542617, 0.03011087,\n",
      "       0.03204808, 0.03513883, 0.03784857, 0.03754167, 0.03203251,\n",
      "       0.03490991, 0.03448268, 0.03401242, 0.03467259, 0.02486343,\n",
      "       0.02578888, 0.03563008, 0.03075173, 0.02272417, 0.02407647,\n",
      "       0.03476115, 0.03205308, 0.03679407, 0.03422087, 0.03546667,\n",
      "       0.03034764, 0.03467259, 0.03448268, 0.03490991, 0.03477699]), 'rank_test_score': array([ 97,  97,  97,  97,  97,  97,  97,  97,  97,  97,  97,  97,  97,\n",
      "        97,  97,  97, 232, 232, 232, 232, 232, 232, 232, 232, 232, 232,\n",
      "       232, 232, 232, 232, 232, 232,   1,   1,   1,  16,   1,   1,   1,\n",
      "        16,   1,   1,   1,  16,  16,  16,  16,  16,  13,  23,  23,  31,\n",
      "        23,  13,  13,  31,  11,  10,  11,  26,  26,  26,  26,  26,  33,\n",
      "        41,  39,  49,  34,  40,  35,  47,  37,  35,  37,  46,  42,  42,\n",
      "        42,  42,  48,  55,  50,  57,  56,  59,  51,  57,  52,  52,  54,\n",
      "        64,  60,  60,  60,  60,  73,  85,  81,  79,  74,  83,  68,  79,\n",
      "        65,  67,  65,  78,  69,  69,  69,  69,  95,  96,  87,  86,  93,\n",
      "        94,  84,  88,  75,  75,  75,  82,  89,  89,  89,  89, 157, 196,\n",
      "       136, 129, 133, 137, 125, 129, 116, 115, 114, 113, 119, 117, 119,\n",
      "       118, 132, 152, 128, 141, 126, 134, 124, 131, 122, 121, 123, 127,\n",
      "       164, 144, 139, 144, 149, 227, 213, 185, 188, 207, 184, 188, 140,\n",
      "       148, 150, 135, 147, 142, 146, 138, 174, 214, 230, 198, 197, 209,\n",
      "       220, 186, 150, 157, 157, 143, 169, 160, 175, 169, 252, 225, 263,\n",
      "       224, 265, 229, 258, 222, 195, 212, 208, 156, 201, 179, 175, 188,\n",
      "       266, 264, 289, 262, 281, 267, 269, 228, 218, 223, 216, 201, 166,\n",
      "       201, 179, 199, 275, 277, 290, 282, 288, 267, 287, 231, 219, 221,\n",
      "       225, 200, 188, 188, 201, 160, 291, 297, 298, 284, 302, 292, 301,\n",
      "       256, 260, 253, 253, 214, 166, 201, 188, 166, 294, 293, 305, 285,\n",
      "       313, 303, 299, 256, 253, 249, 232, 210, 163, 152, 179, 169, 309,\n",
      "       308, 312, 270, 320, 307, 316, 250, 273, 278, 283, 210, 162, 188,\n",
      "       165, 179, 309, 296, 300, 276, 314, 315, 311, 261, 278, 278, 273,\n",
      "       217, 175, 169, 179, 152, 304, 295, 306, 285, 318, 318, 316, 250,\n",
      "       272, 259, 271, 206, 152, 169, 175, 187])}\n",
      "Resultados para OverSampler:\n",
      "{'mean_fit_time': array([0.00129998, 0.00109797, 0.00129979, 0.0017    , 0.00129945,\n",
      "       0.00130193, 0.00139863, 0.0013669 , 0.00109971, 0.00119927,\n",
      "       0.00137398, 0.00100155, 0.00170097, 0.00146246, 0.00133924,\n",
      "       0.00135698, 0.00153365, 0.0015372 , 0.0014142 , 0.0015722 ,\n",
      "       0.00141065, 0.00180352, 0.00163486, 0.0014652 , 0.00126336,\n",
      "       0.00151236, 0.00136149, 0.00147531, 0.00156324, 0.00145104,\n",
      "       0.00151756, 0.00153971, 0.00192997, 0.00190105, 0.00200787,\n",
      "       0.0021136 , 0.00225766, 0.00193217, 0.0019604 , 0.0017215 ,\n",
      "       0.00175157, 0.00225601, 0.00199986, 0.00169983, 0.00170217,\n",
      "       0.00210011, 0.00220063, 0.00282333, 0.00249794, 0.00190668,\n",
      "       0.00190229, 0.00200009, 0.00200012, 0.00200031, 0.00190055,\n",
      "       0.0018003 , 0.00199854, 0.00200167, 0.00179908, 0.00181732,\n",
      "       0.00180264, 0.00189979, 0.00180106, 0.00190115, 0.00189898,\n",
      "       0.00200036, 0.00199983, 0.00200021, 0.00209937, 0.00200024,\n",
      "       0.00200019, 0.00200009, 0.00200014, 0.00199988, 0.00209961,\n",
      "       0.00189991, 0.00199943, 0.00189998, 0.00200024, 0.00200014,\n",
      "       0.00259817, 0.00200002, 0.00199959, 0.00239899, 0.00199955,\n",
      "       0.00211754, 0.00250368, 0.00249991, 0.00230012, 0.00220089,\n",
      "       0.00210044, 0.00199981, 0.00230017, 0.00210152, 0.00200088,\n",
      "       0.00200038, 0.00220006, 0.0020998 , 0.00239997, 0.00249949,\n",
      "       0.00240102, 0.0021009 , 0.0022001 , 0.00220063, 0.00220146,\n",
      "       0.00230021, 0.00219948, 0.00220015, 0.00227759, 0.00194407,\n",
      "       0.00209663, 0.00226064, 0.00241992, 0.00271685, 0.0026232 ,\n",
      "       0.00240402, 0.00230172, 0.0024009 , 0.00229976, 0.00256591,\n",
      "       0.00232525, 0.00239952, 0.00219195, 0.00225222, 0.00285356,\n",
      "       0.00254354, 0.00229149, 0.00249975, 0.00240119, 0.00239832,\n",
      "       0.00238953, 0.00224812, 0.00259295, 0.00259631, 0.00256221,\n",
      "       0.00233819, 0.00240183, 0.00249743, 0.00249994, 0.00231335,\n",
      "       0.00246108, 0.00237334, 0.00257785, 0.00226274, 0.00260665,\n",
      "       0.00249767, 0.00249774, 0.00239887, 0.00290706, 0.00251889,\n",
      "       0.00240109, 0.00260119, 0.00260015, 0.00239911, 0.00230021,\n",
      "       0.00246234, 0.00240088, 0.00239868, 0.00260177, 0.00240018,\n",
      "       0.00250049, 0.00260043, 0.0026263 , 0.00240123, 0.00270276,\n",
      "       0.00249946, 0.00249884, 0.00249939, 0.00260053, 0.00257139,\n",
      "       0.0025116 , 0.00239873, 0.00235214, 0.0024168 , 0.00250072,\n",
      "       0.00228138, 0.00279887, 0.00279849, 0.00279946, 0.00260024,\n",
      "       0.00259914, 0.00275121, 0.00249264, 0.00235612, 0.00259895,\n",
      "       0.002742  , 0.00249958, 0.00260348, 0.00249994, 0.00250041,\n",
      "       0.0025012 , 0.00259972, 0.0026994 , 0.0028986 , 0.00299892,\n",
      "       0.00269878, 0.00269837, 0.00269949, 0.00279927, 0.00259936,\n",
      "       0.00269964, 0.00259891, 0.00249937, 0.00260105, 0.00249884,\n",
      "       0.00269954, 0.0027992 , 0.00249951, 0.00289876, 0.0028986 ,\n",
      "       0.0028996 , 0.00259943, 0.00271378, 0.00279942, 0.00259745,\n",
      "       0.00249932, 0.00269818, 0.00259955, 0.00269928, 0.00269809,\n",
      "       0.0024996 , 0.00259945, 0.00239911, 0.00259914, 0.0028971 ,\n",
      "       0.00279839, 0.00269926, 0.00269866, 0.00289876, 0.00289891,\n",
      "       0.00289886, 0.00289962, 0.00279899, 0.00279815, 0.00259917,\n",
      "       0.00270092, 0.00260029, 0.00249937, 0.00239956, 0.0026546 ,\n",
      "       0.0028981 , 0.00289881, 0.00279863, 0.00259883, 0.0028986 ,\n",
      "       0.00289896, 0.00259645, 0.00259957, 0.00269885, 0.00269895,\n",
      "       0.00274613, 0.0026993 , 0.00259888, 0.00269957, 0.0023994 ,\n",
      "       0.00239942, 0.00289795, 0.00289843, 0.00269904, 0.00269926,\n",
      "       0.00289998, 0.00279894, 0.0028985 , 0.00259919, 0.0026989 ,\n",
      "       0.00279884, 0.00259774, 0.00259933, 0.00239954, 0.00259941,\n",
      "       0.00260103, 0.00269945, 0.00279796, 0.00280054, 0.00279815,\n",
      "       0.0025003 , 0.00279913, 0.00279765, 0.00279911, 0.00259922,\n",
      "       0.00259931, 0.00269938, 0.00269876, 0.0026    , 0.00270069,\n",
      "       0.0026    , 0.00249903, 0.00249939, 0.00289774, 0.00289953,\n",
      "       0.00269802, 0.0026988 , 0.00279865, 0.00279717, 0.00269692,\n",
      "       0.00269942, 0.00249901, 0.00289955, 0.00259919, 0.00279925,\n",
      "       0.00269916, 0.00289862, 0.0024986 , 0.00239956, 0.00289884,\n",
      "       0.00289853, 0.00269871, 0.00270061, 0.0028985 , 0.00289903,\n",
      "       0.00259876, 0.00249913, 0.00269866, 0.00269797, 0.00280063,\n",
      "       0.00259931, 0.00245273, 0.00259905, 0.00246444, 0.00259914]), 'std_fit_time': array([4.58385798e-04, 2.97708761e-04, 4.58302926e-04, 4.58563105e-04,\n",
      "       4.57755365e-04, 4.59255332e-04, 4.89199207e-04, 5.67353525e-04,\n",
      "       2.99192087e-04, 4.00964247e-04, 4.64687847e-04, 4.88007364e-06,\n",
      "       4.58480579e-04, 4.05170318e-04, 4.29034890e-04, 4.49970779e-04,\n",
      "       4.59255519e-04, 4.64649237e-04, 4.85197100e-04, 4.72854986e-04,\n",
      "       4.38639325e-04, 6.19493801e-04, 4.08579922e-04, 4.70585954e-04,\n",
      "       4.11707267e-04, 4.48471825e-04, 4.54266224e-04, 4.70756086e-04,\n",
      "       4.69066558e-04, 4.73339935e-04, 5.79046555e-04, 5.53676638e-04,\n",
      "       4.67661996e-04, 6.98288052e-04, 6.50635987e-04, 4.82844697e-04,\n",
      "       3.83664775e-04, 5.35859475e-04, 5.63529144e-04, 6.18474524e-04,\n",
      "       3.50170850e-04, 6.02953886e-04, 4.46916374e-04, 4.58714040e-04,\n",
      "       4.57042013e-04, 6.99946220e-04, 5.99539596e-04, 1.15760866e-03,\n",
      "       6.26965847e-04, 2.84334019e-04, 3.00577430e-04, 5.54034712e-07,\n",
      "       5.05199912e-07, 6.69697376e-07, 3.00053059e-04, 4.00008031e-04,\n",
      "       4.84318457e-06, 4.20077028e-06, 3.99530718e-04, 4.11233281e-04,\n",
      "       4.00906662e-04, 2.99798694e-04, 4.00338955e-04, 3.00502497e-04,\n",
      "       2.99699029e-04, 7.26687939e-07, 1.07922271e-06, 7.85335021e-07,\n",
      "       3.01585672e-04, 9.12243198e-07, 8.47644274e-07, 9.94522744e-07,\n",
      "       8.10623169e-07, 7.34468546e-07, 3.00137993e-04, 3.00074552e-04,\n",
      "       4.45319353e-04, 2.99939545e-04, 4.47288190e-04, 8.77950317e-07,\n",
      "       4.92138342e-04, 3.26911780e-06, 3.61335922e-06, 4.90598974e-04,\n",
      "       2.83106377e-07, 2.40629984e-04, 4.96143069e-04, 5.00012274e-04,\n",
      "       4.58403257e-04, 3.99210418e-04, 3.00417258e-04, 5.51978917e-07,\n",
      "       4.56917114e-04, 2.99502387e-04, 7.15652991e-07, 1.44945947e-06,\n",
      "       3.99810286e-04, 3.00869280e-04, 4.90673937e-04, 4.99440913e-04,\n",
      "       4.89443092e-04, 2.99487879e-04, 3.99304522e-04, 3.99936964e-04,\n",
      "       3.99247372e-04, 4.58704283e-04, 4.00508599e-04, 3.99697686e-04,\n",
      "       4.27239554e-04, 1.66922873e-04, 2.09117137e-04, 4.11459559e-04,\n",
      "       4.66547457e-04, 5.98886638e-04, 4.19903601e-04, 4.88633719e-04,\n",
      "       4.61279109e-04, 4.90266188e-04, 4.59743226e-04, 5.06022086e-04,\n",
      "       4.49525428e-04, 4.89440082e-04, 4.32156336e-04, 4.03703180e-04,\n",
      "       8.72228628e-04, 4.89020384e-04, 3.94408842e-04, 5.01951169e-04,\n",
      "       4.88858469e-04, 4.89534158e-04, 5.34815423e-04, 4.04246657e-04,\n",
      "       5.19462723e-04, 4.23657137e-04, 4.56464347e-04, 4.93730057e-04,\n",
      "       4.88234251e-04, 5.01841354e-04, 4.99512702e-04, 4.06937528e-04,\n",
      "       4.74126745e-04, 5.15914274e-04, 4.83980262e-04, 4.16141735e-04,\n",
      "       4.97593837e-04, 4.99870613e-04, 4.98797116e-04, 4.89528052e-04,\n",
      "       3.03080910e-04, 4.85112598e-04, 4.89420203e-04, 4.89639764e-04,\n",
      "       4.89024587e-04, 4.90691087e-04, 4.59280900e-04, 4.74944170e-04,\n",
      "       4.89838093e-04, 4.90073165e-04, 4.86568351e-04, 4.90301816e-04,\n",
      "       4.99445665e-04, 4.88861189e-04, 5.16763789e-04, 4.89543635e-04,\n",
      "       4.56636984e-04, 4.99661300e-04, 5.00421758e-04, 4.99652444e-04,\n",
      "       4.89425473e-04, 4.72441606e-04, 4.89141525e-04, 4.89008932e-04,\n",
      "       4.49794039e-04, 4.42405250e-04, 4.99061023e-04, 4.33023393e-04,\n",
      "       4.00760882e-04, 4.00273383e-04, 4.00103313e-04, 4.90506219e-04,\n",
      "       4.89132380e-04, 4.01877302e-04, 4.92857471e-04, 8.96972680e-04,\n",
      "       4.89261633e-04, 5.18036170e-04, 4.99584284e-04, 4.94368174e-04,\n",
      "       4.99940307e-04, 4.99606474e-04, 5.01430830e-04, 4.89786334e-04,\n",
      "       4.58068950e-04, 2.99583342e-04, 4.46970187e-04, 4.58127777e-04,\n",
      "       4.57444760e-04, 4.57866544e-04, 3.99830985e-04, 4.89542288e-04,\n",
      "       4.57908556e-04, 4.89026103e-04, 4.99320155e-04, 4.90945726e-04,\n",
      "       4.99039992e-04, 4.57934470e-04, 3.99616851e-04, 4.99463548e-04,\n",
      "       3.00037805e-04, 2.99901370e-04, 3.00106412e-04, 4.89552246e-04,\n",
      "       3.96104256e-04, 3.99843669e-04, 4.88915630e-04, 4.99654044e-04,\n",
      "       4.59566663e-04, 4.89651028e-04, 4.57726047e-04, 4.59037120e-04,\n",
      "       4.99845850e-04, 4.89474138e-04, 4.89668501e-04, 4.89171902e-04,\n",
      "       5.38177100e-04, 3.99449892e-04, 4.57918348e-04, 4.57632660e-04,\n",
      "       2.99639232e-04, 3.00960362e-04, 2.99592712e-04, 3.00008180e-04,\n",
      "       3.99807794e-04, 3.99346310e-04, 4.89581439e-04, 4.56678491e-04,\n",
      "       4.88940835e-04, 4.99415876e-04, 4.89298176e-04, 4.52314163e-04,\n",
      "       2.99653103e-04, 2.99735704e-04, 3.99566963e-04, 4.89163987e-04,\n",
      "       2.99583456e-04, 2.99782717e-04, 4.89764074e-04, 4.89717196e-04,\n",
      "       4.57756976e-04, 4.57769146e-04, 5.07661971e-04, 4.58106817e-04,\n",
      "       4.89347292e-04, 4.58227308e-04, 4.89093779e-04, 4.89415046e-04,\n",
      "       2.99844241e-04, 2.99685695e-04, 4.55342251e-04, 4.57710462e-04,\n",
      "       3.00134319e-04, 3.99721745e-04, 2.99724488e-04, 4.89456048e-04,\n",
      "       4.59518459e-04, 3.99734140e-04, 4.90905603e-04, 4.89522490e-04,\n",
      "       4.89463520e-04, 4.89532381e-04, 4.90629211e-04, 4.57783391e-04,\n",
      "       3.99324619e-04, 4.01311334e-04, 4.00762570e-04, 4.97928752e-04,\n",
      "       3.98686884e-04, 3.99085238e-04, 3.99686261e-04, 4.89377042e-04,\n",
      "       4.89503247e-04, 4.57788569e-04, 4.57642599e-04, 4.88660870e-04,\n",
      "       4.58876457e-04, 4.90415691e-04, 4.97433624e-04, 4.99582996e-04,\n",
      "       2.95362266e-04, 3.00071946e-04, 4.58933025e-04, 4.58038791e-04,\n",
      "       3.99595189e-04, 3.98789506e-04, 6.41938135e-04, 4.58080880e-04,\n",
      "       4.99296484e-04, 5.37773727e-04, 4.89649899e-04, 3.99639359e-04,\n",
      "       4.57648701e-04, 2.99514720e-04, 5.00565317e-04, 4.89541534e-04,\n",
      "       2.99661600e-04, 2.99718879e-04, 4.57663647e-04, 4.58453210e-04,\n",
      "       2.99634200e-04, 2.99727131e-04, 4.89298731e-04, 5.00856782e-04,\n",
      "       4.56448842e-04, 4.56978072e-04, 4.00462370e-04, 4.89600514e-04,\n",
      "       4.71067514e-04, 4.89194092e-04, 4.73867554e-04, 4.89637215e-04]), 'mean_score_time': array([4.00137901e-04, 7.02071190e-04, 5.00297546e-04, 2.00080872e-04,\n",
      "       4.00996208e-04, 3.99041176e-04, 3.00002098e-04, 4.20451164e-04,\n",
      "       4.99916077e-04, 3.99851799e-04, 9.97304916e-05, 3.15761566e-04,\n",
      "       7.17306137e-04, 3.01361084e-04, 4.17232513e-04, 9.88483429e-05,\n",
      "       4.49037552e-04, 4.53829765e-04, 3.32856178e-04, 4.51159477e-04,\n",
      "       4.00066376e-04, 3.00025940e-04, 3.51476669e-04, 4.14967537e-04,\n",
      "       6.27517700e-04, 2.99954414e-04, 4.52399254e-04, 3.49473953e-04,\n",
      "       3.29160690e-04, 3.99971008e-04, 4.14252281e-04, 3.51023674e-04,\n",
      "       1.00016594e-04, 5.36966324e-04, 5.08308411e-04, 2.01487541e-04,\n",
      "       7.07435608e-04, 5.18679619e-04, 4.00233269e-04, 6.27183914e-04,\n",
      "       4.24885750e-04, 4.08625603e-04, 5.00178337e-04, 3.99994850e-04,\n",
      "       7.97772408e-04, 6.99496269e-04, 3.20219994e-04, 9.00268555e-04,\n",
      "       7.99727440e-04, 6.01792336e-04, 3.98373604e-04, 3.99899483e-04,\n",
      "       3.99947166e-04, 3.00002098e-04, 5.99408150e-04, 3.99827957e-04,\n",
      "       2.99787521e-04, 2.99930573e-04, 4.99773026e-04, 4.50849533e-04,\n",
      "       3.99804115e-04, 3.00264359e-04, 3.99851799e-04, 3.98898125e-04,\n",
      "       3.99923325e-04, 5.99503517e-04, 2.99882889e-04, 4.99844551e-04,\n",
      "       6.00576401e-04, 4.99701500e-04, 3.99708748e-04, 3.99756432e-04,\n",
      "       4.99749184e-04, 1.99842453e-04, 3.00264359e-04, 2.99835205e-04,\n",
      "       4.00304794e-04, 5.99837303e-04, 4.99796867e-04, 3.99708748e-04,\n",
      "       2.01392174e-04, 1.00004673e-03, 1.00049973e-03, 4.00638580e-04,\n",
      "       0.00000000e+00, 9.98735428e-05, 3.00502777e-04, 1.99651718e-04,\n",
      "       5.99455833e-04, 7.99369812e-04, 4.99153137e-04, 0.00000000e+00,\n",
      "       2.99453735e-04, 8.98504257e-04, 7.99131393e-04, 0.00000000e+00,\n",
      "       1.99818611e-04, 3.99446487e-04, 3.99470329e-04, 2.99811363e-04,\n",
      "       9.99212265e-05, 5.98955154e-04, 5.99265099e-04, 4.99391556e-04,\n",
      "       1.99604034e-04, 1.99699402e-04, 2.00009346e-04, 4.99415398e-04,\n",
      "       4.99987602e-04, 1.00109577e-03, 1.99484825e-04, 3.00168991e-04,\n",
      "       4.50801849e-04, 4.08411026e-04, 6.01482391e-04, 4.99296188e-04,\n",
      "       5.05518913e-04, 4.99343872e-04, 4.99939919e-04, 3.99851799e-04,\n",
      "       3.01194191e-04, 5.00965118e-04, 6.01387024e-04, 6.12425804e-04,\n",
      "       4.56953049e-04, 2.00653076e-04, 4.15802002e-04, 5.99551201e-04,\n",
      "       4.32419777e-04, 4.01139259e-04, 3.99255753e-04, 4.00424004e-04,\n",
      "       3.98039818e-04, 2.50530243e-04, 2.01845169e-04, 6.08491898e-04,\n",
      "       5.99193573e-04, 3.00550461e-04, 3.99589539e-04, 5.00655174e-04,\n",
      "       3.00049782e-04, 3.00812721e-04, 2.99525261e-04, 4.00614738e-04,\n",
      "       4.50682640e-04, 5.02443314e-04, 5.02133369e-04, 2.99739838e-04,\n",
      "       4.49967384e-04, 3.50284576e-04, 4.99272346e-04, 3.99160385e-04,\n",
      "       4.00018692e-04, 3.99923325e-04, 5.99408150e-04, 3.00145149e-04,\n",
      "       2.99668312e-04, 3.00478935e-04, 3.00192833e-04, 3.99851799e-04,\n",
      "       4.98819351e-04, 3.99899483e-04, 2.99906731e-04, 2.99668312e-04,\n",
      "       2.98643112e-04, 5.01370430e-04, 4.00924683e-04, 3.00025940e-04,\n",
      "       2.99525261e-04, 4.00304794e-04, 4.50515747e-04, 3.99899483e-04,\n",
      "       4.99272346e-04, 4.50873375e-04, 3.99184227e-04, 5.00106812e-04,\n",
      "       2.99954414e-04, 2.00009346e-04, 3.00097466e-04, 3.99827957e-04,\n",
      "       6.01029396e-04, 3.99899483e-04, 6.00504875e-04, 2.99882889e-04,\n",
      "       3.00049782e-04, 3.00312042e-04, 4.00781631e-04, 4.50491905e-04,\n",
      "       3.00002098e-04, 4.99606133e-04, 3.00240517e-04, 3.99589539e-04,\n",
      "       5.99598885e-04, 3.00049782e-04, 6.00218773e-04, 5.15675545e-04,\n",
      "       3.99804115e-04, 5.99861145e-04, 3.00025940e-04, 3.99613380e-04,\n",
      "       4.99868393e-04, 4.99725342e-04, 4.99582291e-04, 3.99684906e-04,\n",
      "       4.00447845e-04, 3.99994850e-04, 2.99978256e-04, 4.99677658e-04,\n",
      "       2.99859047e-04, 4.00304794e-04, 4.99463081e-04, 3.99613380e-04,\n",
      "       4.50086594e-04, 4.99510765e-04, 4.00710106e-04, 4.99534607e-04,\n",
      "       2.99382210e-04, 5.99789619e-04, 2.99668312e-04, 4.00090218e-04,\n",
      "       4.99510765e-04, 3.99637222e-04, 5.99360466e-04, 3.99875641e-04,\n",
      "       2.99715996e-04, 2.99906731e-04, 6.00028038e-04, 4.00090218e-04,\n",
      "       4.00257111e-04, 3.99851799e-04, 5.00416756e-04, 5.00154495e-04,\n",
      "       4.00066376e-04, 4.00996208e-04, 4.00018692e-04, 4.98747826e-04,\n",
      "       5.99193573e-04, 3.99684906e-04, 5.99503517e-04, 2.99811363e-04,\n",
      "       4.00686264e-04, 4.00209427e-04, 2.99978256e-04, 4.99868393e-04,\n",
      "       4.00280952e-04, 5.00392914e-04, 7.01451302e-04, 5.99598885e-04,\n",
      "       2.99906731e-04, 3.99804115e-04, 3.99851799e-04, 4.00042534e-04,\n",
      "       1.99937820e-04, 1.99770927e-04, 3.99637222e-04, 3.99684906e-04,\n",
      "       2.00057030e-04, 3.00121307e-04, 3.99541855e-04, 3.99851799e-04,\n",
      "       5.00226021e-04, 6.00218773e-04, 2.00152397e-04, 4.99868393e-04,\n",
      "       3.99231911e-04, 4.00257111e-04, 4.99892235e-04, 3.99589539e-04,\n",
      "       4.99534607e-04, 3.99851799e-04, 3.99541855e-04, 2.99739838e-04,\n",
      "       3.99875641e-04, 4.00257111e-04, 3.99994850e-04, 4.98604774e-04,\n",
      "       4.99844551e-04, 4.01043892e-04, 3.99875641e-04, 4.99677658e-04,\n",
      "       5.99765778e-04, 3.99804115e-04, 4.00137901e-04, 3.98921967e-04,\n",
      "       3.98898125e-04, 3.99923325e-04, 3.99231911e-04, 3.99708748e-04,\n",
      "       2.00462341e-04, 3.99494171e-04, 4.99916077e-04, 4.00018692e-04,\n",
      "       6.00600243e-04, 3.00168991e-04, 3.99661064e-04, 3.99947166e-04,\n",
      "       4.99701500e-04, 5.99789619e-04, 6.99853897e-04, 3.99899483e-04,\n",
      "       4.99844551e-04, 3.00240517e-04, 4.00280952e-04, 3.99541855e-04,\n",
      "       4.00137901e-04, 3.00097466e-04, 3.99756432e-04, 3.98373604e-04,\n",
      "       5.00416756e-04, 5.00321388e-04, 4.99820709e-04, 5.00845909e-04,\n",
      "       3.99208069e-04, 4.00781631e-04, 4.99963760e-04, 3.99589539e-04,\n",
      "       4.99725342e-04, 3.00288200e-04, 5.00130653e-04, 3.99875641e-04]), 'std_score_time': array([4.90066870e-04, 4.59631114e-04, 5.00297721e-04, 4.00161743e-04,\n",
      "       4.91125589e-04, 4.88735013e-04, 4.58260952e-04, 5.18310489e-04,\n",
      "       4.99917346e-04, 4.89716479e-04, 2.99191475e-04, 4.84187624e-04,\n",
      "       6.77463229e-04, 4.60346555e-04, 5.13113851e-04, 2.96545029e-04,\n",
      "       4.69575378e-04, 4.75199848e-04, 5.15423477e-04, 4.72052182e-04,\n",
      "       4.89979323e-04, 4.58297247e-04, 4.51155803e-04, 5.08874789e-04,\n",
      "       5.15152652e-04, 4.58187953e-04, 5.61559141e-04, 4.48235677e-04,\n",
      "       5.07280351e-04, 4.89862963e-04, 5.08858648e-04, 4.50405852e-04,\n",
      "       3.00049782e-04, 5.46974184e-04, 5.08691302e-04, 4.02988204e-04,\n",
      "       4.63525634e-04, 5.19843326e-04, 4.90184320e-04, 5.14619135e-04,\n",
      "       5.24830905e-04, 5.00885018e-04, 5.00179887e-04, 4.89891669e-04,\n",
      "       3.98908875e-04, 4.57928157e-04, 4.91879503e-04, 3.00091528e-04,\n",
      "       3.99866370e-04, 4.91373756e-04, 4.87912930e-04, 4.89774868e-04,\n",
      "       4.89833489e-04, 4.58260791e-04, 4.89416138e-04, 4.89687246e-04,\n",
      "       4.57933057e-04, 4.58151546e-04, 4.99773044e-04, 4.71518755e-04,\n",
      "       4.89658172e-04, 4.58662958e-04, 4.89716445e-04, 4.88555848e-04,\n",
      "       4.89804105e-04, 4.89492681e-04, 4.58078708e-04, 4.99844608e-04,\n",
      "       4.90378520e-04, 4.99701607e-04, 4.89541371e-04, 4.89599783e-04,\n",
      "       4.99749268e-04, 3.99684906e-04, 4.58713693e-04, 4.58005878e-04,\n",
      "       4.90273429e-04, 4.89765657e-04, 4.99796988e-04, 4.89541383e-04,\n",
      "       4.02802133e-04, 3.44718968e-06, 3.69233335e-06, 4.90686152e-04,\n",
      "       0.00000000e+00, 2.99620628e-04, 4.59035931e-04, 3.99303792e-04,\n",
      "       4.89454518e-04, 3.99685219e-04, 4.99153893e-04, 0.00000000e+00,\n",
      "       4.57423563e-04, 2.99502463e-04, 3.99566177e-04, 0.00000000e+00,\n",
      "       3.99638250e-04, 4.89220879e-04, 4.89250148e-04, 4.57969736e-04,\n",
      "       2.99763680e-04, 4.89048474e-04, 4.89298223e-04, 4.99391902e-04,\n",
      "       3.99208581e-04, 3.99399316e-04, 4.00018696e-04, 4.99416258e-04,\n",
      "       4.99988346e-04, 3.91246269e-06, 3.98970252e-04, 4.58515836e-04,\n",
      "       4.72135777e-04, 5.00737618e-04, 4.91129667e-04, 4.99298495e-04,\n",
      "       5.05783638e-04, 4.99345095e-04, 4.99941128e-04, 4.89716816e-04,\n",
      "       4.00236473e-04, 5.00967258e-04, 4.91040196e-04, 5.01441432e-04,\n",
      "       4.79280010e-04, 4.01306167e-04, 5.10082840e-04, 4.89533206e-04,\n",
      "       5.37344767e-04, 4.91294701e-04, 4.88987429e-04, 4.90418176e-04,\n",
      "       4.87523651e-04, 4.03167295e-04, 4.03742730e-04, 4.97420434e-04,\n",
      "       4.89240290e-04, 4.59099316e-04, 4.89395250e-04, 5.00661117e-04,\n",
      "       4.58333625e-04, 4.59502700e-04, 4.57535193e-04, 4.90651337e-04,\n",
      "       4.72020884e-04, 5.02443556e-04, 5.02134155e-04, 4.57860281e-04,\n",
      "       4.71289696e-04, 4.49940291e-04, 4.99274002e-04, 4.88870082e-04,\n",
      "       4.89924711e-04, 4.89804058e-04, 4.89415139e-04, 4.58480458e-04,\n",
      "       4.57751061e-04, 4.58990505e-04, 4.58553850e-04, 4.89716479e-04,\n",
      "       4.98819791e-04, 4.89775495e-04, 4.58115148e-04, 4.57751024e-04,\n",
      "       4.56185043e-04, 5.01373110e-04, 4.91031248e-04, 4.58297247e-04,\n",
      "       4.57532770e-04, 4.90278960e-04, 4.71753321e-04, 4.89775205e-04,\n",
      "       4.99272875e-04, 4.72323506e-04, 4.88900153e-04, 5.00106896e-04,\n",
      "       4.58187940e-04, 4.00018696e-04, 4.58407174e-04, 4.89687431e-04,\n",
      "       4.90745614e-04, 4.89774984e-04, 4.90312281e-04, 4.58078683e-04,\n",
      "       4.58333662e-04, 4.58734548e-04, 4.90855404e-04, 4.71798215e-04,\n",
      "       4.58260989e-04, 4.99606303e-04, 4.58626729e-04, 4.89395296e-04,\n",
      "       4.89572724e-04, 4.58334059e-04, 4.90077868e-04, 5.17668005e-04,\n",
      "       4.89658787e-04, 4.89785649e-04, 4.58298264e-04, 4.89424698e-04,\n",
      "       4.99868886e-04, 4.99725967e-04, 4.99582466e-04, 4.89512364e-04,\n",
      "       4.90449829e-04, 4.89891762e-04, 4.58224355e-04, 4.99677983e-04,\n",
      "       4.58042537e-04, 4.90271806e-04, 4.99474398e-04, 4.89424768e-04,\n",
      "       4.71152524e-04, 4.99511475e-04, 4.90773547e-04, 4.99534682e-04,\n",
      "       4.57313883e-04, 4.89727571e-04, 4.57751061e-04, 4.90009595e-04,\n",
      "       4.99510895e-04, 4.89453853e-04, 4.89375950e-04, 4.89745780e-04,\n",
      "       4.57823961e-04, 4.58115111e-04, 4.89922370e-04, 4.90008667e-04,\n",
      "       4.90213887e-04, 4.89717048e-04, 5.00417067e-04, 5.00154513e-04,\n",
      "       4.89979312e-04, 4.91129107e-04, 4.89920859e-04, 4.98756207e-04,\n",
      "       4.89242079e-04, 4.89512329e-04, 4.89493157e-04, 4.57969451e-04,\n",
      "       4.90738893e-04, 4.90155121e-04, 4.58224504e-04, 4.99868705e-04,\n",
      "       4.90242999e-04, 5.00393114e-04, 4.59215406e-04, 4.89571191e-04,\n",
      "       4.58115098e-04, 4.89658648e-04, 4.89716491e-04, 4.89950092e-04,\n",
      "       3.99875641e-04, 3.99542029e-04, 4.89453737e-04, 4.89512259e-04,\n",
      "       4.00114859e-04, 4.58444023e-04, 4.89340851e-04, 4.89716886e-04,\n",
      "       5.00226741e-04, 4.90077636e-04, 4.00305082e-04, 4.99868886e-04,\n",
      "       4.88960495e-04, 4.90213261e-04, 4.99892719e-04, 4.89395377e-04,\n",
      "       4.99534898e-04, 4.89716456e-04, 4.89337006e-04, 4.57860467e-04,\n",
      "       4.89745861e-04, 4.90213864e-04, 4.89892400e-04, 4.98619613e-04,\n",
      "       4.99847872e-04, 4.91184740e-04, 4.89745884e-04, 4.99678018e-04,\n",
      "       4.89707782e-04, 4.89658474e-04, 4.90067241e-04, 4.88583822e-04,\n",
      "       4.88556779e-04, 4.89804093e-04, 4.88960181e-04, 4.89541371e-04,\n",
      "       4.00988323e-04, 4.89284699e-04, 4.99917300e-04, 4.89921010e-04,\n",
      "       4.90388969e-04, 4.58516084e-04, 4.89482959e-04, 4.89833756e-04,\n",
      "       4.99701778e-04, 4.89727061e-04, 4.58162926e-04, 4.89775274e-04,\n",
      "       4.99844676e-04, 4.58625093e-04, 4.90244216e-04, 4.89337041e-04,\n",
      "       4.90067995e-04, 4.58406653e-04, 4.89600131e-04, 4.87915260e-04,\n",
      "       5.00419782e-04, 5.00322763e-04, 4.99821135e-04, 5.00854042e-04,\n",
      "       4.88930697e-04, 4.90862167e-04, 4.99964067e-04, 4.89395482e-04,\n",
      "       4.99725751e-04, 4.58699096e-04, 5.00134706e-04, 4.89746302e-04]), 'param_classifier__max_depth': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
      "                   2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3,\n",
      "                   3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4,\n",
      "                   4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "                   6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "                   7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "                   8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
      "                   11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
      "                   12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13,\n",
      "                   13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14,\n",
      "                   14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15,\n",
      "                   15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16,\n",
      "                   16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "                   17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "                   17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
      "                   18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
      "                   19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "                   20, 20, 20, 20, 20, 20, 20, 20],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_classifier__min_samples_leaf': masked_array(data=[1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1,\n",
      "                   1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1,\n",
      "                   1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1,\n",
      "                   1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1,\n",
      "                   2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2,\n",
      "                   2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2,\n",
      "                   2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2,\n",
      "                   2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "                   5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5,\n",
      "                   5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5,\n",
      "                   5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5,\n",
      "                   5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5,\n",
      "                   10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10,\n",
      "                   10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10,\n",
      "                   10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10,\n",
      "                   10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10,\n",
      "                   1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1,\n",
      "                   1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1,\n",
      "                   1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_classifier__min_samples_split': masked_array(data=[2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'classifier__max_depth': 1, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}], 'split0_test_score': array([0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.74213836, 0.74213836, 0.74213836, 0.74213836,\n",
      "       0.74213836, 0.74213836, 0.74213836, 0.74213836, 0.74213836,\n",
      "       0.74213836, 0.74213836, 0.74213836, 0.74213836, 0.74213836,\n",
      "       0.74213836, 0.74213836, 0.83018868, 0.83018868, 0.83018868,\n",
      "       0.82389937, 0.83018868, 0.83018868, 0.83018868, 0.83018868,\n",
      "       0.83018868, 0.83018868, 0.83018868, 0.82389937, 0.83018868,\n",
      "       0.83018868, 0.83018868, 0.82389937, 0.82389937, 0.80503145,\n",
      "       0.81761006, 0.82389937, 0.81132075, 0.81132075, 0.80503145,\n",
      "       0.81761006, 0.81132075, 0.81761006, 0.82389937, 0.80503145,\n",
      "       0.83018868, 0.83018868, 0.83018868, 0.83018868, 0.79874214,\n",
      "       0.79874214, 0.78616352, 0.81132075, 0.81132075, 0.81761006,\n",
      "       0.78616352, 0.81132075, 0.82389937, 0.80503145, 0.79874214,\n",
      "       0.82389937, 0.82389937, 0.81132075, 0.81132075, 0.80503145,\n",
      "       0.81132075, 0.79874214, 0.78616352, 0.80503145, 0.79245283,\n",
      "       0.79245283, 0.78616352, 0.80503145, 0.81132075, 0.81132075,\n",
      "       0.80503145, 0.80503145, 0.78616352, 0.80503145, 0.81132075,\n",
      "       0.81761006, 0.81761006, 0.77358491, 0.77358491, 0.79245283,\n",
      "       0.79245283, 0.77987421, 0.80503145, 0.77358491, 0.79874214,\n",
      "       0.77358491, 0.78616352, 0.80503145, 0.80503145, 0.78616352,\n",
      "       0.79874214, 0.79874214, 0.79245283, 0.7672956 , 0.74842767,\n",
      "       0.77987421, 0.74842767, 0.77987421, 0.81132075, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.79874214, 0.79245283, 0.79874214,\n",
      "       0.78616352, 0.79245283, 0.81761006, 0.76100629, 0.75471698,\n",
      "       0.77358491, 0.7672956 , 0.75471698, 0.73584906, 0.77358491,\n",
      "       0.74842767, 0.77987421, 0.7672956 , 0.78616352, 0.79245283,\n",
      "       0.80503145, 0.81761006, 0.77987421, 0.7672956 , 0.70440252,\n",
      "       0.72955975, 0.74842767, 0.75471698, 0.75471698, 0.74842767,\n",
      "       0.71698113, 0.75471698, 0.77358491, 0.77358491, 0.7672956 ,\n",
      "       0.77987421, 0.77987421, 0.7672956 , 0.74842767, 0.74842767,\n",
      "       0.72327044, 0.72955975, 0.74842767, 0.73584906, 0.72955975,\n",
      "       0.71069182, 0.75471698, 0.68553459, 0.77358491, 0.74213836,\n",
      "       0.7672956 , 0.74213836, 0.79245283, 0.74213836, 0.77987421,\n",
      "       0.77987421, 0.72327044, 0.74213836, 0.74842767, 0.77358491,\n",
      "       0.72327044, 0.74213836, 0.72955975, 0.7672956 , 0.78616352,\n",
      "       0.76100629, 0.73584906, 0.73584906, 0.75471698, 0.77358491,\n",
      "       0.7672956 , 0.78616352, 0.72955975, 0.76100629, 0.73584906,\n",
      "       0.74213836, 0.74842767, 0.70440252, 0.7672956 , 0.76100629,\n",
      "       0.73584906, 0.75471698, 0.75471698, 0.75471698, 0.76100629,\n",
      "       0.77987421, 0.77987421, 0.77987421, 0.6918239 , 0.7672956 ,\n",
      "       0.70440252, 0.69811321, 0.76100629, 0.72955975, 0.74213836,\n",
      "       0.72327044, 0.7672956 , 0.77358491, 0.77358491, 0.73584906,\n",
      "       0.77358491, 0.73584906, 0.77987421, 0.78616352, 0.71698113,\n",
      "       0.6918239 , 0.73584906, 0.68553459, 0.72955975, 0.71069182,\n",
      "       0.72955975, 0.75471698, 0.74842767, 0.74213836, 0.7672956 ,\n",
      "       0.76100629, 0.76100629, 0.78616352, 0.76100629, 0.7672956 ,\n",
      "       0.70440252, 0.71069182, 0.72327044, 0.71698113, 0.72327044,\n",
      "       0.71698113, 0.7672956 , 0.76100629, 0.78616352, 0.73584906,\n",
      "       0.74213836, 0.71698113, 0.7672956 , 0.76100629, 0.76100629,\n",
      "       0.7672956 , 0.72327044, 0.70440252, 0.67924528, 0.71698113,\n",
      "       0.74213836, 0.74842767, 0.71069182, 0.72955975, 0.7672956 ,\n",
      "       0.76100629, 0.74213836, 0.75471698, 0.7672956 , 0.78616352,\n",
      "       0.71698113, 0.74842767, 0.75471698, 0.68553459, 0.71069182,\n",
      "       0.72955975, 0.73584906, 0.72955975, 0.72327044, 0.73584906,\n",
      "       0.72955975, 0.76100629, 0.77358491, 0.74842767, 0.75471698,\n",
      "       0.79874214, 0.77358491, 0.74213836, 0.72955975, 0.72955975,\n",
      "       0.71698113, 0.7672956 , 0.73584906, 0.72955975, 0.71069182,\n",
      "       0.75471698, 0.77358491, 0.74842767, 0.74842767, 0.74842767,\n",
      "       0.72327044, 0.74842767, 0.73584906, 0.73584906, 0.69811321,\n",
      "       0.74213836, 0.72955975, 0.74213836, 0.74213836, 0.73584906,\n",
      "       0.76100629, 0.71698113, 0.75471698, 0.77358491, 0.7672956 ,\n",
      "       0.71069182, 0.78616352, 0.78616352, 0.7672956 , 0.77358491]), 'split1_test_score': array([0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.88679245, 0.88679245, 0.88679245,\n",
      "       0.88679245, 0.88679245, 0.88679245, 0.88679245, 0.88679245,\n",
      "       0.88679245, 0.88679245, 0.88679245, 0.88679245, 0.88679245,\n",
      "       0.88679245, 0.88679245, 0.88679245, 0.88679245, 0.87421384,\n",
      "       0.87421384, 0.88679245, 0.86792453, 0.86792453, 0.88679245,\n",
      "       0.88679245, 0.88679245, 0.86163522, 0.88679245, 0.86163522,\n",
      "       0.88679245, 0.88679245, 0.88050314, 0.88679245, 0.87421384,\n",
      "       0.83018868, 0.86163522, 0.87421384, 0.86163522, 0.87421384,\n",
      "       0.8490566 , 0.88679245, 0.88679245, 0.88050314, 0.88050314,\n",
      "       0.87421384, 0.88050314, 0.86792453, 0.89308176, 0.88679245,\n",
      "       0.83018868, 0.88050314, 0.86163522, 0.88050314, 0.85534591,\n",
      "       0.82389937, 0.8490566 , 0.86163522, 0.86792453, 0.83647799,\n",
      "       0.88679245, 0.85534591, 0.87421384, 0.86163522, 0.88679245,\n",
      "       0.87421384, 0.82389937, 0.83018868, 0.81132075, 0.82389937,\n",
      "       0.79874214, 0.83018868, 0.81132075, 0.83647799, 0.8490566 ,\n",
      "       0.83647799, 0.8427673 , 0.8490566 , 0.86792453, 0.85534591,\n",
      "       0.8427673 , 0.86792453, 0.77987421, 0.8427673 , 0.81761006,\n",
      "       0.85534591, 0.81761006, 0.85534591, 0.8490566 , 0.85534591,\n",
      "       0.81132075, 0.81132075, 0.85534591, 0.85534591, 0.83647799,\n",
      "       0.82389937, 0.85534591, 0.8427673 , 0.83018868, 0.80503145,\n",
      "       0.80503145, 0.83018868, 0.83647799, 0.83018868, 0.80503145,\n",
      "       0.83018868, 0.83018868, 0.78616352, 0.8427673 , 0.8427673 ,\n",
      "       0.86792453, 0.86792453, 0.88050314, 0.8490566 , 0.74213836,\n",
      "       0.82389937, 0.81761006, 0.83018868, 0.79874214, 0.77358491,\n",
      "       0.74842767, 0.79874214, 0.79874214, 0.8490566 , 0.82389937,\n",
      "       0.81761006, 0.83647799, 0.82389937, 0.86792453, 0.8427673 ,\n",
      "       0.79245283, 0.77987421, 0.8427673 , 0.82389937, 0.74213836,\n",
      "       0.81132075, 0.79874214, 0.81132075, 0.77358491, 0.80503145,\n",
      "       0.77987421, 0.80503145, 0.83018868, 0.85534591, 0.83018868,\n",
      "       0.80503145, 0.74213836, 0.7672956 , 0.7672956 , 0.80503145,\n",
      "       0.72955975, 0.79245283, 0.79245283, 0.72327044, 0.79245283,\n",
      "       0.8490566 , 0.82389937, 0.79245283, 0.83647799, 0.83647799,\n",
      "       0.83018868, 0.78616352, 0.7672956 , 0.74842767, 0.79874214,\n",
      "       0.80503145, 0.80503145, 0.73584906, 0.74842767, 0.78616352,\n",
      "       0.80503145, 0.81761006, 0.79874214, 0.78616352, 0.7672956 ,\n",
      "       0.8427673 , 0.80503145, 0.83018868, 0.77358491, 0.76100629,\n",
      "       0.76100629, 0.79874214, 0.75471698, 0.75471698, 0.72327044,\n",
      "       0.79874214, 0.78616352, 0.78616352, 0.75471698, 0.80503145,\n",
      "       0.8490566 , 0.80503145, 0.81761006, 0.8490566 , 0.75471698,\n",
      "       0.77987421, 0.73584906, 0.81132075, 0.78616352, 0.77987421,\n",
      "       0.77987421, 0.81132075, 0.77358491, 0.80503145, 0.72955975,\n",
      "       0.81761006, 0.8427673 , 0.79874214, 0.79874214, 0.83018868,\n",
      "       0.7672956 , 0.76100629, 0.78616352, 0.83647799, 0.77987421,\n",
      "       0.78616352, 0.77987421, 0.74213836, 0.81132075, 0.83018868,\n",
      "       0.81761006, 0.79245283, 0.85534591, 0.80503145, 0.76100629,\n",
      "       0.83018868, 0.75471698, 0.78616352, 0.7672956 , 0.78616352,\n",
      "       0.74213836, 0.78616352, 0.77987421, 0.76100629, 0.80503145,\n",
      "       0.81132075, 0.82389937, 0.81132075, 0.83647799, 0.83647799,\n",
      "       0.79245283, 0.83018868, 0.74213836, 0.75471698, 0.74842767,\n",
      "       0.79245283, 0.80503145, 0.77987421, 0.77987421, 0.73584906,\n",
      "       0.78616352, 0.7672956 , 0.81761006, 0.85534591, 0.81761006,\n",
      "       0.77987421, 0.8427673 , 0.85534591, 0.73584906, 0.74213836,\n",
      "       0.80503145, 0.79874214, 0.73584906, 0.74213836, 0.76100629,\n",
      "       0.81132075, 0.77358491, 0.79874214, 0.74842767, 0.77987421,\n",
      "       0.7672956 , 0.81132075, 0.79874214, 0.8490566 , 0.74842767,\n",
      "       0.75471698, 0.77987421, 0.79245283, 0.71069182, 0.7672956 ,\n",
      "       0.76100629, 0.80503145, 0.77987421, 0.77358491, 0.77987421,\n",
      "       0.77987421, 0.83647799, 0.83018868, 0.8427673 , 0.79874214]), 'split2_test_score': array([0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.71698113, 0.71698113, 0.71698113, 0.71698113,\n",
      "       0.71698113, 0.71698113, 0.71698113, 0.71698113, 0.71698113,\n",
      "       0.71698113, 0.71698113, 0.71698113, 0.71698113, 0.71698113,\n",
      "       0.71698113, 0.71698113, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.80503145, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.80503145, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81761006, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.80503145, 0.81761006,\n",
      "       0.80503145, 0.79874214, 0.77358491, 0.81761006, 0.81761006,\n",
      "       0.80503145, 0.79874214, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.79874214, 0.79874214, 0.79874214, 0.81132075,\n",
      "       0.77987421, 0.77987421, 0.80503145, 0.7672956 , 0.79874214,\n",
      "       0.79874214, 0.78616352, 0.77358491, 0.80503145, 0.77987421,\n",
      "       0.78616352, 0.79245283, 0.78616352, 0.77358491, 0.77358491,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.75471698, 0.79874214,\n",
      "       0.7672956 , 0.76100629, 0.74213836, 0.77987421, 0.78616352,\n",
      "       0.77987421, 0.75471698, 0.74842767, 0.74842767, 0.77358491,\n",
      "       0.76100629, 0.7672956 , 0.73584906, 0.74842767, 0.7672956 ,\n",
      "       0.7672956 , 0.76100629, 0.77358491, 0.75471698, 0.73584906,\n",
      "       0.77987421, 0.71698113, 0.74842767, 0.77358491, 0.78616352,\n",
      "       0.75471698, 0.78616352, 0.7672956 , 0.73584906, 0.75471698,\n",
      "       0.72327044, 0.74842767, 0.71698113, 0.76100629, 0.78616352,\n",
      "       0.75471698, 0.76100629, 0.79245283, 0.77358491, 0.75471698,\n",
      "       0.75471698, 0.76100629, 0.74842767, 0.7672956 , 0.7672956 ,\n",
      "       0.73584906, 0.72327044, 0.70440252, 0.72955975, 0.77358491,\n",
      "       0.73584906, 0.74842767, 0.78616352, 0.74213836, 0.74842767,\n",
      "       0.72327044, 0.77358491, 0.7672956 , 0.74213836, 0.77358491,\n",
      "       0.7672956 , 0.75471698, 0.71069182, 0.74842767, 0.75471698,\n",
      "       0.70440252, 0.75471698, 0.74213836, 0.73584906, 0.72955975,\n",
      "       0.72955975, 0.74213836, 0.74213836, 0.76100629, 0.78616352,\n",
      "       0.74842767, 0.74213836, 0.74213836, 0.75471698, 0.73584906,\n",
      "       0.69811321, 0.74842767, 0.72955975, 0.76100629, 0.74213836,\n",
      "       0.72955975, 0.73584906, 0.73584906, 0.74213836, 0.71069182,\n",
      "       0.69811321, 0.72955975, 0.72955975, 0.7672956 , 0.74213836,\n",
      "       0.69811321, 0.73584906, 0.69811321, 0.72955975, 0.71698113,\n",
      "       0.73584906, 0.70440252, 0.73584906, 0.71069182, 0.73584906,\n",
      "       0.76100629, 0.74213836, 0.77358491, 0.72327044, 0.74213836,\n",
      "       0.71698113, 0.72327044, 0.77358491, 0.72955975, 0.69811321,\n",
      "       0.71069182, 0.73584906, 0.75471698, 0.67295597, 0.73584906,\n",
      "       0.74842767, 0.76100629, 0.7672956 , 0.72955975, 0.77987421,\n",
      "       0.73584906, 0.67924528, 0.73584906, 0.70440252, 0.74842767,\n",
      "       0.74213836, 0.72327044, 0.74213836, 0.71698113, 0.70440252,\n",
      "       0.74213836, 0.73584906, 0.75471698, 0.72327044, 0.7672956 ,\n",
      "       0.76100629, 0.72955975, 0.70440252, 0.68553459, 0.74842767,\n",
      "       0.72327044, 0.74842767, 0.73584906, 0.71069182, 0.71698113,\n",
      "       0.72955975, 0.70440252, 0.70440252, 0.77358491, 0.74842767,\n",
      "       0.74842767, 0.72955975, 0.72327044, 0.69811321, 0.74213836,\n",
      "       0.78616352, 0.67924528, 0.71069182, 0.74842767, 0.6918239 ,\n",
      "       0.74842767, 0.71069182, 0.76100629, 0.75471698, 0.72327044,\n",
      "       0.7672956 , 0.72955975, 0.73584906, 0.72327044, 0.71698113,\n",
      "       0.71698113, 0.76100629, 0.71698113, 0.71698113, 0.72955975,\n",
      "       0.74842767, 0.7672956 , 0.74213836, 0.72327044, 0.73584906,\n",
      "       0.74213836, 0.74842767, 0.74213836, 0.76100629, 0.70440252,\n",
      "       0.71069182, 0.73584906, 0.67295597, 0.74842767, 0.72327044,\n",
      "       0.74213836, 0.72327044, 0.71069182, 0.71069182, 0.71698113,\n",
      "       0.71698113, 0.75471698, 0.73584906, 0.73584906, 0.75471698,\n",
      "       0.72955975, 0.70440252, 0.74842767, 0.73584906, 0.72327044,\n",
      "       0.72955975, 0.74842767, 0.73584906, 0.75471698, 0.71698113,\n",
      "       0.72327044, 0.74213836, 0.73584906, 0.74842767, 0.72327044]), 'split3_test_score': array([0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.71069182, 0.71069182, 0.71069182, 0.71069182,\n",
      "       0.71069182, 0.71069182, 0.71069182, 0.71069182, 0.71069182,\n",
      "       0.71069182, 0.71069182, 0.71069182, 0.71069182, 0.71069182,\n",
      "       0.71069182, 0.71069182, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.79245283, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.81132075, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.77358491, 0.81132075, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.80503145, 0.79874214,\n",
      "       0.79874214, 0.77358491, 0.80503145, 0.79245283, 0.78616352,\n",
      "       0.79874214, 0.77358491, 0.80503145, 0.78616352, 0.79245283,\n",
      "       0.79245283, 0.80503145, 0.79874214, 0.79874214, 0.80503145,\n",
      "       0.81132075, 0.79245283, 0.78616352, 0.77987421, 0.77987421,\n",
      "       0.80503145, 0.79874214, 0.79245283, 0.77987421, 0.79874214,\n",
      "       0.79245283, 0.79245283, 0.79874214, 0.79874214, 0.77358491,\n",
      "       0.79245283, 0.73584906, 0.78616352, 0.78616352, 0.79874214,\n",
      "       0.77358491, 0.80503145, 0.77987421, 0.81132075, 0.7672956 ,\n",
      "       0.78616352, 0.79874214, 0.79245283, 0.77987421, 0.74213836,\n",
      "       0.81761006, 0.77987421, 0.77358491, 0.7672956 , 0.75471698,\n",
      "       0.77358491, 0.78616352, 0.7672956 , 0.78616352, 0.75471698,\n",
      "       0.74842767, 0.79874214, 0.76100629, 0.77358491, 0.79245283,\n",
      "       0.74213836, 0.76100629, 0.78616352, 0.74842767, 0.76100629,\n",
      "       0.76100629, 0.77987421, 0.76100629, 0.7672956 , 0.78616352,\n",
      "       0.74213836, 0.74842767, 0.79245283, 0.77358491, 0.75471698,\n",
      "       0.79874214, 0.82389937, 0.71698113, 0.79245283, 0.75471698,\n",
      "       0.77358491, 0.74842767, 0.73584906, 0.79874214, 0.77358491,\n",
      "       0.78616352, 0.77987421, 0.81761006, 0.76100629, 0.7672956 ,\n",
      "       0.7672956 , 0.78616352, 0.77358491, 0.74842767, 0.75471698,\n",
      "       0.78616352, 0.72327044, 0.75471698, 0.79245283, 0.7672956 ,\n",
      "       0.79245283, 0.70440252, 0.75471698, 0.77358491, 0.78616352,\n",
      "       0.7672956 , 0.78616352, 0.73584906, 0.7672956 , 0.74213836,\n",
      "       0.79245283, 0.77987421, 0.78616352, 0.79245283, 0.76100629,\n",
      "       0.75471698, 0.74842767, 0.75471698, 0.74842767, 0.72955975,\n",
      "       0.79245283, 0.79874214, 0.78616352, 0.77987421, 0.76100629,\n",
      "       0.77987421, 0.7672956 , 0.75471698, 0.74842767, 0.7672956 ,\n",
      "       0.77358491, 0.75471698, 0.80503145, 0.77987421, 0.80503145,\n",
      "       0.7672956 , 0.77358491, 0.79245283, 0.77358491, 0.73584906,\n",
      "       0.7672956 , 0.72327044, 0.78616352, 0.79245283, 0.74842767,\n",
      "       0.79245283, 0.75471698, 0.74842767, 0.72955975, 0.76100629,\n",
      "       0.77987421, 0.80503145, 0.79245283, 0.81761006, 0.7672956 ,\n",
      "       0.77358491, 0.78616352, 0.74842767, 0.78616352, 0.74842767,\n",
      "       0.75471698, 0.74842767, 0.75471698, 0.77358491, 0.76100629,\n",
      "       0.77358491, 0.77358491, 0.78616352, 0.75471698, 0.79245283,\n",
      "       0.75471698, 0.73584906, 0.77358491, 0.75471698, 0.78616352,\n",
      "       0.75471698, 0.7672956 , 0.74842767, 0.7672956 , 0.80503145,\n",
      "       0.74842767, 0.73584906, 0.79874214, 0.7672956 , 0.78616352,\n",
      "       0.73584906, 0.70440252, 0.75471698, 0.79245283, 0.75471698,\n",
      "       0.72327044, 0.74842767, 0.74842767, 0.73584906, 0.7672956 ,\n",
      "       0.73584906, 0.74213836, 0.74213836, 0.73584906, 0.75471698,\n",
      "       0.71698113, 0.76100629, 0.7672956 , 0.75471698, 0.77987421,\n",
      "       0.74842767, 0.74213836, 0.73584906, 0.69811321, 0.74213836,\n",
      "       0.79245283, 0.77987421, 0.79245283, 0.73584906, 0.76100629,\n",
      "       0.7672956 , 0.74213836, 0.77358491, 0.78616352, 0.69811321,\n",
      "       0.75471698, 0.7672956 , 0.69811321, 0.72955975, 0.77358491,\n",
      "       0.74842767, 0.77358491, 0.79874214, 0.74842767, 0.77358491,\n",
      "       0.81761006, 0.81132075, 0.73584906, 0.75471698, 0.81132075]), 'split4_test_score': array([0.74842767, 0.74842767, 0.74842767, 0.74842767, 0.74842767,\n",
      "       0.74842767, 0.74842767, 0.74842767, 0.74842767, 0.74842767,\n",
      "       0.74842767, 0.74842767, 0.74842767, 0.74842767, 0.74842767,\n",
      "       0.74842767, 0.72955975, 0.72955975, 0.72955975, 0.72955975,\n",
      "       0.72955975, 0.72955975, 0.72955975, 0.72955975, 0.72955975,\n",
      "       0.72955975, 0.72955975, 0.72955975, 0.72955975, 0.72955975,\n",
      "       0.72955975, 0.72955975, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.78616352, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.78616352, 0.79874214,\n",
      "       0.74842767, 0.74842767, 0.77987421, 0.79874214, 0.79874214,\n",
      "       0.77358491, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.76100629, 0.77987421, 0.77987421, 0.7672956 , 0.7672956 ,\n",
      "       0.77987421, 0.77358491, 0.79874214, 0.76100629, 0.7672956 ,\n",
      "       0.79874214, 0.78616352, 0.77358491, 0.79874214, 0.79874214,\n",
      "       0.7672956 , 0.74842767, 0.77358491, 0.76100629, 0.78616352,\n",
      "       0.77358491, 0.78616352, 0.7672956 , 0.75471698, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.78616352, 0.73584906,\n",
      "       0.77358491, 0.73584906, 0.75471698, 0.77358491, 0.74842767,\n",
      "       0.7672956 , 0.74842767, 0.74213836, 0.76100629, 0.76100629,\n",
      "       0.77987421, 0.77987421, 0.7672956 , 0.76100629, 0.74213836,\n",
      "       0.78616352, 0.77987421, 0.74213836, 0.75471698, 0.72327044,\n",
      "       0.72955975, 0.72955975, 0.74213836, 0.7672956 , 0.7672956 ,\n",
      "       0.77358491, 0.74842767, 0.76100629, 0.77358491, 0.74213836,\n",
      "       0.76100629, 0.77987421, 0.75471698, 0.72327044, 0.71069182,\n",
      "       0.72327044, 0.74213836, 0.71069182, 0.73584906, 0.74842767,\n",
      "       0.6918239 , 0.76100629, 0.74213836, 0.72955975, 0.75471698,\n",
      "       0.74213836, 0.73584906, 0.77358491, 0.7672956 , 0.74213836,\n",
      "       0.74842767, 0.68553459, 0.74213836, 0.75471698, 0.75471698,\n",
      "       0.72327044, 0.69811321, 0.73584906, 0.77358491, 0.73584906,\n",
      "       0.72955975, 0.71069182, 0.7672956 , 0.75471698, 0.73584906,\n",
      "       0.74842767, 0.75471698, 0.72955975, 0.71069182, 0.7672956 ,\n",
      "       0.77358491, 0.75471698, 0.72327044, 0.75471698, 0.73584906,\n",
      "       0.71698113, 0.69811321, 0.77358491, 0.74213836, 0.74842767,\n",
      "       0.77358491, 0.72955975, 0.74842767, 0.74842767, 0.69811321,\n",
      "       0.6918239 , 0.71698113, 0.73584906, 0.74213836, 0.71069182,\n",
      "       0.72327044, 0.72955975, 0.74213836, 0.73584906, 0.73584906,\n",
      "       0.75471698, 0.73584906, 0.77358491, 0.74842767, 0.76100629,\n",
      "       0.71698113, 0.75471698, 0.74842767, 0.72327044, 0.70440252,\n",
      "       0.74842767, 0.73584906, 0.73584906, 0.73584906, 0.75471698,\n",
      "       0.70440252, 0.75471698, 0.75471698, 0.74842767, 0.72955975,\n",
      "       0.76100629, 0.66037736, 0.77358491, 0.71698113, 0.71069182,\n",
      "       0.73584906, 0.74842767, 0.73584906, 0.72327044, 0.73584906,\n",
      "       0.74213836, 0.75471698, 0.73584906, 0.72327044, 0.70440252,\n",
      "       0.72955975, 0.73584906, 0.71069182, 0.71069182, 0.7672956 ,\n",
      "       0.72955975, 0.69811321, 0.71698113, 0.71698113, 0.74213836,\n",
      "       0.71069182, 0.70440252, 0.72955975, 0.73584906, 0.72327044,\n",
      "       0.73584906, 0.7672956 , 0.73584906, 0.69811321, 0.74842767,\n",
      "       0.74213836, 0.71069182, 0.69811321, 0.75471698, 0.73584906,\n",
      "       0.72327044, 0.74842767, 0.74842767, 0.74842767, 0.75471698,\n",
      "       0.72955975, 0.73584906, 0.75471698, 0.74842767, 0.72955975,\n",
      "       0.77987421, 0.75471698, 0.72327044, 0.71069182, 0.71698113,\n",
      "       0.77358491, 0.71069182, 0.6918239 , 0.74213836, 0.72327044,\n",
      "       0.71698113, 0.73584906, 0.74842767, 0.76100629, 0.74213836,\n",
      "       0.72327044, 0.7672956 , 0.74213836, 0.6918239 , 0.71069182,\n",
      "       0.71698113, 0.76100629, 0.74213836, 0.74213836, 0.77987421,\n",
      "       0.75471698, 0.76100629, 0.72327044, 0.76100629, 0.72327044,\n",
      "       0.72327044, 0.70440252, 0.74213836, 0.72955975, 0.69811321,\n",
      "       0.74842767, 0.67295597, 0.73584906, 0.70440252, 0.74842767,\n",
      "       0.74213836, 0.73584906, 0.73584906, 0.70440252, 0.71069182,\n",
      "       0.73584906, 0.67924528, 0.70440252, 0.72955975, 0.74842767,\n",
      "       0.71069182, 0.77987421, 0.73584906, 0.74842767, 0.72327044,\n",
      "       0.69811321, 0.77358491, 0.72327044, 0.72327044, 0.71698113]), 'split5_test_score': array([0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 ,\n",
      "       0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 ,\n",
      "       0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 ,\n",
      "       0.7672956 , 0.71698113, 0.71698113, 0.71698113, 0.71698113,\n",
      "       0.71698113, 0.71698113, 0.71698113, 0.71698113, 0.71698113,\n",
      "       0.71698113, 0.71698113, 0.71698113, 0.71698113, 0.71698113,\n",
      "       0.71698113, 0.71698113, 0.82389937, 0.82389937, 0.82389937,\n",
      "       0.81761006, 0.82389937, 0.82389937, 0.82389937, 0.81761006,\n",
      "       0.82389937, 0.82389937, 0.82389937, 0.81761006, 0.81761006,\n",
      "       0.82389937, 0.81761006, 0.81761006, 0.82389937, 0.81132075,\n",
      "       0.82389937, 0.81132075, 0.81761006, 0.81761006, 0.80503145,\n",
      "       0.81132075, 0.82389937, 0.82389937, 0.82389937, 0.80503145,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81761006, 0.78616352,\n",
      "       0.81761006, 0.80503145, 0.81761006, 0.80503145, 0.79874214,\n",
      "       0.80503145, 0.83018868, 0.79874214, 0.80503145, 0.81761006,\n",
      "       0.81132075, 0.80503145, 0.81761006, 0.80503145, 0.81761006,\n",
      "       0.77358491, 0.79245283, 0.80503145, 0.81132075, 0.76100629,\n",
      "       0.78616352, 0.79874214, 0.79245283, 0.82389937, 0.81132075,\n",
      "       0.77358491, 0.72955975, 0.79874214, 0.79874214, 0.81761006,\n",
      "       0.80503145, 0.80503145, 0.81132075, 0.7672956 , 0.79874214,\n",
      "       0.79874214, 0.79245283, 0.77358491, 0.79245283, 0.78616352,\n",
      "       0.78616352, 0.75471698, 0.79245283, 0.79245283, 0.79874214,\n",
      "       0.77358491, 0.80503145, 0.79245283, 0.79874214, 0.78616352,\n",
      "       0.79245283, 0.77358491, 0.7672956 , 0.79245283, 0.82389937,\n",
      "       0.77987421, 0.77987421, 0.81761006, 0.76100629, 0.77358491,\n",
      "       0.77358491, 0.79245283, 0.81761006, 0.77358491, 0.77987421,\n",
      "       0.81132075, 0.79245283, 0.74213836, 0.80503145, 0.75471698,\n",
      "       0.74213836, 0.80503145, 0.79245283, 0.77987421, 0.81132075,\n",
      "       0.75471698, 0.77358491, 0.76100629, 0.74213836, 0.76100629,\n",
      "       0.7672956 , 0.72955975, 0.74842767, 0.7672956 , 0.73584906,\n",
      "       0.74213836, 0.72955975, 0.72327044, 0.79874214, 0.7672956 ,\n",
      "       0.77358491, 0.76100629, 0.74213836, 0.75471698, 0.7672956 ,\n",
      "       0.79874214, 0.70440252, 0.72955975, 0.7672956 , 0.71698113,\n",
      "       0.74213836, 0.74213836, 0.74213836, 0.71698113, 0.72955975,\n",
      "       0.75471698, 0.72955975, 0.76100629, 0.74213836, 0.72955975,\n",
      "       0.7672956 , 0.73584906, 0.75471698, 0.73584906, 0.72955975,\n",
      "       0.71698113, 0.77358491, 0.74213836, 0.68553459, 0.76100629,\n",
      "       0.73584906, 0.72327044, 0.70440252, 0.73584906, 0.74213836,\n",
      "       0.72955975, 0.77358491, 0.73584906, 0.72327044, 0.70440252,\n",
      "       0.68553459, 0.75471698, 0.74213836, 0.74213836, 0.74213836,\n",
      "       0.72327044, 0.74213836, 0.72955975, 0.76100629, 0.72327044,\n",
      "       0.7672956 , 0.76100629, 0.72327044, 0.7672956 , 0.67295597,\n",
      "       0.66666667, 0.76100629, 0.73584906, 0.69811321, 0.69811321,\n",
      "       0.71069182, 0.72327044, 0.72955975, 0.72955975, 0.6918239 ,\n",
      "       0.72327044, 0.72955975, 0.75471698, 0.71069182, 0.71069182,\n",
      "       0.73584906, 0.74842767, 0.7672956 , 0.71069182, 0.73584906,\n",
      "       0.72955975, 0.72327044, 0.75471698, 0.75471698, 0.73584906,\n",
      "       0.72955975, 0.76100629, 0.79874214, 0.71069182, 0.7672956 ,\n",
      "       0.68553459, 0.74213836, 0.75471698, 0.70440252, 0.74213836,\n",
      "       0.72955975, 0.71069182, 0.73584906, 0.74842767, 0.72327044,\n",
      "       0.7672956 , 0.74213836, 0.72327044, 0.77358491, 0.72327044,\n",
      "       0.6918239 , 0.71698113, 0.67924528, 0.6918239 , 0.73584906,\n",
      "       0.70440252, 0.72327044, 0.74842767, 0.73584906, 0.75471698,\n",
      "       0.71069182, 0.71698113, 0.74213836, 0.75471698, 0.72955975,\n",
      "       0.71698113, 0.77358491, 0.71698113, 0.68553459, 0.70440252,\n",
      "       0.77987421, 0.71698113, 0.73584906, 0.70440252, 0.74213836,\n",
      "       0.68553459, 0.71069182, 0.77987421, 0.72327044, 0.72955975,\n",
      "       0.75471698, 0.76100629, 0.75471698, 0.72955975, 0.69811321,\n",
      "       0.67924528, 0.71069182, 0.73584906, 0.72955975, 0.66666667,\n",
      "       0.69811321, 0.70440252, 0.72327044, 0.79245283, 0.74213836,\n",
      "       0.7672956 , 0.76100629, 0.76100629, 0.76100629, 0.73584906,\n",
      "       0.71698113, 0.69811321, 0.72955975, 0.73584906, 0.71069182,\n",
      "       0.76100629, 0.70440252, 0.7672956 , 0.71069182, 0.71069182,\n",
      "       0.69811321, 0.79874214, 0.76100629, 0.71069182, 0.74842767]), 'split6_test_score': array([0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.77987421, 0.77987421, 0.77987421, 0.77987421,\n",
      "       0.77987421, 0.77987421, 0.77987421, 0.77987421, 0.78616352,\n",
      "       0.77987421, 0.77987421, 0.77987421, 0.77987421, 0.77987421,\n",
      "       0.77987421, 0.77987421, 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.83647799,\n",
      "       0.83647799, 0.83647799, 0.79874214, 0.83018868, 0.79874214,\n",
      "       0.77358491, 0.82389937, 0.83647799, 0.83647799, 0.83647799,\n",
      "       0.8427673 , 0.8490566 , 0.83647799, 0.83647799, 0.83647799,\n",
      "       0.79874214, 0.83018868, 0.8427673 , 0.77987421, 0.77987421,\n",
      "       0.8427673 , 0.81761006, 0.8427673 , 0.8427673 , 0.78616352,\n",
      "       0.83647799, 0.81132075, 0.83647799, 0.8490566 , 0.81132075,\n",
      "       0.82389937, 0.83018868, 0.83647799, 0.81132075, 0.83647799,\n",
      "       0.78616352, 0.81132075, 0.82389937, 0.81761006, 0.81132075,\n",
      "       0.83647799, 0.83018868, 0.8427673 , 0.79245283, 0.83647799,\n",
      "       0.81132075, 0.80503145, 0.83018868, 0.81761006, 0.77358491,\n",
      "       0.82389937, 0.78616352, 0.83018868, 0.80503145, 0.79874214,\n",
      "       0.83647799, 0.82389937, 0.82389937, 0.7672956 , 0.83647799,\n",
      "       0.80503145, 0.81761006, 0.8427673 , 0.76100629, 0.81761006,\n",
      "       0.72327044, 0.74213836, 0.80503145, 0.76100629, 0.75471698,\n",
      "       0.82389937, 0.81761006, 0.73584906, 0.80503145, 0.77987421,\n",
      "       0.77987421, 0.81132075, 0.78616352, 0.81761006, 0.73584906,\n",
      "       0.75471698, 0.77358491, 0.77987421, 0.80503145, 0.75471698,\n",
      "       0.77358491, 0.77987421, 0.76100629, 0.80503145, 0.78616352,\n",
      "       0.79874214, 0.7672956 , 0.78616352, 0.81132075, 0.77358491,\n",
      "       0.77358491, 0.73584906, 0.7672956 , 0.77987421, 0.77358491,\n",
      "       0.79245283, 0.7672956 , 0.78616352, 0.76100629, 0.75471698,\n",
      "       0.81761006, 0.80503145, 0.72955975, 0.78616352, 0.72327044,\n",
      "       0.7672956 , 0.75471698, 0.73584906, 0.77358491, 0.7672956 ,\n",
      "       0.75471698, 0.79874214, 0.71698113, 0.74842767, 0.73584906,\n",
      "       0.77358491, 0.74842767, 0.77358491, 0.77987421, 0.77987421,\n",
      "       0.81132075, 0.81132075, 0.71698113, 0.77358491, 0.77987421,\n",
      "       0.77358491, 0.76100629, 0.7672956 , 0.74842767, 0.77358491,\n",
      "       0.80503145, 0.78616352, 0.78616352, 0.72327044, 0.77358491,\n",
      "       0.79874214, 0.79874214, 0.80503145, 0.77358491, 0.76100629,\n",
      "       0.7672956 , 0.78616352, 0.77358491, 0.75471698, 0.73584906,\n",
      "       0.71069182, 0.69811321, 0.77987421, 0.76100629, 0.74842767,\n",
      "       0.77358491, 0.77987421, 0.77987421, 0.77358491, 0.73584906,\n",
      "       0.75471698, 0.72955975, 0.74213836, 0.7672956 , 0.80503145,\n",
      "       0.71698113, 0.79245283, 0.73584906, 0.7672956 , 0.73584906,\n",
      "       0.74842767, 0.80503145, 0.74842767, 0.75471698, 0.77358491,\n",
      "       0.74213836, 0.74213836, 0.74842767, 0.72327044, 0.72955975,\n",
      "       0.81132075, 0.77987421, 0.73584906, 0.75471698, 0.81761006,\n",
      "       0.76100629, 0.74213836, 0.77358491, 0.79245283, 0.79245283,\n",
      "       0.74842767, 0.77358491, 0.76100629, 0.71069182, 0.77987421,\n",
      "       0.7672956 , 0.79245283, 0.79245283, 0.74842767, 0.73584906,\n",
      "       0.7672956 , 0.76100629, 0.71069182, 0.75471698, 0.74842767,\n",
      "       0.72955975, 0.7672956 , 0.73584906, 0.74213836, 0.76100629,\n",
      "       0.76100629, 0.7672956 , 0.79874214, 0.74213836, 0.77358491,\n",
      "       0.82389937, 0.74213836, 0.73584906, 0.76100629, 0.74213836,\n",
      "       0.74213836, 0.7672956 , 0.75471698, 0.76100629, 0.76100629,\n",
      "       0.75471698, 0.83018868, 0.77358491, 0.75471698, 0.74842767,\n",
      "       0.76100629, 0.76100629, 0.77987421, 0.77358491, 0.77987421,\n",
      "       0.75471698, 0.78616352, 0.77987421, 0.78616352, 0.72955975,\n",
      "       0.75471698, 0.74213836, 0.80503145, 0.79245283, 0.75471698,\n",
      "       0.78616352, 0.71069182, 0.77358491, 0.75471698, 0.74213836,\n",
      "       0.75471698, 0.7672956 , 0.79874214, 0.77987421, 0.81761006]), 'split7_test_score': array([0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.82389937, 0.82389937, 0.82389937,\n",
      "       0.81132075, 0.82389937, 0.82389937, 0.82389937, 0.81132075,\n",
      "       0.82389937, 0.82389937, 0.82389937, 0.81132075, 0.82389937,\n",
      "       0.81132075, 0.82389937, 0.82389937, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.82389937, 0.81761006, 0.81761006, 0.79245283,\n",
      "       0.81132075, 0.81761006, 0.81761006, 0.82389937, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.82389937, 0.79245283,\n",
      "       0.74842767, 0.72955975, 0.82389937, 0.72955975, 0.81132075,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.74842767, 0.74842767,\n",
      "       0.81132075, 0.74842767, 0.81132075, 0.81132075, 0.82389937,\n",
      "       0.81761006, 0.79874214, 0.77358491, 0.75471698, 0.7672956 ,\n",
      "       0.81132075, 0.81761006, 0.80503145, 0.77987421, 0.79874214,\n",
      "       0.81132075, 0.81761006, 0.81132075, 0.73584906, 0.82389937,\n",
      "       0.80503145, 0.77358491, 0.79874214, 0.77358491, 0.82389937,\n",
      "       0.7672956 , 0.79245283, 0.81761006, 0.77358491, 0.74213836,\n",
      "       0.78616352, 0.79245283, 0.75471698, 0.82389937, 0.81132075,\n",
      "       0.75471698, 0.77987421, 0.75471698, 0.74842767, 0.74842767,\n",
      "       0.77987421, 0.78616352, 0.7672956 , 0.73584906, 0.73584906,\n",
      "       0.77358491, 0.78616352, 0.74842767, 0.74213836, 0.77987421,\n",
      "       0.76100629, 0.78616352, 0.7672956 , 0.77987421, 0.73584906,\n",
      "       0.77987421, 0.79245283, 0.7672956 , 0.71069182, 0.77358491,\n",
      "       0.77987421, 0.79245283, 0.76100629, 0.76100629, 0.76100629,\n",
      "       0.78616352, 0.7672956 , 0.75471698, 0.79245283, 0.7672956 ,\n",
      "       0.75471698, 0.74213836, 0.78616352, 0.72955975, 0.76100629,\n",
      "       0.77987421, 0.74842767, 0.75471698, 0.75471698, 0.78616352,\n",
      "       0.76100629, 0.76100629, 0.75471698, 0.74213836, 0.79245283,\n",
      "       0.78616352, 0.77358491, 0.7672956 , 0.74213836, 0.75471698,\n",
      "       0.74842767, 0.77987421, 0.7672956 , 0.72327044, 0.77987421,\n",
      "       0.7672956 , 0.79245283, 0.75471698, 0.77358491, 0.78616352,\n",
      "       0.71698113, 0.72955975, 0.72327044, 0.73584906, 0.74213836,\n",
      "       0.74842767, 0.78616352, 0.73584906, 0.76100629, 0.75471698,\n",
      "       0.76100629, 0.73584906, 0.74842767, 0.74213836, 0.75471698,\n",
      "       0.76100629, 0.75471698, 0.7672956 , 0.71698113, 0.74842767,\n",
      "       0.76100629, 0.73584906, 0.77358491, 0.73584906, 0.71069182,\n",
      "       0.77987421, 0.75471698, 0.71698113, 0.76100629, 0.80503145,\n",
      "       0.77987421, 0.74213836, 0.75471698, 0.70440252, 0.7672956 ,\n",
      "       0.72955975, 0.68553459, 0.77358491, 0.70440252, 0.7672956 ,\n",
      "       0.74842767, 0.74213836, 0.75471698, 0.72955975, 0.75471698,\n",
      "       0.75471698, 0.71698113, 0.7672956 , 0.79245283, 0.7672956 ,\n",
      "       0.72955975, 0.71069182, 0.77358491, 0.75471698, 0.71069182,\n",
      "       0.74842767, 0.77358491, 0.79874214, 0.74842767, 0.74213836,\n",
      "       0.76100629, 0.72327044, 0.7672956 , 0.74213836, 0.76100629,\n",
      "       0.77987421, 0.74842767, 0.75471698, 0.74213836, 0.7672956 ,\n",
      "       0.81761006, 0.71069182, 0.77358491, 0.73584906, 0.74842767,\n",
      "       0.75471698, 0.75471698, 0.77987421, 0.7672956 , 0.7672956 ,\n",
      "       0.78616352, 0.73584906, 0.74842767, 0.70440252, 0.72327044,\n",
      "       0.74213836, 0.73584906, 0.70440252, 0.71069182, 0.78616352,\n",
      "       0.77358491, 0.71698113, 0.74842767, 0.74842767, 0.77987421,\n",
      "       0.76100629, 0.74842767, 0.72955975, 0.77358491, 0.77358491,\n",
      "       0.7672956 , 0.74842767, 0.72955975, 0.74213836, 0.72955975,\n",
      "       0.75471698, 0.75471698, 0.74213836, 0.72327044, 0.81761006,\n",
      "       0.77987421, 0.77358491, 0.75471698, 0.74842767, 0.74213836,\n",
      "       0.71698113, 0.72327044, 0.76100629, 0.77358491, 0.7672956 ,\n",
      "       0.71069182, 0.7672956 , 0.73584906, 0.75471698, 0.77987421,\n",
      "       0.77358491, 0.7672956 , 0.74842767, 0.76100629, 0.72327044,\n",
      "       0.79245283, 0.75471698, 0.71069182, 0.75471698, 0.73584906,\n",
      "       0.72327044, 0.74842767, 0.72327044, 0.76100629, 0.76100629,\n",
      "       0.77358491, 0.78616352, 0.77987421, 0.7672956 , 0.72327044]), 'split8_test_score': array([0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 ,\n",
      "       0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 ,\n",
      "       0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 ,\n",
      "       0.7672956 , 0.7672956 , 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.85534591, 0.85534591, 0.83018868, 0.83018868,\n",
      "       0.8490566 , 0.8427673 , 0.83018868, 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.83018868, 0.83018868,\n",
      "       0.8490566 , 0.83018868, 0.8490566 , 0.8427673 , 0.81761006,\n",
      "       0.8427673 , 0.83647799, 0.83647799, 0.8427673 , 0.8427673 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8490566 , 0.8490566 ,\n",
      "       0.83647799, 0.81132075, 0.82389937, 0.82389937, 0.83647799,\n",
      "       0.85534591, 0.83647799, 0.82389937, 0.83647799, 0.8427673 ,\n",
      "       0.82389937, 0.80503145, 0.8427673 , 0.83018868, 0.81132075,\n",
      "       0.83647799, 0.82389937, 0.83647799, 0.83018868, 0.83647799,\n",
      "       0.85534591, 0.8427673 , 0.8427673 , 0.83647799, 0.8427673 ,\n",
      "       0.83647799, 0.82389937, 0.83647799, 0.81132075, 0.8490566 ,\n",
      "       0.83647799, 0.83018868, 0.83018868, 0.8427673 , 0.80503145,\n",
      "       0.85534591, 0.79874214, 0.83018868, 0.80503145, 0.81761006,\n",
      "       0.81761006, 0.82389937, 0.8427673 , 0.83018868, 0.8427673 ,\n",
      "       0.82389937, 0.82389937, 0.83647799, 0.8427673 , 0.81132075,\n",
      "       0.83018868, 0.81132075, 0.8427673 , 0.83647799, 0.82389937,\n",
      "       0.7672956 , 0.80503145, 0.80503145, 0.83647799, 0.81132075,\n",
      "       0.80503145, 0.82389937, 0.80503145, 0.79245283, 0.8427673 ,\n",
      "       0.81132075, 0.79245283, 0.83018868, 0.80503145, 0.80503145,\n",
      "       0.79245283, 0.81132075, 0.81132075, 0.81132075, 0.80503145,\n",
      "       0.82389937, 0.82389937, 0.81132075, 0.83647799, 0.83647799,\n",
      "       0.81761006, 0.79874214, 0.81132075, 0.77987421, 0.81132075,\n",
      "       0.83647799, 0.81761006, 0.79874214, 0.77358491, 0.81132075,\n",
      "       0.83647799, 0.79874214, 0.82389937, 0.77987421, 0.83018868,\n",
      "       0.79874214, 0.79874214, 0.80503145, 0.78616352, 0.79874214,\n",
      "       0.8427673 , 0.80503145, 0.81761006, 0.79245283, 0.79245283,\n",
      "       0.80503145, 0.79874214, 0.83647799, 0.8427673 , 0.83018868,\n",
      "       0.83647799, 0.81761006, 0.77358491, 0.7672956 , 0.80503145,\n",
      "       0.75471698, 0.81132075, 0.81132075, 0.82389937, 0.80503145,\n",
      "       0.81132075, 0.79245283, 0.81132075, 0.79245283, 0.82389937,\n",
      "       0.81761006, 0.79245283, 0.78616352, 0.79874214, 0.78616352,\n",
      "       0.7672956 , 0.77358491, 0.81132075, 0.81132075, 0.82389937,\n",
      "       0.77358491, 0.81132075, 0.81132075, 0.78616352, 0.83018868,\n",
      "       0.81761006, 0.79245283, 0.81761006, 0.79874214, 0.78616352,\n",
      "       0.76100629, 0.80503145, 0.77358491, 0.79245283, 0.83018868,\n",
      "       0.78616352, 0.77358491, 0.81132075, 0.79874214, 0.81132075,\n",
      "       0.78616352, 0.77358491, 0.81761006, 0.83647799, 0.83018868,\n",
      "       0.75471698, 0.77358491, 0.79245283, 0.74213836, 0.79245283,\n",
      "       0.7672956 , 0.7672956 , 0.82389937, 0.81761006, 0.85534591,\n",
      "       0.81761006, 0.79874214, 0.81761006, 0.77987421, 0.7672956 ,\n",
      "       0.81132075, 0.75471698, 0.81761006, 0.75471698, 0.73584906,\n",
      "       0.79245283, 0.74842767, 0.81132075, 0.79245283, 0.77987421,\n",
      "       0.77987421, 0.81761006, 0.81761006, 0.81132075, 0.81761006,\n",
      "       0.79874214, 0.77358491, 0.78616352, 0.83018868, 0.78616352,\n",
      "       0.78616352, 0.80503145, 0.83647799, 0.81132075, 0.74842767,\n",
      "       0.81761006, 0.77987421, 0.80503145, 0.77987421, 0.78616352,\n",
      "       0.79874214, 0.82389937, 0.83018868, 0.7672956 , 0.79874214,\n",
      "       0.75471698, 0.7672956 , 0.81761006, 0.79245283, 0.80503145,\n",
      "       0.77358491, 0.77987421, 0.81132075, 0.77987421, 0.83647799,\n",
      "       0.83018868, 0.74842767, 0.81761006, 0.81132075, 0.76100629,\n",
      "       0.7672956 , 0.7672956 , 0.72955975, 0.79245283, 0.77987421,\n",
      "       0.74842767, 0.83018868, 0.81761006, 0.79874214, 0.81132075,\n",
      "       0.83647799, 0.77358491, 0.81132075, 0.76100629, 0.77987421]), 'split9_test_score': array([0.80379747, 0.80379747, 0.80379747, 0.80379747, 0.80379747,\n",
      "       0.80379747, 0.80379747, 0.80379747, 0.80379747, 0.80379747,\n",
      "       0.80379747, 0.80379747, 0.80379747, 0.80379747, 0.80379747,\n",
      "       0.80379747, 0.74683544, 0.74050633, 0.74683544, 0.74050633,\n",
      "       0.74683544, 0.74683544, 0.74683544, 0.74683544, 0.74683544,\n",
      "       0.74683544, 0.74683544, 0.74683544, 0.74683544, 0.74050633,\n",
      "       0.74683544, 0.74683544, 0.86075949, 0.86075949, 0.86075949,\n",
      "       0.84810127, 0.86075949, 0.84810127, 0.86075949, 0.86075949,\n",
      "       0.86075949, 0.86075949, 0.86075949, 0.85443038, 0.86075949,\n",
      "       0.85443038, 0.85443038, 0.86075949, 0.86075949, 0.86075949,\n",
      "       0.86075949, 0.85443038, 0.86075949, 0.86708861, 0.86708861,\n",
      "       0.86075949, 0.86075949, 0.86075949, 0.86075949, 0.85443038,\n",
      "       0.85443038, 0.86075949, 0.85443038, 0.85443038, 0.86708861,\n",
      "       0.86708861, 0.86708861, 0.85443038, 0.87341772, 0.86708861,\n",
      "       0.85443038, 0.86708861, 0.84177215, 0.84177215, 0.84810127,\n",
      "       0.84177215, 0.84177215, 0.86075949, 0.85443038, 0.85443038,\n",
      "       0.85443038, 0.82278481, 0.85443038, 0.84177215, 0.86708861,\n",
      "       0.85443038, 0.84177215, 0.83544304, 0.84810127, 0.81012658,\n",
      "       0.84810127, 0.84810127, 0.8164557 , 0.81012658, 0.8164557 ,\n",
      "       0.84177215, 0.84177215, 0.85443038, 0.81012658, 0.84177215,\n",
      "       0.84810127, 0.84177215, 0.86075949, 0.84810127, 0.8164557 ,\n",
      "       0.83544304, 0.83544304, 0.80379747, 0.8164557 , 0.84177215,\n",
      "       0.82278481, 0.82911392, 0.83544304, 0.81012658, 0.82278481,\n",
      "       0.85443038, 0.8164557 , 0.82278481, 0.75316456, 0.82911392,\n",
      "       0.82911392, 0.83544304, 0.80379747, 0.76582278, 0.82911392,\n",
      "       0.79113924, 0.83544304, 0.82278481, 0.74050633, 0.80379747,\n",
      "       0.75316456, 0.75949367, 0.83544304, 0.7721519 , 0.81012658,\n",
      "       0.81012658, 0.8164557 , 0.77848101, 0.8164557 , 0.76582278,\n",
      "       0.82278481, 0.81012658, 0.7721519 , 0.79113924, 0.73417722,\n",
      "       0.82278481, 0.82278481, 0.76582278, 0.79113924, 0.8164557 ,\n",
      "       0.81012658, 0.75316456, 0.7721519 , 0.82911392, 0.79746835,\n",
      "       0.76582278, 0.75949367, 0.7721519 , 0.84177215, 0.80379747,\n",
      "       0.78481013, 0.7721519 , 0.78481013, 0.75316456, 0.79113924,\n",
      "       0.74050633, 0.76582278, 0.78481013, 0.76582278, 0.7721519 ,\n",
      "       0.77848101, 0.77848101, 0.74683544, 0.77848101, 0.79746835,\n",
      "       0.7278481 , 0.8164557 , 0.76582278, 0.76582278, 0.79113924,\n",
      "       0.74050633, 0.78481013, 0.78481013, 0.76582278, 0.7721519 ,\n",
      "       0.79113924, 0.78481013, 0.77848101, 0.74050633, 0.75949367,\n",
      "       0.76582278, 0.77848101, 0.81012658, 0.8164557 , 0.78481013,\n",
      "       0.75949367, 0.81012658, 0.80379747, 0.78481013, 0.82278481,\n",
      "       0.78481013, 0.79746835, 0.78481013, 0.77848101, 0.7721519 ,\n",
      "       0.77848101, 0.76582278, 0.79746835, 0.7721519 , 0.8164557 ,\n",
      "       0.78481013, 0.74050633, 0.75949367, 0.75949367, 0.82278481,\n",
      "       0.78481013, 0.76582278, 0.79113924, 0.7721519 , 0.75949367,\n",
      "       0.75949367, 0.7721519 , 0.75316456, 0.75316456, 0.78481013,\n",
      "       0.80379747, 0.79113924, 0.78481013, 0.80379747, 0.7721519 ,\n",
      "       0.79746835, 0.75949367, 0.77848101, 0.75316456, 0.75949367,\n",
      "       0.75949367, 0.75316456, 0.78481013, 0.75949367, 0.79113924,\n",
      "       0.75949367, 0.79113924, 0.7721519 , 0.78481013, 0.77848101,\n",
      "       0.80379747, 0.75949367, 0.77848101, 0.75949367, 0.74050633,\n",
      "       0.75316456, 0.77848101, 0.77848101, 0.74683544, 0.75949367,\n",
      "       0.78481013, 0.79113924, 0.75316456, 0.76582278, 0.80379747,\n",
      "       0.80379747, 0.80379747, 0.77848101, 0.80379747, 0.71518987,\n",
      "       0.76582278, 0.82911392, 0.75949367, 0.77848101, 0.78481013,\n",
      "       0.77848101, 0.79113924, 0.76582278, 0.78481013, 0.79746835,\n",
      "       0.78481013, 0.77848101, 0.77848101, 0.7721519 , 0.78481013,\n",
      "       0.78481013, 0.75316456, 0.7721519 , 0.75316456, 0.75316456,\n",
      "       0.75949367, 0.74050633, 0.81012658, 0.80379747, 0.78481013,\n",
      "       0.79113924, 0.78481013, 0.79746835, 0.7721519 , 0.77848101,\n",
      "       0.79746835, 0.75949367, 0.74050633, 0.75949367, 0.79113924,\n",
      "       0.74050633, 0.79113924, 0.78481013, 0.75316456, 0.7721519 ,\n",
      "       0.77848101, 0.75316456, 0.74683544, 0.7721519 , 0.75949367,\n",
      "       0.75949367, 0.75949367, 0.79113924, 0.78481013, 0.76582278,\n",
      "       0.79113924, 0.77848101, 0.79746835, 0.76582278, 0.78481013]), 'mean_test_score': array([0.78478226, 0.78478226, 0.78478226, 0.78478226, 0.78478226,\n",
      "       0.78478226, 0.78478226, 0.78478226, 0.78478226, 0.78478226,\n",
      "       0.78478226, 0.78478226, 0.78478226, 0.78478226, 0.78478226,\n",
      "       0.78478226, 0.74952631, 0.7488934 , 0.74952631, 0.7488934 ,\n",
      "       0.74952631, 0.74952631, 0.74952631, 0.74952631, 0.75015524,\n",
      "       0.74952631, 0.74952631, 0.74952631, 0.74952631, 0.7488934 ,\n",
      "       0.74952631, 0.74952631, 0.83324576, 0.83324576, 0.83324576,\n",
      "       0.82883528, 0.83324576, 0.83072208, 0.83324576, 0.83135897,\n",
      "       0.83324576, 0.83324576, 0.83324576, 0.83009713, 0.83261683,\n",
      "       0.83072606, 0.83261285, 0.83261683, 0.82884324, 0.82569859,\n",
      "       0.82506966, 0.82380782, 0.82506966, 0.82884723, 0.8263315 ,\n",
      "       0.82695645, 0.83073004, 0.82884324, 0.83073004, 0.82254996,\n",
      "       0.83072606, 0.82947218, 0.83009713, 0.83072606, 0.81941326,\n",
      "       0.81123716, 0.81123716, 0.81751851, 0.8143858 , 0.82004219,\n",
      "       0.80934241, 0.82696043, 0.82694451, 0.81373696, 0.81562774,\n",
      "       0.82631558, 0.81813948, 0.82255394, 0.82632354, 0.82883926,\n",
      "       0.80556882, 0.80491999, 0.8112292 , 0.80304514, 0.80431892,\n",
      "       0.81374492, 0.80933445, 0.81121726, 0.81625667, 0.80365417,\n",
      "       0.81436988, 0.80116233, 0.81309211, 0.80365417, 0.80806066,\n",
      "       0.81562376, 0.804303  , 0.80808455, 0.79044662, 0.81059231,\n",
      "       0.79927554, 0.79927155, 0.80054136, 0.79990447, 0.79736884,\n",
      "       0.80555688, 0.79989651, 0.79924767, 0.79988456, 0.80933445,\n",
      "       0.79800175, 0.8055529 , 0.78920468, 0.79296234, 0.7766181 ,\n",
      "       0.8030531 , 0.77535626, 0.79548603, 0.78600828, 0.79486108,\n",
      "       0.79611894, 0.7917204 , 0.79798981, 0.7872741 , 0.79926359,\n",
      "       0.78666109, 0.80681474, 0.80617785, 0.77279277, 0.77157472,\n",
      "       0.77405859, 0.7765783 , 0.77851286, 0.77155481, 0.77849693,\n",
      "       0.77220763, 0.79548205, 0.77281665, 0.79170846, 0.78287159,\n",
      "       0.786681  , 0.79673593, 0.78224664, 0.78603216, 0.75895231,\n",
      "       0.76907093, 0.75963697, 0.77280869, 0.7684221 , 0.76843802,\n",
      "       0.75837115, 0.76022212, 0.76778123, 0.79045856, 0.78037577,\n",
      "       0.77155083, 0.77217578, 0.77847305, 0.78732187, 0.78289547,\n",
      "       0.77910994, 0.76274978, 0.76087095, 0.76336677, 0.75961707,\n",
      "       0.76335881, 0.76840618, 0.7577263 , 0.75771435, 0.76337871,\n",
      "       0.77344559, 0.76715628, 0.77719927, 0.77218772, 0.77786004,\n",
      "       0.76523764, 0.75585941, 0.75582756, 0.75645649, 0.75961707,\n",
      "       0.74323302, 0.76716026, 0.75395271, 0.75394077, 0.76149192,\n",
      "       0.77219569, 0.75206592, 0.76023804, 0.76839026, 0.77091792,\n",
      "       0.77217976, 0.77596131, 0.75396863, 0.75900406, 0.76024202,\n",
      "       0.74890534, 0.7696919 , 0.75710931, 0.75961309, 0.75837911,\n",
      "       0.76841812, 0.76339463, 0.76087095, 0.75520659, 0.76463657,\n",
      "       0.78225062, 0.77406656, 0.7791179 , 0.75331582, 0.75648834,\n",
      "       0.74388982, 0.73945944, 0.76714434, 0.74072924, 0.74894515,\n",
      "       0.74703447, 0.75331184, 0.77219569, 0.74828437, 0.7602261 ,\n",
      "       0.77091792, 0.76212085, 0.77657432, 0.76902715, 0.7476634 ,\n",
      "       0.74893321, 0.73949128, 0.75709736, 0.75522251, 0.76086299,\n",
      "       0.75521853, 0.75645251, 0.76086697, 0.75330388, 0.74890534,\n",
      "       0.75959717, 0.76651142, 0.77785208, 0.76399968, 0.77785606,\n",
      "       0.74638962, 0.75521455, 0.75205796, 0.74200303, 0.75583552,\n",
      "       0.76528541, 0.74827641, 0.75394873, 0.76525754, 0.76650346,\n",
      "       0.7639957 , 0.75520659, 0.77344559, 0.77028103, 0.76274182,\n",
      "       0.76527347, 0.74515166, 0.75015922, 0.72752567, 0.75396465,\n",
      "       0.76151182, 0.75396465, 0.75080408, 0.75082   , 0.75579572,\n",
      "       0.76400366, 0.7564963 , 0.75959717, 0.77155879, 0.77156277,\n",
      "       0.75143301, 0.760246  , 0.74702253, 0.75332378, 0.74955816,\n",
      "       0.75646843, 0.76338269, 0.75960911, 0.74199506, 0.74577661,\n",
      "       0.75835523, 0.75393281, 0.7652655 , 0.75456174, 0.76714036,\n",
      "       0.76274182, 0.77530849, 0.77346549, 0.75522251, 0.74640554,\n",
      "       0.74012021, 0.75646843, 0.75081602, 0.74702651, 0.74011225,\n",
      "       0.75899212, 0.74953427, 0.75769843, 0.75079213, 0.7684221 ,\n",
      "       0.75832736, 0.76464852, 0.76716026, 0.76839822, 0.73319003,\n",
      "       0.75269087, 0.73758061, 0.74072128, 0.74954223, 0.74890534,\n",
      "       0.74890534, 0.75771037, 0.76779317, 0.76087095, 0.75519863,\n",
      "       0.75835921, 0.78539527, 0.77597325, 0.76211687, 0.76778919]), 'std_test_score': array([0.0180514 , 0.0180514 , 0.0180514 , 0.0180514 , 0.0180514 ,\n",
      "       0.0180514 , 0.0180514 , 0.0180514 , 0.0180514 , 0.0180514 ,\n",
      "       0.0180514 , 0.0180514 , 0.0180514 , 0.0180514 , 0.0180514 ,\n",
      "       0.0180514 , 0.03117867, 0.0312909 , 0.03117867, 0.0312909 ,\n",
      "       0.03117867, 0.03117867, 0.03117867, 0.03117867, 0.0318409 ,\n",
      "       0.03117867, 0.03117867, 0.03117867, 0.03117867, 0.0312909 ,\n",
      "       0.03117867, 0.03117867, 0.02572199, 0.02572199, 0.02572199,\n",
      "       0.02613271, 0.02572199, 0.02653758, 0.02572199, 0.02670408,\n",
      "       0.02572199, 0.02572199, 0.02572199, 0.02614829, 0.02601801,\n",
      "       0.0263689 , 0.02588346, 0.02661919, 0.02728207, 0.02440139,\n",
      "       0.03339867, 0.03549775, 0.02499968, 0.02435577, 0.03098156,\n",
      "       0.03100226, 0.02679813, 0.02180217, 0.02527902, 0.02179635,\n",
      "       0.02606716, 0.02604542, 0.02474941, 0.02560788, 0.02909912,\n",
      "       0.03442634, 0.03925775, 0.02978452, 0.04047253, 0.03109207,\n",
      "       0.03042321, 0.03149606, 0.0260632 , 0.03725941, 0.03702211,\n",
      "       0.02228934, 0.03556037, 0.02769374, 0.02957178, 0.02641482,\n",
      "       0.02774569, 0.03333719, 0.03119276, 0.03732104, 0.03457582,\n",
      "       0.02759405, 0.02550431, 0.02845576, 0.03268269, 0.0220733 ,\n",
      "       0.03380173, 0.03502371, 0.02908581, 0.03508379, 0.03645519,\n",
      "       0.02832017, 0.02996459, 0.02992122, 0.02360622, 0.02678009,\n",
      "       0.02993346, 0.03060115, 0.03760019, 0.03011332, 0.03197392,\n",
      "       0.02618284, 0.03053493, 0.0339029 , 0.03210644, 0.03470224,\n",
      "       0.02878519, 0.02837819, 0.0345658 , 0.03466722, 0.03041516,\n",
      "       0.04064775, 0.02974456, 0.03461596, 0.03210155, 0.03744713,\n",
      "       0.02358119, 0.03493753, 0.03604728, 0.03322922, 0.03323538,\n",
      "       0.02374689, 0.02374808, 0.03161188, 0.03664587, 0.03513325,\n",
      "       0.03950192, 0.02852841, 0.04675273, 0.03907529, 0.02544317,\n",
      "       0.03974116, 0.0224349 , 0.02127765, 0.03276635, 0.0290754 ,\n",
      "       0.03756971, 0.03608874, 0.03629779, 0.02865755, 0.03602685,\n",
      "       0.03450789, 0.04095364, 0.036854  , 0.02813029, 0.02376385,\n",
      "       0.02890637, 0.0316596 , 0.02551139, 0.03219076, 0.02498069,\n",
      "       0.03282978, 0.03413176, 0.02386718, 0.04512717, 0.03405306,\n",
      "       0.02596717, 0.03300371, 0.04058043, 0.03062744, 0.02649487,\n",
      "       0.04018396, 0.022654  , 0.03681287, 0.02418293, 0.02838685,\n",
      "       0.03419447, 0.0349698 , 0.0347217 , 0.03189073, 0.03506255,\n",
      "       0.02648009, 0.03106898, 0.02204008, 0.01557834, 0.03228242,\n",
      "       0.04227259, 0.03034228, 0.03136762, 0.03029109, 0.02516359,\n",
      "       0.03679662, 0.03580587, 0.03487991, 0.03845439, 0.03769503,\n",
      "       0.04105064, 0.02742732, 0.02737668, 0.02643877, 0.02997679,\n",
      "       0.03688979, 0.02826175, 0.036535  , 0.03041283, 0.03808757,\n",
      "       0.03109467, 0.0324475 , 0.03070317, 0.02525267, 0.03028083,\n",
      "       0.03471227, 0.0228038 , 0.02838431, 0.03352788, 0.03560935,\n",
      "       0.03619813, 0.04385651, 0.01871353, 0.03120111, 0.04387713,\n",
      "       0.0318821 , 0.0303337 , 0.0264078 , 0.03293484, 0.03942267,\n",
      "       0.03508632, 0.02674446, 0.0254917 , 0.03934163, 0.02965436,\n",
      "       0.02972936, 0.03450134, 0.03626384, 0.03666373, 0.03640935,\n",
      "       0.02896784, 0.03242596, 0.02775253, 0.02879075, 0.02698092,\n",
      "       0.02865302, 0.03967217, 0.02574642, 0.03901362, 0.03062954,\n",
      "       0.0288929 , 0.02407045, 0.02569376, 0.04495993, 0.02160088,\n",
      "       0.03578072, 0.02661574, 0.03189167, 0.03122493, 0.04668449,\n",
      "       0.03063709, 0.02931225, 0.04103026, 0.01782548, 0.01910712,\n",
      "       0.0380865 , 0.02209386, 0.03793497, 0.03201985, 0.0298829 ,\n",
      "       0.02856115, 0.03477687, 0.0362608 , 0.02970391, 0.03758906,\n",
      "       0.02454565, 0.04639308, 0.03874724, 0.02851549, 0.03737521,\n",
      "       0.03045938, 0.0334464 , 0.01867306, 0.04372782, 0.03006246,\n",
      "       0.02855366, 0.02663077, 0.03581188, 0.03477756, 0.02175839,\n",
      "       0.04212184, 0.018109  , 0.02766969, 0.03784339, 0.03023072,\n",
      "       0.02502294, 0.03086963, 0.04103763, 0.02084359, 0.03240247,\n",
      "       0.03638419, 0.03846872, 0.03780698, 0.02606331, 0.03904202,\n",
      "       0.03465318, 0.0348354 , 0.03315236, 0.02680769, 0.03119725,\n",
      "       0.03028091, 0.02307424, 0.02717902, 0.03941449, 0.02464336,\n",
      "       0.02162636, 0.03199657, 0.03346066, 0.02637876, 0.0212387 ,\n",
      "       0.02105163, 0.03888764, 0.028911  , 0.02287789, 0.03003495,\n",
      "       0.04707259, 0.02446718, 0.03392606, 0.03359189, 0.03567172]), 'rank_test_score': array([103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103,\n",
      "       103, 103, 103, 277, 295, 277, 295, 277, 277, 277, 277, 273, 277,\n",
      "       277, 277, 277, 295, 277, 277,   1,   1,   1,  26,   1,  18,   1,\n",
      "        12,   1,   1,   1,  19,   9,  15,  11,  10,  23,  33,  34,  36,\n",
      "        34,  22,  30,  28,  13,  23,  13,  38,  15,  21,  19,  15,  40,\n",
      "        51,  51,  42,  46,  39,  56,  27,  29,  49,  44,  32,  41,  37,\n",
      "        31,  25,  63,  66,  53,  72,  67,  48,  57,  54,  43,  69,  47,\n",
      "        73,  50,  70,  60,  45,  68,  59,  94,  55,  78,  79,  74,  75,\n",
      "        84,  64,  76,  81,  77,  57,  82,  65,  95,  90, 133,  71, 138,\n",
      "        87, 101,  89,  86,  91,  83,  97,  80,  99,  61,  62, 147, 154,\n",
      "       141, 134, 126, 157, 127, 148,  88, 145,  92, 120,  98,  85, 122,\n",
      "       100, 223, 163, 214, 146, 166, 165, 225, 213, 174,  93, 123, 158,\n",
      "       153, 128,  96, 119, 125, 197, 204, 195, 215, 196, 169, 229, 230,\n",
      "       194, 144, 177, 132, 151, 129, 186, 241, 243, 239, 215, 309, 176,\n",
      "       256, 258, 203, 149, 265, 211, 171, 159, 152, 137, 253, 221, 210,\n",
      "       292, 162, 233, 217, 224, 168, 192, 204, 249, 188, 121, 140, 124,\n",
      "       261, 236, 308, 317, 178, 312, 289, 301, 262, 149, 298, 212, 159,\n",
      "       200, 135, 164, 300, 290, 316, 234, 245, 208, 247, 240, 207, 263,\n",
      "       292, 219, 180, 131, 190, 130, 305, 248, 266, 310, 242, 182, 299,\n",
      "       257, 185, 181, 191, 250, 143, 161, 198, 183, 307, 272, 320, 255,\n",
      "       202, 254, 270, 268, 244, 189, 235, 220, 156, 155, 267, 209, 303,\n",
      "       260, 274, 237, 193, 218, 311, 306, 227, 259, 184, 252, 179, 198,\n",
      "       139, 142, 245, 304, 314, 238, 269, 302, 315, 222, 276, 232, 271,\n",
      "       166, 228, 187, 175, 170, 319, 264, 318, 313, 275, 292, 291, 231,\n",
      "       172, 204, 251, 226, 102, 136, 201, 173])}\n",
      "Resultados para UnderSampler:\n",
      "{'mean_fit_time': array([0.00099933, 0.00120132, 0.00128083, 0.00099869, 0.00100021,\n",
      "       0.00103674, 0.00105133, 0.00139985, 0.00105519, 0.00119946,\n",
      "       0.00130088, 0.00121856, 0.0012449 , 0.00134094, 0.00095074,\n",
      "       0.00109849, 0.00100036, 0.00140047, 0.00099978, 0.00109472,\n",
      "       0.00126688, 0.00140016, 0.00102541, 0.00100067, 0.00100043,\n",
      "       0.00105088, 0.00151544, 0.00100069, 0.00180025, 0.00129876,\n",
      "       0.00119965, 0.0016016 , 0.00130041, 0.00140009, 0.00114994,\n",
      "       0.00140252, 0.00119927, 0.00159984, 0.00151243, 0.00130043,\n",
      "       0.00125377, 0.00105107, 0.00140083, 0.00119987, 0.00139828,\n",
      "       0.00144992, 0.00150042, 0.00125136, 0.00150075, 0.00155175,\n",
      "       0.00140057, 0.00147064, 0.00145681, 0.00137358, 0.00137925,\n",
      "       0.00139959, 0.00146589, 0.00170052, 0.001717  , 0.00190217,\n",
      "       0.00148876, 0.00149925, 0.00158   , 0.0014008 , 0.00139997,\n",
      "       0.00149839, 0.0014307 , 0.00152998, 0.00155816, 0.00160062,\n",
      "       0.00146976, 0.00160089, 0.00150051, 0.00170007, 0.00148427,\n",
      "       0.00159953, 0.00149865, 0.00159662, 0.0014009 , 0.00150087,\n",
      "       0.00156868, 0.00149977, 0.00159984, 0.00160027, 0.00169995,\n",
      "       0.00171556, 0.00171709, 0.00151243, 0.00160077, 0.00170109,\n",
      "       0.00159976, 0.00150018, 0.00160074, 0.00175219, 0.0016362 ,\n",
      "       0.00170026, 0.0017031 , 0.00180106, 0.00166974, 0.00164938,\n",
      "       0.00164263, 0.00169897, 0.00160007, 0.00160084, 0.00139973,\n",
      "       0.00166342, 0.00163798, 0.00149963, 0.00165904, 0.00163805,\n",
      "       0.00160069, 0.0016    , 0.00169959, 0.00169976, 0.00187383,\n",
      "       0.00169859, 0.00169983, 0.00178454, 0.00167649, 0.00169923,\n",
      "       0.00151494, 0.00160015, 0.00170071, 0.00161791, 0.00149996,\n",
      "       0.0018986 , 0.00180016, 0.00179994, 0.00179956, 0.00169985,\n",
      "       0.0016978 , 0.00179925, 0.00176501, 0.00179982, 0.00185206,\n",
      "       0.00180075, 0.0017813 , 0.00180013, 0.00183482, 0.00170002,\n",
      "       0.0017606 , 0.00173855, 0.00186315, 0.00189188, 0.00180016,\n",
      "       0.00185447, 0.00170002, 0.00180047, 0.00195086, 0.00179965,\n",
      "       0.00180185, 0.00179994, 0.00175252, 0.00179989, 0.00165157,\n",
      "       0.00179985, 0.00170035, 0.0018887 , 0.00169981, 0.0017997 ,\n",
      "       0.00190017, 0.00176272, 0.00170107, 0.00199802, 0.00190008,\n",
      "       0.00190001, 0.00160015, 0.00171671, 0.00190034, 0.00159969,\n",
      "       0.00204155, 0.00179963, 0.00185158, 0.00179963, 0.00179987,\n",
      "       0.00169983, 0.0020504 , 0.00207057, 0.00190022, 0.00200019,\n",
      "       0.00190008, 0.00200016, 0.00186009, 0.00170012, 0.00189991,\n",
      "       0.00189991, 0.001969  , 0.00170052, 0.00170031, 0.0016    ,\n",
      "       0.00180054, 0.00190027, 0.00207257, 0.00196745, 0.00190012,\n",
      "       0.00200052, 0.00196879, 0.00200152, 0.00190134, 0.00185249,\n",
      "       0.00189927, 0.00190074, 0.00189829, 0.00199993, 0.00196593,\n",
      "       0.00182471, 0.00180061, 0.00200062, 0.00217524, 0.00207067,\n",
      "       0.00220056, 0.00199955, 0.00210059, 0.00209923, 0.00190067,\n",
      "       0.00200031, 0.00190017, 0.0020014 , 0.00196056, 0.01226425,\n",
      "       0.00180984, 0.00182238, 0.00170066, 0.0017632 , 0.00200467,\n",
      "       0.002143  , 0.00190377, 0.00193088, 0.0019999 , 0.00187731,\n",
      "       0.00200057, 0.00225229, 0.00240319, 0.00199964, 0.00200078,\n",
      "       0.00189989, 0.00190015, 0.00180025, 0.00179992, 0.0018003 ,\n",
      "       0.00219951, 0.00219958, 0.00220048, 0.00200071, 0.00199859,\n",
      "       0.00199945, 0.00200043, 0.00200002, 0.00189681, 0.00190043,\n",
      "       0.00199821, 0.00190022, 0.00190027, 0.00190008, 0.00179927,\n",
      "       0.00160029, 0.0022011 , 0.00219922, 0.00199804, 0.00180016,\n",
      "       0.00200012, 0.00200028, 0.00210016, 0.00190008, 0.00199983,\n",
      "       0.00189896, 0.0019016 , 0.00179985, 0.00180035, 0.00160012,\n",
      "       0.00190053, 0.00175734, 0.00215397, 0.00209932, 0.00200069,\n",
      "       0.00189891, 0.00200014, 0.00230041, 0.00200253, 0.00199976,\n",
      "       0.00199945, 0.0019999 , 0.0017987 , 0.00200009, 0.00180037,\n",
      "       0.00180221, 0.00180018, 0.00170012, 0.00219972, 0.00200078,\n",
      "       0.00200176, 0.00200155, 0.00200019, 0.00209973, 0.00190032,\n",
      "       0.00189922, 0.0020005 , 0.00190191, 0.00200002, 0.00190032,\n",
      "       0.00179961, 0.00180008, 0.00179837, 0.00179853, 0.00260003,\n",
      "       0.00209882, 0.00229979, 0.00200031, 0.00230024, 0.00219965,\n",
      "       0.00210059, 0.00190027, 0.0018002 , 0.002     , 0.00200019,\n",
      "       0.00200167, 0.0015985 , 0.00179768, 0.00180023, 0.00190191]), 'std_fit_time': array([2.21164558e-06, 4.00529206e-04, 4.30648845e-04, 3.08620856e-06,\n",
      "       2.29378004e-06, 1.09017333e-04, 1.52872320e-04, 4.90047802e-04,\n",
      "       1.42554805e-04, 6.00273123e-04, 4.57954926e-04, 3.93948766e-04,\n",
      "       4.02260732e-04, 5.39677473e-04, 1.49089337e-04, 3.00925187e-04,\n",
      "       1.64767766e-06, 4.89546175e-04, 9.95665217e-07, 2.02891135e-04,\n",
      "       4.17582393e-04, 4.90738347e-04, 7.65281636e-05, 9.50390407e-07,\n",
      "       2.23770793e-06, 1.52696111e-04, 4.87178457e-04, 2.33552874e-06,\n",
      "       3.99568297e-04, 4.58951742e-04, 3.99523385e-04, 4.92179146e-04,\n",
      "       4.59043916e-04, 4.89710429e-04, 4.48638136e-04, 4.91697222e-04,\n",
      "       3.98746537e-04, 4.90481940e-04, 4.88491988e-04, 4.60704237e-04,\n",
      "       4.08809713e-04, 1.52470993e-04, 4.90373028e-04, 4.00174633e-04,\n",
      "       4.91680177e-04, 4.73166670e-04, 4.99395824e-04, 4.04249457e-04,\n",
      "       4.99014098e-04, 4.71380945e-04, 4.90201971e-04, 4.77446989e-04,\n",
      "       4.74912240e-04, 4.62564423e-04, 4.68431292e-04, 4.88519611e-04,\n",
      "       4.77168233e-04, 4.57766221e-04, 3.93257136e-04, 5.38960827e-04,\n",
      "       4.87606484e-04, 5.00656400e-04, 4.76859891e-04, 4.89132542e-04,\n",
      "       4.89904901e-04, 5.02337582e-04, 4.73114200e-04, 5.35635595e-04,\n",
      "       4.72136252e-04, 4.90126384e-04, 4.78014199e-04, 4.91081475e-04,\n",
      "       5.01899539e-04, 4.58505672e-04, 4.85491259e-04, 4.89815515e-04,\n",
      "       4.99537015e-04, 4.90220905e-04, 4.94352709e-04, 5.01133899e-04,\n",
      "       4.72531949e-04, 5.00137982e-04, 4.90556291e-04, 4.89981539e-04,\n",
      "       4.58479553e-04, 4.81173789e-04, 3.94380740e-04, 4.90509445e-04,\n",
      "       4.89672033e-04, 4.57884063e-04, 4.89805953e-04, 4.99395084e-04,\n",
      "       4.90079872e-04, 5.13860691e-04, 4.55348279e-04, 4.55486390e-04,\n",
      "       3.98802566e-04, 4.00476320e-04, 4.47365641e-04, 5.45833446e-04,\n",
      "       4.53032003e-04, 4.57665798e-04, 4.88853210e-04, 4.90644527e-04,\n",
      "       4.88786620e-04, 4.60343177e-04, 5.32361810e-04, 4.99131849e-04,\n",
      "       5.63573858e-04, 5.32743605e-04, 4.89073289e-04, 4.90888169e-04,\n",
      "       4.57935006e-04, 4.57577594e-04, 3.27250014e-04, 4.61512161e-04,\n",
      "       4.58823596e-04, 3.94867544e-04, 4.48112486e-04, 4.58899562e-04,\n",
      "       5.13900432e-04, 4.90126674e-04, 4.59036709e-04, 5.07640590e-04,\n",
      "       5.01278337e-04, 2.99734771e-04, 3.99638659e-04, 3.99478141e-04,\n",
      "       3.99763243e-04, 4.58577248e-04, 4.56989553e-04, 4.01774685e-04,\n",
      "       3.94549426e-04, 4.00308273e-04, 3.16889549e-04, 4.00609247e-04,\n",
      "       3.94289508e-04, 4.00104382e-04, 4.35109959e-04, 4.58528756e-04,\n",
      "       3.97877754e-04, 4.96544525e-04, 3.06507632e-04, 3.24498100e-04,\n",
      "       4.00054628e-04, 3.20758822e-04, 4.58474578e-04, 3.99258960e-04,\n",
      "       1.47073434e-04, 3.98687353e-04, 3.97227466e-04, 3.99233391e-04,\n",
      "       4.03570097e-04, 4.00226062e-04, 4.48677425e-04, 3.99900648e-04,\n",
      "       4.58539053e-04, 2.98286394e-04, 4.58281954e-04, 4.02163343e-04,\n",
      "       3.00081706e-04, 5.21019249e-04, 4.58539797e-04, 1.53173502e-04,\n",
      "       3.00052529e-04, 2.99004576e-04, 4.90466716e-04, 4.72149170e-04,\n",
      "       3.00060371e-04, 4.89708560e-04, 1.23045676e-04, 3.99555080e-04,\n",
      "       3.17368793e-04, 3.99852904e-04, 3.99911769e-04, 4.58349648e-04,\n",
      "       1.50212598e-04, 3.21076561e-04, 3.00257253e-04, 6.67572021e-07,\n",
      "       2.99970696e-04, 1.43467773e-06, 3.11654485e-04, 4.57964319e-04,\n",
      "       2.99923158e-04, 3.00161034e-04, 1.99166188e-04, 4.58909754e-04,\n",
      "       4.57829731e-04, 4.89960128e-04, 3.98220212e-04, 3.00119145e-04,\n",
      "       3.20879664e-04, 9.92015816e-05, 3.00152895e-04, 1.71859944e-06,\n",
      "       5.87356159e-04, 5.36627208e-06, 3.00030222e-04, 3.19545253e-04,\n",
      "       2.99554182e-04, 3.00281666e-04, 2.99645965e-04, 2.84118530e-06,\n",
      "       3.77072924e-04, 4.19110177e-04, 3.98687809e-04, 4.47504176e-04,\n",
      "       3.55707292e-04, 4.96103921e-04, 3.99736756e-04, 1.47376628e-06,\n",
      "       2.99342597e-04, 3.00354344e-04, 3.00518670e-04, 6.81264142e-06,\n",
      "       3.00244209e-04, 5.31865842e-06, 3.60950623e-04, 3.11285673e-02,\n",
      "       4.04068063e-04, 4.16218769e-04, 4.57494707e-04, 3.99906601e-04,\n",
      "       9.16954260e-06, 3.11644570e-04, 3.01337449e-04, 3.24414068e-04,\n",
      "       4.47789951e-04, 3.38502951e-04, 4.47881723e-04, 4.05149270e-04,\n",
      "       4.38451042e-04, 4.46969974e-04, 2.17065681e-06, 3.00066638e-04,\n",
      "       2.99915482e-04, 4.00102418e-04, 3.99757125e-04, 3.99902618e-04,\n",
      "       4.00498425e-04, 3.99930662e-04, 3.99591776e-04, 2.23198504e-06,\n",
      "       3.75772187e-06, 1.45825660e-06, 1.61773638e-06, 8.12374355e-07,\n",
      "       2.98861085e-04, 2.99613505e-04, 4.74141368e-06, 3.00019264e-04,\n",
      "       3.00034868e-04, 2.99891230e-04, 3.99502228e-04, 4.89706857e-04,\n",
      "       3.98744984e-04, 4.00342150e-04, 6.51995263e-06, 3.99875925e-04,\n",
      "       5.88367590e-07, 1.63033686e-06, 3.00194405e-04, 3.00129964e-04,\n",
      "       8.08165133e-07, 2.99645620e-04, 2.95336389e-04, 3.99735642e-04,\n",
      "       3.99912536e-04, 4.89814004e-04, 3.00244620e-04, 4.03663761e-04,\n",
      "       3.29436457e-04, 3.00232723e-04, 1.30696011e-06, 2.99603264e-04,\n",
      "       1.51841005e-06, 4.57540115e-04, 3.85589998e-06, 1.58579723e-06,\n",
      "       3.57953559e-06, 8.90805325e-07, 3.99353882e-04, 6.57274664e-07,\n",
      "       3.99685279e-04, 4.01011800e-04, 3.99768444e-04, 4.58276429e-04,\n",
      "       3.99141984e-04, 2.02992104e-06, 4.03765929e-06, 6.43681595e-06,\n",
      "       2.86102295e-07, 2.99384317e-04, 3.00288446e-04, 2.99536496e-04,\n",
      "       5.74682750e-07, 3.00612036e-04, 9.89077974e-07, 3.00129377e-04,\n",
      "       3.99843488e-04, 4.00078530e-04, 3.99146076e-04, 3.98198331e-04,\n",
      "       4.89472217e-04, 3.00524258e-04, 4.58523906e-04, 3.44677741e-07,\n",
      "       4.54456751e-04, 3.99649850e-04, 2.99415754e-04, 3.00113766e-04,\n",
      "       4.00138011e-04, 1.00701867e-06, 4.90933902e-07, 2.55052168e-06,\n",
      "       4.88745284e-04, 3.98876948e-04, 4.00149914e-04, 3.00702011e-04]), 'mean_score_time': array([1.00069046e-03, 2.00200081e-04, 7.00521469e-04, 9.00793076e-04,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.00216675e-04,\n",
      "       1.99770927e-04, 4.99534607e-04, 4.99343872e-04, 3.00121307e-04,\n",
      "       3.50570679e-04, 5.01227379e-04, 7.00402260e-04, 2.02012062e-04,\n",
      "       9.99808311e-04, 0.00000000e+00, 6.00433350e-04, 3.01098824e-04,\n",
      "       6.00886345e-04, 2.99906731e-04, 7.62867928e-04, 3.99613380e-04,\n",
      "       4.18710709e-04, 9.96828079e-05, 3.50785255e-04, 9.99307632e-04,\n",
      "       1.99842453e-04, 0.00000000e+00, 2.00653076e-04, 0.00000000e+00,\n",
      "       4.00018692e-04, 4.99987602e-04, 4.01020050e-04, 9.96589661e-05,\n",
      "       5.00464439e-04, 2.00295448e-04, 4.50420380e-04, 3.00908089e-04,\n",
      "       5.00082970e-04, 2.99859047e-04, 2.99811363e-04, 6.00004196e-04,\n",
      "       3.00574303e-04, 1.99604034e-04, 3.99708748e-04, 3.08251381e-04,\n",
      "       1.99842453e-04, 3.72719765e-04, 3.99422646e-04, 2.00724602e-04,\n",
      "       3.99684906e-04, 3.99327278e-04, 4.00233269e-04, 4.00567055e-04,\n",
      "       2.99811363e-04, 4.99272346e-04, 4.00757790e-04, 5.10072708e-04,\n",
      "       5.08093834e-04, 4.00447845e-04, 3.00478935e-04, 5.08022308e-04,\n",
      "       4.16970253e-04, 4.99987602e-04, 4.28462029e-04, 3.99971008e-04,\n",
      "       3.00812721e-04, 2.99811363e-04, 4.99892235e-04, 2.99906731e-04,\n",
      "       3.99279594e-04, 2.99930573e-04, 3.01003456e-04, 4.00638580e-04,\n",
      "       2.00176239e-04, 4.51159477e-04, 4.00018692e-04, 3.99947166e-04,\n",
      "       4.99725342e-04, 4.00567055e-04, 4.00161743e-04, 3.99923325e-04,\n",
      "       2.99978256e-04, 4.51040268e-04, 4.01234627e-04, 5.00321388e-04,\n",
      "       3.00288200e-04, 2.99263000e-04, 4.00209427e-04, 5.00059128e-04,\n",
      "       3.99851799e-04, 2.99954414e-04, 3.00049782e-04, 2.99715996e-04,\n",
      "       4.00042534e-04, 2.00128555e-04, 5.26642799e-04, 4.82559204e-04,\n",
      "       3.00359726e-04, 4.01139259e-04, 5.00035286e-04, 3.99780273e-04,\n",
      "       6.25920296e-04, 3.50284576e-04, 4.50563431e-04, 5.00369072e-04,\n",
      "       2.99811363e-04, 4.00662422e-04, 5.18226624e-04, 4.00090218e-04,\n",
      "       4.00137901e-04, 3.00383568e-04, 1.50370598e-04, 3.99971008e-04,\n",
      "       3.99994850e-04, 4.00662422e-04, 5.00392914e-04, 4.00066376e-04,\n",
      "       5.67293167e-04, 3.99994850e-04, 2.99978256e-04, 5.50937653e-04,\n",
      "       5.00249863e-04, 1.00088120e-04, 3.99804115e-04, 3.00121307e-04,\n",
      "       3.00598145e-04, 4.00876999e-04, 5.00273705e-04, 2.99572945e-04,\n",
      "       3.00765038e-04, 3.99827957e-04, 2.99787521e-04, 3.00669670e-04,\n",
      "       4.00757790e-04, 3.99875641e-04, 3.50284576e-04, 4.00352478e-04,\n",
      "       1.99937820e-04, 3.00002098e-04, 4.00876999e-04, 1.50370598e-04,\n",
      "       3.99923325e-04, 3.50999832e-04, 5.00321388e-04, 2.00414658e-04,\n",
      "       2.99978256e-04, 4.00400162e-04, 3.98612022e-04, 4.00042534e-04,\n",
      "       2.98690796e-04, 3.99971008e-04, 2.99882889e-04, 3.00216675e-04,\n",
      "       3.99827957e-04, 2.00033188e-04, 2.99930573e-04, 2.99477577e-04,\n",
      "       4.99868393e-04, 3.50403786e-04, 4.00137901e-04, 2.99811363e-04,\n",
      "       3.99732590e-04, 3.24130058e-04, 4.00042534e-04, 4.50348854e-04,\n",
      "       3.00192833e-04, 6.00481033e-04, 3.50999832e-04, 3.99756432e-04,\n",
      "       9.99927521e-05, 3.00168991e-04, 5.00178337e-04, 4.00114059e-04,\n",
      "       1.99866295e-04, 2.00128555e-04, 5.99884987e-04, 3.99780273e-04,\n",
      "       4.00042534e-04, 1.99604034e-04, 4.99773026e-04, 3.99875641e-04,\n",
      "       2.99978256e-04, 3.00431252e-04, 3.50570679e-04, 3.99947166e-04,\n",
      "       3.99827957e-04, 5.25856018e-04, 2.99763680e-04, 2.99954414e-04,\n",
      "       3.00335884e-04, 3.99661064e-04, 3.00455093e-04, 2.99572945e-04,\n",
      "       4.99939919e-04, 2.98309326e-04, 3.99279594e-04, 3.98731232e-04,\n",
      "       3.99923325e-04, 3.00359726e-04, 5.01513481e-04, 4.99701500e-04,\n",
      "       3.00097466e-04, 4.51064110e-04, 5.99431992e-04, 5.00226021e-04,\n",
      "       6.00028038e-04, 9.99927521e-05, 3.00192833e-04, 3.99732590e-04,\n",
      "       2.99739838e-04, 8.00251961e-04, 4.98914719e-04, 1.99866295e-04,\n",
      "       2.99501419e-04, 3.98588181e-04, 3.50141525e-04, 5.00345230e-04,\n",
      "       4.50944901e-04, 3.00145149e-04, 5.99503517e-04, 3.50356102e-04,\n",
      "       5.96785545e-04, 2.99739838e-04, 4.99463081e-04, 4.00757790e-04,\n",
      "       2.99835205e-04, 2.15911865e-04, 4.00567055e-04, 1.99866295e-04,\n",
      "       2.51078606e-04, 2.99787521e-04, 2.00009346e-04, 3.99804115e-04,\n",
      "       3.99804115e-04, 4.99749184e-04, 3.99899483e-04, 3.99804115e-04,\n",
      "       1.99508667e-04, 0.00000000e+00, 2.99572945e-04, 2.99906731e-04,\n",
      "       4.99796867e-04, 2.99763680e-04, 3.99708748e-04, 1.99818611e-04,\n",
      "       4.00662422e-04, 4.99606133e-04, 3.01384926e-04, 2.99835205e-04,\n",
      "       2.99930573e-04, 2.99811363e-04, 2.99882889e-04, 3.99708748e-04,\n",
      "       7.98511505e-04, 0.00000000e+00, 2.99763680e-04, 4.99749184e-04,\n",
      "       4.99749184e-04, 3.99208069e-04, 1.99604034e-04, 2.99787521e-04,\n",
      "       1.99866295e-04, 5.01441956e-04, 4.98461723e-04, 3.99661064e-04,\n",
      "       2.99787521e-04, 4.99773026e-04, 5.00965118e-04, 2.50649452e-04,\n",
      "       0.00000000e+00, 0.00000000e+00, 3.99184227e-04, 4.01067734e-04,\n",
      "       9.96828079e-05, 4.99486923e-04, 4.98342514e-04, 2.99692154e-04,\n",
      "       4.99510765e-04, 1.99842453e-04, 4.99653816e-04, 1.99770927e-04,\n",
      "       3.99637222e-04, 2.99811363e-04, 4.99773026e-04, 4.99892235e-04,\n",
      "       0.00000000e+00, 0.00000000e+00, 3.99565697e-04, 1.99913979e-04,\n",
      "       2.99835205e-04, 3.99589539e-04, 4.99701500e-04, 5.00845909e-04,\n",
      "       4.99534607e-04, 3.99708748e-04, 1.99842453e-04, 5.99765778e-04,\n",
      "       2.99882889e-04, 4.99939919e-04, 4.01687622e-04, 5.01036644e-04,\n",
      "       1.99651718e-04, 0.00000000e+00, 5.99575043e-04, 2.99811363e-04,\n",
      "       4.99677658e-04, 1.99890137e-04, 4.99749184e-04, 2.99739838e-04,\n",
      "       4.99773026e-04, 3.99732590e-04, 2.99763680e-04, 3.99136543e-04,\n",
      "       6.01029396e-04, 4.01115417e-04, 2.99882889e-04, 2.99787521e-04]), 'std_score_time': array([2.67794058e-06, 4.00400449e-04, 4.58600610e-04, 3.00274619e-04,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.58590657e-04,\n",
      "       3.99542029e-04, 4.99536855e-04, 4.99345641e-04, 4.58443514e-04,\n",
      "       4.50118153e-04, 5.01240144e-04, 4.58524415e-04, 4.04055867e-04,\n",
      "       1.82277202e-06, 0.00000000e+00, 4.90253779e-04, 4.59937846e-04,\n",
      "       4.90624285e-04, 4.58115135e-04, 4.12056135e-04, 4.89424965e-04,\n",
      "       5.15394806e-04, 2.99048424e-04, 4.50636937e-04, 2.27486810e-06,\n",
      "       3.99684920e-04, 0.00000000e+00, 4.01308546e-04, 0.00000000e+00,\n",
      "       4.89921381e-04, 4.99988687e-04, 4.91149854e-04, 2.98976898e-04,\n",
      "       5.00468385e-04, 4.00592773e-04, 4.71815318e-04, 4.59648148e-04,\n",
      "       5.00083470e-04, 4.58042686e-04, 4.57969501e-04, 4.89901905e-04,\n",
      "       4.59138810e-04, 3.99208767e-04, 4.89544773e-04, 4.71354646e-04,\n",
      "       3.99685134e-04, 4.62435548e-04, 4.89191864e-04, 4.01449490e-04,\n",
      "       4.89514977e-04, 4.89075121e-04, 4.90183903e-04, 4.90597398e-04,\n",
      "       4.57969501e-04, 4.99275140e-04, 4.90830800e-04, 5.10946315e-04,\n",
      "       5.08637745e-04, 4.90446735e-04, 4.58991248e-04, 5.08498414e-04,\n",
      "       5.12920096e-04, 4.99987618e-04, 5.30137363e-04, 4.89862824e-04,\n",
      "       4.59500275e-04, 4.57969488e-04, 4.99892253e-04, 4.58115185e-04,\n",
      "       4.89019383e-04, 4.58151596e-04, 4.59800874e-04, 4.90680684e-04,\n",
      "       4.00352535e-04, 4.72578403e-04, 4.89920859e-04, 4.89833245e-04,\n",
      "       4.99725808e-04, 4.90593713e-04, 4.90096077e-04, 4.89804116e-04,\n",
      "       4.58224368e-04, 4.72464345e-04, 4.91413734e-04, 5.00323127e-04,\n",
      "       4.58701450e-04, 4.57134818e-04, 4.90154890e-04, 5.00062486e-04,\n",
      "       4.89716874e-04, 4.58188189e-04, 4.58333811e-04, 4.57869315e-04,\n",
      "       4.89951415e-04, 4.00257167e-04, 5.31693632e-04, 5.16674009e-04,\n",
      "       4.58808117e-04, 4.91303275e-04, 5.00042295e-04, 4.89628921e-04,\n",
      "       5.16179220e-04, 4.49992793e-04, 4.71831715e-04, 5.00371714e-04,\n",
      "       4.57969488e-04, 4.90711325e-04, 5.20738262e-04, 4.90008586e-04,\n",
      "       4.90067380e-04, 4.58847708e-04, 3.20257589e-04, 4.89863149e-04,\n",
      "       4.89891947e-04, 4.90710653e-04, 5.00395715e-04, 4.89979903e-04,\n",
      "       4.90332141e-04, 4.89892133e-04, 4.58224554e-04, 4.72195346e-04,\n",
      "       5.00249983e-04, 3.00264359e-04, 4.89659228e-04, 4.58443068e-04,\n",
      "       4.59176417e-04, 4.90976245e-04, 5.00274586e-04, 4.57606230e-04,\n",
      "       4.59430279e-04, 4.89687629e-04, 4.57933268e-04, 4.59287195e-04,\n",
      "       4.90827859e-04, 4.89745710e-04, 4.49992793e-04, 4.90330769e-04,\n",
      "       3.99875641e-04, 4.58260791e-04, 4.90977473e-04, 3.20588726e-04,\n",
      "       4.89804058e-04, 4.50974308e-04, 5.00326183e-04, 4.00831031e-04,\n",
      "       4.58224442e-04, 4.90389951e-04, 4.88213590e-04, 4.89950638e-04,\n",
      "       4.56272690e-04, 4.89862441e-04, 4.58085012e-04, 4.58589256e-04,\n",
      "       4.89687826e-04, 4.00066376e-04, 4.58151546e-04, 4.57460686e-04,\n",
      "       4.99868432e-04, 4.50164812e-04, 4.90067404e-04, 4.57969476e-04,\n",
      "       4.89571293e-04, 4.99109684e-04, 4.89950058e-04, 4.71706702e-04,\n",
      "       4.58552139e-04, 4.90292388e-04, 4.51081737e-04, 4.89599829e-04,\n",
      "       2.99978256e-04, 4.58516208e-04, 5.00178614e-04, 4.90037671e-04,\n",
      "       3.99734470e-04, 4.00257167e-04, 4.89804235e-04, 4.89628898e-04,\n",
      "       4.89950127e-04, 3.99208197e-04, 4.99777514e-04, 4.89745722e-04,\n",
      "       4.58224554e-04, 4.58918080e-04, 4.50406384e-04, 4.89833257e-04,\n",
      "       4.89687815e-04, 5.30850113e-04, 4.57898980e-04, 4.58187965e-04,\n",
      "       4.58773020e-04, 4.89484178e-04, 4.58954388e-04, 4.57605695e-04,\n",
      "       4.99942038e-04, 4.55694561e-04, 4.89016756e-04, 4.88362725e-04,\n",
      "       4.89808689e-04, 4.58807758e-04, 5.01542020e-04, 4.99702346e-04,\n",
      "       4.58407124e-04, 4.72468540e-04, 4.89435817e-04, 5.00226480e-04,\n",
      "       4.89931629e-04, 2.99978256e-04, 4.58556007e-04, 4.89570608e-04,\n",
      "       4.57861771e-04, 4.00126562e-04, 4.98916387e-04, 3.99732764e-04,\n",
      "       4.57496426e-04, 4.88193241e-04, 4.49629416e-04, 5.00345405e-04,\n",
      "       4.71803155e-04, 4.58479590e-04, 4.89498999e-04, 4.49807940e-04,\n",
      "       4.87311402e-04, 4.57860467e-04, 4.99463564e-04, 4.90831194e-04,\n",
      "       4.58005928e-04, 4.33298494e-04, 4.90593713e-04, 3.99732593e-04,\n",
      "       4.03632563e-04, 4.57933119e-04, 4.00018696e-04, 4.89658079e-04,\n",
      "       4.89658114e-04, 4.99749245e-04, 4.89774857e-04, 4.89658056e-04,\n",
      "       3.99017334e-04, 0.00000000e+00, 4.57605447e-04, 4.58115111e-04,\n",
      "       4.99796874e-04, 4.57896696e-04, 4.89541255e-04, 3.99637397e-04,\n",
      "       4.90715205e-04, 4.99606212e-04, 4.60393036e-04, 4.58005891e-04,\n",
      "       4.58151645e-04, 4.57969426e-04, 4.58078683e-04, 4.89541255e-04,\n",
      "       3.99256393e-04, 0.00000000e+00, 4.57896671e-04, 4.99749245e-04,\n",
      "       4.99749268e-04, 4.88928326e-04, 3.99208581e-04, 4.57933020e-04,\n",
      "       3.99732679e-04, 5.01465495e-04, 4.98484184e-04, 4.89482878e-04,\n",
      "       4.57933032e-04, 4.99773192e-04, 5.00983393e-04, 4.03356973e-04,\n",
      "       0.00000000e+00, 0.00000000e+00, 4.88899211e-04, 4.91216510e-04,\n",
      "       2.99048424e-04, 4.99487060e-04, 4.98351737e-04, 4.57787364e-04,\n",
      "       4.99510986e-04, 3.99684920e-04, 4.99653914e-04, 3.99541858e-04,\n",
      "       4.89453702e-04, 4.57969451e-04, 4.99773055e-04, 4.99892264e-04,\n",
      "       0.00000000e+00, 0.00000000e+00, 4.89366112e-04, 3.99827989e-04,\n",
      "       4.58005854e-04, 4.89395296e-04, 4.99701550e-04, 5.00852499e-04,\n",
      "       4.99534682e-04, 4.89541290e-04, 3.99684906e-04, 4.89706831e-04,\n",
      "       4.58078708e-04, 4.99941253e-04, 4.91995438e-04, 5.01060990e-04,\n",
      "       3.99303493e-04, 0.00000000e+00, 4.89551201e-04, 4.57969451e-04,\n",
      "       4.99677710e-04, 3.99780273e-04, 4.99749200e-04, 4.57860169e-04,\n",
      "       4.99773044e-04, 4.89570608e-04, 4.57896621e-04, 4.88842776e-04,\n",
      "       4.90749378e-04, 4.91301712e-04, 4.58078683e-04, 4.57933020e-04]), 'param_classifier__max_depth': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
      "                   2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3,\n",
      "                   3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4,\n",
      "                   4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "                   6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "                   7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "                   8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
      "                   11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
      "                   12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13,\n",
      "                   13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14,\n",
      "                   14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15,\n",
      "                   15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16,\n",
      "                   16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "                   17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "                   17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
      "                   18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
      "                   19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "                   20, 20, 20, 20, 20, 20, 20, 20],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_classifier__min_samples_leaf': masked_array(data=[1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1,\n",
      "                   1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1,\n",
      "                   1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1,\n",
      "                   1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1,\n",
      "                   2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2,\n",
      "                   2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2,\n",
      "                   2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2,\n",
      "                   2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "                   5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5,\n",
      "                   5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5,\n",
      "                   5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5,\n",
      "                   5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5,\n",
      "                   10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10,\n",
      "                   10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10,\n",
      "                   10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10,\n",
      "                   10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10,\n",
      "                   1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1,\n",
      "                   1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1,\n",
      "                   1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_classifier__min_samples_split': masked_array(data=[2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'classifier__max_depth': 1, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}], 'split0_test_score': array([0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.74213836, 0.74213836, 0.74213836, 0.74213836,\n",
      "       0.74213836, 0.74213836, 0.74213836, 0.74213836, 0.74213836,\n",
      "       0.74213836, 0.74213836, 0.74213836, 0.74213836, 0.74213836,\n",
      "       0.74213836, 0.74213836, 0.83018868, 0.83018868, 0.83018868,\n",
      "       0.82389937, 0.83018868, 0.83018868, 0.83018868, 0.82389937,\n",
      "       0.82389937, 0.82389937, 0.83018868, 0.82389937, 0.82389937,\n",
      "       0.82389937, 0.82389937, 0.82389937, 0.83018868, 0.82389937,\n",
      "       0.82389937, 0.81761006, 0.82389937, 0.83018868, 0.83018868,\n",
      "       0.79874214, 0.81761006, 0.80503145, 0.83018868, 0.82389937,\n",
      "       0.81132075, 0.81132075, 0.83018868, 0.82389937, 0.79874214,\n",
      "       0.77358491, 0.81761006, 0.80503145, 0.79245283, 0.79874214,\n",
      "       0.81132075, 0.79245283, 0.82389937, 0.81761006, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.77987421, 0.81132075, 0.79874214,\n",
      "       0.81761006, 0.77987421, 0.78616352, 0.80503145, 0.78616352,\n",
      "       0.77987421, 0.81761006, 0.79874214, 0.79874214, 0.81132075,\n",
      "       0.80503145, 0.78616352, 0.77358491, 0.80503145, 0.80503145,\n",
      "       0.78616352, 0.76100629, 0.75471698, 0.77987421, 0.76100629,\n",
      "       0.77987421, 0.78616352, 0.79245283, 0.76100629, 0.81132075,\n",
      "       0.79245283, 0.81132075, 0.72955975, 0.77987421, 0.77358491,\n",
      "       0.80503145, 0.74213836, 0.7672956 , 0.77987421, 0.79874214,\n",
      "       0.77987421, 0.77358491, 0.79874214, 0.77358491, 0.79874214,\n",
      "       0.7672956 , 0.76100629, 0.80503145, 0.74842767, 0.79874214,\n",
      "       0.78616352, 0.7672956 , 0.79874214, 0.77987421, 0.77358491,\n",
      "       0.74842767, 0.7672956 , 0.7672956 , 0.71698113, 0.77358491,\n",
      "       0.75471698, 0.80503145, 0.75471698, 0.77987421, 0.77358491,\n",
      "       0.77987421, 0.79245283, 0.74842767, 0.7672956 , 0.73584906,\n",
      "       0.76100629, 0.74213836, 0.72955975, 0.74842767, 0.7672956 ,\n",
      "       0.7672956 , 0.75471698, 0.7672956 , 0.73584906, 0.75471698,\n",
      "       0.79245283, 0.72955975, 0.79245283, 0.77358491, 0.75471698,\n",
      "       0.79874214, 0.74213836, 0.73584906, 0.72955975, 0.72955975,\n",
      "       0.75471698, 0.74842767, 0.7672956 , 0.73584906, 0.77358491,\n",
      "       0.76100629, 0.77358491, 0.78616352, 0.72955975, 0.73584906,\n",
      "       0.79245283, 0.73584906, 0.71069182, 0.71069182, 0.71069182,\n",
      "       0.71698113, 0.70440252, 0.71698113, 0.74842767, 0.78616352,\n",
      "       0.72955975, 0.7672956 , 0.72955975, 0.75471698, 0.74213836,\n",
      "       0.75471698, 0.78616352, 0.73584906, 0.72955975, 0.71698113,\n",
      "       0.72955975, 0.70440252, 0.6918239 , 0.71069182, 0.76100629,\n",
      "       0.72327044, 0.77358491, 0.72955975, 0.74213836, 0.79874214,\n",
      "       0.77358491, 0.81132075, 0.7672956 , 0.72955975, 0.68553459,\n",
      "       0.71698113, 0.7672956 , 0.71698113, 0.78616352, 0.73584906,\n",
      "       0.77358491, 0.75471698, 0.7672956 , 0.75471698, 0.71698113,\n",
      "       0.74842767, 0.79874214, 0.7672956 , 0.73584906, 0.69811321,\n",
      "       0.73584906, 0.74213836, 0.73584906, 0.72327044, 0.74213836,\n",
      "       0.7672956 , 0.71698113, 0.76100629, 0.76100629, 0.74213836,\n",
      "       0.74213836, 0.77987421, 0.76100629, 0.72955975, 0.77358491,\n",
      "       0.73584906, 0.70440252, 0.71069182, 0.71698113, 0.72327044,\n",
      "       0.73584906, 0.70440252, 0.74213836, 0.69811321, 0.72327044,\n",
      "       0.79245283, 0.77987421, 0.74213836, 0.77987421, 0.74842767,\n",
      "       0.79874214, 0.72955975, 0.71069182, 0.70440252, 0.74842767,\n",
      "       0.69811321, 0.71069182, 0.73584906, 0.76100629, 0.72955975,\n",
      "       0.72327044, 0.77358491, 0.71069182, 0.77987421, 0.71069182,\n",
      "       0.79874214, 0.76100629, 0.66037736, 0.72327044, 0.74213836,\n",
      "       0.72955975, 0.74213836, 0.71069182, 0.76100629, 0.67295597,\n",
      "       0.7672956 , 0.71698113, 0.67924528, 0.73584906, 0.73584906,\n",
      "       0.75471698, 0.76100629, 0.74213836, 0.74213836, 0.75471698,\n",
      "       0.72955975, 0.71069182, 0.74213836, 0.71069182, 0.75471698,\n",
      "       0.72955975, 0.74213836, 0.72955975, 0.74842767, 0.73584906,\n",
      "       0.77358491, 0.75471698, 0.76100629, 0.76100629, 0.66666667,\n",
      "       0.74213836, 0.73584906, 0.74842767, 0.71069182, 0.71698113,\n",
      "       0.71698113, 0.76100629, 0.72327044, 0.73584906, 0.75471698,\n",
      "       0.77358491, 0.7672956 , 0.73584906, 0.7672956 , 0.7672956 ]), 'split1_test_score': array([0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.88679245, 0.88679245, 0.88679245,\n",
      "       0.88050314, 0.88679245, 0.88679245, 0.88679245, 0.88050314,\n",
      "       0.88679245, 0.88679245, 0.88679245, 0.88050314, 0.88050314,\n",
      "       0.88050314, 0.88050314, 0.88050314, 0.88050314, 0.86792453,\n",
      "       0.86792453, 0.88050314, 0.88679245, 0.88679245, 0.88679245,\n",
      "       0.88050314, 0.86163522, 0.88050314, 0.86792453, 0.88050314,\n",
      "       0.88050314, 0.88050314, 0.88050314, 0.88050314, 0.86163522,\n",
      "       0.86163522, 0.86163522, 0.86163522, 0.86163522, 0.87421384,\n",
      "       0.86163522, 0.8490566 , 0.86792453, 0.86792453, 0.88050314,\n",
      "       0.86792453, 0.82389937, 0.88050314, 0.86163522, 0.88050314,\n",
      "       0.8490566 , 0.88050314, 0.82389937, 0.86163522, 0.86163522,\n",
      "       0.81132075, 0.86792453, 0.88679245, 0.82389937, 0.85534591,\n",
      "       0.8427673 , 0.87421384, 0.85534591, 0.85534591, 0.8427673 ,\n",
      "       0.87421384, 0.81132075, 0.82389937, 0.86163522, 0.85534591,\n",
      "       0.85534591, 0.8490566 , 0.83018868, 0.85534591, 0.88679245,\n",
      "       0.86792453, 0.8427673 , 0.83018868, 0.82389937, 0.86163522,\n",
      "       0.8427673 , 0.8427673 , 0.7672956 , 0.8427673 , 0.82389937,\n",
      "       0.81761006, 0.77358491, 0.86792453, 0.8427673 , 0.81761006,\n",
      "       0.79874214, 0.87421384, 0.79245283, 0.85534591, 0.87421384,\n",
      "       0.80503145, 0.82389937, 0.8427673 , 0.78616352, 0.76100629,\n",
      "       0.83018868, 0.78616352, 0.79245283, 0.85534591, 0.80503145,\n",
      "       0.79874214, 0.83647799, 0.79874214, 0.79874214, 0.81761006,\n",
      "       0.80503145, 0.8490566 , 0.86792453, 0.79874214, 0.78616352,\n",
      "       0.80503145, 0.82389937, 0.76100629, 0.74842767, 0.82389937,\n",
      "       0.79874214, 0.75471698, 0.81132075, 0.86163522, 0.82389937,\n",
      "       0.81132075, 0.83647799, 0.78616352, 0.83647799, 0.78616352,\n",
      "       0.77358491, 0.79245283, 0.73584906, 0.82389937, 0.81132075,\n",
      "       0.79874214, 0.80503145, 0.76100629, 0.79874214, 0.79874214,\n",
      "       0.81761006, 0.82389937, 0.85534591, 0.85534591, 0.81761006,\n",
      "       0.79245283, 0.79245283, 0.81132075, 0.6918239 , 0.74842767,\n",
      "       0.77987421, 0.7672956 , 0.72955975, 0.83647799, 0.77987421,\n",
      "       0.77358491, 0.79245283, 0.81761006, 0.8427673 , 0.79874214,\n",
      "       0.81132075, 0.80503145, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77987421, 0.75471698, 0.77987421,\n",
      "       0.80503145, 0.81132075, 0.82389937, 0.83018868, 0.77358491,\n",
      "       0.7672956 , 0.80503145, 0.79874214, 0.7672956 , 0.7672956 ,\n",
      "       0.78616352, 0.79874214, 0.81132075, 0.76100629, 0.76100629,\n",
      "       0.76100629, 0.77987421, 0.81132075, 0.76100629, 0.77987421,\n",
      "       0.80503145, 0.81761006, 0.8490566 , 0.79245283, 0.75471698,\n",
      "       0.74842767, 0.78616352, 0.79874214, 0.76100629, 0.73584906,\n",
      "       0.7672956 , 0.74213836, 0.7672956 , 0.80503145, 0.79245283,\n",
      "       0.80503145, 0.81761006, 0.82389937, 0.82389937, 0.81132075,\n",
      "       0.76100629, 0.74213836, 0.76100629, 0.72955975, 0.79874214,\n",
      "       0.78616352, 0.7672956 , 0.77987421, 0.82389937, 0.77987421,\n",
      "       0.79874214, 0.77987421, 0.77987421, 0.74842767, 0.82389937,\n",
      "       0.85534591, 0.74842767, 0.72955975, 0.7672956 , 0.80503145,\n",
      "       0.79245283, 0.77358491, 0.74842767, 0.74842767, 0.79245283,\n",
      "       0.79874214, 0.77358491, 0.81761006, 0.81761006, 0.83018868,\n",
      "       0.85534591, 0.79245283, 0.73584906, 0.72955975, 0.77358491,\n",
      "       0.81761006, 0.77987421, 0.76100629, 0.8427673 , 0.77358491,\n",
      "       0.81132075, 0.74842767, 0.78616352, 0.75471698, 0.80503145,\n",
      "       0.81132075, 0.82389937, 0.80503145, 0.74213836, 0.72327044,\n",
      "       0.81132075, 0.85534591, 0.72327044, 0.78616352, 0.78616352,\n",
      "       0.73584906, 0.79874214, 0.76100629, 0.79874214, 0.76100629,\n",
      "       0.80503145, 0.77987421, 0.83018868, 0.83647799, 0.73584906,\n",
      "       0.73584906, 0.77358491, 0.80503145, 0.78616352, 0.75471698,\n",
      "       0.73584906, 0.79874214, 0.73584906, 0.76100629, 0.81132075,\n",
      "       0.77358491, 0.80503145, 0.78616352, 0.7672956 , 0.79874214]), 'split2_test_score': array([0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.71698113, 0.71698113, 0.71698113, 0.71698113,\n",
      "       0.71069182, 0.71698113, 0.71698113, 0.71698113, 0.71698113,\n",
      "       0.71698113, 0.66037736, 0.71698113, 0.71698113, 0.71069182,\n",
      "       0.71698113, 0.71069182, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.80503145, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.80503145, 0.81132075, 0.81132075, 0.80503145,\n",
      "       0.80503145, 0.79874214, 0.81132075, 0.81761006, 0.79245283,\n",
      "       0.80503145, 0.79874214, 0.79874214, 0.79245283, 0.81132075,\n",
      "       0.80503145, 0.80503145, 0.81132075, 0.80503145, 0.79874214,\n",
      "       0.81132075, 0.79874214, 0.7672956 , 0.79245283, 0.77987421,\n",
      "       0.77358491, 0.77358491, 0.79245283, 0.76100629, 0.76100629,\n",
      "       0.79874214, 0.78616352, 0.78616352, 0.78616352, 0.79245283,\n",
      "       0.79245283, 0.81761006, 0.77987421, 0.81132075, 0.74842767,\n",
      "       0.79874214, 0.7672956 , 0.77358491, 0.77987421, 0.77358491,\n",
      "       0.79874214, 0.76100629, 0.74842767, 0.78616352, 0.76100629,\n",
      "       0.76100629, 0.77358491, 0.76100629, 0.77358491, 0.78616352,\n",
      "       0.77987421, 0.75471698, 0.76100629, 0.77987421, 0.77987421,\n",
      "       0.73584906, 0.77358491, 0.79245283, 0.71698113, 0.7672956 ,\n",
      "       0.7672956 , 0.77358491, 0.7672956 , 0.75471698, 0.73584906,\n",
      "       0.7672956 , 0.74213836, 0.74213836, 0.7672956 , 0.7672956 ,\n",
      "       0.77987421, 0.77358491, 0.7672956 , 0.68553459, 0.74213836,\n",
      "       0.74213836, 0.74213836, 0.76100629, 0.74842767, 0.7672956 ,\n",
      "       0.72955975, 0.73584906, 0.74842767, 0.7672956 , 0.72955975,\n",
      "       0.74842767, 0.71698113, 0.76100629, 0.73584906, 0.75471698,\n",
      "       0.73584906, 0.73584906, 0.74213836, 0.7672956 , 0.7672956 ,\n",
      "       0.76100629, 0.72327044, 0.75471698, 0.74842767, 0.68553459,\n",
      "       0.71069182, 0.7672956 , 0.73584906, 0.74213836, 0.73584906,\n",
      "       0.72327044, 0.77987421, 0.70440252, 0.7672956 , 0.76100629,\n",
      "       0.77358491, 0.75471698, 0.7672956 , 0.7672956 , 0.71698113,\n",
      "       0.66666667, 0.74842767, 0.73584906, 0.72955975, 0.75471698,\n",
      "       0.72327044, 0.73584906, 0.73584906, 0.73584906, 0.74842767,\n",
      "       0.75471698, 0.74842767, 0.76100629, 0.71698113, 0.70440252,\n",
      "       0.76100629, 0.73584906, 0.74213836, 0.71698113, 0.6918239 ,\n",
      "       0.72327044, 0.76100629, 0.7672956 , 0.6918239 , 0.74842767,\n",
      "       0.74213836, 0.75471698, 0.77358491, 0.75471698, 0.70440252,\n",
      "       0.72955975, 0.75471698, 0.75471698, 0.71698113, 0.73584906,\n",
      "       0.74842767, 0.71069182, 0.74842767, 0.71069182, 0.72327044,\n",
      "       0.77358491, 0.74842767, 0.75471698, 0.75471698, 0.76100629,\n",
      "       0.71069182, 0.66666667, 0.73584906, 0.72327044, 0.71069182,\n",
      "       0.6918239 , 0.74842767, 0.74842767, 0.72327044, 0.74213836,\n",
      "       0.74213836, 0.72327044, 0.73584906, 0.72327044, 0.72327044,\n",
      "       0.75471698, 0.68553459, 0.72327044, 0.72955975, 0.70440252,\n",
      "       0.6918239 , 0.72955975, 0.7672956 , 0.71698113, 0.75471698,\n",
      "       0.73584906, 0.72955975, 0.71069182, 0.7672956 , 0.72955975,\n",
      "       0.74842767, 0.71069182, 0.72955975, 0.72327044, 0.76100629,\n",
      "       0.69811321, 0.67924528, 0.72327044, 0.74213836, 0.74842767,\n",
      "       0.71698113, 0.74213836, 0.71069182, 0.76100629, 0.75471698,\n",
      "       0.7672956 , 0.73584906, 0.72327044, 0.72327044, 0.72955975,\n",
      "       0.73584906, 0.73584906, 0.75471698, 0.76100629, 0.71069182,\n",
      "       0.72327044, 0.73584906, 0.7672956 , 0.71069182, 0.7672956 ,\n",
      "       0.72955975, 0.75471698, 0.7672956 , 0.74213836, 0.74213836,\n",
      "       0.72955975, 0.74842767, 0.72955975, 0.71698113, 0.73584906,\n",
      "       0.74213836, 0.70440252, 0.71069182, 0.69811321, 0.74842767,\n",
      "       0.71069182, 0.78616352, 0.72955975, 0.75471698, 0.68553459,\n",
      "       0.73584906, 0.68553459, 0.75471698, 0.73584906, 0.74213836,\n",
      "       0.70440252, 0.74213836, 0.72327044, 0.70440252, 0.72955975,\n",
      "       0.71698113, 0.7672956 , 0.75471698, 0.77987421, 0.77358491]), 'split3_test_score': array([0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.71069182, 0.71069182, 0.71069182, 0.71069182,\n",
      "       0.71069182, 0.71069182, 0.71069182, 0.71069182, 0.71069182,\n",
      "       0.71069182, 0.71069182, 0.71069182, 0.71069182, 0.71069182,\n",
      "       0.71069182, 0.71069182, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.79874214, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.79874214, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.7672956 , 0.80503145, 0.79874214, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.79874214, 0.81132075,\n",
      "       0.79245283, 0.79245283, 0.77358491, 0.80503145, 0.80503145,\n",
      "       0.81132075, 0.77987421, 0.78616352, 0.80503145, 0.80503145,\n",
      "       0.74842767, 0.78616352, 0.80503145, 0.77987421, 0.79874214,\n",
      "       0.80503145, 0.78616352, 0.78616352, 0.80503145, 0.80503145,\n",
      "       0.79874214, 0.79245283, 0.79874214, 0.77358491, 0.76100629,\n",
      "       0.76100629, 0.77987421, 0.79245283, 0.77987421, 0.7672956 ,\n",
      "       0.78616352, 0.79245283, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.77987421, 0.79245283, 0.79245283, 0.7672956 , 0.76100629,\n",
      "       0.79874214, 0.81132075, 0.79874214, 0.79874214, 0.77987421,\n",
      "       0.78616352, 0.80503145, 0.77358491, 0.80503145, 0.77987421,\n",
      "       0.77358491, 0.77987421, 0.79245283, 0.7672956 , 0.7672956 ,\n",
      "       0.79874214, 0.76100629, 0.76100629, 0.80503145, 0.79874214,\n",
      "       0.7672956 , 0.72327044, 0.81132075, 0.76100629, 0.79874214,\n",
      "       0.75471698, 0.76100629, 0.77358491, 0.74842767, 0.77987421,\n",
      "       0.77358491, 0.72955975, 0.74213836, 0.78616352, 0.74213836,\n",
      "       0.76100629, 0.7672956 , 0.7672956 , 0.73584906, 0.75471698,\n",
      "       0.74842767, 0.75471698, 0.74213836, 0.73584906, 0.76100629,\n",
      "       0.79874214, 0.77358491, 0.77987421, 0.77987421, 0.79245283,\n",
      "       0.77358491, 0.79245283, 0.77358491, 0.75471698, 0.76100629,\n",
      "       0.76100629, 0.75471698, 0.7672956 , 0.77987421, 0.77987421,\n",
      "       0.7672956 , 0.7672956 , 0.78616352, 0.74842767, 0.75471698,\n",
      "       0.82389937, 0.76100629, 0.74842767, 0.77987421, 0.74842767,\n",
      "       0.76100629, 0.76100629, 0.72327044, 0.74842767, 0.77358491,\n",
      "       0.79245283, 0.74213836, 0.77358491, 0.77987421, 0.79245283,\n",
      "       0.7672956 , 0.74842767, 0.72955975, 0.74213836, 0.75471698,\n",
      "       0.76100629, 0.75471698, 0.76100629, 0.73584906, 0.74213836,\n",
      "       0.79874214, 0.77987421, 0.7672956 , 0.75471698, 0.7672956 ,\n",
      "       0.75471698, 0.81132075, 0.74842767, 0.73584906, 0.79245283,\n",
      "       0.70440252, 0.75471698, 0.77987421, 0.82389937, 0.72955975,\n",
      "       0.74213836, 0.74842767, 0.71698113, 0.77987421, 0.74213836,\n",
      "       0.8427673 , 0.72327044, 0.73584906, 0.7672956 , 0.73584906,\n",
      "       0.74213836, 0.75471698, 0.7672956 , 0.74842767, 0.74842767,\n",
      "       0.79245283, 0.79874214, 0.7672956 , 0.73584906, 0.79874214,\n",
      "       0.77987421, 0.7672956 , 0.72955975, 0.81132075, 0.77358491,\n",
      "       0.77987421, 0.74842767, 0.7672956 , 0.80503145, 0.73584906,\n",
      "       0.7672956 , 0.72955975, 0.74842767, 0.76100629, 0.74213836,\n",
      "       0.74213836, 0.71698113, 0.7672956 , 0.77358491, 0.72955975,\n",
      "       0.76100629, 0.73584906, 0.7672956 , 0.73584906, 0.77987421,\n",
      "       0.75471698, 0.72955975, 0.76100629, 0.79245283, 0.74842767,\n",
      "       0.77987421, 0.76100629, 0.72327044, 0.74842767, 0.74842767,\n",
      "       0.75471698, 0.72955975, 0.76100629, 0.75471698, 0.7672956 ,\n",
      "       0.71069182, 0.72327044, 0.72955975, 0.79874214, 0.7672956 ,\n",
      "       0.74842767, 0.76100629, 0.79245283, 0.74842767, 0.78616352,\n",
      "       0.77358491, 0.72955975, 0.76100629, 0.71698113, 0.75471698,\n",
      "       0.81761006, 0.7672956 , 0.74842767, 0.7672956 , 0.75471698,\n",
      "       0.71698113, 0.77358491, 0.76100629, 0.77987421, 0.71069182,\n",
      "       0.72955975, 0.75471698, 0.74842767, 0.77358491, 0.77987421,\n",
      "       0.73584906, 0.7672956 , 0.74213836, 0.73584906, 0.77358491,\n",
      "       0.77987421, 0.71069182, 0.77358491, 0.72955975, 0.7672956 ]), 'split4_test_score': array([0.74842767, 0.74842767, 0.74842767, 0.74842767, 0.74842767,\n",
      "       0.74842767, 0.74842767, 0.74842767, 0.74842767, 0.74842767,\n",
      "       0.74842767, 0.74842767, 0.74842767, 0.74842767, 0.74842767,\n",
      "       0.74842767, 0.72955975, 0.72955975, 0.72955975, 0.72955975,\n",
      "       0.72955975, 0.72955975, 0.72955975, 0.72955975, 0.72955975,\n",
      "       0.72955975, 0.72955975, 0.72955975, 0.72955975, 0.72955975,\n",
      "       0.72955975, 0.72955975, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79245283, 0.78616352, 0.79874214, 0.76100629,\n",
      "       0.79874214, 0.79874214, 0.78616352, 0.78616352, 0.79874214,\n",
      "       0.77987421, 0.76100629, 0.79245283, 0.77358491, 0.74842767,\n",
      "       0.77987421, 0.78616352, 0.78616352, 0.78616352, 0.77358491,\n",
      "       0.79874214, 0.78616352, 0.79874214, 0.78616352, 0.76100629,\n",
      "       0.77358491, 0.77358491, 0.76100629, 0.79245283, 0.78616352,\n",
      "       0.77987421, 0.71698113, 0.74842767, 0.76100629, 0.75471698,\n",
      "       0.76100629, 0.75471698, 0.77358491, 0.75471698, 0.78616352,\n",
      "       0.7672956 , 0.75471698, 0.77358491, 0.78616352, 0.7672956 ,\n",
      "       0.79874214, 0.78616352, 0.77358491, 0.77358491, 0.79245283,\n",
      "       0.74842767, 0.77358491, 0.74842767, 0.79245283, 0.76100629,\n",
      "       0.74213836, 0.74842767, 0.7672956 , 0.7672956 , 0.74213836,\n",
      "       0.75471698, 0.7672956 , 0.74842767, 0.72327044, 0.72955975,\n",
      "       0.75471698, 0.73584906, 0.74842767, 0.74213836, 0.73584906,\n",
      "       0.72955975, 0.75471698, 0.74213836, 0.74842767, 0.75471698,\n",
      "       0.72955975, 0.74213836, 0.78616352, 0.76100629, 0.73584906,\n",
      "       0.71698113, 0.72327044, 0.74213836, 0.73584906, 0.71069182,\n",
      "       0.77987421, 0.7672956 , 0.71698113, 0.74213836, 0.73584906,\n",
      "       0.7672956 , 0.72955975, 0.74842767, 0.75471698, 0.71698113,\n",
      "       0.71698113, 0.6918239 , 0.78616352, 0.71698113, 0.72955975,\n",
      "       0.72327044, 0.71698113, 0.72955975, 0.71069182, 0.70440252,\n",
      "       0.77358491, 0.75471698, 0.74213836, 0.74842767, 0.71698113,\n",
      "       0.72327044, 0.69811321, 0.71069182, 0.74213836, 0.70440252,\n",
      "       0.72955975, 0.74213836, 0.70440252, 0.68553459, 0.73584906,\n",
      "       0.73584906, 0.73584906, 0.72955975, 0.75471698, 0.74213836,\n",
      "       0.75471698, 0.71069182, 0.72955975, 0.71698113, 0.71698113,\n",
      "       0.67924528, 0.71069182, 0.69811321, 0.71698113, 0.72327044,\n",
      "       0.77987421, 0.71069182, 0.72955975, 0.72327044, 0.7672956 ,\n",
      "       0.72955975, 0.76100629, 0.74842767, 0.71698113, 0.68553459,\n",
      "       0.6918239 , 0.67924528, 0.74213836, 0.68553459, 0.74842767,\n",
      "       0.73584906, 0.70440252, 0.68553459, 0.70440252, 0.74842767,\n",
      "       0.72327044, 0.76100629, 0.72955975, 0.69811321, 0.65408805,\n",
      "       0.6918239 , 0.74213836, 0.72955975, 0.67295597, 0.74213836,\n",
      "       0.70440252, 0.71698113, 0.71698113, 0.71698113, 0.77358491,\n",
      "       0.72327044, 0.72327044, 0.75471698, 0.74213836, 0.67924528,\n",
      "       0.72327044, 0.65408805, 0.69811321, 0.71698113, 0.71069182,\n",
      "       0.72955975, 0.68553459, 0.71069182, 0.70440252, 0.69811321,\n",
      "       0.71698113, 0.69811321, 0.69811321, 0.7672956 , 0.72955975,\n",
      "       0.72327044, 0.72327044, 0.68553459, 0.71698113, 0.72327044,\n",
      "       0.74842767, 0.71069182, 0.67924528, 0.74213836, 0.74213836,\n",
      "       0.73584906, 0.71698113, 0.6918239 , 0.72327044, 0.71069182,\n",
      "       0.71069182, 0.73584906, 0.66666667, 0.6918239 , 0.71698113,\n",
      "       0.72955975, 0.74842767, 0.66037736, 0.73584906, 0.72955975,\n",
      "       0.71698113, 0.72327044, 0.71698113, 0.71069182, 0.74213836,\n",
      "       0.70440252, 0.70440252, 0.6918239 , 0.71698113, 0.6918239 ,\n",
      "       0.71069182, 0.66666667, 0.71698113, 0.69811321, 0.72955975,\n",
      "       0.73584906, 0.72955975, 0.71698113, 0.70440252, 0.74842767,\n",
      "       0.71069182, 0.70440252, 0.78616352, 0.70440252, 0.72955975,\n",
      "       0.67924528, 0.6918239 , 0.72955975, 0.71698113, 0.71069182,\n",
      "       0.67295597, 0.69811321, 0.6918239 , 0.71069182, 0.70440252,\n",
      "       0.73584906, 0.72955975, 0.70440252, 0.71698113, 0.72955975,\n",
      "       0.70440252, 0.71698113, 0.71069182, 0.71069182, 0.70440252,\n",
      "       0.70440252, 0.73584906, 0.71069182, 0.66666667, 0.74213836,\n",
      "       0.7672956 , 0.67924528, 0.69811321, 0.74842767, 0.67924528]), 'split5_test_score': array([0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 ,\n",
      "       0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 ,\n",
      "       0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 ,\n",
      "       0.7672956 , 0.71698113, 0.71698113, 0.71698113, 0.71698113,\n",
      "       0.71698113, 0.71698113, 0.71698113, 0.71698113, 0.71698113,\n",
      "       0.71698113, 0.71698113, 0.71698113, 0.71698113, 0.71698113,\n",
      "       0.71698113, 0.71698113, 0.82389937, 0.82389937, 0.82389937,\n",
      "       0.81761006, 0.82389937, 0.82389937, 0.82389937, 0.81761006,\n",
      "       0.82389937, 0.81761006, 0.82389937, 0.81761006, 0.81132075,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.80503145, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.82389937, 0.80503145, 0.81132075,\n",
      "       0.81761006, 0.81132075, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.80503145, 0.83018868, 0.78616352, 0.79245283, 0.81132075,\n",
      "       0.80503145, 0.80503145, 0.81761006, 0.79874214, 0.81132075,\n",
      "       0.79245283, 0.81132075, 0.79874214, 0.81761006, 0.81761006,\n",
      "       0.75471698, 0.81761006, 0.80503145, 0.80503145, 0.74842767,\n",
      "       0.77987421, 0.80503145, 0.77987421, 0.7672956 , 0.81761006,\n",
      "       0.82389937, 0.79245283, 0.80503145, 0.82389937, 0.79245283,\n",
      "       0.79874214, 0.82389937, 0.81761006, 0.78616352, 0.77987421,\n",
      "       0.77987421, 0.77358491, 0.74213836, 0.72327044, 0.80503145,\n",
      "       0.77358491, 0.71698113, 0.79245283, 0.78616352, 0.79874214,\n",
      "       0.80503145, 0.81761006, 0.80503145, 0.79874214, 0.72955975,\n",
      "       0.71698113, 0.78616352, 0.74213836, 0.74213836, 0.79245283,\n",
      "       0.76100629, 0.83018868, 0.74842767, 0.76100629, 0.74842767,\n",
      "       0.74842767, 0.74842767, 0.79874214, 0.72327044, 0.77358491,\n",
      "       0.74842767, 0.76100629, 0.72955975, 0.7672956 , 0.74213836,\n",
      "       0.76100629, 0.74842767, 0.76100629, 0.77987421, 0.7672956 ,\n",
      "       0.77358491, 0.77358491, 0.74842767, 0.78616352, 0.72327044,\n",
      "       0.72327044, 0.76100629, 0.72327044, 0.7672956 , 0.77987421,\n",
      "       0.72955975, 0.77358491, 0.74213836, 0.74842767, 0.6918239 ,\n",
      "       0.75471698, 0.72327044, 0.80503145, 0.77358491, 0.81132075,\n",
      "       0.71069182, 0.72327044, 0.79874214, 0.70440252, 0.74842767,\n",
      "       0.7672956 , 0.72955975, 0.73584906, 0.77987421, 0.74842767,\n",
      "       0.73584906, 0.74842767, 0.77987421, 0.74213836, 0.74842767,\n",
      "       0.7672956 , 0.72327044, 0.74842767, 0.7672956 , 0.76100629,\n",
      "       0.68553459, 0.73584906, 0.72955975, 0.74842767, 0.77358491,\n",
      "       0.74213836, 0.72955975, 0.77987421, 0.79874214, 0.76100629,\n",
      "       0.73584906, 0.74842767, 0.67295597, 0.70440252, 0.6918239 ,\n",
      "       0.72955975, 0.70440252, 0.72955975, 0.69811321, 0.71698113,\n",
      "       0.71069182, 0.75471698, 0.72327044, 0.67295597, 0.78616352,\n",
      "       0.72327044, 0.74842767, 0.79245283, 0.70440252, 0.74213836,\n",
      "       0.72955975, 0.73584906, 0.69811321, 0.69811321, 0.77987421,\n",
      "       0.73584906, 0.74213836, 0.72955975, 0.72955975, 0.67924528,\n",
      "       0.77987421, 0.79874214, 0.75471698, 0.72327044, 0.6918239 ,\n",
      "       0.71069182, 0.70440252, 0.77987421, 0.71698113, 0.76100629,\n",
      "       0.70440252, 0.73584906, 0.69811321, 0.72955975, 0.74213836,\n",
      "       0.76100629, 0.74842767, 0.74842767, 0.72327044, 0.73584906,\n",
      "       0.64150943, 0.6918239 , 0.68553459, 0.7672956 , 0.71698113,\n",
      "       0.67295597, 0.73584906, 0.69811321, 0.70440252, 0.72327044,\n",
      "       0.74213836, 0.7672956 , 0.80503145, 0.7672956 , 0.72955975,\n",
      "       0.76100629, 0.68553459, 0.6918239 , 0.68553459, 0.71698113,\n",
      "       0.71069182, 0.71069182, 0.66037736, 0.7672956 , 0.71698113,\n",
      "       0.71698113, 0.71069182, 0.74842767, 0.74842767, 0.76100629,\n",
      "       0.79245283, 0.73584906, 0.67924528, 0.67924528, 0.70440252,\n",
      "       0.74213836, 0.71069182, 0.72327044, 0.69811321, 0.66666667,\n",
      "       0.72955975, 0.76100629, 0.71069182, 0.75471698, 0.72327044,\n",
      "       0.77987421, 0.7672956 , 0.7672956 , 0.67295597, 0.71069182,\n",
      "       0.72327044, 0.71698113, 0.71069182, 0.69811321, 0.73584906,\n",
      "       0.72327044, 0.76100629, 0.72955975, 0.71698113, 0.70440252,\n",
      "       0.77987421, 0.74213836, 0.7672956 , 0.77987421, 0.70440252,\n",
      "       0.73584906, 0.71069182, 0.77987421, 0.76100629, 0.71069182,\n",
      "       0.71069182, 0.71698113, 0.71069182, 0.72955975, 0.70440252,\n",
      "       0.73584906, 0.73584906, 0.79874214, 0.72327044, 0.77358491]), 'split6_test_score': array([0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.77987421, 0.77987421, 0.77987421, 0.77987421,\n",
      "       0.77987421, 0.77987421, 0.77987421, 0.77987421, 0.77987421,\n",
      "       0.77987421, 0.63522013, 0.63522013, 0.77987421, 0.77987421,\n",
      "       0.77987421, 0.77987421, 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8490566 ,\n",
      "       0.81761006, 0.82389937, 0.77987421, 0.81761006, 0.81761006,\n",
      "       0.83647799, 0.8427673 , 0.8427673 , 0.8490566 , 0.83647799,\n",
      "       0.79245283, 0.8490566 , 0.79874214, 0.8427673 , 0.83647799,\n",
      "       0.83647799, 0.79874214, 0.81132075, 0.83647799, 0.79874214,\n",
      "       0.83647799, 0.83018868, 0.81761006, 0.77987421, 0.83018868,\n",
      "       0.79874214, 0.81132075, 0.83647799, 0.83647799, 0.81761006,\n",
      "       0.83018868, 0.72955975, 0.8427673 , 0.81761006, 0.80503145,\n",
      "       0.81132075, 0.76100629, 0.83018868, 0.81132075, 0.8490566 ,\n",
      "       0.8490566 , 0.81761006, 0.78616352, 0.81761006, 0.83018868,\n",
      "       0.77987421, 0.8490566 , 0.80503145, 0.78616352, 0.83647799,\n",
      "       0.83018868, 0.77987421, 0.77987421, 0.79874214, 0.81761006,\n",
      "       0.81761006, 0.80503145, 0.7672956 , 0.7672956 , 0.77987421,\n",
      "       0.82389937, 0.78616352, 0.78616352, 0.78616352, 0.77358491,\n",
      "       0.77987421, 0.7672956 , 0.76100629, 0.77358491, 0.77358491,\n",
      "       0.79874214, 0.80503145, 0.80503145, 0.83647799, 0.76100629,\n",
      "       0.81761006, 0.81132075, 0.74213836, 0.77987421, 0.76100629,\n",
      "       0.7672956 , 0.76100629, 0.72955975, 0.73584906, 0.80503145,\n",
      "       0.81132075, 0.80503145, 0.7672956 , 0.74842767, 0.74842767,\n",
      "       0.79874214, 0.81132075, 0.79874214, 0.76100629, 0.74213836,\n",
      "       0.77358491, 0.77358491, 0.72327044, 0.73584906, 0.73584906,\n",
      "       0.74213836, 0.74213836, 0.74842767, 0.77987421, 0.81132075,\n",
      "       0.77987421, 0.77358491, 0.74842767, 0.77358491, 0.83647799,\n",
      "       0.74842767, 0.71698113, 0.72955975, 0.75471698, 0.74842767,\n",
      "       0.7672956 , 0.7672956 , 0.77358491, 0.68553459, 0.74842767,\n",
      "       0.72955975, 0.79245283, 0.72327044, 0.79245283, 0.7672956 ,\n",
      "       0.7672956 , 0.79245283, 0.74213836, 0.7672956 , 0.75471698,\n",
      "       0.73584906, 0.74842767, 0.72327044, 0.73584906, 0.72955975,\n",
      "       0.73584906, 0.73584906, 0.79874214, 0.74213836, 0.80503145,\n",
      "       0.76100629, 0.77358491, 0.79874214, 0.74213836, 0.74213836,\n",
      "       0.79245283, 0.7672956 , 0.74213836, 0.73584906, 0.79245283,\n",
      "       0.77987421, 0.77987421, 0.7672956 , 0.71698113, 0.81132075,\n",
      "       0.82389937, 0.82389937, 0.82389937, 0.81761006, 0.74842767,\n",
      "       0.73584906, 0.67924528, 0.77987421, 0.75471698, 0.74213836,\n",
      "       0.74213836, 0.71698113, 0.72327044, 0.73584906, 0.71698113,\n",
      "       0.74842767, 0.81761006, 0.81132075, 0.7672956 , 0.79245283,\n",
      "       0.71698113, 0.72955975, 0.7672956 , 0.70440252, 0.72955975,\n",
      "       0.78616352, 0.74213836, 0.72327044, 0.71698113, 0.74213836,\n",
      "       0.74842767, 0.79874214, 0.77987421, 0.79245283, 0.75471698,\n",
      "       0.7672956 , 0.70440252, 0.74213836, 0.71069182, 0.76100629,\n",
      "       0.76100629, 0.76100629, 0.7672956 , 0.74213836, 0.74213836,\n",
      "       0.76100629, 0.73584906, 0.73584906, 0.81132075, 0.77358491,\n",
      "       0.79874214, 0.7672956 , 0.73584906, 0.67924528, 0.71698113,\n",
      "       0.77358491, 0.77987421, 0.72955975, 0.73584906, 0.77987421,\n",
      "       0.75471698, 0.72327044, 0.7672956 , 0.73584906, 0.7672956 ,\n",
      "       0.71069182, 0.77358491, 0.77358491, 0.70440252, 0.77987421,\n",
      "       0.7672956 , 0.72327044, 0.74213836, 0.77358491, 0.70440252,\n",
      "       0.77358491, 0.72955975, 0.70440252, 0.70440252, 0.74213836,\n",
      "       0.7672956 , 0.74213836, 0.77358491, 0.80503145, 0.72955975,\n",
      "       0.69811321, 0.71698113, 0.76100629, 0.74213836, 0.79245283,\n",
      "       0.72955975, 0.75471698, 0.71698113, 0.72955975, 0.77358491,\n",
      "       0.74213836, 0.79245283, 0.74213836, 0.7672956 , 0.79874214]), 'split7_test_score': array([0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77987421, 0.77358491, 0.77358491, 0.77987421, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.81761006, 0.81132075, 0.82389937,\n",
      "       0.81132075, 0.82389937, 0.82389937, 0.82389937, 0.81132075,\n",
      "       0.82389937, 0.82389937, 0.82389937, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81761006, 0.78616352,\n",
      "       0.82389937, 0.82389937, 0.81761006, 0.81761006, 0.82389937,\n",
      "       0.81132075, 0.82389937, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.74842767,\n",
      "       0.75471698, 0.75471698, 0.77987421, 0.82389937, 0.74213836,\n",
      "       0.74842767, 0.79245283, 0.80503145, 0.82389937, 0.71698113,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.81132075,\n",
      "       0.80503145, 0.77358491, 0.79874214, 0.78616352, 0.74213836,\n",
      "       0.81132075, 0.80503145, 0.80503145, 0.74842767, 0.81761006,\n",
      "       0.80503145, 0.76100629, 0.78616352, 0.79874214, 0.77987421,\n",
      "       0.80503145, 0.78616352, 0.7672956 , 0.78616352, 0.77987421,\n",
      "       0.7672956 , 0.77987421, 0.79245283, 0.79874214, 0.78616352,\n",
      "       0.79874214, 0.79245283, 0.75471698, 0.77358491, 0.78616352,\n",
      "       0.72955975, 0.7672956 , 0.78616352, 0.74842767, 0.79245283,\n",
      "       0.79874214, 0.73584906, 0.72955975, 0.80503145, 0.76100629,\n",
      "       0.73584906, 0.79245283, 0.81132075, 0.7672956 , 0.79874214,\n",
      "       0.79874214, 0.78616352, 0.68553459, 0.76100629, 0.74842767,\n",
      "       0.78616352, 0.71069182, 0.71069182, 0.77987421, 0.74213836,\n",
      "       0.7672956 , 0.80503145, 0.76100629, 0.74213836, 0.71069182,\n",
      "       0.76100629, 0.72327044, 0.77987421, 0.76100629, 0.73584906,\n",
      "       0.76100629, 0.77358491, 0.76100629, 0.77987421, 0.74213836,\n",
      "       0.79245283, 0.78616352, 0.74213836, 0.76100629, 0.73584906,\n",
      "       0.77987421, 0.72955975, 0.76100629, 0.7672956 , 0.73584906,\n",
      "       0.74213836, 0.68553459, 0.71698113, 0.74842767, 0.77358491,\n",
      "       0.6918239 , 0.77358491, 0.72327044, 0.73584906, 0.77358491,\n",
      "       0.79874214, 0.74213836, 0.73584906, 0.7672956 , 0.7672956 ,\n",
      "       0.72327044, 0.75471698, 0.74213836, 0.73584906, 0.6918239 ,\n",
      "       0.78616352, 0.79874214, 0.71698113, 0.7672956 , 0.77358491,\n",
      "       0.77987421, 0.74213836, 0.73584906, 0.76100629, 0.74213836,\n",
      "       0.69811321, 0.73584906, 0.72955975, 0.72327044, 0.74842767,\n",
      "       0.74842767, 0.7672956 , 0.71069182, 0.74842767, 0.74842767,\n",
      "       0.73584906, 0.74842767, 0.71698113, 0.77987421, 0.77987421,\n",
      "       0.7672956 , 0.73584906, 0.76100629, 0.6918239 , 0.68553459,\n",
      "       0.75471698, 0.71698113, 0.71698113, 0.73584906, 0.7672956 ,\n",
      "       0.73584906, 0.74842767, 0.71698113, 0.70440252, 0.77358491,\n",
      "       0.72955975, 0.78616352, 0.77358491, 0.76100629, 0.71698113,\n",
      "       0.72327044, 0.72955975, 0.72955975, 0.75471698, 0.77358491,\n",
      "       0.74213836, 0.74842767, 0.77358491, 0.72327044, 0.76100629,\n",
      "       0.71069182, 0.79874214, 0.74842767, 0.7672956 , 0.75471698,\n",
      "       0.69811321, 0.70440252, 0.7672956 , 0.75471698, 0.72327044,\n",
      "       0.76100629, 0.72327044, 0.72955975, 0.78616352, 0.7672956 ,\n",
      "       0.74842767, 0.68553459, 0.76100629, 0.72327044, 0.74213836,\n",
      "       0.75471698, 0.73584906, 0.74213836, 0.68553459, 0.76100629,\n",
      "       0.7672956 , 0.74213836, 0.71698113, 0.72955975, 0.71069182,\n",
      "       0.72327044, 0.7672956 , 0.76100629, 0.78616352, 0.75471698,\n",
      "       0.70440252, 0.78616352, 0.74213836, 0.72327044, 0.71069182,\n",
      "       0.72955975, 0.74213836, 0.71698113, 0.72955975, 0.74213836,\n",
      "       0.74842767, 0.72327044, 0.73584906, 0.75471698, 0.7672956 ,\n",
      "       0.74842767, 0.74842767, 0.72955975, 0.71698113, 0.72955975,\n",
      "       0.72327044, 0.78616352, 0.74213836, 0.74213836, 0.70440252,\n",
      "       0.66037736, 0.71698113, 0.74842767, 0.79245283, 0.72955975,\n",
      "       0.77987421, 0.73584906, 0.77358491, 0.74213836, 0.70440252,\n",
      "       0.7672956 , 0.71698113, 0.77987421, 0.72955975, 0.67295597,\n",
      "       0.70440252, 0.72327044, 0.7672956 , 0.74842767, 0.72955975,\n",
      "       0.73584906, 0.7672956 , 0.74842767, 0.71698113, 0.77358491]), 'split8_test_score': array([0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 ,\n",
      "       0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 ,\n",
      "       0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 ,\n",
      "       0.7672956 , 0.7672956 , 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.83018868, 0.8490566 ,\n",
      "       0.83018868, 0.8427673 , 0.8490566 , 0.8427673 , 0.8490566 ,\n",
      "       0.8490566 , 0.83018868, 0.83018868, 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.8427673 , 0.83018868, 0.85534591,\n",
      "       0.8427673 , 0.83647799, 0.83018868, 0.8490566 , 0.83647799,\n",
      "       0.8427673 , 0.83018868, 0.82389937, 0.83647799, 0.83018868,\n",
      "       0.82389937, 0.83018868, 0.83018868, 0.83647799, 0.82389937,\n",
      "       0.83018868, 0.81761006, 0.83018868, 0.83018868, 0.81132075,\n",
      "       0.8427673 , 0.82389937, 0.81132075, 0.83018868, 0.79245283,\n",
      "       0.83018868, 0.81132075, 0.82389937, 0.8490566 , 0.80503145,\n",
      "       0.8490566 , 0.79874214, 0.78616352, 0.83647799, 0.80503145,\n",
      "       0.8427673 , 0.8490566 , 0.83647799, 0.8427673 , 0.83647799,\n",
      "       0.83647799, 0.83647799, 0.82389937, 0.8427673 , 0.83018868,\n",
      "       0.82389937, 0.8427673 , 0.83018868, 0.81761006, 0.80503145,\n",
      "       0.79874214, 0.81132075, 0.81761006, 0.79245283, 0.83647799,\n",
      "       0.81132075, 0.82389937, 0.79874214, 0.79874214, 0.82389937,\n",
      "       0.81761006, 0.81132075, 0.81132075, 0.79245283, 0.83018868,\n",
      "       0.82389937, 0.76100629, 0.79245283, 0.83647799, 0.77987421,\n",
      "       0.80503145, 0.77358491, 0.79245283, 0.77987421, 0.83647799,\n",
      "       0.82389937, 0.81132075, 0.83647799, 0.83018868, 0.79245283,\n",
      "       0.8427673 , 0.78616352, 0.80503145, 0.80503145, 0.79874214,\n",
      "       0.81761006, 0.75471698, 0.78616352, 0.81761006, 0.81761006,\n",
      "       0.78616352, 0.79245283, 0.79245283, 0.80503145, 0.81132075,\n",
      "       0.77987421, 0.78616352, 0.78616352, 0.8427673 , 0.83018868,\n",
      "       0.81132075, 0.79245283, 0.79245283, 0.83018868, 0.81132075,\n",
      "       0.83647799, 0.77358491, 0.83647799, 0.79874214, 0.79874214,\n",
      "       0.83018868, 0.7672956 , 0.77358491, 0.78616352, 0.80503145,\n",
      "       0.80503145, 0.76100629, 0.81761006, 0.81132075, 0.79874214,\n",
      "       0.82389937, 0.78616352, 0.8490566 , 0.81132075, 0.81132075,\n",
      "       0.81761006, 0.82389937, 0.79245283, 0.78616352, 0.75471698,\n",
      "       0.79874214, 0.79874214, 0.81761006, 0.77358491, 0.79874214,\n",
      "       0.7672956 , 0.83647799, 0.79245283, 0.78616352, 0.81132075,\n",
      "       0.81761006, 0.79874214, 0.79245283, 0.74213836, 0.79245283,\n",
      "       0.78616352, 0.74213836, 0.79874214, 0.74842767, 0.76100629,\n",
      "       0.76100629, 0.79245283, 0.7672956 , 0.81132075, 0.78616352,\n",
      "       0.79874214, 0.72327044, 0.80503145, 0.7672956 , 0.78616352,\n",
      "       0.76100629, 0.77358491, 0.81132075, 0.79245283, 0.80503145,\n",
      "       0.79874214, 0.79245283, 0.79874214, 0.81761006, 0.74213836,\n",
      "       0.80503145, 0.81132075, 0.80503145, 0.7672956 , 0.80503145,\n",
      "       0.74213836, 0.77358491, 0.79874214, 0.75471698, 0.78616352,\n",
      "       0.78616352, 0.77358491, 0.75471698, 0.81761006, 0.80503145,\n",
      "       0.81132075, 0.72955975, 0.83647799, 0.82389937, 0.81132075,\n",
      "       0.83018868, 0.74213836, 0.75471698, 0.76100629, 0.76100629,\n",
      "       0.76100629, 0.78616352, 0.77358491, 0.74842767, 0.74213836,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.83018868, 0.80503145,\n",
      "       0.81761006, 0.77987421, 0.74213836, 0.7672956 , 0.79245283,\n",
      "       0.76100629, 0.79874214, 0.79874214, 0.79245283, 0.79874214,\n",
      "       0.80503145, 0.74842767, 0.79245283, 0.79245283, 0.83018868,\n",
      "       0.77987421, 0.80503145, 0.83647799, 0.72327044, 0.71069182,\n",
      "       0.78616352, 0.80503145, 0.80503145, 0.77987421, 0.74842767,\n",
      "       0.74213836, 0.77987421, 0.77987421, 0.77987421, 0.79874214,\n",
      "       0.79245283, 0.80503145, 0.82389937, 0.81761006, 0.7672956 ,\n",
      "       0.75471698, 0.68553459, 0.77358491, 0.74842767, 0.77358491,\n",
      "       0.7672956 , 0.79245283, 0.79245283, 0.74842767, 0.78616352,\n",
      "       0.75471698, 0.79245283, 0.81761006, 0.81132075, 0.78616352]), 'split9_test_score': array([0.80379747, 0.80379747, 0.80379747, 0.80379747, 0.80379747,\n",
      "       0.80379747, 0.80379747, 0.80379747, 0.80379747, 0.80379747,\n",
      "       0.80379747, 0.80379747, 0.80379747, 0.80379747, 0.80379747,\n",
      "       0.80379747, 0.74683544, 0.74683544, 0.74683544, 0.74050633,\n",
      "       0.74050633, 0.74683544, 0.74683544, 0.71518987, 0.74683544,\n",
      "       0.74683544, 0.74683544, 0.74050633, 0.74683544, 0.74683544,\n",
      "       0.74683544, 0.74683544, 0.86075949, 0.86075949, 0.86075949,\n",
      "       0.85443038, 0.84810127, 0.86075949, 0.86075949, 0.85443038,\n",
      "       0.85443038, 0.86075949, 0.85443038, 0.85443038, 0.85443038,\n",
      "       0.85443038, 0.85443038, 0.85443038, 0.86075949, 0.86075949,\n",
      "       0.86075949, 0.85443038, 0.85443038, 0.86075949, 0.86708861,\n",
      "       0.85443038, 0.85443038, 0.85443038, 0.85443038, 0.85443038,\n",
      "       0.83544304, 0.85443038, 0.85443038, 0.85443038, 0.84810127,\n",
      "       0.86075949, 0.84810127, 0.85443038, 0.85443038, 0.85443038,\n",
      "       0.84810127, 0.84177215, 0.84810127, 0.86075949, 0.84810127,\n",
      "       0.84177215, 0.85443038, 0.85443038, 0.84810127, 0.84810127,\n",
      "       0.84177215, 0.83544304, 0.85443038, 0.82911392, 0.84810127,\n",
      "       0.8164557 , 0.85443038, 0.84810127, 0.82278481, 0.82911392,\n",
      "       0.84810127, 0.84177215, 0.82278481, 0.83544304, 0.83544304,\n",
      "       0.80379747, 0.82911392, 0.86075949, 0.8164557 , 0.8164557 ,\n",
      "       0.82278481, 0.81012658, 0.80379747, 0.81012658, 0.81012658,\n",
      "       0.80379747, 0.8164557 , 0.80379747, 0.75949367, 0.82911392,\n",
      "       0.80379747, 0.8164557 , 0.74683544, 0.8164557 , 0.70886076,\n",
      "       0.80379747, 0.84177215, 0.79746835, 0.81012658, 0.79113924,\n",
      "       0.81012658, 0.75316456, 0.82278481, 0.80379747, 0.78481013,\n",
      "       0.82278481, 0.74050633, 0.8164557 , 0.82278481, 0.7721519 ,\n",
      "       0.74683544, 0.78481013, 0.82278481, 0.8164557 , 0.77848101,\n",
      "       0.79113924, 0.73417722, 0.7721519 , 0.82278481, 0.79113924,\n",
      "       0.74050633, 0.79113924, 0.79746835, 0.78481013, 0.78481013,\n",
      "       0.73417722, 0.75949367, 0.77848101, 0.74683544, 0.80379747,\n",
      "       0.74683544, 0.75949367, 0.75949367, 0.79113924, 0.7721519 ,\n",
      "       0.75316456, 0.7721519 , 0.75949367, 0.76582278, 0.75949367,\n",
      "       0.73417722, 0.80379747, 0.78481013, 0.70886076, 0.7721519 ,\n",
      "       0.72151899, 0.80379747, 0.74050633, 0.79113924, 0.75949367,\n",
      "       0.70253165, 0.7721519 , 0.78481013, 0.78481013, 0.75316456,\n",
      "       0.75316456, 0.77848101, 0.76582278, 0.77848101, 0.74683544,\n",
      "       0.74050633, 0.7721519 , 0.78481013, 0.77848101, 0.74050633,\n",
      "       0.72151899, 0.81012658, 0.7721519 , 0.79746835, 0.77848101,\n",
      "       0.81012658, 0.80379747, 0.75949367, 0.7278481 , 0.76582278,\n",
      "       0.74683544, 0.77848101, 0.80379747, 0.76582278, 0.79113924,\n",
      "       0.76582278, 0.7278481 , 0.77848101, 0.78481013, 0.73417722,\n",
      "       0.75949367, 0.79746835, 0.78481013, 0.73417722, 0.76582278,\n",
      "       0.74683544, 0.77848101, 0.75316456, 0.7721519 , 0.76582278,\n",
      "       0.74683544, 0.75949367, 0.7721519 , 0.77848101, 0.77848101,\n",
      "       0.80379747, 0.77848101, 0.7721519 , 0.8164557 , 0.74050633,\n",
      "       0.74683544, 0.75316456, 0.77848101, 0.75316456, 0.75949367,\n",
      "       0.76582278, 0.75316456, 0.73417722, 0.76582278, 0.79746835,\n",
      "       0.70886076, 0.79113924, 0.7721519 , 0.75316456, 0.79746835,\n",
      "       0.77848101, 0.76582278, 0.77848101, 0.73417722, 0.75949367,\n",
      "       0.74683544, 0.76582278, 0.73417722, 0.74683544, 0.7721519 ,\n",
      "       0.74050633, 0.71518987, 0.79113924, 0.81012658, 0.76582278,\n",
      "       0.75316456, 0.74050633, 0.74050633, 0.76582278, 0.71518987,\n",
      "       0.75316456, 0.73417722, 0.77848101, 0.74050633, 0.75949367,\n",
      "       0.76582278, 0.77848101, 0.75316456, 0.82278481, 0.73417722,\n",
      "       0.74683544, 0.74050633, 0.74050633, 0.76582278, 0.74050633,\n",
      "       0.80379747, 0.77848101, 0.75316456, 0.7278481 , 0.7278481 ,\n",
      "       0.71518987, 0.76582278, 0.70253165, 0.7721519 , 0.80379747,\n",
      "       0.75949367, 0.76582278, 0.75949367, 0.73417722, 0.74683544,\n",
      "       0.77848101, 0.77848101, 0.78481013, 0.74683544, 0.74683544,\n",
      "       0.78481013, 0.7721519 , 0.74050633, 0.76582278, 0.80379747,\n",
      "       0.7278481 , 0.78481013, 0.82911392, 0.82911392, 0.73417722,\n",
      "       0.74683544, 0.7721519 , 0.76582278, 0.77848101, 0.73417722,\n",
      "       0.75949367, 0.72151899, 0.72151899, 0.77848101, 0.73417722,\n",
      "       0.76582278, 0.78481013, 0.77848101, 0.75949367, 0.73417722]), 'mean_test_score': array([0.78478226, 0.78478226, 0.78478226, 0.78478226, 0.78478226,\n",
      "       0.78478226, 0.78478226, 0.78478226, 0.78478226, 0.78478226,\n",
      "       0.78478226, 0.78478226, 0.78478226, 0.78478226, 0.78478226,\n",
      "       0.78478226, 0.74952631, 0.74952631, 0.74952631, 0.7488934 ,\n",
      "       0.74826447, 0.74952631, 0.74952631, 0.74636175, 0.74952631,\n",
      "       0.75015524, 0.72940053, 0.73442799, 0.75015524, 0.74889738,\n",
      "       0.74952631, 0.74889738, 0.83261683, 0.8319879 , 0.83324576,\n",
      "       0.8294682 , 0.83197994, 0.83324576, 0.83324576, 0.8294682 ,\n",
      "       0.83198392, 0.8319879 , 0.83261285, 0.8294682 , 0.82883926,\n",
      "       0.8294682 , 0.8294682 , 0.8294682 , 0.82884324, 0.82632752,\n",
      "       0.82758538, 0.82883926, 0.82821033, 0.83135897, 0.82947616,\n",
      "       0.82632354, 0.82632354, 0.82506568, 0.82632354, 0.82883926,\n",
      "       0.82442481, 0.82317889, 0.82883926, 0.82506568, 0.81374094,\n",
      "       0.81060425, 0.81248308, 0.80997134, 0.8194053 , 0.81060027,\n",
      "       0.81625667, 0.81436589, 0.82317491, 0.82318287, 0.81185415,\n",
      "       0.80996338, 0.81500279, 0.80871348, 0.82191704, 0.82065918,\n",
      "       0.81373696, 0.79989651, 0.80116631, 0.81121328, 0.79361516,\n",
      "       0.79611098, 0.81185813, 0.81185415, 0.786681  , 0.80995542,\n",
      "       0.81248308, 0.80052942, 0.80491999, 0.8181355 , 0.80429902,\n",
      "       0.81371308, 0.79360322, 0.80054136, 0.80428708, 0.7904506 ,\n",
      "       0.79674389, 0.79296234, 0.79421622, 0.79547807, 0.80868561,\n",
      "       0.80490805, 0.79359526, 0.78226654, 0.79230157, 0.79989252,\n",
      "       0.78855585, 0.80114242, 0.78097285, 0.78541915, 0.77717538,\n",
      "       0.78792692, 0.78040363, 0.78414935, 0.78855983, 0.79106361,\n",
      "       0.77535228, 0.79732903, 0.78542314, 0.77723509, 0.79105963,\n",
      "       0.78730993, 0.77593743, 0.78856381, 0.77347345, 0.7671523 ,\n",
      "       0.77468354, 0.75646843, 0.76215269, 0.78541915, 0.76715628,\n",
      "       0.78037179, 0.77719131, 0.77407054, 0.77284452, 0.77345355,\n",
      "       0.77656636, 0.77848499, 0.78037577, 0.77596529, 0.75835523,\n",
      "       0.76146804, 0.75645251, 0.75646445, 0.76021814, 0.77220365,\n",
      "       0.7696521 , 0.75896824, 0.76337075, 0.76464852, 0.75583154,\n",
      "       0.77342966, 0.76400764, 0.77217578, 0.77343762, 0.76462861,\n",
      "       0.75958124, 0.75019107, 0.75269485, 0.75642067, 0.75834727,\n",
      "       0.75013932, 0.76968792, 0.74826447, 0.76339065, 0.77091792,\n",
      "       0.76522172, 0.76778123, 0.77282064, 0.77533636, 0.77405859,\n",
      "       0.77028501, 0.75017515, 0.75645649, 0.74577263, 0.74009235,\n",
      "       0.74511982, 0.75268689, 0.74514768, 0.76023804, 0.76272988,\n",
      "       0.75642863, 0.76277366, 0.75960513, 0.77660218, 0.76904307,\n",
      "       0.76717618, 0.77471937, 0.74890534, 0.74259613, 0.73884643,\n",
      "       0.74826845, 0.74388584, 0.74704641, 0.73318605, 0.7520699 ,\n",
      "       0.7463936 , 0.76083512, 0.75772232, 0.74703447, 0.77278879,\n",
      "       0.76337075, 0.77660218, 0.77659422, 0.73190829, 0.73067033,\n",
      "       0.74889738, 0.7614959 , 0.74701457, 0.73633469, 0.76337473,\n",
      "       0.7451238 , 0.75393679, 0.75771833, 0.75080408, 0.75520659,\n",
      "       0.77283258, 0.77470345, 0.77721519, 0.76906695, 0.73191227,\n",
      "       0.74386593, 0.72122841, 0.75835125, 0.74638564, 0.74764748,\n",
      "       0.74513574, 0.7394674 , 0.74826049, 0.75142505, 0.74830029,\n",
      "       0.75327601, 0.77848499, 0.7671523 , 0.7558196 , 0.77219967,\n",
      "       0.73319401, 0.72878354, 0.74074118, 0.74197118, 0.7438739 ,\n",
      "       0.74952631, 0.74010429, 0.73756866, 0.75581562, 0.75457368,\n",
      "       0.76210095, 0.7432171 , 0.76464852, 0.7696919 , 0.75582756,\n",
      "       0.7721718 , 0.72499403, 0.72750975, 0.72689674, 0.74761962,\n",
      "       0.74324098, 0.7381976 , 0.73319401, 0.74511982, 0.74513176,\n",
      "       0.74765146, 0.7533198 , 0.75141708, 0.78605207, 0.76146804,\n",
      "       0.77657034, 0.75644057, 0.71744686, 0.72563888, 0.73505692,\n",
      "       0.75585144, 0.74640156, 0.74261205, 0.7501433 , 0.73693575,\n",
      "       0.75013534, 0.73758857, 0.73880662, 0.75142903, 0.77157472,\n",
      "       0.75330786, 0.76651939, 0.77594937, 0.72310326, 0.74135021,\n",
      "       0.75017515, 0.75457766, 0.74703447, 0.73883449, 0.73820556,\n",
      "       0.73822944, 0.74702651, 0.73442799, 0.74828039, 0.74830428,\n",
      "       0.75894833, 0.76338667, 0.77536422, 0.78228246, 0.71681395,\n",
      "       0.7350609 , 0.72690072, 0.7627458 , 0.74765942, 0.7381976 ,\n",
      "       0.72689276, 0.75139718, 0.73441605, 0.73382294, 0.75392087,\n",
      "       0.7545697 , 0.76024202, 0.76338269, 0.75708144, 0.76524162]), 'std_test_score': array([0.0180514 , 0.0180514 , 0.0180514 , 0.0180514 , 0.0180514 ,\n",
      "       0.0180514 , 0.0180514 , 0.0180514 , 0.0180514 , 0.0180514 ,\n",
      "       0.0180514 , 0.0180514 , 0.0180514 , 0.0180514 , 0.0180514 ,\n",
      "       0.0180514 , 0.03117867, 0.03117867, 0.03117867, 0.0312909 ,\n",
      "       0.03198159, 0.03117867, 0.03117867, 0.03285224, 0.03117867,\n",
      "       0.03171643, 0.04970299, 0.04434019, 0.03171643, 0.03188427,\n",
      "       0.03117867, 0.03188427, 0.02601801, 0.02644567, 0.02572199,\n",
      "       0.0248189 , 0.02462491, 0.02572199, 0.02572199, 0.0248189 ,\n",
      "       0.02523901, 0.02614481, 0.02510773, 0.0248189 , 0.02518837,\n",
      "       0.0248189 , 0.0248189 , 0.0248189 , 0.0250129 , 0.02614855,\n",
      "       0.02222838, 0.02487231, 0.02832753, 0.02595288, 0.03323793,\n",
      "       0.02705717, 0.01979682, 0.02640173, 0.02508479, 0.02518837,\n",
      "       0.02670543, 0.0320344 , 0.02518837, 0.02785969, 0.03921218,\n",
      "       0.03425576, 0.03315239, 0.02837328, 0.02626941, 0.03639396,\n",
      "       0.03081382, 0.02277203, 0.02211791, 0.02793039, 0.04307732,\n",
      "       0.0263834 , 0.02374626, 0.03514506, 0.02239686, 0.02662047,\n",
      "       0.02748412, 0.04093927, 0.02949379, 0.02734229, 0.03809823,\n",
      "       0.03037041, 0.03309576, 0.03176744, 0.02887862, 0.02519907,\n",
      "       0.02283796, 0.03421767, 0.02690214, 0.02402894, 0.02207949,\n",
      "       0.02690354, 0.02893383, 0.0328863 , 0.02799692, 0.03006736,\n",
      "       0.03390423, 0.03067166, 0.03116018, 0.03632494, 0.03775055,\n",
      "       0.03524452, 0.03826853, 0.03087672, 0.02550523, 0.03524178,\n",
      "       0.0324015 , 0.03588081, 0.02595364, 0.03346114, 0.04088768,\n",
      "       0.03088013, 0.03230217, 0.03913574, 0.02916675, 0.02781238,\n",
      "       0.03231309, 0.03672718, 0.02537377, 0.03713931, 0.03478994,\n",
      "       0.03065498, 0.02647964, 0.03941453, 0.02525083, 0.02543798,\n",
      "       0.03432051, 0.02320396, 0.03170678, 0.04100408, 0.02691634,\n",
      "       0.01665724, 0.03398395, 0.02705077, 0.0412445 , 0.03660713,\n",
      "       0.02836576, 0.03819015, 0.04006256, 0.02433833, 0.02672386,\n",
      "       0.03726877, 0.03362371, 0.02566353, 0.02467459, 0.03313661,\n",
      "       0.03195682, 0.02593207, 0.02220442, 0.04341907, 0.03989478,\n",
      "       0.02332442, 0.03655723, 0.024074  , 0.02701605, 0.02928014,\n",
      "       0.02920866, 0.03931299, 0.03080225, 0.04359298, 0.0438159 ,\n",
      "       0.03637835, 0.02655229, 0.02456694, 0.03889812, 0.02692101,\n",
      "       0.04075697, 0.02374467, 0.04447381, 0.03288593, 0.03197575,\n",
      "       0.02797074, 0.02608827, 0.02863902, 0.02963671, 0.03052093,\n",
      "       0.0529506 , 0.02731638, 0.03466226, 0.04226353, 0.02213562,\n",
      "       0.03151701, 0.03088866, 0.04184372, 0.03575068, 0.02173145,\n",
      "       0.03801647, 0.02961664, 0.03119637, 0.02896564, 0.03481584,\n",
      "       0.02784805, 0.03610845, 0.03856656, 0.02783829, 0.0315574 ,\n",
      "       0.02672799, 0.03682271, 0.04080756, 0.04634385, 0.0265421 ,\n",
      "       0.02831198, 0.02477055, 0.02046647, 0.0245319 , 0.04316009,\n",
      "       0.03125782, 0.0276772 , 0.03381417, 0.03220827, 0.01990527,\n",
      "       0.02454479, 0.02503294, 0.02836523, 0.04048704, 0.0385251 ,\n",
      "       0.03345376, 0.03497725, 0.03660357, 0.03076647, 0.03241467,\n",
      "       0.03644562, 0.04244879, 0.0342717 , 0.0239913 , 0.02712012,\n",
      "       0.03009091, 0.02707107, 0.02970837, 0.03475538, 0.02860055,\n",
      "       0.03510965, 0.03941346, 0.03621632, 0.02894131, 0.03194174,\n",
      "       0.0394358 , 0.03081712, 0.03746746, 0.02967296, 0.03112117,\n",
      "       0.03803648, 0.02268823, 0.03018364, 0.0458846 , 0.02505322,\n",
      "       0.02707482, 0.03422132, 0.04117462, 0.0316925 , 0.03414847,\n",
      "       0.04129146, 0.01894735, 0.02861234, 0.03453122, 0.02696083,\n",
      "       0.03060291, 0.03033744, 0.04148874, 0.01104129, 0.02478893,\n",
      "       0.03128875, 0.02725408, 0.03400347, 0.03568326, 0.03274932,\n",
      "       0.04530206, 0.02588219, 0.02805176, 0.02877716, 0.02965925,\n",
      "       0.03235015, 0.03751487, 0.02638639, 0.04143136, 0.04220495,\n",
      "       0.03346905, 0.01639425, 0.03601154, 0.02956321, 0.03132397,\n",
      "       0.03010174, 0.03035219, 0.02933856, 0.02258906, 0.02487266,\n",
      "       0.03742333, 0.04815623, 0.02748459, 0.03014923, 0.02465277,\n",
      "       0.04514176, 0.03229869, 0.02555022, 0.03605504, 0.03197685,\n",
      "       0.03161745, 0.02443073, 0.03983436, 0.03741101, 0.0271585 ,\n",
      "       0.01987803, 0.03010172, 0.02385145, 0.02552287, 0.03583671,\n",
      "       0.0217736 , 0.02734773, 0.02521003, 0.02929157, 0.03045645,\n",
      "       0.0198001 , 0.03800622, 0.03287884, 0.02713627, 0.03355582]), 'rank_test_score': array([ 91,  91,  91,  91,  91,  91,  91,  91,  91,  91,  91,  91,  91,\n",
      "        91,  91,  91, 233, 233, 233, 245, 250, 233, 233, 265, 233, 228,\n",
      "       309, 299, 228, 242, 233, 242,   4,   6,   1,  12,   9,   1,   1,\n",
      "        12,   8,   6,   5,  12,  19,  12,  12,  12,  18,  25,  24,  19,\n",
      "        23,  10,  11,  26,  26,  29,  26,  19,  31,  33,  19,  29,  42,\n",
      "        51,  45,  53,  37,  52,  39,  41,  34,  32,  48,  54,  40,  56,\n",
      "        35,  36,  43,  66,  62,  50,  73,  70,  47,  49,  86,  55,  45,\n",
      "        65,  58,  38,  60,  44,  74,  64,  61,  80,  69,  76,  72,  71,\n",
      "        57,  59,  75, 109,  77,  67,  83,  63, 110,  89, 119,  84, 111,\n",
      "       107,  82,  78, 129,  68,  88, 116,  79,  85, 127,  81, 136, 159,\n",
      "       133, 196, 177,  90, 158, 113, 118, 134, 140, 137, 124, 114, 112,\n",
      "       125, 190, 180, 199, 197, 185, 144, 153, 188, 172, 164, 204, 139,\n",
      "       167, 146, 138, 166, 187, 225, 217, 202, 192, 231, 152, 250, 168,\n",
      "       149, 163, 156, 142, 130, 135, 150, 226, 198, 266, 284, 271, 218,\n",
      "       267, 184, 176, 201, 174, 186, 121, 155, 157, 131, 241, 279, 286,\n",
      "       249, 273, 257, 305, 219, 263, 182, 193, 258, 143, 173, 120, 122,\n",
      "       307, 308, 242, 179, 261, 296, 171, 270, 212, 194, 224, 208, 141,\n",
      "       132, 117, 154, 306, 275, 318, 191, 264, 255, 268, 285, 252, 221,\n",
      "       247, 216, 114, 159, 206, 145, 303, 310, 282, 280, 274, 233, 283,\n",
      "       294, 207, 210, 178, 277, 165, 151, 205, 147, 316, 311, 313, 256,\n",
      "       276, 291, 303, 271, 269, 254, 214, 222,  87, 181, 123, 200, 319,\n",
      "       315, 298, 203, 262, 278, 230, 295, 232, 293, 288, 220, 148, 215,\n",
      "       161, 126, 317, 281, 226, 209, 259, 287, 290, 289, 260, 299, 248,\n",
      "       246, 189, 169, 128, 108, 320, 297, 312, 175, 253, 291, 314, 223,\n",
      "       301, 302, 213, 211, 183, 170, 195, 162])}\n",
      "Resultados para SMOTEENN:\n",
      "{'mean_fit_time': array([0.01790979, 0.01825607, 0.01775088, 0.01810098, 0.01882899,\n",
      "       0.01835535, 0.01925607, 0.01724219, 0.01739447, 0.0175781 ,\n",
      "       0.01741514, 0.01761529, 0.01759944, 0.01749077, 0.01746805,\n",
      "       0.0173867 , 0.01758263, 0.01739728, 0.01740968, 0.01742241,\n",
      "       0.01760137, 0.01747165, 0.0176286 , 0.01758547, 0.01763897,\n",
      "       0.01753004, 0.01717682, 0.01746759, 0.01717651, 0.01750035,\n",
      "       0.01745813, 0.01747742, 0.0177    , 0.0174474 , 0.01749909,\n",
      "       0.01766629, 0.01769137, 0.01777728, 0.0180007 , 0.01788862,\n",
      "       0.01746137, 0.01760468, 0.01769903, 0.01764536, 0.01782856,\n",
      "       0.0173955 , 0.01782284, 0.01773713, 0.01781354, 0.01781802,\n",
      "       0.01798325, 0.01785054, 0.01767216, 0.01806219, 0.01781957,\n",
      "       0.01777084, 0.01777177, 0.01774886, 0.01766679, 0.01767058,\n",
      "       0.01793797, 0.01773396, 0.01779127, 0.01772394, 0.01773388,\n",
      "       0.01781278, 0.01769946, 0.01785669, 0.01769476, 0.01769753,\n",
      "       0.01767039, 0.01772234, 0.01780849, 0.01777062, 0.01775701,\n",
      "       0.01756246, 0.01786449, 0.01786664, 0.01774347, 0.01777334,\n",
      "       0.01778777, 0.01769533, 0.01799955, 0.01800044, 0.01790705,\n",
      "       0.01779678, 0.01779697, 0.01780145, 0.01783268, 0.01810598,\n",
      "       0.01774147, 0.01770065, 0.01796165, 0.01791103, 0.01769445,\n",
      "       0.01793084, 0.01793101, 0.01817148, 0.01782551, 0.01787839,\n",
      "       0.01778114, 0.01799262, 0.01785524, 0.0176841 , 0.01780071,\n",
      "       0.01809139, 0.01791036, 0.01799443, 0.01789484, 0.01787302,\n",
      "       0.01809556, 0.01799128, 0.01785603, 0.018205  , 0.01853616,\n",
      "       0.01852062, 0.01879785, 0.01875474, 0.01876504, 0.01860175,\n",
      "       0.018537  , 0.01854141, 0.01851938, 0.01815221, 0.01783655,\n",
      "       0.0181757 , 0.01813095, 0.01924915, 0.01810012, 0.01827817,\n",
      "       0.01819992, 0.01839941, 0.0184586 , 0.01819916, 0.01829915,\n",
      "       0.01829982, 0.01827319, 0.01820133, 0.01829979, 0.01799889,\n",
      "       0.01799986, 0.01829758, 0.0181999 , 0.0182683 , 0.01830008,\n",
      "       0.01809802, 0.0181988 , 0.01809981, 0.01810155, 0.01830041,\n",
      "       0.01816909, 0.01799936, 0.01819971, 0.0183001 , 0.01820009,\n",
      "       0.01800015, 0.01829998, 0.01816921, 0.01810296, 0.01809957,\n",
      "       0.01840127, 0.01837802, 0.01839967, 0.01830018, 0.01809986,\n",
      "       0.01830163, 0.01819994, 0.01839976, 0.01829963, 0.01809978,\n",
      "       0.01809986, 0.01810012, 0.01839983, 0.01819806, 0.01809831,\n",
      "       0.01809967, 0.01810002, 0.01820042, 0.01810017, 0.01819992,\n",
      "       0.0182116 , 0.01810012, 0.01810238, 0.01790082, 0.01830068,\n",
      "       0.01796994, 0.01829979, 0.01839924, 0.01790035, 0.01829963,\n",
      "       0.01799991, 0.01799815, 0.01819944, 0.01840007, 0.01819975,\n",
      "       0.01809888, 0.01829994, 0.01819818, 0.01830053, 0.01879976,\n",
      "       0.01916401, 0.01997821, 0.01821902, 0.01913784, 0.01889775,\n",
      "       0.01839211, 0.01803641, 0.01824372, 0.02017992, 0.01912878,\n",
      "       0.01840022, 0.01839886, 0.01860509, 0.01820357, 0.01784079,\n",
      "       0.01826131, 0.01829762, 0.01818693, 0.01830964, 0.01797392,\n",
      "       0.0181479 , 0.01816373, 0.01835058, 0.01800926, 0.0182606 ,\n",
      "       0.01830318, 0.01821191, 0.01823676, 0.01808248, 0.0180794 ,\n",
      "       0.01805668, 0.01807985, 0.01798165, 0.01829989, 0.01939669,\n",
      "       0.01914673, 0.0191591 , 0.01940951, 0.01905906, 0.01900332,\n",
      "       0.01913345, 0.01902461, 0.01912878, 0.01908579, 0.01969886,\n",
      "       0.0194999 , 0.01961443, 0.01960025, 0.01884866, 0.01905644,\n",
      "       0.01893084, 0.01930039, 0.01940045, 0.01898777, 0.01962695,\n",
      "       0.01840022, 0.01919837, 0.0187999 , 0.01899905, 0.01910148,\n",
      "       0.01883857, 0.01921082, 0.018537  , 0.01901968, 0.01918008,\n",
      "       0.02067966, 0.01946542, 0.01954253, 0.01906998, 0.01944256,\n",
      "       0.019033  , 0.01910594, 0.0191164 , 0.01962221, 0.01934485,\n",
      "       0.01895216, 0.01932905, 0.01915643, 0.01909306, 0.01890075,\n",
      "       0.01953211, 0.01891866, 0.01896143, 0.01930425, 0.01856091,\n",
      "       0.01904404, 0.01872828, 0.01883538, 0.01910961, 0.0193737 ,\n",
      "       0.01957242, 0.0191047 , 0.01913025, 0.01927617, 0.01941631,\n",
      "       0.01924086, 0.01935446, 0.01913638, 0.01910837, 0.01950827,\n",
      "       0.01930692, 0.01899171, 0.01911228, 0.01921983, 0.01956992,\n",
      "       0.02042477, 0.02020092, 0.01960008, 0.01875968, 0.01922436,\n",
      "       0.0192131 , 0.01975131, 0.01980858, 0.02015295, 0.01907675,\n",
      "       0.01943021, 0.02091658, 0.01918914, 0.01875558, 0.01957738]), 'std_fit_time': array([8.56676928e-04, 9.67310902e-04, 4.04385929e-04, 4.92562802e-04,\n",
      "       1.47713205e-03, 5.75857330e-04, 2.25307463e-03, 3.86588753e-04,\n",
      "       4.90369896e-04, 4.45413797e-04, 3.92076265e-04, 4.74580676e-04,\n",
      "       4.88318108e-04, 5.53535827e-04, 4.63646378e-04, 4.99273080e-04,\n",
      "       4.77074164e-04, 5.23853530e-04, 5.38138126e-04, 5.09835512e-04,\n",
      "       4.89801784e-04, 4.76556328e-04, 4.77192318e-04, 7.04677366e-04,\n",
      "       6.79212427e-04, 4.52384412e-04, 5.73348430e-04, 5.41084304e-04,\n",
      "       7.73980678e-04, 5.00536612e-04, 5.54591986e-04, 4.96001283e-04,\n",
      "       4.57925691e-04, 4.96386463e-04, 4.99009200e-04, 4.47386080e-04,\n",
      "       2.25984066e-04, 5.97178681e-04, 4.47674322e-04, 5.38428675e-04,\n",
      "       4.74057872e-04, 4.53451256e-04, 4.58224785e-04, 4.44118678e-04,\n",
      "       3.87038447e-04, 5.99570063e-04, 4.38468753e-04, 3.87998772e-04,\n",
      "       2.97241486e-04, 6.61074066e-04, 5.71514725e-04, 3.20011439e-04,\n",
      "       3.72706553e-04, 6.93273330e-04, 5.21733235e-04, 7.51487132e-04,\n",
      "       3.92491365e-04, 3.88310012e-04, 6.27580041e-04, 6.38203587e-04,\n",
      "       3.80851618e-04, 2.21715491e-04, 4.72422477e-04, 5.24323006e-04,\n",
      "       4.33395376e-04, 4.64179002e-04, 4.59127907e-04, 4.91934968e-04,\n",
      "       4.98904214e-04, 4.83094746e-04, 7.18651214e-04, 4.75780562e-04,\n",
      "       5.18170745e-04, 4.69799841e-04, 6.26753027e-04, 4.95725871e-04,\n",
      "       3.08010072e-04, 5.64684411e-04, 3.92464099e-04, 5.49146857e-04,\n",
      "       4.23202663e-04, 4.63112207e-04, 4.47504588e-04, 4.48355581e-04,\n",
      "       4.99453341e-04, 5.79670690e-04, 4.50677708e-04, 6.01535216e-04,\n",
      "       4.65774966e-04, 4.05741982e-04, 3.84755489e-04, 5.90604568e-04,\n",
      "       3.91925659e-04, 5.90529728e-04, 4.29065966e-04, 3.35326696e-04,\n",
      "       5.78021400e-04, 3.80914672e-04, 5.50260548e-04, 5.43783350e-04,\n",
      "       4.20007378e-04, 2.14089397e-05, 4.10816342e-04, 5.28214231e-04,\n",
      "       6.00279191e-04, 3.31341216e-04, 3.25541328e-04, 1.72069680e-05,\n",
      "       3.27984896e-04, 3.02047631e-04, 6.58910436e-04, 5.21098824e-04,\n",
      "       2.46333453e-04, 6.19364967e-04, 4.52679801e-04, 4.68381687e-04,\n",
      "       5.93986829e-04, 4.00755469e-04, 5.07962508e-04, 5.40070228e-04,\n",
      "       5.60054355e-04, 6.62257610e-04, 3.95399031e-04, 7.79772327e-04,\n",
      "       5.94400990e-04, 6.16812763e-04, 5.22109591e-04, 1.85067380e-03,\n",
      "       3.00137671e-04, 4.12775730e-04, 6.00139697e-04, 4.90378613e-04,\n",
      "       4.71455291e-04, 5.99126704e-04, 6.40341181e-04, 4.58567827e-04,\n",
      "       4.20659001e-04, 6.00196159e-04, 4.58479789e-04, 4.47580574e-04,\n",
      "       6.32711346e-04, 4.59646810e-04, 3.98241572e-04, 4.17824717e-04,\n",
      "       4.58188064e-04, 5.35303043e-04, 4.00885368e-04, 3.00002420e-04,\n",
      "       5.38406316e-04, 4.58021951e-04, 5.64335045e-04, 4.47076094e-04,\n",
      "       3.99221790e-04, 4.58745770e-04, 4.00102393e-04, 4.47342404e-04,\n",
      "       4.58458929e-04, 4.25425174e-04, 2.99002147e-04, 3.00277774e-04,\n",
      "       4.89084428e-04, 4.66830579e-04, 4.89580600e-04, 4.58385686e-04,\n",
      "       7.00157140e-04, 4.57035322e-04, 3.99816234e-04, 4.89746197e-04,\n",
      "       4.58538321e-04, 5.38495266e-04, 3.00145547e-04, 7.00188081e-04,\n",
      "       4.89736523e-04, 4.01135824e-04, 3.00605436e-04, 7.00456981e-04,\n",
      "       5.38495298e-04, 3.99283168e-04, 2.99963248e-04, 3.99947248e-04,\n",
      "       6.16355033e-04, 2.99900839e-04, 2.98390228e-04, 3.00466862e-04,\n",
      "       6.40297685e-04, 1.14958022e-04, 4.58375706e-04, 4.90666826e-04,\n",
      "       3.00625583e-04, 4.58276876e-04, 6.32485221e-04, 7.72216041e-04,\n",
      "       4.00127695e-04, 6.63291544e-04, 4.00209729e-04, 3.00199153e-04,\n",
      "       4.58593935e-04, 6.00659269e-04, 8.99184714e-04, 6.00012738e-04,\n",
      "       5.42761412e-04, 2.71889562e-03, 3.66016200e-04, 1.59896625e-03,\n",
      "       6.63907376e-04, 5.81015613e-04, 3.89003987e-04, 6.41661491e-04,\n",
      "       1.86709509e-03, 5.46488986e-04, 6.14396532e-04, 4.36606931e-04,\n",
      "       4.18048975e-04, 7.43598065e-04, 2.78528296e-04, 6.46176109e-04,\n",
      "       4.69731614e-04, 3.81371310e-04, 5.22353722e-04, 5.75456029e-04,\n",
      "       2.03675588e-04, 5.71480927e-04, 5.89372063e-04, 5.83055305e-04,\n",
      "       3.97216905e-04, 4.01545580e-04, 3.41346404e-04, 4.39552494e-04,\n",
      "       4.58006809e-04, 2.42637599e-04, 3.27810024e-04, 3.39248848e-04,\n",
      "       4.60123796e-04, 6.15969089e-04, 2.13674751e-03, 6.90119945e-04,\n",
      "       5.91814961e-04, 6.48956148e-04, 8.66445023e-04, 9.63738116e-04,\n",
      "       9.00939559e-04, 7.73092233e-04, 1.13962387e-03, 1.01869396e-03,\n",
      "       1.00348549e-03, 1.35930370e-03, 9.06761434e-04, 7.99406092e-04,\n",
      "       9.25370760e-04, 6.97508198e-04, 5.49198592e-04, 6.40956147e-04,\n",
      "       9.16495657e-04, 6.15381356e-04, 1.31196939e-03, 1.01963658e-03,\n",
      "       9.80610195e-04, 8.71104310e-04, 6.34074207e-04, 5.36313446e-04,\n",
      "       8.60534506e-04, 1.00265649e-03, 6.89336903e-04, 9.65209926e-04,\n",
      "       7.39812386e-04, 1.99294340e-03, 7.40249478e-04, 9.92805830e-04,\n",
      "       1.22162375e-03, 9.52743977e-04, 7.97043093e-04, 5.21095191e-04,\n",
      "       7.25400068e-04, 1.09328624e-03, 9.10246383e-04, 6.78868538e-04,\n",
      "       8.18558181e-04, 6.63398507e-04, 9.92110309e-04, 8.16158422e-04,\n",
      "       6.88633782e-04, 7.01414876e-04, 1.04605618e-03, 8.55588060e-04,\n",
      "       1.10269571e-03, 1.10175623e-03, 8.13427908e-04, 6.90046348e-04,\n",
      "       8.01332905e-04, 9.68422347e-04, 9.99425960e-04, 5.26514636e-04,\n",
      "       6.20789235e-04, 7.88445421e-04, 6.68245235e-04, 7.37727464e-04,\n",
      "       8.49589961e-04, 1.11764144e-03, 6.42382775e-04, 7.83353993e-04,\n",
      "       7.56050422e-04, 8.96282319e-04, 7.58273550e-04, 1.13922288e-03,\n",
      "       1.06471357e-03, 2.24307999e-03, 1.25127056e-03, 6.63032836e-04,\n",
      "       6.84427529e-04, 9.92264000e-04, 6.19923565e-04, 6.41564391e-04,\n",
      "       9.77661063e-04, 1.38544383e-03, 8.37316926e-04, 8.19217158e-04,\n",
      "       3.84122459e-03, 6.17410959e-04, 5.72642459e-04, 9.40187331e-04]), 'mean_score_time': array([2.99978256e-04, 5.99765778e-04, 4.00924683e-04, 8.00871849e-04,\n",
      "       2.00176239e-04, 6.00385666e-04, 7.17854500e-04, 5.42759895e-04,\n",
      "       4.98986244e-04, 4.99868393e-04, 2.99787521e-04, 4.00328636e-04,\n",
      "       4.08768654e-04, 6.50525093e-04, 4.99773026e-04, 2.99882889e-04,\n",
      "       4.99916077e-04, 4.99773026e-04, 2.00772285e-04, 5.00893593e-04,\n",
      "       4.00233269e-04, 4.50468063e-04, 5.00750542e-04, 1.99866295e-04,\n",
      "       5.00202179e-04, 3.99708748e-04, 3.99994850e-04, 4.99939919e-04,\n",
      "       4.99367714e-04, 4.99868393e-04, 4.00114059e-04, 3.00264359e-04,\n",
      "       3.99661064e-04, 4.50372696e-04, 3.99804115e-04, 6.00337982e-04,\n",
      "       2.98905373e-04, 6.00528717e-04, 5.00464439e-04, 5.01441956e-04,\n",
      "       4.00543213e-04, 5.00321388e-04, 3.00693512e-04, 5.00106812e-04,\n",
      "       5.00535965e-04, 6.00457191e-04, 4.00519371e-04, 5.00178337e-04,\n",
      "       3.50880623e-04, 3.99303436e-04, 4.99606133e-04, 3.99923325e-04,\n",
      "       7.00664520e-04, 2.01272964e-04, 5.00559807e-04, 4.99701500e-04,\n",
      "       5.00082970e-04, 5.50031662e-04, 2.20203400e-04, 7.99584389e-04,\n",
      "       2.00128555e-04, 2.00510025e-04, 2.00009346e-04, 2.17461586e-04,\n",
      "       2.51293182e-04, 3.02934647e-04, 5.00106812e-04, 3.99494171e-04,\n",
      "       5.50460815e-04, 4.99796867e-04, 2.00223923e-04, 5.00392914e-04,\n",
      "       5.00202179e-04, 5.00321388e-04, 8.02850723e-04, 5.00464439e-04,\n",
      "       4.99987602e-04, 3.99422646e-04, 6.00171089e-04, 4.09889221e-04,\n",
      "       2.00223923e-04, 5.00369072e-04, 2.99978256e-04, 1.99985504e-04,\n",
      "       5.00631332e-04, 5.99956512e-04, 3.00264359e-04, 7.50422478e-04,\n",
      "       6.40296936e-04, 3.99899483e-04, 5.01132011e-04, 6.00290298e-04,\n",
      "       2.00724602e-04, 5.00345230e-04, 6.01124763e-04, 5.50270081e-04,\n",
      "       3.00097466e-04, 6.99949265e-04, 4.00185585e-04, 3.99780273e-04,\n",
      "       7.99918175e-04, 1.99794769e-04, 5.99908829e-04, 3.99351120e-04,\n",
      "       4.98890877e-04, 2.99978256e-04, 9.99927521e-05, 4.99582291e-04,\n",
      "       2.00009346e-04, 1.99937820e-04, 3.50117683e-04, 3.00216675e-04,\n",
      "       5.15007973e-04, 2.00033188e-04, 5.99718094e-04, 3.00049782e-04,\n",
      "       4.00280952e-04, 2.00057030e-04, 5.00154495e-04, 6.00075722e-04,\n",
      "       3.99899483e-04, 3.99804115e-04, 6.00767136e-04, 3.99804115e-04,\n",
      "       5.00249863e-04, 3.50141525e-04, 2.99978256e-04, 7.31277466e-04,\n",
      "       6.00051880e-04, 4.00018692e-04, 6.00123405e-04, 7.00354576e-04,\n",
      "       3.00097466e-04, 7.01165199e-04, 4.00257111e-04, 6.00242615e-04,\n",
      "       5.99956512e-04, 3.00097466e-04, 7.00020790e-04, 4.99987602e-04,\n",
      "       5.00226021e-04, 2.99930573e-04, 4.00137901e-04, 4.99987602e-04,\n",
      "       4.99939919e-04, 5.02228737e-04, 5.99908829e-04, 5.00106812e-04,\n",
      "       5.98382950e-04, 3.00002098e-04, 4.99916077e-04, 6.00814819e-04,\n",
      "       5.00273705e-04, 2.98643112e-04, 2.00009346e-04, 7.00998306e-04,\n",
      "       5.00082970e-04, 3.98707390e-04, 8.96906853e-04, 5.00535965e-04,\n",
      "       5.99718094e-04, 4.99963760e-04, 4.00042534e-04, 4.99820709e-04,\n",
      "       4.00042534e-04, 5.00106812e-04, 5.00106812e-04, 3.00073624e-04,\n",
      "       3.99971008e-04, 5.00512123e-04, 3.99994850e-04, 5.99956512e-04,\n",
      "       2.99954414e-04, 0.00000000e+00, 5.00273705e-04, 6.00290298e-04,\n",
      "       5.99861145e-04, 2.99930573e-04, 6.00123405e-04, 4.00042534e-04,\n",
      "       5.51199913e-04, 4.99701500e-04, 2.01845169e-04, 7.99012184e-04,\n",
      "       3.99565697e-04, 2.00176239e-04, 6.00218773e-04, 6.00790977e-04,\n",
      "       4.00304794e-04, 5.00345230e-04, 7.01475143e-04, 4.00018692e-04,\n",
      "       6.99973106e-04, 2.00080872e-04, 5.01680374e-04, 3.00073624e-04,\n",
      "       5.00059128e-04, 6.01696968e-04, 5.99455833e-04, 6.20579720e-04,\n",
      "       5.34081459e-04, 3.36885452e-04, 5.00607491e-04, 5.99670410e-04,\n",
      "       3.77869606e-04, 5.81645966e-04, 8.01873207e-04, 5.27358055e-04,\n",
      "       8.60714912e-04, 3.99804115e-04, 6.00242615e-04, 4.00996208e-04,\n",
      "       6.01077080e-04, 4.99749184e-04, 4.00376320e-04, 3.50761414e-04,\n",
      "       4.01616096e-04, 1.99913979e-04, 3.01074982e-04, 2.00080872e-04,\n",
      "       5.51795959e-04, 5.38563728e-04, 4.99677658e-04, 4.23502922e-04,\n",
      "       8.99934769e-04, 5.00798225e-04, 2.00009346e-04, 5.98263741e-04,\n",
      "       3.00741196e-04, 4.50325012e-04, 3.00383568e-04, 1.99770927e-04,\n",
      "       4.00543213e-04, 7.10582733e-04, 7.00259209e-04, 4.12821770e-04,\n",
      "       6.57844543e-04, 2.91466713e-04, 6.00838661e-04, 2.00295448e-04,\n",
      "       2.16794014e-04, 4.50849533e-04, 4.00376320e-04, 4.01806831e-04,\n",
      "       6.01220131e-04, 4.99963760e-04, 7.98797607e-04, 1.00064278e-04,\n",
      "       3.00168991e-04, 2.38251686e-04, 3.99899483e-04, 4.99820709e-04,\n",
      "       3.99923325e-04, 6.01387024e-04, 4.00042534e-04, 5.99908829e-04,\n",
      "       2.99954414e-04, 3.00168991e-04, 7.01165199e-04, 4.98676300e-04,\n",
      "       5.00726700e-04, 4.99844551e-04, 5.50341606e-04, 3.00145149e-04,\n",
      "       4.46867943e-04, 8.25428963e-04, 5.19394875e-04, 6.52265549e-04,\n",
      "       4.50706482e-04, 5.50317764e-04, 2.50887871e-04, 3.51309776e-04,\n",
      "       5.50818443e-04, 3.13830376e-04, 9.39512253e-04, 6.91556931e-04,\n",
      "       3.00765038e-04, 5.01036644e-04, 4.47893143e-04, 4.55498695e-04,\n",
      "       2.25949287e-04, 3.00049782e-04, 4.91285324e-04, 5.51056862e-04,\n",
      "       7.63988495e-04, 2.99811363e-04, 4.52065468e-04, 2.50649452e-04,\n",
      "       4.57429886e-04, 4.01878357e-04, 1.50942802e-04, 4.53329086e-04,\n",
      "       2.00462341e-04, 5.51986694e-04, 5.01084328e-04, 3.64351273e-04,\n",
      "       7.00092316e-04, 6.50048256e-04, 1.49559975e-04, 4.09865379e-04,\n",
      "       3.03649902e-04, 3.99589539e-04, 5.12695313e-04, 4.50229645e-04,\n",
      "       5.00869751e-04, 7.71903992e-04, 4.00352478e-04, 6.99830055e-04,\n",
      "       4.01043892e-04, 6.71887398e-04, 7.32064247e-04, 3.00550461e-04,\n",
      "       7.64060020e-04, 4.40192223e-04, 6.00028038e-04, 5.07307053e-04,\n",
      "       3.32880020e-04, 5.08713722e-04, 7.00926781e-04, 3.99613380e-04]), 'std_score_time': array([0.00045822, 0.00048971, 0.00049103, 0.00040044, 0.00040036,\n",
      "       0.00049021, 0.00047265, 0.00055597, 0.000499  , 0.00049987,\n",
      "       0.00045793, 0.0004903 , 0.00050108, 0.00044955, 0.00049977,\n",
      "       0.00045808, 0.00049992, 0.00049977, 0.00040154, 0.0005009 ,\n",
      "       0.00049018, 0.00047155, 0.00050075, 0.00039973, 0.0005002 ,\n",
      "       0.00048954, 0.00048989, 0.00049994, 0.00049937, 0.00049987,\n",
      "       0.00049004, 0.00045866, 0.00048948, 0.00047173, 0.00048966,\n",
      "       0.00049018, 0.00045659, 0.00049033, 0.00050046, 0.00050144,\n",
      "       0.00049057, 0.00050032, 0.00045932, 0.00050011, 0.00050054,\n",
      "       0.00049028, 0.00049054, 0.00050018, 0.00045023, 0.00048905,\n",
      "       0.00049961, 0.0004898 , 0.0004587 , 0.00040255, 0.00050056,\n",
      "       0.00049971, 0.00050008, 0.00047129, 0.00044261, 0.0003998 ,\n",
      "       0.00040026, 0.00040102, 0.00040002, 0.0004367 , 0.000405  ,\n",
      "       0.00046283, 0.00050011, 0.00048928, 0.00047167, 0.0004998 ,\n",
      "       0.00040045, 0.0005004 , 0.00050021, 0.00050032, 0.00040147,\n",
      "       0.00050047, 0.00049999, 0.00048919, 0.00049004, 0.00050272,\n",
      "       0.00040045, 0.00050037, 0.00045823, 0.00039997, 0.00050063,\n",
      "       0.00048986, 0.00045866, 0.00040283, 0.00053662, 0.00048977,\n",
      "       0.00050114, 0.00049014, 0.00040146, 0.00050035, 0.00049082,\n",
      "       0.00047156, 0.00045841, 0.00045823, 0.00049013, 0.00048963,\n",
      "       0.00039996, 0.00039959, 0.00048983, 0.00048911, 0.0004989 ,\n",
      "       0.00045823, 0.00029998, 0.00049958, 0.00040002, 0.00039988,\n",
      "       0.00044962, 0.00045859, 0.00051668, 0.00040007, 0.00048967,\n",
      "       0.00045833, 0.00049025, 0.00040011, 0.00050015, 0.00048996,\n",
      "       0.00048977, 0.00048966, 0.00049054, 0.00048966, 0.00050025,\n",
      "       0.00044971, 0.00045823, 0.00048754, 0.00048994, 0.00048992,\n",
      "       0.00049   , 0.00045849, 0.00045841, 0.00045903, 0.00049021,\n",
      "       0.0004901 , 0.0004899 , 0.00045841, 0.00045827, 0.00049999,\n",
      "       0.00050023, 0.00045815, 0.00049007, 0.00049999, 0.00049994,\n",
      "       0.00050227, 0.00048982, 0.00050011, 0.0004886 , 0.00045826,\n",
      "       0.00049992, 0.00049056, 0.00050028, 0.0004562 , 0.00040002,\n",
      "       0.00045893, 0.00050008, 0.00048833, 0.00029903, 0.00050056,\n",
      "       0.00048967, 0.00049996, 0.00048995, 0.00049982, 0.00048995,\n",
      "       0.00050011, 0.00050011, 0.00045837, 0.00048986, 0.00050051,\n",
      "       0.00048989, 0.00048986, 0.00045819, 0.        , 0.00050027,\n",
      "       0.00049014, 0.00048978, 0.00045815, 0.00049   , 0.00048995,\n",
      "       0.0004717 , 0.0004997 , 0.00040371, 0.00039952, 0.00048937,\n",
      "       0.00040035, 0.00049008, 0.00049055, 0.00049027, 0.00050035,\n",
      "       0.00045925, 0.00048992, 0.00045824, 0.00040016, 0.00050171,\n",
      "       0.00045837, 0.00050006, 0.00049131, 0.00048946, 0.00051016,\n",
      "       0.000458  , 0.00052355, 0.00050061, 0.00053293, 0.00049503,\n",
      "       0.00050932, 0.00040096, 0.00053267, 0.00045651, 0.00048966,\n",
      "       0.0004901 , 0.00043629, 0.00049078, 0.00049975, 0.00049036,\n",
      "       0.00045029, 0.00043641, 0.00039983, 0.00045992, 0.00040016,\n",
      "       0.00047292, 0.00054929, 0.00049968, 0.00052187, 0.00029998,\n",
      "       0.0005008 , 0.00040002, 0.00048855, 0.00045939, 0.00056716,\n",
      "       0.00045884, 0.00039954, 0.00049057, 0.00046615, 0.00045843,\n",
      "       0.00044105, 0.0004554 , 0.00043068, 0.00049059, 0.00040059,\n",
      "       0.00043522, 0.00047232, 0.00049036, 0.00049213, 0.0004909 ,\n",
      "       0.00049996, 0.00039941, 0.00030019, 0.00045852, 0.00048411,\n",
      "       0.00048977, 0.00049982, 0.0004898 , 0.00049105, 0.00048995,\n",
      "       0.00048982, 0.00045819, 0.00045852, 0.00045903, 0.00049869,\n",
      "       0.00050073, 0.00049984, 0.0004716 , 0.00045848, 0.00056231,\n",
      "       0.00041894, 0.00068687, 0.00045128, 0.00047213, 0.00047155,\n",
      "       0.00040427, 0.00045153, 0.00047199, 0.00048068, 0.00055012,\n",
      "       0.00049566, 0.00040037, 0.00044759, 0.00056408, 0.00047786,\n",
      "       0.00045557, 0.00045833, 0.00053141, 0.00047229, 0.00051746,\n",
      "       0.00045797, 0.00047368, 0.00040371, 0.00048035, 0.00043715,\n",
      "       0.00032203, 0.00047522, 0.00040093, 0.00056065, 0.00050109,\n",
      "       0.00047152, 0.00045832, 0.00044957, 0.00031837, 0.00044896,\n",
      "       0.00046389, 0.0004894 , 0.00055857, 0.00047152, 0.00050087,\n",
      "       0.0007236 , 0.00049033, 0.00045815, 0.00049119, 0.00063309,\n",
      "       0.00048834, 0.0004591 , 0.00041285, 0.00054964, 0.00048992,\n",
      "       0.00045484, 0.00051205, 0.00050662, 0.00045887, 0.00048944]), 'param_classifier__max_depth': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
      "                   2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3,\n",
      "                   3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4,\n",
      "                   4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "                   6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "                   7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "                   8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
      "                   11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
      "                   12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13,\n",
      "                   13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14,\n",
      "                   14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15,\n",
      "                   15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16,\n",
      "                   16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "                   17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "                   17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
      "                   18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
      "                   19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "                   20, 20, 20, 20, 20, 20, 20, 20],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_classifier__min_samples_leaf': masked_array(data=[1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1,\n",
      "                   1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1,\n",
      "                   1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1,\n",
      "                   1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1,\n",
      "                   2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2,\n",
      "                   2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2,\n",
      "                   2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2,\n",
      "                   2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "                   5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5,\n",
      "                   5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5,\n",
      "                   5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5,\n",
      "                   5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5,\n",
      "                   10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10,\n",
      "                   10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10,\n",
      "                   10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10,\n",
      "                   10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10,\n",
      "                   1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1,\n",
      "                   1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1,\n",
      "                   1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_classifier__min_samples_split': masked_array(data=[2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'classifier__max_depth': 1, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}], 'split0_test_score': array([0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.7672956 ,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.74213836, 0.74213836, 0.74213836, 0.73584906,\n",
      "       0.74213836, 0.74842767, 0.74213836, 0.74213836, 0.74213836,\n",
      "       0.73584906, 0.73584906, 0.74213836, 0.73584906, 0.74213836,\n",
      "       0.74213836, 0.73584906, 0.79874214, 0.83018868, 0.79874214,\n",
      "       0.79245283, 0.79245283, 0.79874214, 0.83018868, 0.82389937,\n",
      "       0.79245283, 0.79874214, 0.79874214, 0.79245283, 0.79245283,\n",
      "       0.79245283, 0.79245283, 0.79245283, 0.82389937, 0.81132075,\n",
      "       0.79874214, 0.7672956 , 0.79874214, 0.80503145, 0.77987421,\n",
      "       0.79874214, 0.77358491, 0.80503145, 0.81132075, 0.79245283,\n",
      "       0.79245283, 0.82389937, 0.79245283, 0.7672956 , 0.80503145,\n",
      "       0.81761006, 0.81132075, 0.79874214, 0.80503145, 0.81761006,\n",
      "       0.81761006, 0.79245283, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.79245283, 0.74842767, 0.79245283, 0.79245283, 0.79245283,\n",
      "       0.80503145, 0.77358491, 0.74213836, 0.79245283, 0.81761006,\n",
      "       0.79874214, 0.79874214, 0.77987421, 0.81761006, 0.79245283,\n",
      "       0.76100629, 0.77987421, 0.77358491, 0.79245283, 0.77358491,\n",
      "       0.78616352, 0.75471698, 0.81132075, 0.7672956 , 0.77987421,\n",
      "       0.80503145, 0.81132075, 0.7672956 , 0.75471698, 0.82389937,\n",
      "       0.78616352, 0.7672956 , 0.78616352, 0.75471698, 0.75471698,\n",
      "       0.81132075, 0.77987421, 0.7672956 , 0.79874214, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77987421, 0.81761006, 0.76100629,\n",
      "       0.77987421, 0.76100629, 0.7672956 , 0.74842767, 0.78616352,\n",
      "       0.71069182, 0.76100629, 0.7672956 , 0.75471698, 0.81761006,\n",
      "       0.72955975, 0.73584906, 0.7672956 , 0.76100629, 0.7672956 ,\n",
      "       0.7672956 , 0.79874214, 0.77987421, 0.77987421, 0.79874214,\n",
      "       0.75471698, 0.81761006, 0.7672956 , 0.7672956 , 0.77358491,\n",
      "       0.80503145, 0.77358491, 0.72955975, 0.75471698, 0.79245283,\n",
      "       0.71069182, 0.73584906, 0.77358491, 0.76100629, 0.80503145,\n",
      "       0.7672956 , 0.77987421, 0.82389937, 0.75471698, 0.78616352,\n",
      "       0.7672956 , 0.79245283, 0.74842767, 0.69811321, 0.78616352,\n",
      "       0.7672956 , 0.78616352, 0.74842767, 0.74842767, 0.78616352,\n",
      "       0.74842767, 0.72955975, 0.78616352, 0.7672956 , 0.78616352,\n",
      "       0.75471698, 0.73584906, 0.71698113, 0.74213836, 0.74213836,\n",
      "       0.79245283, 0.7672956 , 0.75471698, 0.7672956 , 0.76100629,\n",
      "       0.79245283, 0.79874214, 0.76100629, 0.78616352, 0.77987421,\n",
      "       0.75471698, 0.77358491, 0.77987421, 0.77358491, 0.7672956 ,\n",
      "       0.74213836, 0.74842767, 0.79874214, 0.77987421, 0.76100629,\n",
      "       0.7672956 , 0.7672956 , 0.77987421, 0.79874214, 0.74842767,\n",
      "       0.70440252, 0.74213836, 0.72327044, 0.75471698, 0.77358491,\n",
      "       0.74213836, 0.75471698, 0.76100629, 0.76100629, 0.74842767,\n",
      "       0.75471698, 0.79245283, 0.79245283, 0.71069182, 0.7672956 ,\n",
      "       0.77987421, 0.77987421, 0.74842767, 0.78616352, 0.7672956 ,\n",
      "       0.76100629, 0.79245283, 0.78616352, 0.79874214, 0.73584906,\n",
      "       0.79874214, 0.77358491, 0.77358491, 0.72955975, 0.81761006,\n",
      "       0.7672956 , 0.77358491, 0.75471698, 0.79245283, 0.79245283,\n",
      "       0.77358491, 0.80503145, 0.73584906, 0.72327044, 0.81132075,\n",
      "       0.77358491, 0.77358491, 0.7672956 , 0.77358491, 0.77358491,\n",
      "       0.72327044, 0.71698113, 0.77987421, 0.77987421, 0.77987421,\n",
      "       0.77358491, 0.72327044, 0.74213836, 0.79245283, 0.76100629,\n",
      "       0.77987421, 0.72955975, 0.72955975, 0.74213836, 0.81761006,\n",
      "       0.73584906, 0.7672956 , 0.76100629, 0.78616352, 0.7672956 ,\n",
      "       0.77358491, 0.7672956 , 0.74842767, 0.78616352, 0.82389937,\n",
      "       0.71698113, 0.80503145, 0.77358491, 0.7672956 , 0.78616352,\n",
      "       0.78616352, 0.7672956 , 0.74213836, 0.81761006, 0.77358491,\n",
      "       0.77987421, 0.7672956 , 0.74213836, 0.77358491, 0.74842767,\n",
      "       0.78616352, 0.75471698, 0.74213836, 0.7672956 , 0.76100629,\n",
      "       0.77358491, 0.75471698, 0.77987421, 0.78616352, 0.71069182,\n",
      "       0.74213836, 0.78616352, 0.74213836, 0.7672956 , 0.75471698,\n",
      "       0.75471698, 0.74213836, 0.76100629, 0.78616352, 0.77987421,\n",
      "       0.77987421, 0.7672956 , 0.74842767, 0.72327044, 0.72955975,\n",
      "       0.75471698, 0.78616352, 0.78616352, 0.79245283, 0.77987421]), 'split1_test_score': array([0.80503145, 0.80503145, 0.80503145, 0.79874214, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.79874214, 0.80503145, 0.80503145, 0.79874214, 0.80503145,\n",
      "       0.80503145, 0.79874214, 0.81132075, 0.79874214, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.79874214, 0.81132075, 0.81132075,\n",
      "       0.79874214, 0.81132075, 0.79874214, 0.79874214, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.88679245, 0.88679245, 0.88679245,\n",
      "       0.88050314, 0.88679245, 0.88679245, 0.88679245, 0.88050314,\n",
      "       0.88679245, 0.88679245, 0.88679245, 0.88050314, 0.88050314,\n",
      "       0.88050314, 0.88050314, 0.85534591, 0.88679245, 0.87421384,\n",
      "       0.86792453, 0.85534591, 0.88050314, 0.87421384, 0.88679245,\n",
      "       0.86792453, 0.87421384, 0.87421384, 0.88679245, 0.86792453,\n",
      "       0.86792453, 0.86792453, 0.86792453, 0.88050314, 0.87421384,\n",
      "       0.86792453, 0.86163522, 0.86792453, 0.86163522, 0.88050314,\n",
      "       0.85534591, 0.88050314, 0.86792453, 0.86163522, 0.88050314,\n",
      "       0.88050314, 0.86163522, 0.86792453, 0.88050314, 0.85534591,\n",
      "       0.8490566 , 0.87421384, 0.87421384, 0.86792453, 0.86792453,\n",
      "       0.86163522, 0.83018868, 0.83647799, 0.86163522, 0.8427673 ,\n",
      "       0.86163522, 0.8490566 , 0.86792453, 0.86792453, 0.86792453,\n",
      "       0.86792453, 0.86792453, 0.86792453, 0.86792453, 0.81132075,\n",
      "       0.86163522, 0.87421384, 0.87421384, 0.87421384, 0.86792453,\n",
      "       0.83647799, 0.8427673 , 0.85534591, 0.86792453, 0.85534591,\n",
      "       0.8427673 , 0.83647799, 0.83647799, 0.85534591, 0.86163522,\n",
      "       0.87421384, 0.86163522, 0.87421384, 0.8490566 , 0.83018868,\n",
      "       0.8490566 , 0.8490566 , 0.8427673 , 0.82389937, 0.81132075,\n",
      "       0.83018868, 0.88050314, 0.88050314, 0.86163522, 0.82389937,\n",
      "       0.86163522, 0.83018868, 0.80503145, 0.86163522, 0.85534591,\n",
      "       0.80503145, 0.83647799, 0.83647799, 0.85534591, 0.81761006,\n",
      "       0.86163522, 0.86163522, 0.81761006, 0.85534591, 0.83647799,\n",
      "       0.8490566 , 0.86792453, 0.88050314, 0.79874214, 0.8490566 ,\n",
      "       0.82389937, 0.8427673 , 0.83647799, 0.81132075, 0.86792453,\n",
      "       0.87421384, 0.8490566 , 0.87421384, 0.8490566 , 0.81761006,\n",
      "       0.8427673 , 0.85534591, 0.79874214, 0.86792453, 0.80503145,\n",
      "       0.81132075, 0.80503145, 0.86792453, 0.8490566 , 0.87421384,\n",
      "       0.82389937, 0.86792453, 0.85534591, 0.88050314, 0.85534591,\n",
      "       0.8490566 , 0.79245283, 0.8490566 , 0.81761006, 0.8427673 ,\n",
      "       0.83647799, 0.81132075, 0.81132075, 0.86792453, 0.83647799,\n",
      "       0.8490566 , 0.8427673 , 0.86163522, 0.83647799, 0.83647799,\n",
      "       0.8490566 , 0.86163522, 0.82389937, 0.80503145, 0.81132075,\n",
      "       0.83647799, 0.86163522, 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.82389937, 0.8427673 , 0.8490566 , 0.85534591,\n",
      "       0.88050314, 0.81132075, 0.86163522, 0.8490566 , 0.81132075,\n",
      "       0.80503145, 0.79874214, 0.83018868, 0.8490566 , 0.86163522,\n",
      "       0.82389937, 0.81132075, 0.82389937, 0.80503145, 0.83647799,\n",
      "       0.88050314, 0.85534591, 0.8490566 , 0.83647799, 0.83647799,\n",
      "       0.83018868, 0.83647799, 0.81761006, 0.8490566 , 0.79874214,\n",
      "       0.86792453, 0.8490566 , 0.83018868, 0.8427673 , 0.8427673 ,\n",
      "       0.88050314, 0.87421384, 0.8490566 , 0.86792453, 0.83018868,\n",
      "       0.79874214, 0.83647799, 0.86792453, 0.81761006, 0.87421384,\n",
      "       0.80503145, 0.81761006, 0.8490566 , 0.8427673 , 0.82389937,\n",
      "       0.86163522, 0.8490566 , 0.86792453, 0.86163522, 0.86163522,\n",
      "       0.88050314, 0.82389937, 0.8427673 , 0.81132075, 0.86792453,\n",
      "       0.82389937, 0.86163522, 0.79874214, 0.83018868, 0.83647799,\n",
      "       0.83647799, 0.75471698, 0.86163522, 0.87421384, 0.86163522,\n",
      "       0.83647799, 0.81761006, 0.79874214, 0.86792453, 0.82389937,\n",
      "       0.8490566 , 0.81761006, 0.80503145, 0.8490566 , 0.8490566 ,\n",
      "       0.8427673 , 0.86792453, 0.82389937, 0.86163522, 0.86163522,\n",
      "       0.88050314, 0.86792453, 0.81132075, 0.81761006, 0.86792453,\n",
      "       0.83647799, 0.85534591, 0.85534591, 0.85534591, 0.8427673 ,\n",
      "       0.87421384, 0.83647799, 0.83647799, 0.81761006, 0.85534591,\n",
      "       0.85534591, 0.88050314, 0.86792453, 0.86792453, 0.80503145,\n",
      "       0.79874214, 0.83018868, 0.8490566 , 0.85534591, 0.82389937,\n",
      "       0.83647799, 0.83647799, 0.79245283, 0.8427673 , 0.77987421,\n",
      "       0.85534591, 0.8427673 , 0.79874214, 0.82389937, 0.83018868]), 'split2_test_score': array([0.79874214, 0.7672956 , 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.7672956 ,\n",
      "       0.7672956 , 0.79874214, 0.7672956 , 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.71698113, 0.71698113, 0.71698113, 0.71698113,\n",
      "       0.71698113, 0.71698113, 0.71698113, 0.71069182, 0.71698113,\n",
      "       0.71698113, 0.71698113, 0.71698113, 0.71698113, 0.71069182,\n",
      "       0.71698113, 0.71698113, 0.77358491, 0.81761006, 0.81761006,\n",
      "       0.81132075, 0.81132075, 0.81761006, 0.81132075, 0.81132075,\n",
      "       0.81761006, 0.81132075, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.81132075, 0.81761006, 0.81761006, 0.79245283, 0.80503145,\n",
      "       0.81761006, 0.79874214, 0.81132075, 0.81761006, 0.81132075,\n",
      "       0.81761006, 0.80503145, 0.81761006, 0.79245283, 0.81132075,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81761006, 0.79245283,\n",
      "       0.78616352, 0.80503145, 0.79874214, 0.81132075, 0.79245283,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.80503145, 0.81761006,\n",
      "       0.81132075, 0.79874214, 0.79874214, 0.81132075, 0.81132075,\n",
      "       0.80503145, 0.81761006, 0.77358491, 0.81132075, 0.79245283,\n",
      "       0.79245283, 0.81761006, 0.76100629, 0.79245283, 0.79245283,\n",
      "       0.80503145, 0.79874214, 0.81132075, 0.79245283, 0.76100629,\n",
      "       0.79245283, 0.77987421, 0.77987421, 0.81132075, 0.79874214,\n",
      "       0.77987421, 0.77358491, 0.79874214, 0.81132075, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.77987421, 0.80503145,\n",
      "       0.7672956 , 0.80503145, 0.77358491, 0.80503145, 0.78616352,\n",
      "       0.7672956 , 0.78616352, 0.77358491, 0.77987421, 0.77358491,\n",
      "       0.78616352, 0.75471698, 0.78616352, 0.75471698, 0.7672956 ,\n",
      "       0.74213836, 0.76100629, 0.79874214, 0.77987421, 0.81132075,\n",
      "       0.76100629, 0.79874214, 0.75471698, 0.7672956 , 0.75471698,\n",
      "       0.78616352, 0.72327044, 0.77987421, 0.7672956 , 0.77987421,\n",
      "       0.79874214, 0.77987421, 0.74213836, 0.79874214, 0.76100629,\n",
      "       0.77358491, 0.80503145, 0.77987421, 0.7672956 , 0.79245283,\n",
      "       0.80503145, 0.78616352, 0.74213836, 0.79874214, 0.79874214,\n",
      "       0.81761006, 0.77987421, 0.80503145, 0.79874214, 0.81761006,\n",
      "       0.77987421, 0.7672956 , 0.77358491, 0.76100629, 0.75471698,\n",
      "       0.80503145, 0.78616352, 0.7672956 , 0.76100629, 0.76100629,\n",
      "       0.7672956 , 0.80503145, 0.81761006, 0.78616352, 0.81132075,\n",
      "       0.79245283, 0.74842767, 0.77358491, 0.72955975, 0.77987421,\n",
      "       0.78616352, 0.77358491, 0.79245283, 0.78616352, 0.79874214,\n",
      "       0.79245283, 0.79245283, 0.80503145, 0.7672956 , 0.80503145,\n",
      "       0.75471698, 0.80503145, 0.72955975, 0.73584906, 0.79245283,\n",
      "       0.77358491, 0.81132075, 0.75471698, 0.80503145, 0.79874214,\n",
      "       0.74842767, 0.73584906, 0.74213836, 0.80503145, 0.79874214,\n",
      "       0.77987421, 0.81761006, 0.77987421, 0.74213836, 0.77987421,\n",
      "       0.77987421, 0.76100629, 0.75471698, 0.77358491, 0.79245283,\n",
      "       0.77358491, 0.72955975, 0.78616352, 0.79874214, 0.82389937,\n",
      "       0.80503145, 0.78616352, 0.77358491, 0.80503145, 0.72955975,\n",
      "       0.7672956 , 0.73584906, 0.81132075, 0.73584906, 0.77987421,\n",
      "       0.80503145, 0.7672956 , 0.7672956 , 0.81132075, 0.78616352,\n",
      "       0.77987421, 0.80503145, 0.7672956 , 0.81132075, 0.7672956 ,\n",
      "       0.79245283, 0.81132075, 0.77987421, 0.78616352, 0.76100629,\n",
      "       0.80503145, 0.75471698, 0.81132075, 0.75471698, 0.72955975,\n",
      "       0.80503145, 0.80503145, 0.79874214, 0.79245283, 0.74213836,\n",
      "       0.79874214, 0.69811321, 0.77987421, 0.76100629, 0.79245283,\n",
      "       0.76100629, 0.77987421, 0.7672956 , 0.81761006, 0.79874214,\n",
      "       0.79874214, 0.78616352, 0.78616352, 0.80503145, 0.80503145,\n",
      "       0.78616352, 0.78616352, 0.7672956 , 0.77987421, 0.79245283,\n",
      "       0.80503145, 0.79245283, 0.79874214, 0.79245283, 0.74213836,\n",
      "       0.81132075, 0.78616352, 0.78616352, 0.76100629, 0.79245283,\n",
      "       0.81132075, 0.7672956 , 0.81132075, 0.78616352, 0.78616352,\n",
      "       0.77987421, 0.77987421, 0.77987421, 0.77987421, 0.79874214,\n",
      "       0.80503145, 0.77987421, 0.7672956 , 0.80503145, 0.7672956 ,\n",
      "       0.77987421, 0.74842767, 0.79245283, 0.80503145, 0.72327044,\n",
      "       0.75471698, 0.78616352, 0.80503145, 0.7672956 , 0.78616352,\n",
      "       0.72327044, 0.80503145, 0.76100629, 0.76100629, 0.77358491,\n",
      "       0.77987421, 0.78616352, 0.78616352, 0.79874214, 0.77358491]), 'split3_test_score': array([0.74842767, 0.74842767, 0.74842767, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.74842767, 0.78616352, 0.78616352, 0.74842767,\n",
      "       0.74842767, 0.71069182, 0.69811321, 0.71069182, 0.69811321,\n",
      "       0.71069182, 0.69811321, 0.69811321, 0.71069182, 0.69811321,\n",
      "       0.71069182, 0.71069182, 0.71069182, 0.71069182, 0.71069182,\n",
      "       0.69811321, 0.69811321, 0.80503145, 0.81761006, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.81761006, 0.79245283, 0.80503145,\n",
      "       0.80503145, 0.79874214, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.79874214, 0.80503145, 0.80503145, 0.79874214, 0.80503145,\n",
      "       0.80503145, 0.81761006, 0.80503145, 0.80503145, 0.79245283,\n",
      "       0.79245283, 0.74842767, 0.80503145, 0.79874214, 0.80503145,\n",
      "       0.79245283, 0.77358491, 0.81132075, 0.78616352, 0.80503145,\n",
      "       0.80503145, 0.7672956 , 0.79245283, 0.7672956 , 0.79874214,\n",
      "       0.76100629, 0.78616352, 0.80503145, 0.78616352, 0.79874214,\n",
      "       0.77358491, 0.78616352, 0.79245283, 0.78616352, 0.79874214,\n",
      "       0.77987421, 0.77987421, 0.80503145, 0.7672956 , 0.79245283,\n",
      "       0.78616352, 0.81132075, 0.77358491, 0.78616352, 0.7672956 ,\n",
      "       0.7672956 , 0.75471698, 0.77358491, 0.80503145, 0.79245283,\n",
      "       0.78616352, 0.78616352, 0.80503145, 0.77987421, 0.77358491,\n",
      "       0.79874214, 0.80503145, 0.75471698, 0.77987421, 0.79874214,\n",
      "       0.75471698, 0.76100629, 0.78616352, 0.7672956 , 0.79874214,\n",
      "       0.74842767, 0.78616352, 0.78616352, 0.77987421, 0.78616352,\n",
      "       0.80503145, 0.78616352, 0.77987421, 0.79874214, 0.7672956 ,\n",
      "       0.76100629, 0.77987421, 0.80503145, 0.80503145, 0.77358491,\n",
      "       0.79874214, 0.79874214, 0.77358491, 0.77987421, 0.77987421,\n",
      "       0.77358491, 0.79245283, 0.78616352, 0.79245283, 0.76100629,\n",
      "       0.77358491, 0.77987421, 0.80503145, 0.79245283, 0.79245283,\n",
      "       0.74213836, 0.77358491, 0.78616352, 0.74842767, 0.76100629,\n",
      "       0.74842767, 0.79245283, 0.79874214, 0.77987421, 0.79874214,\n",
      "       0.7672956 , 0.7672956 , 0.7672956 , 0.77987421, 0.73584906,\n",
      "       0.75471698, 0.77987421, 0.78616352, 0.75471698, 0.7672956 ,\n",
      "       0.76100629, 0.77358491, 0.81132075, 0.76100629, 0.73584906,\n",
      "       0.78616352, 0.75471698, 0.76100629, 0.7672956 , 0.76100629,\n",
      "       0.81132075, 0.80503145, 0.78616352, 0.79874214, 0.7672956 ,\n",
      "       0.77358491, 0.76100629, 0.7672956 , 0.79874214, 0.80503145,\n",
      "       0.74213836, 0.78616352, 0.78616352, 0.76100629, 0.75471698,\n",
      "       0.79245283, 0.80503145, 0.7672956 , 0.77358491, 0.7672956 ,\n",
      "       0.77987421, 0.78616352, 0.77987421, 0.79874214, 0.77358491,\n",
      "       0.79245283, 0.78616352, 0.7672956 , 0.7672956 , 0.76100629,\n",
      "       0.77987421, 0.78616352, 0.7672956 , 0.77987421, 0.79245283,\n",
      "       0.79245283, 0.79245283, 0.76100629, 0.79245283, 0.77358491,\n",
      "       0.79874214, 0.79874214, 0.77358491, 0.79245283, 0.75471698,\n",
      "       0.76100629, 0.7672956 , 0.78616352, 0.74842767, 0.76100629,\n",
      "       0.77358491, 0.7672956 , 0.77358491, 0.77987421, 0.72327044,\n",
      "       0.79245283, 0.74213836, 0.75471698, 0.78616352, 0.80503145,\n",
      "       0.74213836, 0.74842767, 0.7672956 , 0.79874214, 0.7672956 ,\n",
      "       0.74213836, 0.79245283, 0.74842767, 0.79245283, 0.77987421,\n",
      "       0.7672956 , 0.76100629, 0.7672956 , 0.76100629, 0.77987421,\n",
      "       0.77987421, 0.77358491, 0.7672956 , 0.7672956 , 0.79245283,\n",
      "       0.7672956 , 0.78616352, 0.80503145, 0.78616352, 0.77987421,\n",
      "       0.80503145, 0.75471698, 0.79245283, 0.8427673 , 0.79245283,\n",
      "       0.78616352, 0.81132075, 0.74213836, 0.77987421, 0.77358491,\n",
      "       0.78616352, 0.7672956 , 0.73584906, 0.77358491, 0.81132075,\n",
      "       0.78616352, 0.76100629, 0.76100629, 0.77358491, 0.77987421,\n",
      "       0.80503145, 0.75471698, 0.78616352, 0.77358491, 0.75471698,\n",
      "       0.77358491, 0.79245283, 0.75471698, 0.75471698, 0.76100629,\n",
      "       0.79245283, 0.77358491, 0.7672956 , 0.79245283, 0.77358491,\n",
      "       0.82389937, 0.78616352, 0.77987421, 0.79245283, 0.72955975,\n",
      "       0.75471698, 0.77358491, 0.79245283, 0.77358491, 0.7672956 ,\n",
      "       0.77358491, 0.7672956 , 0.76100629, 0.78616352, 0.77358491,\n",
      "       0.74842767, 0.80503145, 0.80503145, 0.75471698, 0.78616352]), 'split4_test_score': array([0.74842767, 0.74842767, 0.74842767, 0.74213836, 0.74842767,\n",
      "       0.74842767, 0.74842767, 0.74842767, 0.74842767, 0.74213836,\n",
      "       0.74842767, 0.74842767, 0.74842767, 0.74842767, 0.74842767,\n",
      "       0.74842767, 0.72955975, 0.72955975, 0.6918239 , 0.72327044,\n",
      "       0.72955975, 0.72955975, 0.72955975, 0.72955975, 0.72955975,\n",
      "       0.72955975, 0.72955975, 0.72955975, 0.72955975, 0.72327044,\n",
      "       0.72955975, 0.72955975, 0.79874214, 0.79874214, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.79874214, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.80503145, 0.78616352, 0.79874214, 0.78616352,\n",
      "       0.78616352, 0.76100629, 0.78616352, 0.77987421, 0.77987421,\n",
      "       0.7672956 , 0.79874214, 0.79874214, 0.79245283, 0.78616352,\n",
      "       0.78616352, 0.77358491, 0.77987421, 0.77987421, 0.77987421,\n",
      "       0.78616352, 0.77987421, 0.77358491, 0.76100629, 0.77358491,\n",
      "       0.76100629, 0.77358491, 0.74842767, 0.77358491, 0.75471698,\n",
      "       0.7672956 , 0.77987421, 0.76100629, 0.78616352, 0.77987421,\n",
      "       0.75471698, 0.79874214, 0.77987421, 0.78616352, 0.75471698,\n",
      "       0.76100629, 0.74842767, 0.77358491, 0.7672956 , 0.7672956 ,\n",
      "       0.77987421, 0.77358491, 0.74842767, 0.77987421, 0.77358491,\n",
      "       0.7672956 , 0.78616352, 0.77358491, 0.78616352, 0.77987421,\n",
      "       0.77987421, 0.7672956 , 0.7672956 , 0.77358491, 0.76100629,\n",
      "       0.75471698, 0.79245283, 0.76100629, 0.77358491, 0.77358491,\n",
      "       0.76100629, 0.7672956 , 0.77358491, 0.78616352, 0.77987421,\n",
      "       0.7672956 , 0.77987421, 0.73584906, 0.74842767, 0.76100629,\n",
      "       0.77987421, 0.76100629, 0.77358491, 0.75471698, 0.74213836,\n",
      "       0.74842767, 0.77358491, 0.72955975, 0.76100629, 0.78616352,\n",
      "       0.77358491, 0.77987421, 0.77987421, 0.7672956 , 0.77358491,\n",
      "       0.75471698, 0.78616352, 0.74842767, 0.74842767, 0.76100629,\n",
      "       0.75471698, 0.75471698, 0.76100629, 0.7672956 , 0.77358491,\n",
      "       0.78616352, 0.7672956 , 0.78616352, 0.78616352, 0.73584906,\n",
      "       0.77358491, 0.78616352, 0.74213836, 0.74842767, 0.74842767,\n",
      "       0.77358491, 0.74213836, 0.7672956 , 0.77987421, 0.74842767,\n",
      "       0.74842767, 0.75471698, 0.76100629, 0.74842767, 0.77987421,\n",
      "       0.73584906, 0.74842767, 0.7672956 , 0.76100629, 0.7672956 ,\n",
      "       0.74842767, 0.73584906, 0.77987421, 0.71069182, 0.74842767,\n",
      "       0.77987421, 0.72955975, 0.79874214, 0.75471698, 0.79874214,\n",
      "       0.78616352, 0.72955975, 0.72327044, 0.71069182, 0.76100629,\n",
      "       0.77358491, 0.71698113, 0.75471698, 0.72955975, 0.74842767,\n",
      "       0.74213836, 0.74842767, 0.75471698, 0.74842767, 0.77987421,\n",
      "       0.77358491, 0.77987421, 0.69811321, 0.76100629, 0.74842767,\n",
      "       0.74842767, 0.74213836, 0.80503145, 0.7672956 , 0.70440252,\n",
      "       0.78616352, 0.77987421, 0.72955975, 0.75471698, 0.79245283,\n",
      "       0.77987421, 0.75471698, 0.77358491, 0.73584906, 0.75471698,\n",
      "       0.7672956 , 0.76100629, 0.75471698, 0.73584906, 0.72955975,\n",
      "       0.7672956 , 0.7672956 , 0.75471698, 0.76100629, 0.77987421,\n",
      "       0.74213836, 0.73584906, 0.78616352, 0.79874214, 0.71698113,\n",
      "       0.73584906, 0.77987421, 0.77358491, 0.72955975, 0.72327044,\n",
      "       0.76100629, 0.7672956 , 0.74842767, 0.7672956 , 0.72327044,\n",
      "       0.74213836, 0.76100629, 0.76100629, 0.74213836, 0.77358491,\n",
      "       0.71698113, 0.70440252, 0.72955975, 0.77358491, 0.7672956 ,\n",
      "       0.72327044, 0.75471698, 0.75471698, 0.73584906, 0.75471698,\n",
      "       0.78616352, 0.71698113, 0.7672956 , 0.77987421, 0.77358491,\n",
      "       0.77987421, 0.72327044, 0.73584906, 0.76100629, 0.77358491,\n",
      "       0.74842767, 0.7672956 , 0.77987421, 0.74213836, 0.73584906,\n",
      "       0.72955975, 0.76100629, 0.7672956 , 0.76100629, 0.79245283,\n",
      "       0.73584906, 0.76100629, 0.74213836, 0.76100629, 0.71069182,\n",
      "       0.77358491, 0.7672956 , 0.74213836, 0.74842767, 0.76100629,\n",
      "       0.77987421, 0.74842767, 0.76100629, 0.7672956 , 0.77358491,\n",
      "       0.79874214, 0.79245283, 0.76100629, 0.71698113, 0.72327044,\n",
      "       0.69811321, 0.74842767, 0.76100629, 0.77358491, 0.76100629,\n",
      "       0.78616352, 0.76100629, 0.76100629, 0.76100629, 0.74213836,\n",
      "       0.75471698, 0.7672956 , 0.79245283, 0.77358491, 0.71698113,\n",
      "       0.69811321, 0.73584906, 0.77987421, 0.77358491, 0.75471698,\n",
      "       0.72955975, 0.77987421, 0.72327044, 0.77358491, 0.76100629,\n",
      "       0.77987421, 0.74842767, 0.77987421, 0.78616352, 0.76100629]), 'split5_test_score': array([0.7672956 , 0.7672956 , 0.74842767, 0.74842767, 0.7672956 ,\n",
      "       0.7672956 , 0.74842767, 0.7672956 , 0.74842767, 0.7672956 ,\n",
      "       0.74842767, 0.7672956 , 0.7672956 , 0.7672956 , 0.74842767,\n",
      "       0.7672956 , 0.72327044, 0.72327044, 0.71698113, 0.71698113,\n",
      "       0.71698113, 0.72327044, 0.72327044, 0.71698113, 0.71698113,\n",
      "       0.72327044, 0.71698113, 0.72327044, 0.71698113, 0.71698113,\n",
      "       0.71698113, 0.72327044, 0.82389937, 0.82389937, 0.82389937,\n",
      "       0.81761006, 0.82389937, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.79245283, 0.79245283, 0.79245283, 0.82389937,\n",
      "       0.79245283, 0.81761006, 0.81761006, 0.83018868, 0.80503145,\n",
      "       0.77987421, 0.81132075, 0.81761006, 0.80503145, 0.80503145,\n",
      "       0.77987421, 0.79245283, 0.81761006, 0.81132075, 0.81761006,\n",
      "       0.80503145, 0.81761006, 0.79245283, 0.81761006, 0.80503145,\n",
      "       0.79245283, 0.79245283, 0.77358491, 0.79874214, 0.79245283,\n",
      "       0.80503145, 0.79874214, 0.81132075, 0.78616352, 0.81132075,\n",
      "       0.81132075, 0.77987421, 0.79245283, 0.81761006, 0.81761006,\n",
      "       0.79874214, 0.74842767, 0.77358491, 0.81132075, 0.78616352,\n",
      "       0.79245283, 0.77987421, 0.77987421, 0.78616352, 0.77358491,\n",
      "       0.79245283, 0.79874214, 0.79245283, 0.77987421, 0.7672956 ,\n",
      "       0.74842767, 0.79874214, 0.79245283, 0.7672956 , 0.79245283,\n",
      "       0.78616352, 0.79245283, 0.79245283, 0.80503145, 0.78616352,\n",
      "       0.76100629, 0.79874214, 0.77358491, 0.82389937, 0.79245283,\n",
      "       0.79245283, 0.7672956 , 0.79245283, 0.73584906, 0.75471698,\n",
      "       0.77987421, 0.78616352, 0.76100629, 0.77358491, 0.71069182,\n",
      "       0.81132075, 0.74213836, 0.76100629, 0.77358491, 0.81761006,\n",
      "       0.77987421, 0.77358491, 0.78616352, 0.76100629, 0.75471698,\n",
      "       0.77987421, 0.77358491, 0.74842767, 0.73584906, 0.74213836,\n",
      "       0.7672956 , 0.72327044, 0.72327044, 0.77358491, 0.81132075,\n",
      "       0.77358491, 0.79874214, 0.74213836, 0.72955975, 0.70440252,\n",
      "       0.76100629, 0.74213836, 0.75471698, 0.72955975, 0.72327044,\n",
      "       0.79245283, 0.72327044, 0.7672956 , 0.77358491, 0.78616352,\n",
      "       0.75471698, 0.7672956 , 0.79245283, 0.73584906, 0.77358491,\n",
      "       0.74213836, 0.72955975, 0.72327044, 0.72327044, 0.74213836,\n",
      "       0.79874214, 0.79874214, 0.75471698, 0.7672956 , 0.77987421,\n",
      "       0.75471698, 0.79874214, 0.81132075, 0.71698113, 0.77358491,\n",
      "       0.79874214, 0.74842767, 0.72955975, 0.76100629, 0.7672956 ,\n",
      "       0.7672956 , 0.68553459, 0.71069182, 0.73584906, 0.74842767,\n",
      "       0.76100629, 0.73584906, 0.77987421, 0.7672956 , 0.81132075,\n",
      "       0.81132075, 0.78616352, 0.74842767, 0.79245283, 0.77987421,\n",
      "       0.72955975, 0.76100629, 0.77987421, 0.74842767, 0.74213836,\n",
      "       0.77987421, 0.74842767, 0.73584906, 0.76100629, 0.78616352,\n",
      "       0.74842767, 0.75471698, 0.79874214, 0.73584906, 0.73584906,\n",
      "       0.71069182, 0.76100629, 0.73584906, 0.74213836, 0.74213836,\n",
      "       0.74213836, 0.76100629, 0.69811321, 0.77358491, 0.7672956 ,\n",
      "       0.77987421, 0.75471698, 0.80503145, 0.77358491, 0.70440252,\n",
      "       0.72327044, 0.7672956 , 0.79245283, 0.75471698, 0.76100629,\n",
      "       0.74842767, 0.6918239 , 0.75471698, 0.75471698, 0.7672956 ,\n",
      "       0.72955975, 0.79874214, 0.79874214, 0.80503145, 0.74842767,\n",
      "       0.77987421, 0.76100629, 0.76100629, 0.74213836, 0.74842767,\n",
      "       0.75471698, 0.72955975, 0.7672956 , 0.73584906, 0.74213836,\n",
      "       0.71698113, 0.79245283, 0.82389937, 0.79245283, 0.76100629,\n",
      "       0.80503145, 0.74213836, 0.73584906, 0.78616352, 0.77987421,\n",
      "       0.78616352, 0.74213836, 0.74213836, 0.67295597, 0.78616352,\n",
      "       0.76100629, 0.76100629, 0.76100629, 0.80503145, 0.72955975,\n",
      "       0.75471698, 0.82389937, 0.76100629, 0.79245283, 0.70440252,\n",
      "       0.72955975, 0.7672956 , 0.79874214, 0.74213836, 0.77987421,\n",
      "       0.73584906, 0.73584906, 0.77987421, 0.77358491, 0.73584906,\n",
      "       0.7672956 , 0.7672956 , 0.75471698, 0.72955975, 0.76100629,\n",
      "       0.71698113, 0.78616352, 0.7672956 , 0.77358491, 0.70440252,\n",
      "       0.72327044, 0.74213836, 0.71698113, 0.75471698, 0.77987421,\n",
      "       0.77987421, 0.74842767, 0.74213836, 0.74842767, 0.71698113,\n",
      "       0.72955975, 0.72955975, 0.77358491, 0.75471698, 0.77987421,\n",
      "       0.73584906, 0.70440252, 0.77358491, 0.78616352, 0.74213836,\n",
      "       0.75471698, 0.81132075, 0.79245283, 0.76100629, 0.78616352]), 'split6_test_score': array([0.76100629, 0.76100629, 0.76100629, 0.76100629, 0.78616352,\n",
      "       0.76100629, 0.76100629, 0.76100629, 0.76100629, 0.76100629,\n",
      "       0.76100629, 0.78616352, 0.78616352, 0.78616352, 0.76100629,\n",
      "       0.76100629, 0.77358491, 0.77358491, 0.77987421, 0.77358491,\n",
      "       0.77987421, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77987421, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.83647799, 0.8427673 , 0.8427673 ,\n",
      "       0.80503145, 0.83647799, 0.8427673 , 0.83647799, 0.81761006,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.83018868, 0.8427673 ,\n",
      "       0.8427673 , 0.83647799, 0.8427673 , 0.83647799, 0.83018868,\n",
      "       0.81761006, 0.83647799, 0.82389937, 0.83647799, 0.82389937,\n",
      "       0.83647799, 0.79874214, 0.83018868, 0.81132075, 0.82389937,\n",
      "       0.83647799, 0.83647799, 0.83647799, 0.8427673 , 0.81132075,\n",
      "       0.80503145, 0.79245283, 0.83647799, 0.78616352, 0.81761006,\n",
      "       0.83018868, 0.83647799, 0.8427673 , 0.82389937, 0.83018868,\n",
      "       0.81761006, 0.8427673 , 0.82389937, 0.8427673 , 0.83647799,\n",
      "       0.78616352, 0.75471698, 0.80503145, 0.83018868, 0.81132075,\n",
      "       0.7672956 , 0.80503145, 0.81132075, 0.83018868, 0.81132075,\n",
      "       0.83018868, 0.82389937, 0.81132075, 0.83647799, 0.83018868,\n",
      "       0.83018868, 0.76100629, 0.79245283, 0.79245283, 0.78616352,\n",
      "       0.80503145, 0.79245283, 0.82389937, 0.77358491, 0.79245283,\n",
      "       0.82389937, 0.82389937, 0.82389937, 0.80503145, 0.79874214,\n",
      "       0.81132075, 0.78616352, 0.81132075, 0.77987421, 0.78616352,\n",
      "       0.81761006, 0.83647799, 0.80503145, 0.79245283, 0.8427673 ,\n",
      "       0.79874214, 0.81132075, 0.81761006, 0.79245283, 0.80503145,\n",
      "       0.83018868, 0.83647799, 0.81132075, 0.7672956 , 0.78616352,\n",
      "       0.79874214, 0.79245283, 0.81132075, 0.7672956 , 0.81761006,\n",
      "       0.79245283, 0.8427673 , 0.82389937, 0.81132075, 0.78616352,\n",
      "       0.8427673 , 0.77987421, 0.83647799, 0.82389937, 0.77987421,\n",
      "       0.78616352, 0.75471698, 0.7672956 , 0.76100629, 0.78616352,\n",
      "       0.80503145, 0.79245283, 0.77987421, 0.78616352, 0.80503145,\n",
      "       0.8427673 , 0.79874214, 0.83018868, 0.77987421, 0.78616352,\n",
      "       0.79245283, 0.7672956 , 0.74213836, 0.80503145, 0.79245283,\n",
      "       0.80503145, 0.79245283, 0.74213836, 0.81761006, 0.78616352,\n",
      "       0.79874214, 0.79245283, 0.82389937, 0.79245283, 0.74213836,\n",
      "       0.80503145, 0.77358491, 0.76100629, 0.79874214, 0.79874214,\n",
      "       0.81761006, 0.77358491, 0.81761006, 0.78616352, 0.77987421,\n",
      "       0.77987421, 0.80503145, 0.82389937, 0.77358491, 0.83647799,\n",
      "       0.77358491, 0.81761006, 0.7672956 , 0.79874214, 0.81132075,\n",
      "       0.77987421, 0.80503145, 0.80503145, 0.78616352, 0.75471698,\n",
      "       0.80503145, 0.80503145, 0.77987421, 0.79874214, 0.83018868,\n",
      "       0.80503145, 0.81132075, 0.8427673 , 0.78616352, 0.80503145,\n",
      "       0.77358491, 0.79874214, 0.81761006, 0.77358491, 0.79874214,\n",
      "       0.79245283, 0.76100629, 0.79245283, 0.71698113, 0.79874214,\n",
      "       0.79245283, 0.8427673 , 0.8427673 , 0.79874214, 0.78616352,\n",
      "       0.77987421, 0.77358491, 0.82389937, 0.78616352, 0.81132075,\n",
      "       0.77358491, 0.73584906, 0.81761006, 0.81761006, 0.77987421,\n",
      "       0.83018868, 0.82389937, 0.78616352, 0.81761006, 0.80503145,\n",
      "       0.7672956 , 0.7672956 , 0.81132075, 0.83018868, 0.7672956 ,\n",
      "       0.81132075, 0.77358491, 0.69811321, 0.79245283, 0.79245283,\n",
      "       0.81132075, 0.83018868, 0.82389937, 0.79245283, 0.81132075,\n",
      "       0.77987421, 0.75471698, 0.73584906, 0.78616352, 0.79874214,\n",
      "       0.77358491, 0.80503145, 0.77358491, 0.74842767, 0.78616352,\n",
      "       0.78616352, 0.77358491, 0.77358491, 0.83647799, 0.79874214,\n",
      "       0.80503145, 0.7672956 , 0.80503145, 0.80503145, 0.77358491,\n",
      "       0.83018868, 0.80503145, 0.79874214, 0.76100629, 0.8427673 ,\n",
      "       0.77987421, 0.82389937, 0.81132075, 0.79874214, 0.82389937,\n",
      "       0.82389937, 0.82389937, 0.79874214, 0.77987421, 0.79874214,\n",
      "       0.78616352, 0.82389937, 0.77987421, 0.81132075, 0.77987421,\n",
      "       0.78616352, 0.79245283, 0.81132075, 0.78616352, 0.83647799,\n",
      "       0.82389937, 0.83647799, 0.74842767, 0.79874214, 0.81761006,\n",
      "       0.7672956 , 0.81761006, 0.82389937, 0.80503145, 0.74213836,\n",
      "       0.79874214, 0.72955975, 0.81761006, 0.72327044, 0.79874214,\n",
      "       0.77987421, 0.79874214, 0.79874214, 0.83018868, 0.83018868]), 'split7_test_score': array([0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.81132075, 0.82389937, 0.79874214,\n",
      "       0.82389937, 0.82389937, 0.82389937, 0.81132075, 0.81132075,\n",
      "       0.79874214, 0.80503145, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.79874214, 0.79874214, 0.81132075, 0.79874214,\n",
      "       0.80503145, 0.82389937, 0.81132075, 0.80503145, 0.81132075,\n",
      "       0.80503145, 0.79245283, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.79874214, 0.81132075, 0.81761006,\n",
      "       0.81761006, 0.79245283, 0.81132075, 0.81132075, 0.80503145,\n",
      "       0.80503145, 0.82389937, 0.79874214, 0.77358491, 0.78616352,\n",
      "       0.72955975, 0.82389937, 0.79874214, 0.77987421, 0.79874214,\n",
      "       0.79874214, 0.81132075, 0.77358491, 0.76100629, 0.81761006,\n",
      "       0.77358491, 0.77358491, 0.79874214, 0.74842767, 0.76100629,\n",
      "       0.75471698, 0.81132075, 0.79245283, 0.76100629, 0.7672956 ,\n",
      "       0.81132075, 0.77987421, 0.80503145, 0.76100629, 0.78616352,\n",
      "       0.78616352, 0.76100629, 0.7672956 , 0.74842767, 0.7672956 ,\n",
      "       0.76100629, 0.72327044, 0.77987421, 0.77358491, 0.79245283,\n",
      "       0.75471698, 0.77987421, 0.77987421, 0.75471698, 0.79245283,\n",
      "       0.81132075, 0.78616352, 0.78616352, 0.72955975, 0.78616352,\n",
      "       0.76100629, 0.76100629, 0.75471698, 0.77987421, 0.79874214,\n",
      "       0.77987421, 0.74842767, 0.76100629, 0.77987421, 0.79245283,\n",
      "       0.79874214, 0.77987421, 0.78616352, 0.77358491, 0.80503145,\n",
      "       0.80503145, 0.76100629, 0.7672956 , 0.74842767, 0.76100629,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.79245283, 0.75471698,\n",
      "       0.77987421, 0.77358491, 0.71698113, 0.73584906, 0.74213836,\n",
      "       0.77987421, 0.80503145, 0.73584906, 0.74213836, 0.7672956 ,\n",
      "       0.73584906, 0.79874214, 0.77987421, 0.80503145, 0.76100629,\n",
      "       0.69811321, 0.72955975, 0.75471698, 0.73584906, 0.78616352,\n",
      "       0.76100629, 0.79245283, 0.78616352, 0.74213836, 0.77358491,\n",
      "       0.74213836, 0.7672956 , 0.7672956 , 0.79874214, 0.7672956 ,\n",
      "       0.76100629, 0.74842767, 0.7672956 , 0.7672956 , 0.7672956 ,\n",
      "       0.79874214, 0.79245283, 0.77987421, 0.79245283, 0.81132075,\n",
      "       0.77987421, 0.7672956 , 0.77987421, 0.79874214, 0.78616352,\n",
      "       0.74213836, 0.77358491, 0.77987421, 0.74842767, 0.76100629,\n",
      "       0.74842767, 0.74842767, 0.79874214, 0.77987421, 0.78616352,\n",
      "       0.74842767, 0.76100629, 0.69811321, 0.78616352, 0.75471698,\n",
      "       0.76100629, 0.7672956 , 0.79874214, 0.71069182, 0.79245283,\n",
      "       0.72327044, 0.7672956 , 0.74842767, 0.78616352, 0.7672956 ,\n",
      "       0.76100629, 0.7672956 , 0.7672956 , 0.73584906, 0.6918239 ,\n",
      "       0.79245283, 0.79245283, 0.77987421, 0.7672956 , 0.69811321,\n",
      "       0.74213836, 0.72327044, 0.74842767, 0.77987421, 0.78616352,\n",
      "       0.76100629, 0.81761006, 0.77358491, 0.75471698, 0.77987421,\n",
      "       0.7672956 , 0.78616352, 0.7672956 , 0.81132075, 0.76100629,\n",
      "       0.77358491, 0.75471698, 0.77358491, 0.74842767, 0.78616352,\n",
      "       0.77358491, 0.74842767, 0.79874214, 0.76100629, 0.72955975,\n",
      "       0.77987421, 0.7672956 , 0.76100629, 0.80503145, 0.81132075,\n",
      "       0.75471698, 0.73584906, 0.77358491, 0.76100629, 0.78616352,\n",
      "       0.76100629, 0.77987421, 0.77987421, 0.78616352, 0.75471698,\n",
      "       0.7672956 , 0.7672956 , 0.77358491, 0.77987421, 0.79245283,\n",
      "       0.78616352, 0.68553459, 0.73584906, 0.77358491, 0.72327044,\n",
      "       0.79874214, 0.77358491, 0.71069182, 0.77358491, 0.81761006,\n",
      "       0.74842767, 0.72955975, 0.75471698, 0.77358491, 0.74213836,\n",
      "       0.79245283, 0.77358491, 0.76100629, 0.76100629, 0.76100629,\n",
      "       0.77358491, 0.76100629, 0.77987421, 0.76100629, 0.77987421,\n",
      "       0.72327044, 0.74842767, 0.7672956 , 0.72327044, 0.78616352,\n",
      "       0.81132075, 0.78616352, 0.79874214, 0.77987421, 0.72327044,\n",
      "       0.80503145, 0.74842767, 0.77358491, 0.72955975, 0.75471698,\n",
      "       0.7672956 , 0.72327044, 0.76100629, 0.75471698, 0.74213836,\n",
      "       0.7672956 , 0.73584906, 0.7672956 , 0.77358491, 0.79245283]), 'split8_test_score': array([0.80503145, 0.80503145, 0.80503145, 0.79245283, 0.80503145,\n",
      "       0.79245283, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.79245283, 0.80503145, 0.80503145, 0.79245283,\n",
      "       0.80503145, 0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 ,\n",
      "       0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 , 0.74213836,\n",
      "       0.7672956 , 0.76100629, 0.7672956 , 0.7672956 , 0.7672956 ,\n",
      "       0.7672956 , 0.74842767, 0.82389937, 0.82389937, 0.8490566 ,\n",
      "       0.8490566 , 0.82389937, 0.77987421, 0.8490566 , 0.8490566 ,\n",
      "       0.82389937, 0.82389937, 0.77987421, 0.82389937, 0.82389937,\n",
      "       0.8490566 , 0.8490566 , 0.82389937, 0.83647799, 0.82389937,\n",
      "       0.80503145, 0.81761006, 0.82389937, 0.82389937, 0.82389937,\n",
      "       0.82389937, 0.8490566 , 0.81132075, 0.83647799, 0.83018868,\n",
      "       0.81761006, 0.82389937, 0.77987421, 0.81132075, 0.79874214,\n",
      "       0.82389937, 0.77987421, 0.82389937, 0.8490566 , 0.77987421,\n",
      "       0.81761006, 0.81761006, 0.83018868, 0.81761006, 0.82389937,\n",
      "       0.83018868, 0.81761006, 0.82389937, 0.81761006, 0.81132075,\n",
      "       0.83018868, 0.81761006, 0.83647799, 0.81132075, 0.81761006,\n",
      "       0.8490566 , 0.82389937, 0.83647799, 0.82389937, 0.80503145,\n",
      "       0.81761006, 0.86163522, 0.8427673 , 0.8490566 , 0.82389937,\n",
      "       0.81132075, 0.79874214, 0.81761006, 0.82389937, 0.76100629,\n",
      "       0.83647799, 0.81761006, 0.82389937, 0.83018868, 0.8490566 ,\n",
      "       0.81761006, 0.81132075, 0.79874214, 0.7672956 , 0.80503145,\n",
      "       0.8427673 , 0.8490566 , 0.81132075, 0.80503145, 0.82389937,\n",
      "       0.79874214, 0.77358491, 0.81132075, 0.79245283, 0.83018868,\n",
      "       0.79874214, 0.8427673 , 0.83647799, 0.83647799, 0.83647799,\n",
      "       0.83647799, 0.83018868, 0.82389937, 0.82389937, 0.8427673 ,\n",
      "       0.81761006, 0.81132075, 0.80503145, 0.79245283, 0.82389937,\n",
      "       0.77987421, 0.81761006, 0.79245283, 0.82389937, 0.81132075,\n",
      "       0.82389937, 0.77358491, 0.81761006, 0.79874214, 0.81761006,\n",
      "       0.80503145, 0.79874214, 0.81761006, 0.81761006, 0.79874214,\n",
      "       0.83018868, 0.77987421, 0.81132075, 0.78616352, 0.82389937,\n",
      "       0.82389937, 0.83018868, 0.81761006, 0.83018868, 0.7672956 ,\n",
      "       0.78616352, 0.80503145, 0.81132075, 0.78616352, 0.79874214,\n",
      "       0.79874214, 0.81132075, 0.8427673 , 0.83018868, 0.83647799,\n",
      "       0.77987421, 0.80503145, 0.81132075, 0.81761006, 0.7672956 ,\n",
      "       0.81761006, 0.79874214, 0.81132075, 0.77358491, 0.81132075,\n",
      "       0.77987421, 0.79874214, 0.77358491, 0.81761006, 0.81761006,\n",
      "       0.81132075, 0.81132075, 0.80503145, 0.8427673 , 0.83647799,\n",
      "       0.79874214, 0.81132075, 0.79245283, 0.81761006, 0.79874214,\n",
      "       0.79245283, 0.83647799, 0.81132075, 0.79245283, 0.81761006,\n",
      "       0.79245283, 0.81132075, 0.83647799, 0.79245283, 0.83018868,\n",
      "       0.81761006, 0.80503145, 0.82389937, 0.78616352, 0.77987421,\n",
      "       0.79874214, 0.76100629, 0.81132075, 0.8427673 , 0.79874214,\n",
      "       0.81761006, 0.81132075, 0.82389937, 0.81132075, 0.82389937,\n",
      "       0.79245283, 0.81761006, 0.79874214, 0.82389937, 0.77987421,\n",
      "       0.77987421, 0.80503145, 0.81132075, 0.79874214, 0.81132075,\n",
      "       0.80503145, 0.79874214, 0.79874214, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.74213836, 0.82389937, 0.76100629, 0.83018868,\n",
      "       0.81132075, 0.81132075, 0.78616352, 0.82389937, 0.80503145,\n",
      "       0.80503145, 0.79874214, 0.77987421, 0.81132075, 0.81132075,\n",
      "       0.81761006, 0.74842767, 0.79874214, 0.82389937, 0.81132075,\n",
      "       0.81132075, 0.79245283, 0.79874214, 0.77987421, 0.82389937,\n",
      "       0.83647799, 0.81132075, 0.79874214, 0.80503145, 0.83647799,\n",
      "       0.79874214, 0.79245283, 0.7672956 , 0.83018868, 0.81761006,\n",
      "       0.83647799, 0.79245283, 0.78616352, 0.81132075, 0.7672956 ,\n",
      "       0.82389937, 0.81761006, 0.81761006, 0.79874214, 0.77358491,\n",
      "       0.79874214, 0.79874214, 0.80503145, 0.81761006, 0.82389937,\n",
      "       0.83018868, 0.83018868, 0.81132075, 0.77987421, 0.77358491,\n",
      "       0.78616352, 0.81761006, 0.77987421, 0.80503145, 0.77987421,\n",
      "       0.8490566 , 0.79874214, 0.82389937, 0.81761006, 0.83018868,\n",
      "       0.79874214, 0.81761006, 0.81132075, 0.81132075, 0.80503145,\n",
      "       0.76100629, 0.78616352, 0.85534591, 0.83647799, 0.83647799,\n",
      "       0.79874214, 0.77987421, 0.81132075, 0.79245283, 0.8427673 ,\n",
      "       0.79245283, 0.81761006, 0.8490566 , 0.79874214, 0.82389937]), 'split9_test_score': array([0.80379747, 0.80379747, 0.80379747, 0.81012658, 0.80379747,\n",
      "       0.80379747, 0.80379747, 0.80379747, 0.80379747, 0.81012658,\n",
      "       0.80379747, 0.80379747, 0.81012658, 0.80379747, 0.80379747,\n",
      "       0.80379747, 0.74683544, 0.74050633, 0.74050633, 0.74050633,\n",
      "       0.74050633, 0.74683544, 0.74683544, 0.74683544, 0.74683544,\n",
      "       0.74683544, 0.74050633, 0.74683544, 0.74683544, 0.74683544,\n",
      "       0.74683544, 0.74683544, 0.83544304, 0.83544304, 0.83544304,\n",
      "       0.83544304, 0.85443038, 0.83544304, 0.84810127, 0.85443038,\n",
      "       0.83544304, 0.83544304, 0.83544304, 0.83544304, 0.83544304,\n",
      "       0.83544304, 0.83544304, 0.85443038, 0.84810127, 0.85443038,\n",
      "       0.84177215, 0.82278481, 0.84810127, 0.84177215, 0.84810127,\n",
      "       0.80379747, 0.82278481, 0.84810127, 0.84810127, 0.84177215,\n",
      "       0.81012658, 0.80379747, 0.83544304, 0.85443038, 0.83544304,\n",
      "       0.82911392, 0.84177215, 0.84810127, 0.82278481, 0.83544304,\n",
      "       0.85443038, 0.85443038, 0.84810127, 0.81012658, 0.84810127,\n",
      "       0.74683544, 0.8164557 , 0.85443038, 0.84810127, 0.80379747,\n",
      "       0.84177215, 0.82911392, 0.77848101, 0.79113924, 0.8164557 ,\n",
      "       0.83544304, 0.7721519 , 0.80379747, 0.84177215, 0.80379747,\n",
      "       0.82911392, 0.79746835, 0.8164557 , 0.74683544, 0.81012658,\n",
      "       0.82278481, 0.81012658, 0.84177215, 0.84177215, 0.8164557 ,\n",
      "       0.8164557 , 0.83544304, 0.78481013, 0.79113924, 0.82278481,\n",
      "       0.82911392, 0.84177215, 0.85443038, 0.8164557 , 0.81012658,\n",
      "       0.82911392, 0.82911392, 0.8164557 , 0.79113924, 0.82278481,\n",
      "       0.79113924, 0.79746835, 0.80379747, 0.81012658, 0.81012658,\n",
      "       0.74050633, 0.8164557 , 0.81012658, 0.82911392, 0.7721519 ,\n",
      "       0.82911392, 0.82278481, 0.78481013, 0.79113924, 0.81012658,\n",
      "       0.79746835, 0.78481013, 0.80379747, 0.82911392, 0.82911392,\n",
      "       0.82911392, 0.82911392, 0.7721519 , 0.85443038, 0.76582278,\n",
      "       0.8164557 , 0.82278481, 0.8164557 , 0.81012658, 0.8164557 ,\n",
      "       0.80379747, 0.81012658, 0.81012658, 0.81012658, 0.81012658,\n",
      "       0.79746835, 0.81012658, 0.79113924, 0.84810127, 0.80379747,\n",
      "       0.84177215, 0.8164557 , 0.77848101, 0.76582278, 0.78481013,\n",
      "       0.75316456, 0.80379747, 0.82911392, 0.82911392, 0.8164557 ,\n",
      "       0.81012658, 0.79746835, 0.79746835, 0.84177215, 0.83544304,\n",
      "       0.75316456, 0.76582278, 0.8164557 , 0.77848101, 0.79113924,\n",
      "       0.8164557 , 0.82911392, 0.78481013, 0.79746835, 0.83544304,\n",
      "       0.80379747, 0.80379747, 0.8164557 , 0.82911392, 0.82278481,\n",
      "       0.78481013, 0.81012658, 0.78481013, 0.75949367, 0.84177215,\n",
      "       0.82278481, 0.8164557 , 0.79746835, 0.81012658, 0.8164557 ,\n",
      "       0.82278481, 0.80379747, 0.79746835, 0.79113924, 0.78481013,\n",
      "       0.82911392, 0.77848101, 0.80379747, 0.75316456, 0.81012658,\n",
      "       0.76582278, 0.79113924, 0.72151899, 0.79113924, 0.75949367,\n",
      "       0.80379747, 0.85443038, 0.83544304, 0.8164557 , 0.75949367,\n",
      "       0.7721519 , 0.7721519 , 0.80379747, 0.80379747, 0.7721519 ,\n",
      "       0.75316456, 0.7721519 , 0.82911392, 0.78481013, 0.84177215,\n",
      "       0.81012658, 0.79113924, 0.8164557 , 0.80379747, 0.79746835,\n",
      "       0.82911392, 0.83544304, 0.78481013, 0.79746835, 0.75316456,\n",
      "       0.7721519 , 0.79746835, 0.8164557 , 0.82911392, 0.8164557 ,\n",
      "       0.79746835, 0.74683544, 0.7721519 , 0.82278481, 0.81012658,\n",
      "       0.79746835, 0.81012658, 0.8164557 , 0.81012658, 0.81012658,\n",
      "       0.81012658, 0.8164557 , 0.81012658, 0.81012658, 0.80379747,\n",
      "       0.81012658, 0.80379747, 0.7721519 , 0.76582278, 0.79113924,\n",
      "       0.75949367, 0.8164557 , 0.8164557 , 0.79746835, 0.79113924,\n",
      "       0.81012658, 0.82911392, 0.78481013, 0.79113924, 0.82911392,\n",
      "       0.82278481, 0.79746835, 0.79746835, 0.81012658, 0.81012658,\n",
      "       0.8164557 , 0.8164557 , 0.7721519 , 0.83544304, 0.79113924,\n",
      "       0.82911392, 0.84810127, 0.74050633, 0.70886076, 0.80379747,\n",
      "       0.80379747, 0.81012658, 0.8164557 , 0.79113924, 0.80379747,\n",
      "       0.79113924, 0.78481013, 0.81012658, 0.79746835, 0.79113924,\n",
      "       0.8164557 , 0.81012658, 0.8164557 , 0.81012658, 0.7721519 ,\n",
      "       0.82911392, 0.8164557 , 0.81012658, 0.83544304, 0.81012658,\n",
      "       0.80379747, 0.78481013, 0.8164557 , 0.81012658, 0.78481013,\n",
      "       0.82911392, 0.8164557 , 0.77848101, 0.75949367, 0.79746835,\n",
      "       0.82278481, 0.79113924, 0.8164557 , 0.78481013, 0.80379747]), 'mean_test_score': array([0.77849295, 0.7753483 , 0.77660616, 0.77849693, 0.78415333,\n",
      "       0.78100868, 0.78037975, 0.78226654, 0.78037975, 0.77912587,\n",
      "       0.77660616, 0.77975082, 0.78227052, 0.78415333, 0.7753483 ,\n",
      "       0.77849295, 0.74826845, 0.74763554, 0.74386195, 0.74574875,\n",
      "       0.7488934 , 0.74889738, 0.74701059, 0.74826845, 0.7451238 ,\n",
      "       0.74826845, 0.74700661, 0.74826845, 0.74701059, 0.74763952,\n",
      "       0.74763952, 0.74575273, 0.81939336, 0.83008518, 0.82442481,\n",
      "       0.82065122, 0.82443675, 0.82065122, 0.82820635, 0.82569461,\n",
      "       0.82065122, 0.82065122, 0.81561978, 0.81876443, 0.82190908,\n",
      "       0.82065122, 0.81939336, 0.82066316, 0.82380384, 0.81877637,\n",
      "       0.81059231, 0.81309609, 0.82191704, 0.8206552 , 0.81814346,\n",
      "       0.81182629, 0.80869358, 0.82003025, 0.81877239, 0.81813948,\n",
      "       0.81497492, 0.82000239, 0.8099594 , 0.81688958, 0.81058833,\n",
      "       0.80932649, 0.79990049, 0.81122522, 0.81183823, 0.80807261,\n",
      "       0.81563172, 0.81688958, 0.81877239, 0.80554096, 0.81877239,\n",
      "       0.79795398, 0.80554494, 0.81248706, 0.81436988, 0.8080527 ,\n",
      "       0.80367407, 0.79611894, 0.79357137, 0.8030133 , 0.80931853,\n",
      "       0.80241223, 0.79608311, 0.79484516, 0.80681872, 0.79547409,\n",
      "       0.79989252, 0.80867765, 0.80868959, 0.79795398, 0.79736486,\n",
      "       0.80366213, 0.79296234, 0.80493193, 0.79927155, 0.78604809,\n",
      "       0.79988456, 0.80052544, 0.79672001, 0.79672399, 0.80743571,\n",
      "       0.79611894, 0.7961269 , 0.80493989, 0.79548205, 0.79673593,\n",
      "       0.80177932, 0.80177932, 0.78793488, 0.78540323, 0.79611496,\n",
      "       0.79483719, 0.79232545, 0.79547409, 0.78667304, 0.78855983,\n",
      "       0.78222673, 0.78982167, 0.78918876, 0.78794284, 0.79671205,\n",
      "       0.79171642, 0.79800175, 0.79734894, 0.78854789, 0.79799379,\n",
      "       0.78603614, 0.78728604, 0.7835244 , 0.78416925, 0.79297429,\n",
      "       0.78857177, 0.78857177, 0.78098877, 0.79613486, 0.78853196,\n",
      "       0.80051349, 0.79674389, 0.78856381, 0.79547807, 0.7740984 ,\n",
      "       0.79107157, 0.78918876, 0.78038373, 0.7715787 , 0.78352838,\n",
      "       0.78603614, 0.77912587, 0.77911392, 0.78355226, 0.79673195,\n",
      "       0.79549797, 0.79673991, 0.80614999, 0.78475838, 0.78728604,\n",
      "       0.76651142, 0.77660616, 0.77159064, 0.77473529, 0.77850092,\n",
      "       0.7860441 , 0.78855187, 0.78729401, 0.78229042, 0.79486506,\n",
      "       0.77091394, 0.78350052, 0.80994746, 0.78539527, 0.78288751,\n",
      "       0.79673991, 0.76593026, 0.76778919, 0.76653929, 0.78668896,\n",
      "       0.79673195, 0.77283258, 0.77975878, 0.79108749, 0.78919672,\n",
      "       0.78665711, 0.78730197, 0.79231749, 0.78789905, 0.81185017,\n",
      "       0.78227848, 0.80114242, 0.77031287, 0.78038373, 0.78416129,\n",
      "       0.7766181 , 0.79232943, 0.79609904, 0.78666109, 0.77596529,\n",
      "       0.78794284, 0.77973489, 0.77283258, 0.78978186, 0.79799379,\n",
      "       0.78350052, 0.78414537, 0.78913303, 0.76590638, 0.77532044,\n",
      "       0.76843006, 0.78041159, 0.78165751, 0.78604809, 0.77909402,\n",
      "       0.77973091, 0.77658626, 0.78037975, 0.77094578, 0.7835045 ,\n",
      "       0.79166866, 0.79356739, 0.79863466, 0.79672001, 0.76153571,\n",
      "       0.76906297, 0.77722713, 0.79673991, 0.77849295, 0.77660218,\n",
      "       0.79234535, 0.78039965, 0.7822546 , 0.78729401, 0.77909004,\n",
      "       0.78790701, 0.79043866, 0.78793488, 0.80240825, 0.79296632,\n",
      "       0.77534432, 0.77468354, 0.77847305, 0.786681  , 0.78981769,\n",
      "       0.7791179 , 0.77535228, 0.77912985, 0.78101266, 0.77472335,\n",
      "       0.7879309 , 0.78038771, 0.79988058, 0.79988058, 0.79358729,\n",
      "       0.79736486, 0.75710931, 0.76841016, 0.77721121, 0.79672399,\n",
      "       0.77972295, 0.78793488, 0.77912985, 0.7728286 , 0.79232147,\n",
      "       0.78289945, 0.77473529, 0.78288353, 0.8111894 , 0.79863466,\n",
      "       0.79234137, 0.7810047 , 0.76842608, 0.79673593, 0.77032083,\n",
      "       0.79296632, 0.79296632, 0.7753284 , 0.78417323, 0.79546613,\n",
      "       0.78982963, 0.78669692, 0.77656636, 0.78535148, 0.79107157,\n",
      "       0.80931056, 0.79547807, 0.78541915, 0.77093782, 0.77786402,\n",
      "       0.77282462, 0.7904307 , 0.78101266, 0.78792294, 0.77596927,\n",
      "       0.79296632, 0.7797548 , 0.78479022, 0.78541517, 0.78539129,\n",
      "       0.79989252, 0.79736884, 0.78855983, 0.79800971, 0.76025794,\n",
      "       0.76276968, 0.77344957, 0.80302922, 0.78918876, 0.78099674,\n",
      "       0.77725102, 0.77095375, 0.77281665, 0.77028899, 0.77408646,\n",
      "       0.78353634, 0.79232147, 0.79799777, 0.7904307 , 0.79673195]), 'std_test_score': array([0.02178558, 0.02088679, 0.02342873, 0.02157313, 0.0185337 ,\n",
      "       0.01824371, 0.02154988, 0.01938719, 0.02154988, 0.02095347,\n",
      "       0.020162  , 0.01993473, 0.01893966, 0.01743395, 0.02217285,\n",
      "       0.02178558, 0.02756251, 0.03191027, 0.03317968, 0.03296773,\n",
      "       0.0312909 , 0.03175997, 0.02946972, 0.03132414, 0.03171611,\n",
      "       0.02841053, 0.03055826, 0.02756251, 0.02837561, 0.03175366,\n",
      "       0.03237052, 0.03133661, 0.02890591, 0.02194016, 0.02856614,\n",
      "       0.0268091 , 0.02823139, 0.02824604, 0.02705998, 0.02629132,\n",
      "       0.02796456, 0.0268091 , 0.03049104, 0.02505505, 0.02572991,\n",
      "       0.02880075, 0.03152417, 0.02310136, 0.02995227, 0.02652944,\n",
      "       0.0272196 , 0.02298187, 0.02393364, 0.02314388, 0.02932681,\n",
      "       0.02463019, 0.03039614, 0.02460264, 0.02937602, 0.02367391,\n",
      "       0.02202698, 0.02136296, 0.02786114, 0.03451353, 0.02635325,\n",
      "       0.02762993, 0.03103317, 0.03329165, 0.02548954, 0.03213359,\n",
      "       0.02533623, 0.03176836, 0.02841783, 0.02407998, 0.02799714,\n",
      "       0.04223483, 0.03257308, 0.02781832, 0.03321147, 0.02537101,\n",
      "       0.02866024, 0.03900288, 0.03616319, 0.02955636, 0.02528686,\n",
      "       0.03223215, 0.02105625, 0.0275445 , 0.03221199, 0.02196275,\n",
      "       0.03315997, 0.02676358, 0.02783802, 0.0379948 , 0.03308899,\n",
      "       0.03109833, 0.03130984, 0.02977466, 0.03414457, 0.01846476,\n",
      "       0.03059233, 0.03411614, 0.03345021, 0.03560169, 0.03103547,\n",
      "       0.02802666, 0.03513471, 0.02893697, 0.03177473, 0.02525602,\n",
      "       0.02996433, 0.02660818, 0.02966027, 0.03270923, 0.03073849,\n",
      "       0.03222964, 0.03091576, 0.0302898 , 0.03215869, 0.04022529,\n",
      "       0.03217902, 0.03595456, 0.03519784, 0.03015173, 0.0202661 ,\n",
      "       0.04021428, 0.04024543, 0.03306623, 0.0310789 , 0.02639524,\n",
      "       0.03553469, 0.02350954, 0.02476905, 0.03654469, 0.0360696 ,\n",
      "       0.02106407, 0.0428491 , 0.03017515, 0.03589219, 0.01908075,\n",
      "       0.03286963, 0.02802832, 0.03124095, 0.03142031, 0.03827691,\n",
      "       0.02425842, 0.03311327, 0.04668818, 0.0296159 , 0.03472026,\n",
      "       0.03474675, 0.03507358, 0.02841083, 0.02958391, 0.03253612,\n",
      "       0.04723891, 0.02733636, 0.03065061, 0.03438824, 0.01819858,\n",
      "       0.03666687, 0.03671409, 0.03112717, 0.04808828, 0.02588219,\n",
      "       0.02374274, 0.01966742, 0.0384064 , 0.04567374, 0.0381659 ,\n",
      "       0.02400987, 0.03854823, 0.02207447, 0.04111413, 0.03291614,\n",
      "       0.02630397, 0.03017165, 0.03865206, 0.03124913, 0.03221233,\n",
      "       0.02024576, 0.03912199, 0.03168637, 0.03945293, 0.03071984,\n",
      "       0.02734111, 0.03145845, 0.03084148, 0.03004555, 0.02347959,\n",
      "       0.03479579, 0.02589148, 0.03448894, 0.02676259, 0.02404661,\n",
      "       0.03350909, 0.03862935, 0.02321725, 0.02374689, 0.03730112,\n",
      "       0.0294885 , 0.02653791, 0.04451361, 0.02721312, 0.03256714,\n",
      "       0.04409998, 0.02620433, 0.04386394, 0.0373081 , 0.02225903,\n",
      "       0.03140618, 0.02919313, 0.03564773, 0.03679083, 0.03636651,\n",
      "       0.0251967 , 0.02409508, 0.03554457, 0.036037  , 0.03933588,\n",
      "       0.0351227 , 0.03519232, 0.03121407, 0.02017225, 0.04834348,\n",
      "       0.03116783, 0.03090328, 0.02258194, 0.03490348, 0.02903449,\n",
      "       0.03467546, 0.04456077, 0.02485538, 0.03392193, 0.03757198,\n",
      "       0.04233946, 0.03782015, 0.03121962, 0.03333467, 0.02766571,\n",
      "       0.02687811, 0.0380378 , 0.03720865, 0.03650168, 0.03508179,\n",
      "       0.02920849, 0.02741214, 0.04010839, 0.03326858, 0.03300718,\n",
      "       0.04165818, 0.0434265 , 0.03150616, 0.02645616, 0.03187931,\n",
      "       0.03260732, 0.03822805, 0.03239343, 0.01605914, 0.02843655,\n",
      "       0.02737801, 0.03626074, 0.02613592, 0.04443992, 0.03068507,\n",
      "       0.03224297, 0.02166105, 0.02814959, 0.03251593, 0.03341733,\n",
      "       0.03171309, 0.03797111, 0.02513306, 0.02835488, 0.04238005,\n",
      "       0.04054037, 0.02100089, 0.03341532, 0.03348091, 0.03272545,\n",
      "       0.0312091 , 0.04499881, 0.02794428, 0.03906999, 0.03671423,\n",
      "       0.02966056, 0.03465307, 0.02676159, 0.02777419, 0.03775929,\n",
      "       0.0369758 , 0.03184918, 0.03028089, 0.02864559, 0.03324143,\n",
      "       0.04541815, 0.02841582, 0.03466096, 0.02918778, 0.0419932 ,\n",
      "       0.03375114, 0.03909783, 0.03662221, 0.03297642, 0.04152165,\n",
      "       0.0320388 , 0.03250915, 0.0310214 , 0.03608569, 0.02835755,\n",
      "       0.03760751, 0.04015879, 0.02715764, 0.03335549, 0.03178168,\n",
      "       0.03158209, 0.02990163, 0.02140143, 0.02306067, 0.02316178]), 'rank_test_score': array([248, 266, 257, 247, 198, 220, 230, 214, 230, 240, 257, 234, 213,\n",
      "       198, 266, 248, 308, 313, 320, 318, 306, 305, 314, 307, 319, 308,\n",
      "       316, 308, 314, 311, 311, 317,  18,   1,   5,  11,   4,  13,   2,\n",
      "         3,  13,  13,  30,  24,   8,  11,  18,   9,   6,  20,  40,  33,\n",
      "         7,  10,  25,  37,  47,  16,  21,  26,  31,  17,  42,  27,  41,\n",
      "        44,  70,  38,  36,  50,  29,  27,  21,  56,  21,  84,  55,  34,\n",
      "        32,  51,  59, 107, 122,  62,  45,  63, 110, 119,  53, 115,  71,\n",
      "        49,  48,  84,  87,  60, 129,  58,  76, 182,  73,  68, 101, 100,\n",
      "        52, 106, 105,  57, 112,  94,  65,  65, 165, 189, 108, 120, 133,\n",
      "       115, 179, 158, 216, 146, 150, 162, 103, 137,  80,  89, 160,  82,\n",
      "       185, 174, 204, 196, 124, 154, 154, 223, 104, 161,  69,  90, 156,\n",
      "       113, 275, 141, 152, 227, 284, 203, 185, 241, 243, 201,  96, 111,\n",
      "        92,  54, 194, 174, 298, 257, 283, 272, 246, 184, 159, 172, 211,\n",
      "       118, 288, 207,  43, 190, 209,  91, 299, 296, 297, 177,  96, 278,\n",
      "       232, 139, 149, 181, 171, 136, 170,  35, 212,  67, 290, 227, 197,\n",
      "       256, 132, 109, 180, 264, 162, 235, 278, 148,  82, 206, 200, 153,\n",
      "       300, 270, 293, 224, 217, 182, 244, 236, 261, 229, 286, 205, 138,\n",
      "       123,  77, 101, 302, 292, 254,  92, 248, 260, 130, 225, 215, 172,\n",
      "       245, 169, 142, 164,  64, 125, 268, 274, 251, 178, 147, 242, 265,\n",
      "       238, 219, 273, 167, 226,  74,  74, 121,  88, 304, 295, 255,  99,\n",
      "       237, 165, 238, 280, 134, 208, 271, 210,  39,  77, 131, 221, 294,\n",
      "        95, 289, 128, 125, 269, 195, 117, 145, 176, 262, 192, 140,  46,\n",
      "       113, 187, 287, 252, 281, 143, 218, 168, 263, 125, 233, 193, 188,\n",
      "       191,  71,  86, 157,  79, 303, 301, 277,  61, 150, 222, 253, 285,\n",
      "       282, 291, 276, 202, 134,  81, 143,  96])}\n",
      "\n",
      "Resultados para Normal:\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('classifier',\n",
      "                                        DecisionTreeClassifier())]),\n",
      "             param_grid={'classifier__max_depth': range(1, 21),\n",
      "                         'classifier__min_samples_leaf': [1, 2, 5, 10],\n",
      "                         'classifier__min_samples_split': [2, 5, 10, 20]},\n",
      "             scoring='accuracy')\n",
      "Accuracy: 0.8442211055276382\n",
      "Precision: 0.9876543209876543\n",
      "Recall: 0.5673758865248227\n",
      "F1 Score: 0.7207207207207208\n",
      "ROC AUC Score: 0.7817424179705825\n",
      "Predictions: [0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\n",
      "Resultados para Balanced:\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('classifier',\n",
      "                                        DecisionTreeClassifier(class_weight='balanced'))]),\n",
      "             param_grid={'classifier__max_depth': range(1, 21),\n",
      "                         'classifier__min_samples_leaf': [1, 2, 5, 10],\n",
      "                         'classifier__min_samples_split': [2, 5, 10, 20]},\n",
      "             scoring='accuracy')\n",
      "Accuracy: 0.8442211055276382\n",
      "Precision: 0.9876543209876543\n",
      "Recall: 0.5673758865248227\n",
      "F1 Score: 0.7207207207207208\n",
      "ROC AUC Score: 0.7817424179705825\n",
      "Predictions: [0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\n",
      "Resultados para OverSampler:\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('sampler', RandomOverSampler()),\n",
      "                                       ('classifier',\n",
      "                                        DecisionTreeClassifier())]),\n",
      "             param_grid={'classifier__max_depth': range(1, 21),\n",
      "                         'classifier__min_samples_leaf': [1, 2, 5, 10],\n",
      "                         'classifier__min_samples_split': [2, 5, 10, 20]},\n",
      "             scoring='accuracy')\n",
      "Accuracy: 0.8442211055276382\n",
      "Precision: 0.9876543209876543\n",
      "Recall: 0.5673758865248227\n",
      "F1 Score: 0.7207207207207208\n",
      "ROC AUC Score: 0.7817424179705825\n",
      "Predictions: [0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\n",
      "Resultados para UnderSampler:\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('sampler', RandomUnderSampler()),\n",
      "                                       ('classifier',\n",
      "                                        DecisionTreeClassifier())]),\n",
      "             param_grid={'classifier__max_depth': range(1, 21),\n",
      "                         'classifier__min_samples_leaf': [1, 2, 5, 10],\n",
      "                         'classifier__min_samples_split': [2, 5, 10, 20]},\n",
      "             scoring='accuracy')\n",
      "Accuracy: 0.8442211055276382\n",
      "Precision: 0.9876543209876543\n",
      "Recall: 0.5673758865248227\n",
      "F1 Score: 0.7207207207207208\n",
      "ROC AUC Score: 0.7817424179705825\n",
      "Predictions: [0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\n",
      "Resultados para SMOTEENN:\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('sampler', SMOTEENN()),\n",
      "                                       ('classifier',\n",
      "                                        DecisionTreeClassifier())]),\n",
      "             param_grid={'classifier__max_depth': range(1, 21),\n",
      "                         'classifier__min_samples_leaf': [1, 2, 5, 10],\n",
      "                         'classifier__min_samples_split': [2, 5, 10, 20]},\n",
      "             scoring='accuracy')\n",
      "Accuracy: 0.8065326633165829\n",
      "Precision: 0.82\n",
      "Recall: 0.5815602836879432\n",
      "F1 Score: 0.6804979253112032\n",
      "ROC AUC Score: 0.7557606865910533\n",
      "Predictions: [0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 1 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0\n",
      " 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 1\n",
      " 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree_balanceado = DecisionTreeClassifier(class_weight='balanced')\n",
    "grid_parametros = {'classifier__max_depth': range(1, 21), \n",
    "                   'classifier__min_samples_leaf': [1, 2, 5, 10],\n",
    "                   'classifier__min_samples_split': [2, 5, 10, 20]}\n",
    "\n",
    "\n",
    "oversampler = RandomOverSampler()\n",
    "undersampler = RandomUnderSampler()\n",
    "combinado = SMOTEENN()\n",
    "\n",
    "\n",
    "normal_pipeline = Pipeline([('classifier', decision_tree)])\n",
    "balanceado_pipeline = Pipeline([('classifier', decision_tree_balanceado)])\n",
    "over_pipeline = ImbPipeline([('sampler', oversampler), ('classifier', decision_tree)])\n",
    "under_pipeline = ImbPipeline([('sampler', undersampler), ('classifier', decision_tree)])\n",
    "combinado_pipeline = ImbPipeline([('sampler', combinado), ('classifier', decision_tree)])\n",
    "\n",
    "\n",
    "resultados = {}\n",
    "\n",
    "\n",
    "for nombre, pipeline in [('Normal', normal_pipeline), ('Balanced', balanceado_pipeline), ('OverSampler', over_pipeline), ('UnderSampler', under_pipeline), ('SMOTEENN', combinado_pipeline)]:\n",
    "    grid_search = GridSearchCV(pipeline, grid_parametros, cv=10, scoring='accuracy')\n",
    "    grid_search.fit(X_train, Y_train)\n",
    "\n",
    "    \n",
    "    print(f\"Resultados para {nombre}:\")\n",
    "    print(grid_search.cv_results_)\n",
    "\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "    Y_pred = best_estimator.predict(X_test)\n",
    "\n",
    "    resultados[nombre] = {\"GridSearchModel\": grid_search,\n",
    "                     \"Accuracy\": accuracy_score(Y_test, Y_pred),\n",
    "                     \"Precision\": precision_score(Y_test, Y_pred),\n",
    "                     \"Recall\": recall_score(Y_test, Y_pred),\n",
    "                     \"F1 Score\": f1_score(Y_test, Y_pred),\n",
    "                     \"ROC AUC Score\": roc_auc_score(Y_test, Y_pred),\n",
    "                     \"Predictions\": Y_pred}\n",
    "\n",
    "\n",
    "for nombre, metricas in resultados.items():\n",
    "    print(f\"\\nResultados para {nombre}:\")\n",
    "    for metrica, value in metricas.items():\n",
    "        print(f\"{metrica}: {value}\")\n",
    "\n",
    "for nombre, metricas in resultados.items():\n",
    "    with open(f\"Modelos/DecisionTree_{nombre}_mejor_modelo.pkl\", \"wb\") as f:\n",
    "        pickle.dump(metricas[\"GridSearchModel\"].best_estimator_, f)\n",
    "    \n",
    "    with open(f\"Resultados/DecisionTree_{nombre}_resultados.txt\", \"w\") as f:\n",
    "        for metrica, value in metricas.items():\n",
    "            if metrica != \"Predictions\": \n",
    "                f.write(f\"{metrica}: {value}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para Normal:\n",
      "{'mean_fit_time': array([0.1102366 , 0.10626075, 0.10610161, 0.10693092, 0.10584497,\n",
      "       0.10584819, 0.10877392, 0.10925014, 0.10878758, 0.10752892,\n",
      "       0.10516617, 0.10543027, 0.10528939, 0.10800705, 0.10724578,\n",
      "       0.10589831, 0.10918903, 0.10926349, 0.10780168, 0.10826769,\n",
      "       0.10765297, 0.10764921, 0.10769656, 0.11117659, 0.1089911 ,\n",
      "       0.1090636 , 0.10909824, 0.11111841, 0.11087248, 0.10864446,\n",
      "       0.10850964, 0.10806494, 0.11554193, 0.11334701, 0.11107142,\n",
      "       0.10955255, 0.10945539, 0.11004117, 0.11067142, 0.1101486 ,\n",
      "       0.11732075, 0.1117816 , 0.10718319, 0.10834601, 0.10810943,\n",
      "       0.10861053, 0.10910103, 0.10943818, 0.11309183, 0.11149027,\n",
      "       0.11249995, 0.11337075, 0.11215367, 0.11108105, 0.11417198,\n",
      "       0.11143198, 0.11102979, 0.11096632, 0.11125541, 0.11223879,\n",
      "       0.11252301, 0.11227264, 0.1124558 , 0.11298652, 0.11747777,\n",
      "       0.11688855, 0.11476326, 0.11355219, 0.11762683, 0.1156662 ,\n",
      "       0.11931038, 0.12537189, 0.11941981, 0.12709939, 0.11940804,\n",
      "       0.1186811 , 0.12217255, 0.12134812, 0.1195328 , 0.1177819 ,\n",
      "       0.12419605, 0.12810278, 0.12502987, 0.1338892 , 0.12808776,\n",
      "       0.12596946, 0.12288637, 0.12029614, 0.1215636 , 0.12188647,\n",
      "       0.12608216, 0.12889514, 0.12107801, 0.12927291, 0.12944984,\n",
      "       0.12544427, 0.1271621 , 0.12760148, 0.12948227, 0.13261342,\n",
      "       0.1307591 , 0.12718861, 0.12640274, 0.13153882, 0.12805424,\n",
      "       0.12589414, 0.12541609, 0.12409129, 0.12287745, 0.12337658,\n",
      "       0.12285535, 0.12237959, 0.13181732, 0.13125281, 0.13024755,\n",
      "       0.12893651, 0.13311679, 0.13094075, 0.130299  , 0.12884643,\n",
      "       0.1276269 , 0.13026638, 0.12950063, 0.12587168, 0.12370672,\n",
      "       0.13026834, 0.12446203, 0.12457304, 0.13546712, 0.13334489,\n",
      "       0.13102713, 0.12790511, 0.13305502, 0.13285439, 0.1304805 ,\n",
      "       0.12730186, 0.12846687, 0.12743881, 0.12795475, 0.12756991,\n",
      "       0.12523079, 0.12541649, 0.12574854, 0.12488449, 0.13922369,\n",
      "       0.13854396, 0.13594723, 0.13129475, 0.13747516, 0.1433784 ,\n",
      "       0.13180223, 0.12855067, 0.12967119, 0.12913499, 0.1293231 ,\n",
      "       0.12798572, 0.12532334, 0.12499673, 0.12504051, 0.12517095,\n",
      "       0.14320481, 0.14010313, 0.13491194, 0.13054557, 0.13773844,\n",
      "       0.13675613, 0.13445761, 0.13161552, 0.13183794, 0.1332679 ,\n",
      "       0.13342273, 0.13056922, 0.12660933, 0.12542539, 0.12577441,\n",
      "       0.1259666 , 0.14710021, 0.14064002, 0.13530707, 0.12969377,\n",
      "       0.13803163, 0.13907154, 0.13458695, 0.13016427, 0.13315916,\n",
      "       0.13867478, 0.13464918, 0.13049779, 0.13877058, 0.12626507,\n",
      "       0.12798383, 0.12885451, 0.14992638, 0.14450107, 0.13989801,\n",
      "       0.13475363, 0.14310024, 0.14075611, 0.1376967 , 0.13402035,\n",
      "       0.13450775, 0.13488126, 0.13485837, 0.12975626, 0.12579172,\n",
      "       0.12662289, 0.12648609, 0.12665985, 0.15036559, 0.14709065,\n",
      "       0.13795598, 0.13274698, 0.14242661, 0.14050639, 0.13646519,\n",
      "       0.13140357, 0.13164797, 0.13145375, 0.13192973, 0.12909179,\n",
      "       0.12576008, 0.12625387, 0.12637537, 0.12596238, 0.15060973,\n",
      "       0.14500589, 0.1382587 , 0.13209832, 0.14245479, 0.14138114,\n",
      "       0.13714836, 0.13243535, 0.13256257, 0.13187008, 0.1322407 ,\n",
      "       0.13490739, 0.12856269, 0.12621293, 0.13232834, 0.12624226,\n",
      "       0.15226774, 0.1452899 , 0.14125888, 0.13744285, 0.14178677,\n",
      "       0.1430912 , 0.1359755 , 0.13453143, 0.13674631, 0.13420794,\n",
      "       0.13233061, 0.12992811, 0.12560258, 0.1262496 , 0.12575512,\n",
      "       0.1257277 , 0.15245337, 0.14535244, 0.1388309 , 0.13173559,\n",
      "       0.14511271, 0.14398217, 0.14026403, 0.13396752, 0.13452635,\n",
      "       0.13554342, 0.13208058, 0.12811091, 0.12504616, 0.1261724 ,\n",
      "       0.12866836, 0.12839708, 0.15426528, 0.14835861, 0.13876498,\n",
      "       0.13238199, 0.14280727, 0.14174454, 0.13702078, 0.13124099,\n",
      "       0.13201337, 0.13203464, 0.13212602, 0.13226652, 0.12655537,\n",
      "       0.12834711, 0.12564046, 0.12577865, 0.15466342, 0.14889662,\n",
      "       0.14032481, 0.1325702 , 0.14286473, 0.14219341, 0.13824768,\n",
      "       0.13229644, 0.13205726, 0.13227592, 0.13243997, 0.12858598,\n",
      "       0.12593083, 0.1270499 , 0.1267118 , 0.12686694, 0.15460711,\n",
      "       0.14606302, 0.1439146 , 0.13273113, 0.14412711, 0.14259841,\n",
      "       0.13789721, 0.13456035, 0.13381715, 0.13299625, 0.13528593,\n",
      "       0.12922256, 0.12639122, 0.12925763, 0.12864726, 0.12877655]), 'std_fit_time': array([0.00393739, 0.00115762, 0.00069256, 0.00200646, 0.00059868,\n",
      "       0.00057068, 0.0007179 , 0.000672  , 0.00071631, 0.00162227,\n",
      "       0.00054425, 0.0007148 , 0.00062672, 0.00196212, 0.00118802,\n",
      "       0.00066606, 0.00051819, 0.00066039, 0.00085856, 0.00090567,\n",
      "       0.00071239, 0.00042811, 0.00071989, 0.00368832, 0.00056902,\n",
      "       0.00054501, 0.00052371, 0.00129899, 0.00058403, 0.00192568,\n",
      "       0.00041457, 0.00063819, 0.00618046, 0.00232034, 0.00240603,\n",
      "       0.00116543, 0.00084782, 0.000989  , 0.00089484, 0.00121151,\n",
      "       0.01177788, 0.00920039, 0.00048759, 0.00212413, 0.00160186,\n",
      "       0.0008183 , 0.00053877, 0.00087248, 0.00070201, 0.00187285,\n",
      "       0.00049996, 0.00120707, 0.00237417, 0.00055916, 0.00624731,\n",
      "       0.00063353, 0.00078153, 0.00102053, 0.00078387, 0.00082267,\n",
      "       0.00108563, 0.00291498, 0.00053157, 0.00081231, 0.00088729,\n",
      "       0.00384204, 0.00149603, 0.00107898, 0.00177786, 0.00148807,\n",
      "       0.00239164, 0.00596879, 0.00126407, 0.00855064, 0.00154831,\n",
      "       0.00128755, 0.00244138, 0.00166952, 0.00218598, 0.00050764,\n",
      "       0.00089074, 0.00364979, 0.00414951, 0.0165305 , 0.00573358,\n",
      "       0.00173578, 0.00241343, 0.00071662, 0.00122367, 0.0008563 ,\n",
      "       0.0044274 , 0.00633019, 0.00228293, 0.0111598 , 0.01137003,\n",
      "       0.01086031, 0.00142772, 0.00233277, 0.00530499, 0.00745773,\n",
      "       0.00496348, 0.00186726, 0.00205087, 0.01100032, 0.00245845,\n",
      "       0.00129228, 0.00092846, 0.00063834, 0.00046674, 0.00078751,\n",
      "       0.00048626, 0.00053717, 0.00219601, 0.00191552, 0.00060124,\n",
      "       0.00191662, 0.0027602 , 0.0006198 , 0.00078165, 0.00081402,\n",
      "       0.00082595, 0.0025243 , 0.00068272, 0.00219367, 0.00072295,\n",
      "       0.01069679, 0.00070509, 0.00071665, 0.00080327, 0.00055623,\n",
      "       0.00068129, 0.00063263, 0.00059903, 0.00070262, 0.00052676,\n",
      "       0.00049081, 0.00087641, 0.00110495, 0.00080176, 0.00051668,\n",
      "       0.00061197, 0.00054254, 0.00173563, 0.00034293, 0.00086378,\n",
      "       0.00076264, 0.00071629, 0.00296199, 0.00962487, 0.02047061,\n",
      "       0.00082856, 0.00057531, 0.00047495, 0.00056311, 0.00075774,\n",
      "       0.00124492, 0.00058078, 0.00052775, 0.0010291 , 0.00062607,\n",
      "       0.00232279, 0.00211306, 0.00056533, 0.00087798, 0.00058719,\n",
      "       0.00068996, 0.00064236, 0.00365178, 0.00143735, 0.0007584 ,\n",
      "       0.00047965, 0.00047512, 0.00180943, 0.00074264, 0.0006611 ,\n",
      "       0.00114411, 0.00053854, 0.00147966, 0.00053369, 0.00074327,\n",
      "       0.00052973, 0.00208703, 0.00070106, 0.00050519, 0.00270824,\n",
      "       0.00062881, 0.00204537, 0.00090305, 0.01246338, 0.00136455,\n",
      "       0.0022088 , 0.00085853, 0.00093399, 0.0005007 , 0.00062966,\n",
      "       0.00041781, 0.0007001 , 0.00252687, 0.00088061, 0.00190184,\n",
      "       0.00049252, 0.00078366, 0.00094227, 0.0011774 , 0.00047617,\n",
      "       0.00062091, 0.00058639, 0.00063932, 0.00123459, 0.00160484,\n",
      "       0.00043552, 0.00048436, 0.00157602, 0.0007761 , 0.00123972,\n",
      "       0.00061728, 0.0005075 , 0.00066838, 0.00057522, 0.00067525,\n",
      "       0.00072476, 0.0006684 , 0.00057964, 0.000732  , 0.00044081,\n",
      "       0.00056765, 0.00054093, 0.00056204, 0.00069033, 0.00064386,\n",
      "       0.00075557, 0.00158376, 0.00046375, 0.00094234, 0.00122953,\n",
      "       0.00932803, 0.00262423, 0.0004451 , 0.01219183, 0.00102496,\n",
      "       0.00078521, 0.0006909 , 0.00382092, 0.00462024, 0.0006678 ,\n",
      "       0.00333138, 0.00068228, 0.0012768 , 0.0070458 , 0.00573245,\n",
      "       0.00057802, 0.00200976, 0.00050546, 0.00064975, 0.00040405,\n",
      "       0.00048844, 0.00085997, 0.00081136, 0.00088021, 0.00080288,\n",
      "       0.00613697, 0.00175725, 0.00077759, 0.00063986, 0.00129197,\n",
      "       0.00040649, 0.00124276, 0.0003915 , 0.00051672, 0.00133008,\n",
      "       0.00061898, 0.00100736, 0.00155297, 0.00082277, 0.00098138,\n",
      "       0.00143709, 0.00077414, 0.00067674, 0.00038156, 0.00051924,\n",
      "       0.00073651, 0.00065734, 0.00039136, 0.0044285 , 0.00127335,\n",
      "       0.00357658, 0.00077973, 0.00067538, 0.00188557, 0.00095732,\n",
      "       0.00132683, 0.00062419, 0.00063198, 0.00108225, 0.0018727 ,\n",
      "       0.00137544, 0.00071458, 0.0005876 , 0.00122012, 0.00066775,\n",
      "       0.00054819, 0.00067994, 0.00049233, 0.00057242, 0.00115106,\n",
      "       0.00086737, 0.00380401, 0.00265418, 0.00188452, 0.00067876,\n",
      "       0.00059973, 0.0013606 , 0.00195982, 0.00107402, 0.00404168,\n",
      "       0.00066612, 0.0005524 , 0.00095806, 0.0008014 , 0.00130685]), 'mean_score_time': array([0.00775557, 0.00773563, 0.00758779, 0.00809691, 0.0079524 ,\n",
      "       0.00782058, 0.00799677, 0.00809879, 0.00799942, 0.0078969 ,\n",
      "       0.00791428, 0.00791695, 0.00769932, 0.00760477, 0.0078794 ,\n",
      "       0.00785456, 0.00796127, 0.00784032, 0.00798969, 0.00785692,\n",
      "       0.00776091, 0.00785654, 0.00777946, 0.007916  , 0.00811565,\n",
      "       0.00806155, 0.00786793, 0.00812869, 0.00813861, 0.00771844,\n",
      "       0.00789433, 0.00793293, 0.00799553, 0.00772288, 0.00763538,\n",
      "       0.00769811, 0.00798478, 0.00790029, 0.0076993 , 0.00786958,\n",
      "       0.00859277, 0.00773695, 0.00776253, 0.00812726, 0.00771148,\n",
      "       0.00771406, 0.00769877, 0.00779948, 0.00776954, 0.00801284,\n",
      "       0.00750072, 0.00806465, 0.00798311, 0.00782421, 0.00783324,\n",
      "       0.0078341 , 0.00778351, 0.00818899, 0.00792031, 0.00787003,\n",
      "       0.00817473, 0.00791888, 0.00767066, 0.00779986, 0.00799892,\n",
      "       0.00786526, 0.00780809, 0.00759003, 0.00817127, 0.0080776 ,\n",
      "       0.00839205, 0.0083878 , 0.00839205, 0.00912294, 0.00835478,\n",
      "       0.00835366, 0.00837104, 0.00866807, 0.00812771, 0.00833325,\n",
      "       0.00838375, 0.00856855, 0.00850406, 0.00828271, 0.0085577 ,\n",
      "       0.00835249, 0.0082278 , 0.00799778, 0.00836053, 0.008535  ,\n",
      "       0.00859406, 0.00858583, 0.00853119, 0.00866082, 0.00906625,\n",
      "       0.00863123, 0.00846226, 0.00871711, 0.00858579, 0.00891199,\n",
      "       0.00876329, 0.0085202 , 0.00851767, 0.00882018, 0.0083715 ,\n",
      "       0.00853362, 0.00837708, 0.00846038, 0.00814636, 0.00822976,\n",
      "       0.00829425, 0.00867057, 0.00897417, 0.00876362, 0.00899925,\n",
      "       0.00895147, 0.00893443, 0.00879722, 0.00890026, 0.00886652,\n",
      "       0.00875795, 0.00884972, 0.00908656, 0.00828292, 0.00826366,\n",
      "       0.00834398, 0.00865195, 0.00834589, 0.00910063, 0.00890145,\n",
      "       0.00887151, 0.00865436, 0.00891809, 0.00908749, 0.00867977,\n",
      "       0.00881379, 0.00846324, 0.00858531, 0.00870085, 0.00884469,\n",
      "       0.00859232, 0.00846188, 0.00855296, 0.00864146, 0.00918078,\n",
      "       0.0088208 , 0.00922396, 0.00885155, 0.00927472, 0.00930254,\n",
      "       0.00895123, 0.00854864, 0.00909076, 0.00899208, 0.00895889,\n",
      "       0.00862093, 0.00852184, 0.00864635, 0.00862777, 0.00839574,\n",
      "       0.00967059, 0.00905378, 0.0090626 , 0.00890276, 0.00891962,\n",
      "       0.00904481, 0.00885329, 0.00899334, 0.00866745, 0.00919752,\n",
      "       0.008899  , 0.00909994, 0.00840862, 0.00880451, 0.00853007,\n",
      "       0.00854497, 0.00959952, 0.00913963, 0.00885572, 0.00892093,\n",
      "       0.00902131, 0.00915613, 0.00893364, 0.00850298, 0.00905857,\n",
      "       0.00932672, 0.00886559, 0.0086385 , 0.00950229, 0.00881581,\n",
      "       0.00874469, 0.00899949, 0.00979855, 0.00949881, 0.00910077,\n",
      "       0.0089987 , 0.00930026, 0.00915902, 0.00919378, 0.00872507,\n",
      "       0.00889928, 0.00889943, 0.00889819, 0.00885625, 0.00848358,\n",
      "       0.00858717, 0.00880079, 0.00852764, 0.00965283, 0.00964687,\n",
      "       0.00912273, 0.00884471, 0.00927889, 0.00913904, 0.00899301,\n",
      "       0.00862367, 0.00891516, 0.0089576 , 0.00922482, 0.00902309,\n",
      "       0.00869162, 0.00845885, 0.00851638, 0.00855155, 0.00952306,\n",
      "       0.00956383, 0.00901287, 0.00876141, 0.00900638, 0.00930965,\n",
      "       0.00910895, 0.00899906, 0.00857766, 0.00882192, 0.00863895,\n",
      "       0.00878139, 0.00872796, 0.00877237, 0.00910821, 0.00868998,\n",
      "       0.00984073, 0.00952969, 0.00930235, 0.00931602, 0.0089469 ,\n",
      "       0.00925629, 0.0090785 , 0.00922098, 0.0091804 , 0.0086657 ,\n",
      "       0.00880072, 0.00884457, 0.00878723, 0.00854366, 0.00868435,\n",
      "       0.00843885, 0.00961089, 0.00944197, 0.00914989, 0.00838799,\n",
      "       0.00923419, 0.00928826, 0.00928273, 0.009199  , 0.00893023,\n",
      "       0.00893993, 0.00845809, 0.00848117, 0.00864222, 0.00852096,\n",
      "       0.00871959, 0.00874097, 0.00984783, 0.00957968, 0.0089819 ,\n",
      "       0.00882416, 0.00944533, 0.00910861, 0.00889487, 0.0087189 ,\n",
      "       0.00903809, 0.0089329 , 0.00863082, 0.00898113, 0.00901649,\n",
      "       0.00888677, 0.00893421, 0.00871391, 0.00981517, 0.00963211,\n",
      "       0.00917401, 0.00895755, 0.00911736, 0.00915024, 0.00902808,\n",
      "       0.00884995, 0.00890279, 0.00884061, 0.00875735, 0.00877304,\n",
      "       0.00862744, 0.00876296, 0.00860286, 0.00885344, 0.00968833,\n",
      "       0.0098331 , 0.00921323, 0.00872209, 0.00963323, 0.00953052,\n",
      "       0.0091305 , 0.00885208, 0.00890799, 0.00856056, 0.0090275 ,\n",
      "       0.00863945, 0.00854933, 0.00870061, 0.00870416, 0.00866342]), 'std_score_time': array([5.22526469e-04, 4.54461213e-04, 3.48727077e-04, 5.20614944e-04,\n",
      "       3.29556832e-04, 3.18791522e-04, 7.48228005e-06, 3.00186560e-04,\n",
      "       4.88612688e-07, 3.31279917e-04, 3.07087229e-04, 3.14470372e-04,\n",
      "       5.68624993e-04, 4.56408243e-04, 4.52672859e-04, 2.34262923e-04,\n",
      "       3.19945119e-04, 4.53826619e-04, 2.45262336e-04, 3.65237032e-04,\n",
      "       5.04178310e-04, 3.05107863e-04, 3.42471408e-04, 4.34413103e-04,\n",
      "       4.59933840e-04, 1.99031173e-04, 3.01450294e-04, 3.58247503e-04,\n",
      "       3.95298778e-04, 3.76772832e-04, 2.13860583e-04, 1.37396614e-04,\n",
      "       4.47797850e-04, 4.10058213e-04, 5.14612864e-04, 4.52827357e-04,\n",
      "       1.76065501e-04, 5.39085125e-04, 4.58443056e-04, 7.16461859e-04,\n",
      "       1.06798341e-03, 9.08945213e-04, 3.96829246e-04, 6.42081001e-04,\n",
      "       3.85275041e-04, 4.69191450e-04, 4.58414291e-04, 4.00174008e-04,\n",
      "       3.95218401e-04, 5.80547184e-04, 4.98474320e-04, 3.75504466e-04,\n",
      "       2.70069790e-04, 4.52454048e-04, 2.76262080e-04, 3.80302569e-04,\n",
      "       3.94386753e-04, 2.36293464e-04, 2.31622878e-04, 3.73817509e-04,\n",
      "       6.29161894e-04, 4.23363716e-04, 4.68688776e-04, 3.92203389e-04,\n",
      "       5.88367590e-07, 3.02964785e-04, 3.53050023e-04, 3.90044058e-04,\n",
      "       2.85054370e-04, 4.99535634e-04, 5.04555780e-04, 5.52001779e-04,\n",
      "       2.69827119e-04, 1.34983063e-03, 5.21248878e-04, 4.15531763e-04,\n",
      "       5.02299548e-04, 4.62605213e-04, 4.46368337e-04, 5.13786714e-04,\n",
      "       5.04213854e-04, 4.74269288e-04, 3.55013369e-04, 3.67590187e-04,\n",
      "       4.72467490e-04, 4.01527771e-04, 4.56546597e-04, 3.40135276e-04,\n",
      "       4.38272939e-04, 5.67623949e-04, 8.94083687e-04, 3.95491082e-04,\n",
      "       5.40598650e-04, 1.04222590e-03, 1.05381993e-03, 8.83989122e-04,\n",
      "       3.14799446e-04, 4.57390802e-04, 4.27867661e-04, 4.23845248e-04,\n",
      "       2.47797330e-04, 5.39215621e-04, 3.27501641e-04, 7.65538893e-04,\n",
      "       6.49180739e-04, 4.63942991e-04, 5.87328411e-04, 5.05719339e-04,\n",
      "       5.21619685e-04, 3.60771374e-04, 3.59848159e-04, 3.17100654e-04,\n",
      "       4.84237563e-04, 6.34694529e-04, 4.47501120e-04, 3.53488616e-04,\n",
      "       4.85416387e-04, 3.99248207e-04, 3.00624391e-04, 4.60537494e-04,\n",
      "       3.74655347e-04, 4.50538147e-04, 3.91211656e-04, 3.59241381e-04,\n",
      "       4.32467960e-04, 4.17313688e-04, 3.01789018e-04, 3.31377756e-04,\n",
      "       4.84118548e-04, 4.69828516e-04, 3.99628270e-04, 4.86017393e-04,\n",
      "       4.61465510e-04, 3.04330816e-04, 4.90730599e-04, 3.92499247e-04,\n",
      "       2.34162761e-04, 4.10076577e-04, 5.13427576e-04, 4.71693803e-04,\n",
      "       3.93865642e-04, 4.21567819e-04, 7.21072498e-04, 2.99424244e-04,\n",
      "       4.82940429e-04, 2.81022098e-04, 4.84554490e-04, 4.69188264e-04,\n",
      "       9.17241831e-04, 1.60527934e-03, 4.82930434e-04, 3.97770632e-04,\n",
      "       4.33786460e-04, 5.30663901e-04, 4.48066475e-04, 4.40063217e-04,\n",
      "       3.57753681e-04, 2.61454497e-04, 6.14443287e-04, 4.01322892e-04,\n",
      "       5.94614504e-04, 4.82973526e-04, 2.00750625e-04, 7.07543586e-04,\n",
      "       4.25307969e-04, 4.11017907e-04, 3.55511190e-04, 4.32346411e-04,\n",
      "       4.42011887e-04, 4.01208101e-04, 3.00018241e-04, 2.99875027e-04,\n",
      "       5.02899548e-04, 4.35518688e-04, 4.20571672e-04, 4.74600000e-04,\n",
      "       4.89989103e-04, 4.84757510e-04, 3.79450089e-04, 4.89288896e-04,\n",
      "       3.80860117e-04, 4.65499002e-04, 3.48842317e-04, 5.27029168e-04,\n",
      "       4.53528131e-04, 6.68093796e-04, 3.05790766e-04, 9.75037935e-04,\n",
      "       1.32661735e-03, 3.79301163e-04, 3.89840397e-04, 4.47501666e-04,\n",
      "       4.01273165e-04, 5.00536699e-04, 2.99914031e-04, 6.91413879e-07,\n",
      "       4.58096821e-04, 4.22517641e-04, 3.82221409e-04, 3.81018404e-04,\n",
      "       5.38995894e-04, 5.38756531e-04, 2.99812800e-04, 4.38465442e-04,\n",
      "       3.72155151e-04, 4.16044339e-04, 3.77277447e-04, 3.90430224e-04,\n",
      "       4.24344316e-04, 4.75946088e-04, 3.79322450e-04, 4.95028217e-04,\n",
      "       5.73217729e-04, 4.60780239e-04, 4.23923657e-04, 4.45962842e-04,\n",
      "       4.71772000e-04, 5.32484691e-04, 4.86977778e-04, 2.89690017e-04,\n",
      "       1.26242989e-04, 3.93179490e-04, 4.05362183e-04, 4.88454792e-04,\n",
      "       3.79197794e-04, 3.91175873e-04, 4.35170092e-04, 3.33980095e-04,\n",
      "       3.22721600e-04, 5.79750299e-04, 4.24387991e-04, 3.00222480e-04,\n",
      "       5.23405863e-04, 5.46703303e-04, 4.02648115e-04, 4.43789013e-04,\n",
      "       2.80193873e-04, 4.51544396e-04, 9.37144538e-04, 4.54720227e-04,\n",
      "       4.84282870e-04, 3.61040746e-04, 4.70595015e-04, 7.30901207e-04,\n",
      "       3.30234916e-04, 5.31825271e-04, 3.77938993e-04, 6.42527377e-04,\n",
      "       1.09663999e-03, 4.72276119e-04, 3.78989883e-04, 2.81003576e-04,\n",
      "       2.56927521e-04, 4.88273020e-04, 3.60471464e-04, 4.25378896e-04,\n",
      "       5.74013117e-04, 3.65437764e-04, 4.23459804e-04, 3.34695629e-04,\n",
      "       3.82392572e-04, 3.98171373e-04, 3.95028997e-04, 4.00866214e-04,\n",
      "       3.75090236e-04, 4.45821588e-04, 5.03256440e-04, 4.37814564e-04,\n",
      "       5.61200766e-04, 3.62328398e-04, 5.27260531e-04, 3.34406804e-04,\n",
      "       2.99159341e-04, 4.45973796e-04, 4.38774127e-04, 5.02805076e-04,\n",
      "       4.19023569e-04, 5.57778745e-04, 3.98678737e-04, 3.90750436e-04,\n",
      "       3.92474412e-04, 5.94385714e-04, 3.80371645e-04, 5.84234405e-04,\n",
      "       1.62672732e-03, 4.00516302e-04, 5.44632642e-04, 4.28299237e-04,\n",
      "       2.99154572e-04, 4.07866796e-04, 3.10530698e-04, 6.27921352e-04,\n",
      "       3.80695556e-04, 3.44990406e-04, 2.27478595e-04, 5.20595986e-04,\n",
      "       4.50415998e-04, 4.25758067e-04, 4.85675090e-04, 4.25408605e-04,\n",
      "       2.79866600e-04, 3.38351284e-04, 5.01538651e-04, 3.27163374e-04,\n",
      "       6.28361343e-04, 4.27343472e-04, 6.50104544e-04, 4.17270351e-04,\n",
      "       5.14254064e-04, 4.79962495e-04, 5.88500286e-04, 4.66918900e-04,\n",
      "       3.34957176e-04, 4.65619206e-04, 4.98621487e-04, 3.69801915e-04,\n",
      "       3.23104226e-04, 4.58793958e-04, 3.41896373e-04, 5.25762605e-04]), 'param_classifier__max_depth': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
      "                   2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3,\n",
      "                   3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4,\n",
      "                   4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "                   6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "                   7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "                   8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
      "                   11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
      "                   12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13,\n",
      "                   13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14,\n",
      "                   14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15,\n",
      "                   15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16,\n",
      "                   16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "                   17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "                   17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
      "                   18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
      "                   19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "                   20, 20, 20, 20, 20, 20, 20, 20],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_classifier__min_samples_leaf': masked_array(data=[1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1,\n",
      "                   1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1,\n",
      "                   1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1,\n",
      "                   1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1,\n",
      "                   2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2,\n",
      "                   2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2,\n",
      "                   2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2,\n",
      "                   2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "                   5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5,\n",
      "                   5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5,\n",
      "                   5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5,\n",
      "                   5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5,\n",
      "                   10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10,\n",
      "                   10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10,\n",
      "                   10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10,\n",
      "                   10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10,\n",
      "                   1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1,\n",
      "                   1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1,\n",
      "                   1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_classifier__min_samples_split': masked_array(data=[2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'classifier__max_depth': 1, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}], 'split0_test_score': array([0.77987421, 0.77987421, 0.77987421, 0.77358491, 0.77987421,\n",
      "       0.77987421, 0.77987421, 0.77358491, 0.77987421, 0.77358491,\n",
      "       0.77987421, 0.77987421, 0.77987421, 0.77358491, 0.77987421,\n",
      "       0.77358491, 0.7672956 , 0.7672956 , 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.7672956 , 0.77987421, 0.7672956 , 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.7672956 , 0.77358491,\n",
      "       0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 , 0.77358491,\n",
      "       0.77987421, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.76100629, 0.7672956 , 0.77987421, 0.77358491,\n",
      "       0.77358491, 0.76100629, 0.77358491, 0.77358491, 0.77987421,\n",
      "       0.77987421, 0.77987421, 0.83018868, 0.77987421, 0.77987421,\n",
      "       0.7672956 , 0.79874214, 0.77358491, 0.77358491, 0.78616352,\n",
      "       0.7672956 , 0.77987421, 0.77358491, 0.77358491, 0.81761006,\n",
      "       0.81761006, 0.83018868, 0.82389937, 0.83018868, 0.82389937,\n",
      "       0.83018868, 0.81761006, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.80503145, 0.81132075, 0.81761006, 0.81132075, 0.81761006,\n",
      "       0.82389937, 0.82389937, 0.83018868, 0.83018868, 0.83018868,\n",
      "       0.83018868, 0.81761006, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.81132075, 0.81132075, 0.83018868, 0.80503145, 0.81132075,\n",
      "       0.81132075, 0.83018868, 0.83018868, 0.83018868, 0.82389937,\n",
      "       0.82389937, 0.83018868, 0.83018868, 0.81761006, 0.82389937,\n",
      "       0.82389937, 0.82389937, 0.82389937, 0.81132075, 0.81761006,\n",
      "       0.81761006, 0.81132075, 0.83018868, 0.83018868, 0.82389937,\n",
      "       0.83018868, 0.83018868, 0.81761006, 0.83018868, 0.82389937,\n",
      "       0.82389937, 0.82389937, 0.82389937, 0.82389937, 0.81132075,\n",
      "       0.82389937, 0.81132075, 0.81761006, 0.81761006, 0.82389937,\n",
      "       0.83018868, 0.82389937, 0.82389937, 0.83018868, 0.83018868,\n",
      "       0.82389937, 0.82389937, 0.82389937, 0.82389937, 0.81761006,\n",
      "       0.82389937, 0.82389937, 0.82389937, 0.81761006, 0.81761006,\n",
      "       0.82389937, 0.83018868, 0.83018868, 0.81761006, 0.82389937,\n",
      "       0.83018868, 0.83018868, 0.83018868, 0.82389937, 0.81761006,\n",
      "       0.82389937, 0.82389937, 0.82389937, 0.80503145, 0.81761006,\n",
      "       0.81132075, 0.82389937, 0.83018868, 0.83018868, 0.82389937,\n",
      "       0.82389937, 0.83018868, 0.82389937, 0.81761006, 0.82389937,\n",
      "       0.82389937, 0.82389937, 0.82389937, 0.81761006, 0.82389937,\n",
      "       0.81761006, 0.79874214, 0.82389937, 0.82389937, 0.83018868,\n",
      "       0.82389937, 0.82389937, 0.83018868, 0.83018868, 0.82389937,\n",
      "       0.82389937, 0.82389937, 0.82389937, 0.81132075, 0.82389937,\n",
      "       0.82389937, 0.81761006, 0.79874214, 0.81761006, 0.82389937,\n",
      "       0.82389937, 0.81761006, 0.81761006, 0.82389937, 0.83018868,\n",
      "       0.82389937, 0.82389937, 0.82389937, 0.81761006, 0.82389937,\n",
      "       0.81132075, 0.80503145, 0.81132075, 0.79245283, 0.81132075,\n",
      "       0.82389937, 0.81761006, 0.81761006, 0.81132075, 0.82389937,\n",
      "       0.83018868, 0.82389937, 0.81761006, 0.82389937, 0.82389937,\n",
      "       0.81761006, 0.81761006, 0.81132075, 0.81132075, 0.77987421,\n",
      "       0.81132075, 0.81132075, 0.82389937, 0.81761006, 0.81761006,\n",
      "       0.82389937, 0.83018868, 0.82389937, 0.83018868, 0.81761006,\n",
      "       0.81132075, 0.82389937, 0.81132075, 0.82389937, 0.81132075,\n",
      "       0.78616352, 0.80503145, 0.82389937, 0.83018868, 0.81132075,\n",
      "       0.81761006, 0.82389937, 0.83018868, 0.82389937, 0.82389937,\n",
      "       0.81132075, 0.82389937, 0.81761006, 0.82389937, 0.80503145,\n",
      "       0.81761006, 0.79245283, 0.81132075, 0.81761006, 0.82389937,\n",
      "       0.82389937, 0.81132075, 0.82389937, 0.82389937, 0.82389937,\n",
      "       0.81761006, 0.81761006, 0.82389937, 0.82389937, 0.82389937,\n",
      "       0.81132075, 0.81132075, 0.79245283, 0.80503145, 0.81761006,\n",
      "       0.83018868, 0.81761006, 0.81761006, 0.82389937, 0.81761006,\n",
      "       0.83018868, 0.81761006, 0.82389937, 0.82389937, 0.81132075,\n",
      "       0.81761006, 0.82389937, 0.82389937, 0.79874214, 0.81132075,\n",
      "       0.81761006, 0.83647799, 0.82389937, 0.81132075, 0.81761006,\n",
      "       0.82389937, 0.82389937, 0.83018868, 0.82389937, 0.81761006,\n",
      "       0.81132075, 0.81761006, 0.82389937, 0.81132075, 0.79245283,\n",
      "       0.81761006, 0.81132075, 0.82389937, 0.81132075, 0.81761006,\n",
      "       0.82389937, 0.83018868, 0.81761006, 0.83018868, 0.83018868,\n",
      "       0.82389937, 0.81761006, 0.82389937, 0.81132075, 0.82389937]), 'split1_test_score': array([0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.80503145, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.80503145, 0.81132075, 0.80503145, 0.81132075, 0.80503145,\n",
      "       0.81132075, 0.81132075, 0.80503145, 0.81132075, 0.81761006,\n",
      "       0.80503145, 0.81132075, 0.81132075, 0.81132075, 0.80503145,\n",
      "       0.81132075, 0.81761006, 0.81132075, 0.81761006, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81761006, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81761006, 0.81132075, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.8490566 , 0.8427673 ,\n",
      "       0.81761006, 0.8427673 , 0.83647799, 0.83647799, 0.8427673 ,\n",
      "       0.83018868, 0.81761006, 0.81761006, 0.81132075, 0.83647799,\n",
      "       0.83018868, 0.82389937, 0.82389937, 0.82389937, 0.85534591,\n",
      "       0.87421384, 0.86792453, 0.86792453, 0.88050314, 0.86163522,\n",
      "       0.87421384, 0.85534591, 0.85534591, 0.86792453, 0.86792453,\n",
      "       0.88050314, 0.85534591, 0.86163522, 0.86163522, 0.85534591,\n",
      "       0.87421384, 0.86792453, 0.86792453, 0.86792453, 0.88050314,\n",
      "       0.87421384, 0.88050314, 0.88679245, 0.87421384, 0.88050314,\n",
      "       0.88050314, 0.88050314, 0.87421384, 0.85534591, 0.86163522,\n",
      "       0.87421384, 0.87421384, 0.87421384, 0.87421384, 0.88050314,\n",
      "       0.88050314, 0.88050314, 0.87421384, 0.88050314, 0.88050314,\n",
      "       0.88050314, 0.88050314, 0.88050314, 0.86163522, 0.87421384,\n",
      "       0.88050314, 0.87421384, 0.86792453, 0.87421384, 0.87421384,\n",
      "       0.88050314, 0.87421384, 0.87421384, 0.87421384, 0.88050314,\n",
      "       0.88050314, 0.88679245, 0.88679245, 0.87421384, 0.87421384,\n",
      "       0.87421384, 0.88050314, 0.88050314, 0.86792453, 0.88050314,\n",
      "       0.87421384, 0.88050314, 0.87421384, 0.87421384, 0.86792453,\n",
      "       0.88050314, 0.88050314, 0.88050314, 0.88679245, 0.88050314,\n",
      "       0.87421384, 0.87421384, 0.87421384, 0.87421384, 0.86163522,\n",
      "       0.86792453, 0.87421384, 0.88050314, 0.87421384, 0.87421384,\n",
      "       0.87421384, 0.88050314, 0.87421384, 0.88050314, 0.88679245,\n",
      "       0.87421384, 0.87421384, 0.87421384, 0.86792453, 0.87421384,\n",
      "       0.85534591, 0.86792453, 0.87421384, 0.87421384, 0.87421384,\n",
      "       0.87421384, 0.87421384, 0.88050314, 0.87421384, 0.88679245,\n",
      "       0.88050314, 0.88050314, 0.87421384, 0.88050314, 0.88050314,\n",
      "       0.87421384, 0.8490566 , 0.85534591, 0.86792453, 0.88050314,\n",
      "       0.87421384, 0.87421384, 0.87421384, 0.87421384, 0.88050314,\n",
      "       0.88050314, 0.88050314, 0.88050314, 0.87421384, 0.87421384,\n",
      "       0.88050314, 0.87421384, 0.83018868, 0.85534591, 0.86792453,\n",
      "       0.88050314, 0.87421384, 0.87421384, 0.87421384, 0.88050314,\n",
      "       0.88679245, 0.88050314, 0.88050314, 0.87421384, 0.88050314,\n",
      "       0.87421384, 0.88050314, 0.88050314, 0.80503145, 0.85534591,\n",
      "       0.86792453, 0.87421384, 0.88050314, 0.87421384, 0.87421384,\n",
      "       0.87421384, 0.88050314, 0.88679245, 0.88050314, 0.88050314,\n",
      "       0.87421384, 0.88050314, 0.87421384, 0.86792453, 0.80503145,\n",
      "       0.8490566 , 0.88050314, 0.87421384, 0.87421384, 0.87421384,\n",
      "       0.87421384, 0.88050314, 0.88050314, 0.88050314, 0.88679245,\n",
      "       0.87421384, 0.86792453, 0.87421384, 0.88050314, 0.88050314,\n",
      "       0.78616352, 0.8427673 , 0.88679245, 0.88050314, 0.86163522,\n",
      "       0.86792453, 0.87421384, 0.87421384, 0.88679245, 0.88050314,\n",
      "       0.87421384, 0.87421384, 0.87421384, 0.88050314, 0.88050314,\n",
      "       0.87421384, 0.80503145, 0.79874214, 0.87421384, 0.88050314,\n",
      "       0.87421384, 0.86792453, 0.87421384, 0.88050314, 0.88050314,\n",
      "       0.87421384, 0.88050314, 0.88050314, 0.87421384, 0.87421384,\n",
      "       0.88050314, 0.86163522, 0.79874214, 0.82389937, 0.87421384,\n",
      "       0.88050314, 0.88050314, 0.87421384, 0.87421384, 0.88050314,\n",
      "       0.88679245, 0.88050314, 0.88050314, 0.88050314, 0.87421384,\n",
      "       0.88050314, 0.88050314, 0.86792453, 0.81132075, 0.82389937,\n",
      "       0.86792453, 0.88050314, 0.8490566 , 0.86792453, 0.87421384,\n",
      "       0.88050314, 0.88050314, 0.87421384, 0.88679245, 0.88050314,\n",
      "       0.88050314, 0.87421384, 0.88050314, 0.87421384, 0.79874214,\n",
      "       0.83018868, 0.87421384, 0.88050314, 0.8490566 , 0.86792453,\n",
      "       0.87421384, 0.88050314, 0.88050314, 0.87421384, 0.88679245,\n",
      "       0.88050314, 0.86792453, 0.88050314, 0.88050314, 0.88050314]), 'split2_test_score': array([0.79874214, 0.79874214, 0.79245283, 0.79245283, 0.78616352,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79245283, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79245283, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.80503145,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.80503145, 0.81132075,\n",
      "       0.80503145, 0.81132075, 0.79874214, 0.80503145, 0.79245283,\n",
      "       0.80503145, 0.79245283, 0.78616352, 0.79874214, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81761006, 0.80503145, 0.81761006, 0.81761006,\n",
      "       0.81132075, 0.81132075, 0.81761006, 0.81761006, 0.81132075,\n",
      "       0.81761006, 0.81761006, 0.81132075, 0.81132075, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81132075, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81132075, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81132075, 0.81761006, 0.81132075, 0.81132075,\n",
      "       0.81761006, 0.82389937, 0.82389937, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.81132075, 0.81761006, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81761006, 0.81761006, 0.82389937, 0.82389937, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81132075, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81132075, 0.81132075, 0.81761006,\n",
      "       0.81761006, 0.81132075, 0.81761006, 0.82389937, 0.82389937,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.82389937, 0.81761006, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81132075, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.80503145, 0.81132075, 0.81132075, 0.81761006, 0.81132075,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81132075, 0.81761006,\n",
      "       0.81761006, 0.81132075, 0.81761006, 0.81761006, 0.81132075,\n",
      "       0.81132075, 0.79874214, 0.79245283, 0.81761006, 0.81761006,\n",
      "       0.80503145, 0.81132075, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81132075, 0.79245283, 0.76100629, 0.81132075,\n",
      "       0.81761006, 0.79874214, 0.79245283, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81761006, 0.81132075, 0.75471698, 0.7672956 ,\n",
      "       0.81132075, 0.81761006, 0.77358491, 0.79245283, 0.81132075,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81761006, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81761006, 0.81761006, 0.76100629,\n",
      "       0.76100629, 0.81132075, 0.81761006, 0.79245283, 0.81761006,\n",
      "       0.81761006, 0.81132075, 0.81761006, 0.81761006, 0.81132075,\n",
      "       0.81761006, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.75471698, 0.76100629, 0.81132075, 0.81761006, 0.78616352,\n",
      "       0.77358491, 0.81761006, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.74842767, 0.76100629, 0.79874214, 0.81761006,\n",
      "       0.79245283, 0.77987421, 0.81132075, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81761006, 0.76100629, 0.75471698, 0.81132075,\n",
      "       0.81761006, 0.77987421, 0.78616352, 0.81761006, 0.81761006,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81761006, 0.81761006, 0.81132075, 0.75471698, 0.74842767,\n",
      "       0.81132075, 0.81761006, 0.79245283, 0.78616352, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81761006, 0.81761006, 0.81761006, 0.74842767,\n",
      "       0.76100629, 0.81132075, 0.81761006, 0.78616352, 0.79245283,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.81132075, 0.81761006, 0.81132075, 0.81761006, 0.81761006]), 'split3_test_score': array([0.78616352, 0.77987421, 0.78616352, 0.78616352, 0.79245283,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.7672956 , 0.78616352, 0.79245283, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.79245283, 0.79245283, 0.79245283, 0.79245283,\n",
      "       0.78616352, 0.79245283, 0.79245283, 0.79245283, 0.79245283,\n",
      "       0.79245283, 0.79245283, 0.78616352, 0.79245283, 0.78616352,\n",
      "       0.79245283, 0.79245283, 0.79245283, 0.79245283, 0.79245283,\n",
      "       0.79245283, 0.79245283, 0.79245283, 0.79245283, 0.79245283,\n",
      "       0.79245283, 0.79245283, 0.79245283, 0.79245283, 0.79245283,\n",
      "       0.79245283, 0.79245283, 0.79245283, 0.80503145, 0.80503145,\n",
      "       0.79874214, 0.80503145, 0.79874214, 0.79245283, 0.80503145,\n",
      "       0.80503145, 0.81132075, 0.80503145, 0.81132075, 0.79874214,\n",
      "       0.80503145, 0.79874214, 0.79245283, 0.79245283, 0.80503145,\n",
      "       0.80503145, 0.81132075, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.81132075, 0.81132075, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.81132075,\n",
      "       0.81132075, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.81132075, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.81132075, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.81132075, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.81132075, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.79245283, 0.79874214, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.79245283, 0.79245283, 0.80503145, 0.80503145,\n",
      "       0.79874214, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.75471698, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.79874214, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.7672956 , 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.77987421,\n",
      "       0.79874214, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.77987421, 0.79874214, 0.80503145, 0.80503145, 0.79874214,\n",
      "       0.81132075, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.77987421, 0.77987421, 0.80503145, 0.80503145,\n",
      "       0.78616352, 0.81132075, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.77358491, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.81761006, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.77358491, 0.81761006,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.77358491,\n",
      "       0.77987421, 0.80503145, 0.80503145, 0.81132075, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.80503145]), 'split4_test_score': array([0.73584906, 0.74842767, 0.74842767, 0.74842767, 0.74842767,\n",
      "       0.74842767, 0.74842767, 0.75471698, 0.74842767, 0.75471698,\n",
      "       0.75471698, 0.74842767, 0.74842767, 0.74842767, 0.74842767,\n",
      "       0.74842767, 0.74842767, 0.74842767, 0.74842767, 0.73584906,\n",
      "       0.74842767, 0.74842767, 0.74213836, 0.74842767, 0.74842767,\n",
      "       0.74842767, 0.74842767, 0.74842767, 0.74842767, 0.73584906,\n",
      "       0.74213836, 0.74842767, 0.74842767, 0.74842767, 0.74842767,\n",
      "       0.74842767, 0.74842767, 0.73584906, 0.74213836, 0.74842767,\n",
      "       0.74213836, 0.74842767, 0.74842767, 0.74842767, 0.74842767,\n",
      "       0.73584906, 0.74842767, 0.74842767, 0.76100629, 0.7672956 ,\n",
      "       0.74213836, 0.78616352, 0.74213836, 0.76100629, 0.77358491,\n",
      "       0.74213836, 0.75471698, 0.74842767, 0.74842767, 0.75471698,\n",
      "       0.74842767, 0.75471698, 0.74842767, 0.74842767, 0.78616352,\n",
      "       0.77987421, 0.77358491, 0.79245283, 0.78616352, 0.79245283,\n",
      "       0.78616352, 0.79245283, 0.79245283, 0.79245283, 0.78616352,\n",
      "       0.79245283, 0.78616352, 0.78616352, 0.79245283, 0.7672956 ,\n",
      "       0.79874214, 0.79245283, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.79874214, 0.77987421, 0.79874214, 0.79245283, 0.78616352,\n",
      "       0.79245283, 0.79245283, 0.79245283, 0.79874214, 0.78616352,\n",
      "       0.79245283, 0.81132075, 0.80503145, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.80503145, 0.79245283, 0.77987421, 0.79245283,\n",
      "       0.79245283, 0.79245283, 0.77987421, 0.79245283, 0.79245283,\n",
      "       0.78616352, 0.79245283, 0.81132075, 0.79245283, 0.79245283,\n",
      "       0.80503145, 0.79874214, 0.79874214, 0.79245283, 0.79874214,\n",
      "       0.79245283, 0.79874214, 0.79245283, 0.79245283, 0.79245283,\n",
      "       0.79245283, 0.79245283, 0.79245283, 0.81132075, 0.80503145,\n",
      "       0.79874214, 0.79874214, 0.79245283, 0.79874214, 0.79874214,\n",
      "       0.78616352, 0.79874214, 0.79874214, 0.79874214, 0.79245283,\n",
      "       0.79245283, 0.79874214, 0.79245283, 0.79245283, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.79874214, 0.79874214, 0.78616352,\n",
      "       0.79874214, 0.79245283, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79245283, 0.79245283, 0.79245283, 0.79874214, 0.78616352,\n",
      "       0.81132075, 0.80503145, 0.79245283, 0.79245283, 0.80503145,\n",
      "       0.80503145, 0.79874214, 0.78616352, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79245283, 0.79245283, 0.79245283,\n",
      "       0.79245283, 0.81132075, 0.80503145, 0.79874214, 0.78616352,\n",
      "       0.79874214, 0.80503145, 0.79245283, 0.79245283, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79245283, 0.79874214,\n",
      "       0.77987421, 0.78616352, 0.81761006, 0.79245283, 0.81132075,\n",
      "       0.78616352, 0.80503145, 0.79874214, 0.79874214, 0.78616352,\n",
      "       0.79874214, 0.79245283, 0.79874214, 0.79245283, 0.79245283,\n",
      "       0.79245283, 0.78616352, 0.79245283, 0.81761006, 0.81761006,\n",
      "       0.79874214, 0.78616352, 0.81132075, 0.79245283, 0.78616352,\n",
      "       0.78616352, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79245283, 0.79245283, 0.81132075,\n",
      "       0.80503145, 0.80503145, 0.79874214, 0.79245283, 0.79874214,\n",
      "       0.80503145, 0.79245283, 0.79874214, 0.79874214, 0.79245283,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79245283, 0.79245283,\n",
      "       0.81132075, 0.80503145, 0.79874214, 0.80503145, 0.79874214,\n",
      "       0.79245283, 0.78616352, 0.79245283, 0.79245283, 0.79245283,\n",
      "       0.79874214, 0.79874214, 0.79245283, 0.79874214, 0.79245283,\n",
      "       0.79245283, 0.79245283, 0.80503145, 0.79245283, 0.79245283,\n",
      "       0.79874214, 0.80503145, 0.79874214, 0.79245283, 0.78616352,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.79245283,\n",
      "       0.79245283, 0.79245283, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79245283, 0.81132075, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.79245283,\n",
      "       0.79874214, 0.79245283, 0.79245283, 0.79245283, 0.81132075,\n",
      "       0.78616352, 0.79874214, 0.80503145, 0.80503145, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79245283, 0.79245283,\n",
      "       0.79245283, 0.79245283, 0.79245283, 0.79245283, 0.79245283,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.80503145,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.79245283,\n",
      "       0.79874214, 0.79874214, 0.79245283, 0.79874214, 0.79874214]), 'split5_test_score': array([0.77358491, 0.77358491, 0.77358491, 0.77987421, 0.77987421,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.76100629, 0.77987421, 0.77358491, 0.77987421,\n",
      "       0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.78616352,\n",
      "       0.77987421, 0.78616352, 0.77358491, 0.77987421, 0.77987421,\n",
      "       0.77987421, 0.77987421, 0.78616352, 0.77358491, 0.77987421,\n",
      "       0.77987421, 0.77358491, 0.77358491, 0.79245283, 0.78616352,\n",
      "       0.77987421, 0.77358491, 0.78616352, 0.77987421, 0.77358491,\n",
      "       0.77358491, 0.78616352, 0.78616352, 0.77987421, 0.77358491,\n",
      "       0.77987421, 0.7672956 , 0.7672956 , 0.77987421, 0.77987421,\n",
      "       0.78616352, 0.77987421, 0.79245283, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.77987421, 0.79245283, 0.78616352, 0.77987421,\n",
      "       0.80503145, 0.77358491, 0.77358491, 0.77358491, 0.78616352,\n",
      "       0.81761006, 0.83018868, 0.80503145, 0.82389937, 0.82389937,\n",
      "       0.79874214, 0.82389937, 0.81132075, 0.80503145, 0.81132075,\n",
      "       0.82389937, 0.81761006, 0.81132075, 0.81761006, 0.79874214,\n",
      "       0.82389937, 0.82389937, 0.83018868, 0.82389937, 0.82389937,\n",
      "       0.83018868, 0.81761006, 0.82389937, 0.82389937, 0.81761006,\n",
      "       0.82389937, 0.82389937, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.83647799, 0.82389937, 0.83018868, 0.83018868,\n",
      "       0.83018868, 0.82389937, 0.83018868, 0.82389937, 0.82389937,\n",
      "       0.82389937, 0.82389937, 0.81761006, 0.81761006, 0.81132075,\n",
      "       0.82389937, 0.81761006, 0.83647799, 0.83647799, 0.83018868,\n",
      "       0.83018868, 0.83018868, 0.82389937, 0.83018868, 0.83018868,\n",
      "       0.82389937, 0.82389937, 0.81761006, 0.82389937, 0.81761006,\n",
      "       0.82389937, 0.82389937, 0.81761006, 0.81761006, 0.80503145,\n",
      "       0.82389937, 0.83018868, 0.82389937, 0.83018868, 0.83018868,\n",
      "       0.82389937, 0.82389937, 0.82389937, 0.82389937, 0.82389937,\n",
      "       0.81761006, 0.82389937, 0.82389937, 0.81761006, 0.81761006,\n",
      "       0.81132075, 0.82389937, 0.83018868, 0.82389937, 0.82389937,\n",
      "       0.83018868, 0.83018868, 0.82389937, 0.82389937, 0.82389937,\n",
      "       0.82389937, 0.81132075, 0.82389937, 0.81132075, 0.81761006,\n",
      "       0.79245283, 0.81761006, 0.81761006, 0.82389937, 0.81132075,\n",
      "       0.82389937, 0.83018868, 0.83018868, 0.82389937, 0.82389937,\n",
      "       0.82389937, 0.82389937, 0.82389937, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.80503145, 0.81761006, 0.81761006, 0.83018868,\n",
      "       0.81132075, 0.81761006, 0.83018868, 0.83018868, 0.82389937,\n",
      "       0.82389937, 0.82389937, 0.82389937, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.78616352, 0.81132075, 0.81761006,\n",
      "       0.83018868, 0.80503145, 0.81132075, 0.82389937, 0.83018868,\n",
      "       0.81761006, 0.82389937, 0.83018868, 0.82389937, 0.82389937,\n",
      "       0.82389937, 0.81761006, 0.82389937, 0.77987421, 0.79245283,\n",
      "       0.81761006, 0.83018868, 0.81132075, 0.81132075, 0.83018868,\n",
      "       0.82389937, 0.81761006, 0.82389937, 0.82389937, 0.82389937,\n",
      "       0.81761006, 0.82389937, 0.81761006, 0.81132075, 0.7672956 ,\n",
      "       0.77358491, 0.80503145, 0.82389937, 0.80503145, 0.81132075,\n",
      "       0.82389937, 0.82389937, 0.81761006, 0.81761006, 0.82389937,\n",
      "       0.81761006, 0.82389937, 0.82389937, 0.81761006, 0.81761006,\n",
      "       0.75471698, 0.78616352, 0.82389937, 0.83018868, 0.79874214,\n",
      "       0.79874214, 0.83018868, 0.83018868, 0.82389937, 0.82389937,\n",
      "       0.82389937, 0.81132075, 0.81132075, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.76100629, 0.78616352, 0.81132075, 0.82389937,\n",
      "       0.79874214, 0.80503145, 0.83018868, 0.83018868, 0.83018868,\n",
      "       0.82389937, 0.82389937, 0.82389937, 0.81761006, 0.81761006,\n",
      "       0.82389937, 0.81761006, 0.7672956 , 0.77358491, 0.81132075,\n",
      "       0.83018868, 0.80503145, 0.79874214, 0.83018868, 0.83018868,\n",
      "       0.82389937, 0.82389937, 0.82389937, 0.82389937, 0.81761006,\n",
      "       0.82389937, 0.81761006, 0.81761006, 0.74842767, 0.77358491,\n",
      "       0.81761006, 0.83018868, 0.79245283, 0.80503145, 0.81761006,\n",
      "       0.83018868, 0.82389937, 0.82389937, 0.82389937, 0.82389937,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.82389937, 0.74842767,\n",
      "       0.7672956 , 0.82389937, 0.83018868, 0.81132075, 0.80503145,\n",
      "       0.82389937, 0.83018868, 0.82389937, 0.82389937, 0.82389937,\n",
      "       0.82389937, 0.81761006, 0.81761006, 0.81761006, 0.81761006]), 'split6_test_score': array([0.77358491, 0.77987421, 0.77987421, 0.78616352, 0.78616352,\n",
      "       0.77987421, 0.78616352, 0.77358491, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.79245283, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.79245283, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.79245283, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.79245283, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.79874214, 0.79245283,\n",
      "       0.79245283, 0.79245283, 0.80503145, 0.79874214, 0.80503145,\n",
      "       0.79874214, 0.79874214, 0.79245283, 0.81132075, 0.79874214,\n",
      "       0.81132075, 0.80503145, 0.79245283, 0.79874214, 0.81761006,\n",
      "       0.83647799, 0.83018868, 0.8427673 , 0.81132075, 0.8427673 ,\n",
      "       0.83018868, 0.8427673 , 0.82389937, 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.83018868, 0.81132075, 0.83018868, 0.83018868,\n",
      "       0.83647799, 0.83018868, 0.83647799, 0.83647799, 0.83647799,\n",
      "       0.83647799, 0.8427673 , 0.83647799, 0.8427673 , 0.83647799,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.83647799, 0.83647799, 0.83647799,\n",
      "       0.83018868, 0.83647799, 0.83647799, 0.8427673 , 0.83647799,\n",
      "       0.8427673 , 0.83647799, 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.83647799, 0.83647799, 0.83647799,\n",
      "       0.8427673 , 0.8427673 , 0.83647799, 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.83647799, 0.8427673 ,\n",
      "       0.83647799, 0.83647799, 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.83647799,\n",
      "       0.83647799, 0.83647799, 0.8427673 , 0.8427673 , 0.83647799,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.81761006, 0.83647799, 0.8427673 , 0.8427673 , 0.83647799,\n",
      "       0.8427673 , 0.83647799, 0.83647799, 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.80503145, 0.8490566 , 0.8427673 , 0.8427673 ,\n",
      "       0.83647799, 0.8427673 , 0.83647799, 0.83647799, 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.83018868, 0.8490566 , 0.83647799,\n",
      "       0.83647799, 0.83647799, 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.81132075, 0.83647799,\n",
      "       0.83647799, 0.8427673 , 0.83647799, 0.8427673 , 0.8427673 ,\n",
      "       0.83647799, 0.8427673 , 0.8427673 , 0.83647799, 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.79874214,\n",
      "       0.83647799, 0.8427673 , 0.8427673 , 0.83018868, 0.8427673 ,\n",
      "       0.83647799, 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.80503145, 0.82389937, 0.8427673 , 0.83018868, 0.83647799,\n",
      "       0.83018868, 0.8427673 , 0.83647799, 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.83647799, 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.79245283, 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.83647799, 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.78616352, 0.83647799, 0.83647799,\n",
      "       0.8427673 , 0.82389937, 0.8427673 , 0.8427673 , 0.83647799,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.78616352, 0.83647799,\n",
      "       0.83647799, 0.83647799, 0.8427673 , 0.8427673 , 0.83647799,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.77358491,\n",
      "       0.82389937, 0.83647799, 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ]), 'split7_test_score': array([0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.76100629, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.77358491, 0.77358491, 0.77358491, 0.78616352,\n",
      "       0.77358491, 0.78616352, 0.77358491, 0.77358491, 0.77987421,\n",
      "       0.77358491, 0.78616352, 0.78616352, 0.78616352, 0.77358491,\n",
      "       0.77358491, 0.78616352, 0.77987421, 0.77987421, 0.77987421,\n",
      "       0.77987421, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.77358491, 0.77358491, 0.77987421, 0.77358491,\n",
      "       0.77358491, 0.77987421, 0.77358491, 0.81132075, 0.81132075,\n",
      "       0.80503145, 0.79874214, 0.81761006, 0.79245283, 0.79874214,\n",
      "       0.79245283, 0.79874214, 0.80503145, 0.78616352, 0.79245283,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.79245283, 0.81132075,\n",
      "       0.82389937, 0.82389937, 0.82389937, 0.82389937, 0.80503145,\n",
      "       0.81761006, 0.81761006, 0.81132075, 0.80503145, 0.81132075,\n",
      "       0.81761006, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.82389937, 0.82389937, 0.82389937, 0.82389937, 0.82389937,\n",
      "       0.82389937, 0.82389937, 0.82389937, 0.81761006, 0.81132075,\n",
      "       0.81132075, 0.81761006, 0.81132075, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.82389937, 0.82389937, 0.81761006, 0.81761006,\n",
      "       0.82389937, 0.82389937, 0.82389937, 0.82389937, 0.81761006,\n",
      "       0.81132075, 0.81761006, 0.81132075, 0.81132075, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.82389937, 0.82389937, 0.81761006,\n",
      "       0.81761006, 0.82389937, 0.82389937, 0.82389937, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81132075, 0.81132075, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.81132075, 0.81761006, 0.82389937,\n",
      "       0.82389937, 0.82389937, 0.81761006, 0.82389937, 0.82389937,\n",
      "       0.81761006, 0.81761006, 0.82389937, 0.81761006, 0.81132075,\n",
      "       0.81132075, 0.80503145, 0.80503145, 0.80503145, 0.81761006,\n",
      "       0.82389937, 0.81761006, 0.81761006, 0.82389937, 0.82389937,\n",
      "       0.82389937, 0.81132075, 0.81132075, 0.81761006, 0.81761006,\n",
      "       0.81132075, 0.80503145, 0.80503145, 0.81132075, 0.80503145,\n",
      "       0.81132075, 0.82389937, 0.82389937, 0.82389937, 0.82389937,\n",
      "       0.82389937, 0.82389937, 0.81761006, 0.80503145, 0.80503145,\n",
      "       0.81761006, 0.81132075, 0.80503145, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.79245283, 0.81132075, 0.81761006, 0.81761006,\n",
      "       0.82389937, 0.82389937, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.82389937, 0.81761006, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.78616352, 0.81761006, 0.82389937,\n",
      "       0.82389937, 0.82389937, 0.82389937, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81132075, 0.81761006, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.80503145, 0.79874214, 0.81132075,\n",
      "       0.82389937, 0.81761006, 0.81761006, 0.82389937, 0.81761006,\n",
      "       0.81761006, 0.82389937, 0.81132075, 0.81761006, 0.81761006,\n",
      "       0.80503145, 0.81132075, 0.81132075, 0.80503145, 0.77987421,\n",
      "       0.81132075, 0.82389937, 0.82389937, 0.82389937, 0.82389937,\n",
      "       0.81761006, 0.81761006, 0.82389937, 0.82389937, 0.81761006,\n",
      "       0.81761006, 0.80503145, 0.81132075, 0.80503145, 0.81132075,\n",
      "       0.76100629, 0.82389937, 0.81761006, 0.82389937, 0.81761006,\n",
      "       0.81761006, 0.82389937, 0.81761006, 0.81761006, 0.81132075,\n",
      "       0.81132075, 0.81761006, 0.80503145, 0.81132075, 0.80503145,\n",
      "       0.80503145, 0.7672956 , 0.81132075, 0.82389937, 0.81761006,\n",
      "       0.82389937, 0.82389937, 0.82389937, 0.81761006, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81761006, 0.80503145, 0.81132075,\n",
      "       0.80503145, 0.81132075, 0.7672956 , 0.81132075, 0.82389937,\n",
      "       0.81761006, 0.79874214, 0.82389937, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.80503145, 0.80503145, 0.77358491, 0.79245283,\n",
      "       0.81761006, 0.82389937, 0.82389937, 0.82389937, 0.82389937,\n",
      "       0.81761006, 0.81132075, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.80503145, 0.7672956 ,\n",
      "       0.81132075, 0.82389937, 0.82389937, 0.82389937, 0.82389937,\n",
      "       0.82389937, 0.81761006, 0.82389937, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.80503145, 0.81761006, 0.80503145, 0.81132075]), 'split8_test_score': array([0.80503145, 0.80503145, 0.79874214, 0.79874214, 0.80503145,\n",
      "       0.79874214, 0.79874214, 0.80503145, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.79874214, 0.80503145, 0.80503145, 0.80503145, 0.79874214,\n",
      "       0.80503145, 0.79874214, 0.79874214, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.80503145, 0.79874214, 0.80503145, 0.79874214,\n",
      "       0.79874214, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79245283, 0.79874214, 0.79874214, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.80503145, 0.83647799,\n",
      "       0.82389937, 0.83647799, 0.83647799, 0.81132075, 0.82389937,\n",
      "       0.83647799, 0.81132075, 0.8490566 , 0.83018868, 0.82389937,\n",
      "       0.8427673 , 0.81761006, 0.8427673 , 0.81761006, 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8490566 , 0.8427673 , 0.8490566 , 0.8490566 ,\n",
      "       0.8427673 , 0.8490566 , 0.8490566 , 0.85534591, 0.8490566 ,\n",
      "       0.8490566 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8490566 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8490566 , 0.8427673 , 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 , 0.85534591,\n",
      "       0.8490566 , 0.8490566 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8490566 , 0.8427673 , 0.8427673 , 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.83647799, 0.8490566 , 0.8490566 , 0.8490566 , 0.83647799,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.85534591, 0.8490566 , 0.8490566 , 0.85534591,\n",
      "       0.8427673 , 0.8427673 , 0.8490566 , 0.8427673 , 0.83647799,\n",
      "       0.8427673 , 0.8427673 , 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 , 0.8427673 ,\n",
      "       0.8490566 , 0.83647799, 0.83018868, 0.83647799, 0.8490566 ,\n",
      "       0.83647799, 0.83647799, 0.8427673 , 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.82389937, 0.83018868, 0.8427673 ,\n",
      "       0.8490566 , 0.8427673 , 0.83647799, 0.8427673 , 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.8427673 , 0.8490566 , 0.83018868, 0.83647799,\n",
      "       0.83018868, 0.8490566 , 0.83647799, 0.8427673 , 0.8427673 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 , 0.82389937,\n",
      "       0.8490566 , 0.8427673 , 0.8490566 , 0.8427673 , 0.8490566 ,\n",
      "       0.83647799, 0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.81761006, 0.8427673 , 0.83018868, 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.8427673 , 0.8427673 , 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.82389937, 0.83647799, 0.8427673 , 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.8427673 , 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.85534591, 0.85534591,\n",
      "       0.8490566 , 0.8490566 , 0.80503145, 0.83647799, 0.8427673 ,\n",
      "       0.8490566 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.85534591, 0.82389937, 0.83018868,\n",
      "       0.83647799, 0.8490566 , 0.8490566 , 0.83647799, 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.85534591, 0.8490566 , 0.8490566 , 0.85534591, 0.81761006,\n",
      "       0.83647799, 0.83647799, 0.8490566 , 0.8427673 , 0.8490566 ,\n",
      "       0.8427673 , 0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 ]), 'split9_test_score': array([0.80379747, 0.80379747, 0.80379747, 0.80379747, 0.79746835,\n",
      "       0.80379747, 0.79746835, 0.80379747, 0.80379747, 0.80379747,\n",
      "       0.80379747, 0.77848101, 0.80379747, 0.78481013, 0.80379747,\n",
      "       0.79746835, 0.80379747, 0.80379747, 0.79746835, 0.80379747,\n",
      "       0.79746835, 0.80379747, 0.80379747, 0.80379747, 0.80379747,\n",
      "       0.80379747, 0.79746835, 0.80379747, 0.80379747, 0.80379747,\n",
      "       0.80379747, 0.80379747, 0.80379747, 0.80379747, 0.80379747,\n",
      "       0.80379747, 0.80379747, 0.80379747, 0.80379747, 0.80379747,\n",
      "       0.79746835, 0.80379747, 0.80379747, 0.80379747, 0.80379747,\n",
      "       0.80379747, 0.79746835, 0.80379747, 0.80379747, 0.81012658,\n",
      "       0.81012658, 0.80379747, 0.80379747, 0.8164557 , 0.82278481,\n",
      "       0.80379747, 0.82278481, 0.82278481, 0.80379747, 0.8164557 ,\n",
      "       0.82278481, 0.81012658, 0.80379747, 0.8164557 , 0.85443038,\n",
      "       0.85443038, 0.85443038, 0.85443038, 0.85443038, 0.85443038,\n",
      "       0.85443038, 0.85443038, 0.85443038, 0.85443038, 0.85443038,\n",
      "       0.85443038, 0.84810127, 0.85443038, 0.84177215, 0.83544304,\n",
      "       0.85443038, 0.85443038, 0.85443038, 0.85443038, 0.85443038,\n",
      "       0.85443038, 0.85443038, 0.85443038, 0.85443038, 0.85443038,\n",
      "       0.85443038, 0.85443038, 0.85443038, 0.85443038, 0.85443038,\n",
      "       0.85443038, 0.85443038, 0.86075949, 0.85443038, 0.85443038,\n",
      "       0.85443038, 0.85443038, 0.86075949, 0.85443038, 0.85443038,\n",
      "       0.85443038, 0.85443038, 0.85443038, 0.85443038, 0.85443038,\n",
      "       0.85443038, 0.85443038, 0.85443038, 0.86075949, 0.85443038,\n",
      "       0.85443038, 0.85443038, 0.85443038, 0.85443038, 0.85443038,\n",
      "       0.85443038, 0.85443038, 0.85443038, 0.85443038, 0.85443038,\n",
      "       0.85443038, 0.85443038, 0.85443038, 0.84810127, 0.84810127,\n",
      "       0.85443038, 0.85443038, 0.85443038, 0.85443038, 0.85443038,\n",
      "       0.85443038, 0.85443038, 0.85443038, 0.85443038, 0.85443038,\n",
      "       0.85443038, 0.85443038, 0.85443038, 0.85443038, 0.83544304,\n",
      "       0.84177215, 0.85443038, 0.85443038, 0.85443038, 0.84810127,\n",
      "       0.85443038, 0.85443038, 0.85443038, 0.85443038, 0.85443038,\n",
      "       0.85443038, 0.85443038, 0.85443038, 0.85443038, 0.85443038,\n",
      "       0.8164557 , 0.83544304, 0.85443038, 0.85443038, 0.84810127,\n",
      "       0.85443038, 0.85443038, 0.85443038, 0.85443038, 0.85443038,\n",
      "       0.85443038, 0.85443038, 0.85443038, 0.85443038, 0.85443038,\n",
      "       0.85443038, 0.8164557 , 0.83544304, 0.85443038, 0.85443038,\n",
      "       0.83544304, 0.84177215, 0.85443038, 0.85443038, 0.85443038,\n",
      "       0.85443038, 0.85443038, 0.85443038, 0.85443038, 0.85443038,\n",
      "       0.85443038, 0.85443038, 0.8164557 , 0.82911392, 0.85443038,\n",
      "       0.85443038, 0.84177215, 0.84177215, 0.85443038, 0.85443038,\n",
      "       0.85443038, 0.85443038, 0.85443038, 0.85443038, 0.85443038,\n",
      "       0.85443038, 0.85443038, 0.85443038, 0.81012658, 0.82911392,\n",
      "       0.85443038, 0.85443038, 0.83544304, 0.83544304, 0.85443038,\n",
      "       0.85443038, 0.85443038, 0.85443038, 0.85443038, 0.85443038,\n",
      "       0.85443038, 0.85443038, 0.85443038, 0.85443038, 0.79746835,\n",
      "       0.83544304, 0.84810127, 0.85443038, 0.83544304, 0.82911392,\n",
      "       0.85443038, 0.85443038, 0.85443038, 0.85443038, 0.85443038,\n",
      "       0.85443038, 0.85443038, 0.85443038, 0.85443038, 0.85443038,\n",
      "       0.80379747, 0.82911392, 0.84177215, 0.85443038, 0.82911392,\n",
      "       0.84177215, 0.85443038, 0.85443038, 0.85443038, 0.85443038,\n",
      "       0.85443038, 0.85443038, 0.85443038, 0.85443038, 0.85443038,\n",
      "       0.85443038, 0.80379747, 0.82911392, 0.85443038, 0.85443038,\n",
      "       0.84177215, 0.84177215, 0.85443038, 0.85443038, 0.85443038,\n",
      "       0.85443038, 0.85443038, 0.85443038, 0.85443038, 0.85443038,\n",
      "       0.85443038, 0.85443038, 0.79746835, 0.82911392, 0.85443038,\n",
      "       0.85443038, 0.83544304, 0.84177215, 0.85443038, 0.85443038,\n",
      "       0.85443038, 0.85443038, 0.85443038, 0.85443038, 0.85443038,\n",
      "       0.85443038, 0.85443038, 0.85443038, 0.79746835, 0.82278481,\n",
      "       0.85443038, 0.85443038, 0.82911392, 0.83544304, 0.85443038,\n",
      "       0.85443038, 0.85443038, 0.85443038, 0.85443038, 0.85443038,\n",
      "       0.85443038, 0.85443038, 0.85443038, 0.85443038, 0.81012658,\n",
      "       0.8164557 , 0.85443038, 0.85443038, 0.82911392, 0.84177215,\n",
      "       0.85443038, 0.85443038, 0.85443038, 0.85443038, 0.85443038,\n",
      "       0.85443038, 0.85443038, 0.85443038, 0.85443038, 0.85443038]), 'mean_test_score': array([0.78541119, 0.78666906, 0.78604012, 0.78666906, 0.78729401,\n",
      "       0.7835244 , 0.78666507, 0.78666906, 0.78729799, 0.78729799,\n",
      "       0.78541119, 0.78350848, 0.78855585, 0.78477032, 0.78792692,\n",
      "       0.78477828, 0.78666906, 0.78541119, 0.78603614, 0.78729799,\n",
      "       0.78540721, 0.78855585, 0.78604012, 0.78729799, 0.78792692,\n",
      "       0.78666906, 0.78729401, 0.78792692, 0.78729799, 0.78541119,\n",
      "       0.78604012, 0.78792692, 0.78604012, 0.78855585, 0.78792692,\n",
      "       0.78792692, 0.78792692, 0.78855585, 0.78792692, 0.78729799,\n",
      "       0.78603614, 0.78729799, 0.78792692, 0.78855585, 0.78604012,\n",
      "       0.78541119, 0.78414935, 0.78541119, 0.79861874, 0.79988058,\n",
      "       0.79359127, 0.7998766 , 0.80239233, 0.79673991, 0.80051747,\n",
      "       0.79295836, 0.79674389, 0.79422817, 0.79295836, 0.79736884,\n",
      "       0.79863068, 0.79422021, 0.79044264, 0.79359526, 0.81814744,\n",
      "       0.82443675, 0.8275814 , 0.82569461, 0.82443675, 0.82506568,\n",
      "       0.82443675, 0.82380782, 0.82380782, 0.82317889, 0.82254996,\n",
      "       0.82821033, 0.81940132, 0.82066316, 0.81939734, 0.8181355 ,\n",
      "       0.83072606, 0.82821033, 0.8294682 , 0.82821033, 0.83009713,\n",
      "       0.83135499, 0.82883926, 0.83009713, 0.8294682 , 0.8275814 ,\n",
      "       0.82821033, 0.82883926, 0.8294682 , 0.82506568, 0.82443675,\n",
      "       0.82695247, 0.83449964, 0.83261683, 0.83072606, 0.83135499,\n",
      "       0.83072606, 0.83198392, 0.83135897, 0.8294682 , 0.83009713,\n",
      "       0.8294682 , 0.83009713, 0.8275814 , 0.82632354, 0.82632354,\n",
      "       0.82821033, 0.82695247, 0.83324178, 0.83324576, 0.8294682 ,\n",
      "       0.83324178, 0.83198392, 0.83009713, 0.83135499, 0.83198392,\n",
      "       0.83072606, 0.83198392, 0.8294682 , 0.82883926, 0.8275814 ,\n",
      "       0.82883926, 0.8275814 , 0.82821033, 0.82946421, 0.83009315,\n",
      "       0.83072606, 0.83198392, 0.8294682 , 0.83198392, 0.83198392,\n",
      "       0.83009713, 0.83135499, 0.83198392, 0.83198392, 0.8294682 ,\n",
      "       0.82821033, 0.82883926, 0.82821033, 0.82695247, 0.82568267,\n",
      "       0.82820237, 0.83135499, 0.83261285, 0.83072606, 0.82757742,\n",
      "       0.83261285, 0.83135499, 0.83072606, 0.83135499, 0.83135499,\n",
      "       0.8294682 , 0.8275814 , 0.82883926, 0.82632354, 0.8275814 ,\n",
      "       0.81560783, 0.8263116 , 0.83009713, 0.83072606, 0.82757742,\n",
      "       0.83135499, 0.83135499, 0.83009713, 0.82821033, 0.83072606,\n",
      "       0.83135499, 0.83009713, 0.82883926, 0.82883926, 0.82821033,\n",
      "       0.8275814 , 0.81057639, 0.82128015, 0.82821033, 0.83135499,\n",
      "       0.82442481, 0.82820237, 0.83009713, 0.83072606, 0.83135499,\n",
      "       0.83198392, 0.83135499, 0.83072606, 0.8275814 , 0.8294682 ,\n",
      "       0.82821033, 0.82695247, 0.80365815, 0.81687366, 0.8294682 ,\n",
      "       0.83072606, 0.82505772, 0.82379986, 0.83009713, 0.83135499,\n",
      "       0.83135499, 0.83072606, 0.83135499, 0.82883926, 0.8294682 ,\n",
      "       0.8275814 , 0.82632354, 0.8275814 , 0.79673593, 0.81624473,\n",
      "       0.82695247, 0.8294682 , 0.82253801, 0.82316695, 0.82883926,\n",
      "       0.8294682 , 0.83135499, 0.83072606, 0.83072606, 0.83072606,\n",
      "       0.8275814 , 0.8294682 , 0.8275814 , 0.82569461, 0.79043866,\n",
      "       0.81310405, 0.82757742, 0.83135499, 0.82190908, 0.82693655,\n",
      "       0.8294682 , 0.83072606, 0.83135499, 0.83198392, 0.83009713,\n",
      "       0.82883926, 0.82821033, 0.82821033, 0.82821033, 0.8275814 ,\n",
      "       0.78604012, 0.81184221, 0.82820237, 0.83261285, 0.81876045,\n",
      "       0.82002627, 0.83009713, 0.83009713, 0.83135499, 0.83009713,\n",
      "       0.82883926, 0.82883926, 0.82569461, 0.8294682 , 0.82632354,\n",
      "       0.82695247, 0.78666906, 0.80618183, 0.82632354, 0.83072606,\n",
      "       0.822542  , 0.82379986, 0.83072606, 0.83135499, 0.83009713,\n",
      "       0.8294682 , 0.83009713, 0.83072606, 0.82883926, 0.82883926,\n",
      "       0.8275814 , 0.82632354, 0.78477828, 0.80743969, 0.8275814 ,\n",
      "       0.83198392, 0.82002229, 0.82442879, 0.83072606, 0.83009713,\n",
      "       0.83198392, 0.83009713, 0.83072606, 0.83009713, 0.82695247,\n",
      "       0.83009713, 0.82883926, 0.8275814 , 0.78603614, 0.80680678,\n",
      "       0.82506568, 0.83324178, 0.82127617, 0.82190908, 0.8294682 ,\n",
      "       0.83198392, 0.83072606, 0.83135499, 0.83072606, 0.8294682 ,\n",
      "       0.82821033, 0.82821033, 0.8294682 , 0.82821033, 0.78227052,\n",
      "       0.80428708, 0.8275814 , 0.83261285, 0.82064724, 0.82505772,\n",
      "       0.83072606, 0.83261285, 0.83135499, 0.83135499, 0.83198392,\n",
      "       0.83072606, 0.8275814 , 0.8294682 , 0.82821033, 0.83009713]), 'std_test_score': array([0.02083254, 0.01776623, 0.01674155, 0.01661576, 0.01626827,\n",
      "       0.01791078, 0.01642067, 0.01708525, 0.01693867, 0.01597731,\n",
      "       0.01636649, 0.01741922, 0.0165702 , 0.01634683, 0.01652966,\n",
      "       0.01550104, 0.01905532, 0.01819754, 0.01792473, 0.01974241,\n",
      "       0.01688609, 0.01794541, 0.01874778, 0.01871383, 0.01812752,\n",
      "       0.01731522, 0.01650962, 0.01676725, 0.01850125, 0.02064179,\n",
      "       0.01997362, 0.01939262, 0.01810375, 0.01859492, 0.01700152,\n",
      "       0.01676725, 0.01790799, 0.02080368, 0.01898029, 0.01739945,\n",
      "       0.01836077, 0.01933754, 0.01939262, 0.0172715 , 0.01766136,\n",
      "       0.02025491, 0.01857267, 0.01819754, 0.0228192 , 0.02037473,\n",
      "       0.0201424 , 0.01748843, 0.02438092, 0.01937668, 0.01936626,\n",
      "       0.02269291, 0.01850855, 0.02052112, 0.01909601, 0.02071233,\n",
      "       0.02358369, 0.01939588, 0.02020739, 0.02180816, 0.02312562,\n",
      "       0.02480034, 0.02396037, 0.02325775, 0.0251173 , 0.02106886,\n",
      "       0.0251173 , 0.0195438 , 0.02053085, 0.02348484, 0.0237087 ,\n",
      "       0.02538164, 0.01955691, 0.02292949, 0.01917483, 0.02369742,\n",
      "       0.02083875, 0.02112938, 0.02230049, 0.02275193, 0.02474941,\n",
      "       0.02128285, 0.02700716, 0.02490872, 0.023677  , 0.02616972,\n",
      "       0.02522531, 0.02565516, 0.0240088 , 0.02269574, 0.02415393,\n",
      "       0.02509497, 0.01940109, 0.02096675, 0.02158467, 0.02340711,\n",
      "       0.02265754, 0.02188118, 0.02304675, 0.02681086, 0.02442767,\n",
      "       0.02544842, 0.02442767, 0.02763992, 0.02224316, 0.0253982 ,\n",
      "       0.02674747, 0.02509497, 0.01795486, 0.02208114, 0.02265246,\n",
      "       0.02263278, 0.02151659, 0.02222312, 0.02340711, 0.02361984,\n",
      "       0.02466368, 0.02508179, 0.02695799, 0.02422782, 0.02571228,\n",
      "       0.02439054, 0.0264703 , 0.02506802, 0.01778651, 0.02277297,\n",
      "       0.02140062, 0.02311198, 0.02299905, 0.02151659, 0.02076823,\n",
      "       0.02569046, 0.02374268, 0.02345177, 0.02508179, 0.02529251,\n",
      "       0.02442869, 0.02389906, 0.02475042, 0.02509497, 0.01818087,\n",
      "       0.01749679, 0.02128285, 0.02347951, 0.02248229, 0.02262297,\n",
      "       0.0219109 , 0.02488157, 0.02283146, 0.02374268, 0.02535401,\n",
      "       0.02384348, 0.02586566, 0.02439054, 0.02345497, 0.02632044,\n",
      "       0.01887004, 0.01927217, 0.02377113, 0.02265754, 0.02080115,\n",
      "       0.02090783, 0.02128285, 0.02538065, 0.02410267, 0.02606716,\n",
      "       0.02374268, 0.02458906, 0.02439054, 0.02550051, 0.02522531,\n",
      "       0.02461186, 0.01784729, 0.02063377, 0.02075159, 0.02550954,\n",
      "       0.02181393, 0.0202233 , 0.0225763 , 0.02300405, 0.02374268,\n",
      "       0.02345177, 0.02374268, 0.02417776, 0.02461186, 0.0231704 ,\n",
      "       0.02733261, 0.02556346, 0.02309322, 0.02594738, 0.01945882,\n",
      "       0.02514022, 0.02256595, 0.02411957, 0.02204441, 0.02550954,\n",
      "       0.02535401, 0.02466368, 0.02407357, 0.024064  , 0.02544842,\n",
      "       0.02477206, 0.02676319, 0.0264703 , 0.02225909, 0.02377278,\n",
      "       0.02039995, 0.02465901, 0.02630257, 0.02453904, 0.02439054,\n",
      "       0.024173  , 0.02374268, 0.02576189, 0.02351424, 0.02417776,\n",
      "       0.0242883 , 0.0248189 , 0.02461186, 0.02425674, 0.01903597,\n",
      "       0.02860817, 0.02398098, 0.02219268, 0.02397929, 0.02163699,\n",
      "       0.02064248, 0.02498238, 0.02374268, 0.02361984, 0.02659824,\n",
      "       0.02339727, 0.02275193, 0.023938  , 0.02614924, 0.02616972,\n",
      "       0.02222338, 0.02451501, 0.02381603, 0.02209069, 0.02344918,\n",
      "       0.02677822, 0.02377113, 0.0225763 , 0.02597056, 0.02506702,\n",
      "       0.02356572, 0.02356572, 0.02505883, 0.0248189 , 0.02705717,\n",
      "       0.02509497, 0.02158586, 0.02454664, 0.02508479, 0.02466368,\n",
      "       0.0270228 , 0.02492607, 0.02212761, 0.02456156, 0.02599657,\n",
      "       0.0231704 , 0.02442767, 0.02417776, 0.02471276, 0.02503084,\n",
      "       0.0264703 , 0.02242029, 0.01524373, 0.02540724, 0.02277546,\n",
      "       0.02444283, 0.02650245, 0.02515761, 0.02194812, 0.02326657,\n",
      "       0.02539525, 0.02442767, 0.02417776, 0.02458906, 0.02493684,\n",
      "       0.02442767, 0.02580888, 0.02445062, 0.02260889, 0.02617224,\n",
      "       0.02286936, 0.02297966, 0.02066378, 0.02279537, 0.02247716,\n",
      "       0.02361984, 0.02417776, 0.02237021, 0.0263689 , 0.02529251,\n",
      "       0.02674747, 0.02426623, 0.02529251, 0.02553701, 0.02273614,\n",
      "       0.02516976, 0.02224834, 0.02331043, 0.01948809, 0.02308583,\n",
      "       0.02176715, 0.02347951, 0.02374268, 0.02237021, 0.0258583 ,\n",
      "       0.02417776, 0.02277546, 0.02529251, 0.02553701, 0.02442767]), 'rank_test_score': array([307, 291, 298, 291, 289, 318, 297, 291, 282, 282, 307, 319, 268,\n",
      "       316, 276, 314, 291, 307, 305, 282, 313, 268, 301, 282, 273, 296,\n",
      "       289, 273, 282, 307, 301, 276, 298, 272, 276, 273, 276, 268, 276,\n",
      "       282, 305, 282, 276, 268, 301, 307, 317, 307, 255, 252, 263, 253,\n",
      "       250, 258, 251, 264, 257, 260, 264, 256, 254, 261, 266, 262, 237,\n",
      "       211, 164, 202, 211, 206, 211, 217, 217, 221, 223, 142, 234, 230,\n",
      "       235, 238,  53, 142, 102, 142,  79,  28, 126,  79, 102, 176, 142,\n",
      "       126, 102, 206, 211, 186,   1,   6,  53,  28,  53,  12,  27, 102,\n",
      "        79, 102,  79, 176, 194, 194, 142, 186,   3,   2, 102,   3,  13,\n",
      "        79,  28,  13,  53,  13, 102, 126, 176, 126, 164, 142, 125, 101,\n",
      "        53,  13, 102,  13,  13,  79,  28,  13,  13, 102, 142, 126, 142,\n",
      "       186, 205, 161,  28,   7,  53, 183,  10,  28,  53,  28,  28, 102,\n",
      "       176, 126, 194, 176, 241, 201,  79,  53, 183,  28,  28,  79, 142,\n",
      "        53,  28,  79, 126, 126, 142, 164, 244, 228, 142,  28, 216, 161,\n",
      "        79,  53,  28,  13,  28,  53, 164, 102, 159, 186, 249, 239, 102,\n",
      "        53, 209, 219,  79,  28,  28,  53,  28, 126, 102, 176, 194, 164,\n",
      "       259, 240, 186, 102, 225, 222, 126, 102,  28,  53,  53,  53, 164,\n",
      "       102, 164, 202, 267, 242, 183,  28, 226, 193, 102,  53,  28,  13,\n",
      "        79, 126, 142, 159, 142, 164, 298, 243, 163,   7, 236, 232,  79,\n",
      "        79,  28,  79, 126, 126, 202, 102, 194, 186, 291, 247, 194,  53,\n",
      "       224, 219,  53,  28,  79, 102,  79,  53, 126, 126, 164, 194, 314,\n",
      "       245, 164,  13, 233, 215,  53,  79,  13,  79,  53,  79, 186,  79,\n",
      "       126, 176, 304, 246, 206,   3, 229, 226, 102,  13,  53,  28,  53,\n",
      "       102, 142, 142, 102, 142, 320, 248, 164,  10, 231, 209,  53,   7,\n",
      "        28,  28,  13,  53, 164, 102, 142,  79])}\n",
      "Resultados para Balanced:\n",
      "{'mean_fit_time': array([0.1073535 , 0.10704577, 0.1040128 , 0.10791819, 0.10859144,\n",
      "       0.10596981, 0.10533404, 0.10784004, 0.10452721, 0.10440841,\n",
      "       0.10678866, 0.1060082 , 0.10517876, 0.10511785, 0.10485377,\n",
      "       0.1047081 , 0.10890307, 0.11344013, 0.10785058, 0.10803115,\n",
      "       0.11188915, 0.10825007, 0.10764287, 0.10932877, 0.10743082,\n",
      "       0.10746832, 0.10787778, 0.1074667 , 0.11347563, 0.10749698,\n",
      "       0.10809004, 0.10784762, 0.11089718, 0.11047599, 0.11070552,\n",
      "       0.11097097, 0.1140471 , 0.11496091, 0.11457565, 0.11420138,\n",
      "       0.11505327, 0.11347492, 0.11360033, 0.11387043, 0.11376665,\n",
      "       0.11437552, 0.11438978, 0.11125629, 0.11619997, 0.11413665,\n",
      "       0.11429791, 0.11412208, 0.11549923, 0.1206749 , 0.12595444,\n",
      "       0.11394367, 0.11463456, 0.11737132, 0.11705837, 0.11489325,\n",
      "       0.1141614 , 0.11410925, 0.11441493, 0.11502347, 0.12471759,\n",
      "       0.11812127, 0.11843252, 0.12200692, 0.11749561, 0.11753867,\n",
      "       0.11762114, 0.11695352, 0.11736519, 0.11721153, 0.11712291,\n",
      "       0.11702063, 0.11640718, 0.11661429, 0.11665306, 0.11647696,\n",
      "       0.12119203, 0.12145715, 0.12108207, 0.12043238, 0.12176528,\n",
      "       0.12174635, 0.12157044, 0.12018886, 0.1203263 , 0.12055225,\n",
      "       0.12016187, 0.11975625, 0.11894062, 0.11945717, 0.11915109,\n",
      "       0.11848223, 0.12719519, 0.12870204, 0.12787287, 0.12636585,\n",
      "       0.12828014, 0.12790306, 0.12742858, 0.1253675 , 0.12590494,\n",
      "       0.12607026, 0.12617073, 0.12555799, 0.12459931, 0.12489021,\n",
      "       0.12345011, 0.12410011, 0.13394945, 0.13165553, 0.12764673,\n",
      "       0.12716727, 0.12908802, 0.12862804, 0.12714169, 0.12577221,\n",
      "       0.12567353, 0.12612159, 0.12600276, 0.1247225 , 0.12312596,\n",
      "       0.12311695, 0.123261  , 0.12307541, 0.13466585, 0.13277817,\n",
      "       0.1305135 , 0.12764196, 0.13212895, 0.13146045, 0.1296509 ,\n",
      "       0.12909083, 0.13007531, 0.12917552, 0.12841828, 0.13308897,\n",
      "       0.12715249, 0.12736642, 0.12717347, 0.12571228, 0.13750157,\n",
      "       0.13468091, 0.13212798, 0.12971778, 0.13545527, 0.13381746,\n",
      "       0.13194931, 0.12822046, 0.12907887, 0.12871313, 0.12858791,\n",
      "       0.12648003, 0.12464511, 0.12441289, 0.12449629, 0.12431989,\n",
      "       0.14155304, 0.13828976, 0.13421898, 0.137644  , 0.13924959,\n",
      "       0.13968854, 0.138095  , 0.13082821, 0.13258729, 0.13345416,\n",
      "       0.13287394, 0.13077066, 0.12815223, 0.12820013, 0.12910049,\n",
      "       0.12850254, 0.14817567, 0.14411139, 0.13940027, 0.1348918 ,\n",
      "       0.1419714 , 0.14209843, 0.13854542, 0.13351903, 0.13084576,\n",
      "       0.13134744, 0.13376813, 0.12817457, 0.12517166, 0.12591746,\n",
      "       0.12841463, 0.12755013, 0.15009568, 0.14487138, 0.13994842,\n",
      "       0.13899975, 0.14304833, 0.14233153, 0.13891838, 0.13375306,\n",
      "       0.13338823, 0.13254495, 0.13167841, 0.13031957, 0.12470415,\n",
      "       0.12512016, 0.12561691, 0.12945688, 0.15552709, 0.14735017,\n",
      "       0.14088268, 0.13509448, 0.14485102, 0.14202685, 0.13743994,\n",
      "       0.13011651, 0.13129292, 0.1327105 , 0.13288054, 0.12836175,\n",
      "       0.12579668, 0.12538602, 0.12548988, 0.12537439, 0.15012741,\n",
      "       0.14547267, 0.13733778, 0.13442311, 0.144976  , 0.14389501,\n",
      "       0.13930395, 0.13362584, 0.13500025, 0.13553975, 0.13538015,\n",
      "       0.13114905, 0.13021533, 0.13245928, 0.12581573, 0.12953715,\n",
      "       0.15235813, 0.14865868, 0.13895609, 0.13259828, 0.14492664,\n",
      "       0.14200165, 0.13793361, 0.13198338, 0.13807621, 0.13329623,\n",
      "       0.13398085, 0.13244722, 0.12682865, 0.12739768, 0.12583508,\n",
      "       0.12688351, 0.15850458, 0.15015287, 0.1444113 , 0.13262269,\n",
      "       0.14454486, 0.1408354 , 0.13872054, 0.13410048, 0.13495471,\n",
      "       0.13552611, 0.13832402, 0.13112955, 0.12881992, 0.12894552,\n",
      "       0.12877176, 0.12893422, 0.15780628, 0.14869869, 0.1455251 ,\n",
      "       0.13584819, 0.14698322, 0.14921467, 0.13804479, 0.13602576,\n",
      "       0.13187897, 0.13778996, 0.1582485 , 0.13670437, 0.13273957,\n",
      "       0.13356609, 0.13294272, 0.13314002, 0.16555436, 0.15730553,\n",
      "       0.14877231, 0.1389976 , 0.15113933, 0.14986477, 0.15310731,\n",
      "       0.14311512, 0.1392699 , 0.13979094, 0.13909943, 0.13717036,\n",
      "       0.13451843, 0.13468535, 0.13410285, 0.13555689, 0.16250417,\n",
      "       0.15443261, 0.14734104, 0.13835156, 0.15196114, 0.14879773,\n",
      "       0.14439473, 0.14076326, 0.13887544, 0.13898625, 0.13981795,\n",
      "       0.13728218, 0.1382544 , 0.13272877, 0.13186774, 0.13401887]), 'std_fit_time': array([0.00188281, 0.00351587, 0.00063655, 0.00142533, 0.00035571,\n",
      "       0.00157985, 0.0005321 , 0.00163748, 0.00039924, 0.00088673,\n",
      "       0.00113378, 0.00113185, 0.00047219, 0.0006477 , 0.00059161,\n",
      "       0.00056683, 0.00145123, 0.00106879, 0.00068751, 0.00054407,\n",
      "       0.00079145, 0.00174217, 0.00074528, 0.00377395, 0.00059553,\n",
      "       0.00045478, 0.00041003, 0.0006323 , 0.01005389, 0.00052462,\n",
      "       0.0014481 , 0.00035701, 0.00049523, 0.00058703, 0.00043168,\n",
      "       0.00061668, 0.00040654, 0.00082323, 0.00047399, 0.00060127,\n",
      "       0.00367984, 0.00065627, 0.00048999, 0.00083199, 0.00094418,\n",
      "       0.00087551, 0.0012734 , 0.0004667 , 0.00237794, 0.00058709,\n",
      "       0.00066805, 0.00036482, 0.00177729, 0.00117269, 0.02726776,\n",
      "       0.00047503, 0.00110924, 0.0010967 , 0.00242335, 0.00057605,\n",
      "       0.00099684, 0.00058349, 0.00065266, 0.00124909, 0.00992432,\n",
      "       0.00064236, 0.00060242, 0.00975061, 0.00056305, 0.00085043,\n",
      "       0.00033303, 0.00042443, 0.00069495, 0.0005545 , 0.00050491,\n",
      "       0.00076449, 0.0006816 , 0.00059063, 0.00082602, 0.00063455,\n",
      "       0.00078238, 0.00055708, 0.0004622 , 0.00047609, 0.00100063,\n",
      "       0.00051433, 0.0004867 , 0.0006295 , 0.00041282, 0.00075933,\n",
      "       0.00075594, 0.00068056, 0.00057923, 0.00054716, 0.00084937,\n",
      "       0.00082351, 0.00197587, 0.00078441, 0.00030205, 0.00058172,\n",
      "       0.00065244, 0.00070081, 0.00121312, 0.00045889, 0.00083173,\n",
      "       0.00099207, 0.00095952, 0.00060233, 0.0004905 , 0.00083837,\n",
      "       0.00087416, 0.00083094, 0.00149049, 0.00113088, 0.00067204,\n",
      "       0.0029233 , 0.0005437 , 0.00066541, 0.00055666, 0.00059458,\n",
      "       0.00081603, 0.0005347 , 0.00053577, 0.00093089, 0.00068123,\n",
      "       0.00055976, 0.00062062, 0.00074777, 0.00055929, 0.00071272,\n",
      "       0.00039796, 0.00036718, 0.00109898, 0.00054307, 0.00048005,\n",
      "       0.00072934, 0.00066926, 0.00137106, 0.00125441, 0.00796019,\n",
      "       0.00071073, 0.00078031, 0.00056895, 0.0017425 , 0.00061564,\n",
      "       0.00059605, 0.00043056, 0.00321225, 0.00263006, 0.00056239,\n",
      "       0.00072235, 0.00075665, 0.00053734, 0.00044383, 0.0006968 ,\n",
      "       0.00036356, 0.0006286 , 0.00069864, 0.00069786, 0.00056387,\n",
      "       0.00050226, 0.00104928, 0.00049748, 0.00394111, 0.00038763,\n",
      "       0.00517329, 0.00345401, 0.00235193, 0.00145811, 0.00095199,\n",
      "       0.00084354, 0.00066389, 0.00044774, 0.00087185, 0.00053869,\n",
      "       0.00066067, 0.00075829, 0.00102925, 0.00066306, 0.00145079,\n",
      "       0.00083211, 0.00054214, 0.00069585, 0.00186316, 0.00051956,\n",
      "       0.00046492, 0.00330174, 0.00064683, 0.00077684, 0.00205573,\n",
      "       0.00203743, 0.00047073, 0.00114023, 0.00053843, 0.00078927,\n",
      "       0.01184   , 0.00064896, 0.00083015, 0.00047687, 0.00051659,\n",
      "       0.00114557, 0.00124979, 0.00042776, 0.00347468, 0.0011074 ,\n",
      "       0.00048928, 0.0016412 , 0.00351155, 0.00653036, 0.00178981,\n",
      "       0.00079746, 0.00053969, 0.00077297, 0.00479054, 0.00193397,\n",
      "       0.00067604, 0.00049625, 0.00147595, 0.00183672, 0.00085478,\n",
      "       0.00061014, 0.00078419, 0.00028256, 0.00048113, 0.00092202,\n",
      "       0.00173492, 0.00038623, 0.00117004, 0.00074768, 0.00038946,\n",
      "       0.00081793, 0.00054294, 0.00063233, 0.00067359, 0.00050932,\n",
      "       0.00037693, 0.00459054, 0.00796279, 0.0011382 , 0.00506978,\n",
      "       0.00156077, 0.00470519, 0.0010554 , 0.00073023, 0.00552588,\n",
      "       0.00093988, 0.0016677 , 0.000823  , 0.00327484, 0.00173919,\n",
      "       0.0022061 , 0.00088015, 0.00095059, 0.00313851, 0.00065889,\n",
      "       0.00112235, 0.00449781, 0.00422318, 0.00804628, 0.00113299,\n",
      "       0.00234467, 0.00084084, 0.00166399, 0.00070057, 0.00074723,\n",
      "       0.00082099, 0.00113438, 0.00243401, 0.00047603, 0.0006411 ,\n",
      "       0.00075092, 0.00068701, 0.00107743, 0.00078269, 0.00463117,\n",
      "       0.00412655, 0.00404646, 0.00508087, 0.00276755, 0.00632593,\n",
      "       0.00190929, 0.0042134 , 0.03537562, 0.00273549, 0.00201341,\n",
      "       0.00330766, 0.00101489, 0.00365567, 0.00749265, 0.00144912,\n",
      "       0.00403283, 0.00141826, 0.00392142, 0.00139603, 0.01250686,\n",
      "       0.00658171, 0.00070188, 0.00313154, 0.00166245, 0.0040019 ,\n",
      "       0.00525548, 0.00102426, 0.00371819, 0.00327293, 0.0028431 ,\n",
      "       0.00154309, 0.00317394, 0.00077008, 0.00301119, 0.00096389,\n",
      "       0.00165989, 0.00441987, 0.00157845, 0.00163669, 0.00099499,\n",
      "       0.0034664 , 0.00693758, 0.00074727, 0.0007235 , 0.00404293]), 'mean_score_time': array([0.00787399, 0.00769527, 0.00757067, 0.0081933 , 0.00781801,\n",
      "       0.0078733 , 0.00770302, 0.00770881, 0.00751965, 0.00778215,\n",
      "       0.00790811, 0.0079376 , 0.00778692, 0.0075902 , 0.00748718,\n",
      "       0.00795648, 0.00817947, 0.00811429, 0.00790598, 0.00776029,\n",
      "       0.00817521, 0.00771494, 0.00778444, 0.00774643, 0.00784743,\n",
      "       0.00763733, 0.00788839, 0.00777211, 0.00840006, 0.00777419,\n",
      "       0.00797284, 0.00746868, 0.00772707, 0.00790966, 0.00775051,\n",
      "       0.00795348, 0.00819516, 0.00831511, 0.00819948, 0.00819812,\n",
      "       0.00803108, 0.00826731, 0.00825033, 0.00819931, 0.00809932,\n",
      "       0.00809929, 0.00815032, 0.00789616, 0.00812316, 0.00797768,\n",
      "       0.00802824, 0.0081908 , 0.00831296, 0.00846217, 0.00844085,\n",
      "       0.00789804, 0.00815942, 0.00831306, 0.00804183, 0.00831163,\n",
      "       0.00815604, 0.00810175, 0.00809534, 0.00790033, 0.00904212,\n",
      "       0.00828607, 0.00817564, 0.00820417, 0.00816717, 0.00830643,\n",
      "       0.00827565, 0.00808043, 0.00798361, 0.00801678, 0.00810087,\n",
      "       0.00842366, 0.0080652 , 0.00824134, 0.00823245, 0.00797851,\n",
      "       0.00844989, 0.00834072, 0.00836143, 0.00840194, 0.00826397,\n",
      "       0.00827389, 0.00838709, 0.00812662, 0.0083359 , 0.00825708,\n",
      "       0.00842788, 0.00813937, 0.00838606, 0.00802996, 0.00803318,\n",
      "       0.00823631, 0.00854704, 0.00879762, 0.00869927, 0.0087055 ,\n",
      "       0.00849926, 0.00899949, 0.00887766, 0.00860066, 0.00879934,\n",
      "       0.00849879, 0.00869937, 0.00870032, 0.00859976, 0.00879624,\n",
      "       0.00860281, 0.00829954, 0.00904822, 0.00903232, 0.00858614,\n",
      "       0.00869222, 0.00862188, 0.00864151, 0.00851173, 0.00835023,\n",
      "       0.00835578, 0.00855062, 0.00856559, 0.00838311, 0.0086287 ,\n",
      "       0.00830586, 0.00806482, 0.00832601, 0.00904856, 0.00873632,\n",
      "       0.00869277, 0.00872872, 0.00889959, 0.00874057, 0.00879588,\n",
      "       0.00895886, 0.00859711, 0.00890658, 0.00867426, 0.00913606,\n",
      "       0.00909929, 0.00839806, 0.00849922, 0.00850039, 0.00931137,\n",
      "       0.00872147, 0.00860672, 0.00868382, 0.00884411, 0.00896654,\n",
      "       0.00875783, 0.00873177, 0.00879588, 0.00882134, 0.00896015,\n",
      "       0.00856068, 0.00870419, 0.00843539, 0.00825691, 0.00848527,\n",
      "       0.00923913, 0.00915346, 0.00886803, 0.00931959, 0.00929985,\n",
      "       0.00911624, 0.00906184, 0.00895984, 0.00884306, 0.00885646,\n",
      "       0.00898521, 0.00883539, 0.00869913, 0.00876937, 0.0085989 ,\n",
      "       0.00860167, 0.00949931, 0.00950027, 0.00899885, 0.00905118,\n",
      "       0.00929911, 0.00939915, 0.00910127, 0.00891001, 0.00878279,\n",
      "       0.0088047 , 0.00906076, 0.00873253, 0.00877929, 0.00864167,\n",
      "       0.00886321, 0.00869999, 0.00979934, 0.00950158, 0.00900123,\n",
      "       0.00939944, 0.00949941, 0.00939927, 0.00909898, 0.00930045,\n",
      "       0.00884383, 0.00897586, 0.00865729, 0.00878749, 0.00875354,\n",
      "       0.00840104, 0.00867424, 0.00859964, 0.01019864, 0.00959949,\n",
      "       0.00950048, 0.00910439, 0.00929666, 0.00911455, 0.00930583,\n",
      "       0.00847983, 0.00856042, 0.00860729, 0.00893488, 0.00881395,\n",
      "       0.00830772, 0.00837829, 0.00852273, 0.00852542, 0.0098443 ,\n",
      "       0.00926917, 0.00903561, 0.00920868, 0.00960062, 0.00959964,\n",
      "       0.00909667, 0.0090987 , 0.00909941, 0.00890043, 0.00919912,\n",
      "       0.00899928, 0.00859928, 0.00905321, 0.00855324, 0.0085393 ,\n",
      "       0.00952449, 0.00981712, 0.00885694, 0.00886157, 0.00924854,\n",
      "       0.00918691, 0.00914321, 0.00859158, 0.00904367, 0.0087858 ,\n",
      "       0.00865295, 0.00904768, 0.00877297, 0.00852444, 0.0083967 ,\n",
      "       0.00832689, 0.00952435, 0.00935795, 0.00918217, 0.00882981,\n",
      "       0.00930839, 0.00936007, 0.00939629, 0.00889876, 0.00920265,\n",
      "       0.00929894, 0.00921082, 0.00910327, 0.00869894, 0.00879908,\n",
      "       0.00883429, 0.00879939, 0.01001453, 0.00970006, 0.00928066,\n",
      "       0.00885906, 0.00912523, 0.00927553, 0.00887902, 0.00945499,\n",
      "       0.00868609, 0.00873318, 0.00999937, 0.00946765, 0.00892537,\n",
      "       0.00909023, 0.00923283, 0.00909479, 0.01012034, 0.01029987,\n",
      "       0.00967336, 0.00883799, 0.0097384 , 0.00986364, 0.00986152,\n",
      "       0.00935636, 0.00925527, 0.00918038, 0.00903552, 0.00914397,\n",
      "       0.0091083 , 0.00875745, 0.0088906 , 0.00908713, 0.01025271,\n",
      "       0.0100857 , 0.00931818, 0.00917144, 0.01001217, 0.00947738,\n",
      "       0.00938427, 0.00945055, 0.00933354, 0.00918298, 0.00900671,\n",
      "       0.00898895, 0.00952058, 0.00912116, 0.00907259, 0.00995493]), 'std_score_time': array([4.45186602e-04, 4.28617355e-04, 5.00224600e-04, 3.71798953e-04,\n",
      "       4.45329126e-04, 4.45639365e-04, 4.55420225e-04, 4.60662856e-04,\n",
      "       4.67870557e-04, 5.92226865e-04, 3.81933556e-04, 4.70723659e-04,\n",
      "       3.84737178e-04, 4.45257662e-04, 5.56978493e-04, 3.12933217e-04,\n",
      "       9.71702499e-04, 6.89883502e-04, 5.45631203e-04, 3.16924572e-04,\n",
      "       2.81190230e-04, 4.08728569e-04, 5.09034800e-04, 5.70922831e-04,\n",
      "       2.87416267e-04, 3.77285511e-04, 3.73150198e-04, 3.58638388e-04,\n",
      "       1.68546053e-03, 4.25439701e-04, 3.71524731e-04, 3.78229738e-04,\n",
      "       4.19025927e-04, 2.60087095e-04, 3.60728539e-04, 3.83945493e-04,\n",
      "       4.72566097e-04, 4.50130924e-04, 4.00063739e-04, 4.00682709e-04,\n",
      "       4.30689590e-04, 4.17966227e-04, 4.04025072e-04, 4.00257267e-04,\n",
      "       3.00169086e-04, 3.00018127e-04, 4.48850637e-04, 4.63799045e-04,\n",
      "       4.25743370e-04, 4.09826472e-04, 4.72356878e-04, 4.63967199e-04,\n",
      "       4.39611347e-04, 3.66653505e-04, 3.94463064e-04, 4.84777380e-04,\n",
      "       3.82469870e-04, 3.85160167e-04, 6.44078465e-04, 3.79185922e-04,\n",
      "       4.58932076e-04, 4.45676212e-04, 3.20508075e-04, 3.17157729e-04,\n",
      "       2.23961918e-03, 4.42834616e-04, 4.32743901e-04, 7.14894019e-04,\n",
      "       2.59956627e-04, 6.91268002e-04, 4.76791430e-04, 1.36729253e-04,\n",
      "       4.39452800e-04, 5.32607050e-04, 4.71168322e-04, 4.70823275e-04,\n",
      "       4.24169414e-04, 3.62947917e-04, 3.89839154e-04, 4.51159434e-04,\n",
      "       4.64914031e-04, 4.81667553e-04, 4.06192302e-04, 2.59535484e-04,\n",
      "       4.82904283e-04, 3.63136414e-04, 3.32861249e-04, 4.54286683e-04,\n",
      "       3.33149867e-04, 4.40423370e-04, 4.56904863e-04, 5.87725339e-04,\n",
      "       2.29289418e-04, 4.94655449e-04, 4.78484612e-04, 4.22309561e-04,\n",
      "       4.07027154e-04, 3.99498293e-04, 4.58370085e-04, 4.47871573e-04,\n",
      "       5.00130765e-04, 3.56832255e-07, 2.54744494e-04, 4.88205525e-04,\n",
      "       4.00197647e-04, 4.99818770e-04, 4.58588612e-04, 4.59009091e-04,\n",
      "       4.90271400e-04, 4.39795773e-04, 5.14570107e-04, 4.58390951e-04,\n",
      "       5.08694833e-04, 6.74662175e-04, 3.51667864e-04, 4.86851320e-04,\n",
      "       3.41690621e-04, 4.27089489e-04, 3.36614474e-04, 2.18184088e-04,\n",
      "       2.83964736e-04, 5.53122034e-04, 3.93209185e-04, 2.45875823e-04,\n",
      "       3.26373582e-04, 2.95054721e-04, 3.33983704e-04, 4.14513376e-04,\n",
      "       4.71988069e-04, 4.36630465e-04, 3.86585672e-04, 2.90926952e-04,\n",
      "       3.70557948e-04, 6.17442148e-04, 4.16236359e-04, 2.01859700e-04,\n",
      "       4.91245574e-04, 3.52159099e-04, 4.03287831e-04, 7.16441072e-04,\n",
      "       7.01324871e-04, 4.88625602e-04, 5.00321545e-04, 4.01204460e-04,\n",
      "       3.90289249e-04, 5.24715488e-04, 4.53123085e-04, 4.92010567e-04,\n",
      "       4.28416062e-04, 1.48460827e-04, 3.89395293e-04, 4.03999759e-04,\n",
      "       5.42627164e-04, 2.91528178e-04, 4.83782543e-04, 3.70263293e-04,\n",
      "       4.18675950e-04, 5.07438951e-04, 3.48607132e-04, 4.88863059e-04,\n",
      "       4.57695048e-04, 4.14390917e-04, 5.09397883e-04, 5.62092032e-04,\n",
      "       4.58923007e-04, 5.02807612e-04, 5.73574685e-04, 3.76207460e-04,\n",
      "       6.96270781e-04, 4.09345038e-04, 5.32277282e-04, 5.50421923e-04,\n",
      "       4.58172759e-04, 5.45313945e-04, 4.90008803e-04, 4.89665387e-04,\n",
      "       5.00250179e-04, 5.02033173e-04, 5.37896832e-07, 3.46798312e-04,\n",
      "       4.58521242e-04, 4.90339587e-04, 2.99396788e-04, 2.40148705e-04,\n",
      "       4.07565680e-04, 2.36242357e-04, 6.25127888e-04, 4.08129983e-04,\n",
      "       4.98328117e-04, 5.93352216e-04, 3.10414782e-04, 4.58843938e-04,\n",
      "       4.00293068e-04, 5.02052221e-04, 5.73440052e-06, 1.20082705e-03,\n",
      "       5.00202284e-04, 4.90096379e-04, 3.00415782e-04, 4.58074187e-04,\n",
      "       4.22441205e-04, 3.94546476e-04, 4.72951772e-04, 3.21510370e-04,\n",
      "       3.58306321e-04, 5.08639620e-04, 5.33392422e-04, 4.99328418e-04,\n",
      "       1.07727799e-03, 4.90261775e-04, 5.01373802e-04, 2.98888822e-04,\n",
      "       4.56144205e-04, 4.29270368e-04, 6.62536904e-04, 6.26199279e-04,\n",
      "       3.44531593e-04, 6.02809929e-04, 4.73360743e-04, 4.58258932e-04,\n",
      "       3.59908027e-04, 5.44054548e-04, 2.94044920e-04, 5.08992149e-04,\n",
      "       3.06092539e-04, 5.07661698e-04, 2.72633755e-04, 4.60782256e-04,\n",
      "       4.91386145e-04, 4.89891828e-04, 3.00965940e-04, 2.96546751e-04,\n",
      "       5.38685863e-04, 3.00921414e-04, 4.00555211e-04, 4.47395078e-04,\n",
      "       4.90271748e-04, 1.43335147e-03, 6.00919075e-04, 4.20704310e-04,\n",
      "       4.28382143e-04, 6.74199593e-04, 3.02291255e-04, 5.07218293e-04,\n",
      "       3.44858885e-04, 2.87527648e-04, 3.09156595e-04, 4.17066092e-04,\n",
      "       3.72646034e-04, 2.73613218e-04, 3.59184065e-04, 5.64163431e-04,\n",
      "       4.35552693e-04, 3.89175496e-04, 5.05338277e-04, 3.32165056e-04,\n",
      "       3.12765667e-04, 5.79770234e-04, 5.78663432e-04, 3.68435790e-04,\n",
      "       3.96069147e-04, 4.45999689e-04, 4.02231044e-04, 5.38547225e-04,\n",
      "       3.98672025e-04, 4.58738959e-04, 3.66244277e-04, 5.85608414e-04,\n",
      "       4.58307948e-04, 4.00305050e-04, 3.42457762e-04, 4.00102436e-04,\n",
      "       6.33741438e-04, 4.57529999e-04, 5.99349383e-04, 4.87039279e-04,\n",
      "       3.47733870e-04, 5.51861756e-04, 4.91068833e-04, 8.70832060e-04,\n",
      "       4.95621666e-04, 5.52570240e-04, 1.54270182e-03, 8.51674474e-04,\n",
      "       4.46013913e-04, 6.83563586e-04, 7.35753779e-04, 3.24660438e-04,\n",
      "       4.58005911e-04, 4.58235061e-04, 5.57503876e-04, 4.30100004e-04,\n",
      "       6.24065017e-04, 5.65266663e-04, 6.07987505e-04, 3.90978167e-04,\n",
      "       5.40421192e-04, 4.21063830e-04, 1.83767437e-04, 4.51864389e-04,\n",
      "       4.92287638e-04, 3.54108761e-04, 4.90062131e-04, 6.32711080e-04,\n",
      "       6.41622803e-04, 2.48839477e-04, 4.89792996e-04, 4.16745335e-04,\n",
      "       7.30523634e-04, 5.97834851e-04, 3.72279908e-04, 4.53018204e-04,\n",
      "       6.36545049e-04, 3.19871767e-04, 5.92413593e-04, 6.19502766e-04,\n",
      "       1.17011471e-03, 4.32644492e-04, 6.09621088e-04, 2.53996489e-03]), 'param_classifier__max_depth': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
      "                   2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3,\n",
      "                   3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4,\n",
      "                   4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "                   6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "                   7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "                   8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
      "                   11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
      "                   12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13,\n",
      "                   13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14,\n",
      "                   14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15,\n",
      "                   15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16,\n",
      "                   16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "                   17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "                   17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
      "                   18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
      "                   19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "                   20, 20, 20, 20, 20, 20, 20, 20],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_classifier__min_samples_leaf': masked_array(data=[1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1,\n",
      "                   1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1,\n",
      "                   1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1,\n",
      "                   1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1,\n",
      "                   2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2,\n",
      "                   2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2,\n",
      "                   2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2,\n",
      "                   2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "                   5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5,\n",
      "                   5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5,\n",
      "                   5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5,\n",
      "                   5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5,\n",
      "                   10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10,\n",
      "                   10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10,\n",
      "                   10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10,\n",
      "                   10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10,\n",
      "                   1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1,\n",
      "                   1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1,\n",
      "                   1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_classifier__min_samples_split': masked_array(data=[2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'classifier__max_depth': 1, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}], 'split0_test_score': array([0.75471698, 0.73584906, 0.72327044, 0.71698113, 0.72327044,\n",
      "       0.72327044, 0.74213836, 0.72327044, 0.72955975, 0.72327044,\n",
      "       0.72327044, 0.72327044, 0.72327044, 0.72327044, 0.72327044,\n",
      "       0.72327044, 0.74842767, 0.74842767, 0.74842767, 0.74842767,\n",
      "       0.72327044, 0.74213836, 0.74842767, 0.74842767, 0.72955975,\n",
      "       0.72955975, 0.72955975, 0.74213836, 0.72955975, 0.74842767,\n",
      "       0.73584906, 0.74842767, 0.74213836, 0.77987421, 0.78616352,\n",
      "       0.79245283, 0.78616352, 0.77987421, 0.77987421, 0.77987421,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.79245283, 0.7672956 ,\n",
      "       0.77358491, 0.79874214, 0.75471698, 0.79874214, 0.79245283,\n",
      "       0.81761006, 0.79874214, 0.80503145, 0.81761006, 0.81132075,\n",
      "       0.81132075, 0.79874214, 0.80503145, 0.79874214, 0.80503145,\n",
      "       0.79245283, 0.79245283, 0.79874214, 0.80503145, 0.81761006,\n",
      "       0.82389937, 0.81761006, 0.81132075, 0.82389937, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.81132075, 0.79245283, 0.81761006, 0.81132075, 0.81132075,\n",
      "       0.82389937, 0.81761006, 0.82389937, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.80503145, 0.81761006,\n",
      "       0.81761006, 0.82389937, 0.82389937, 0.81761006, 0.81761006,\n",
      "       0.83018868, 0.82389937, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81761006, 0.81132075,\n",
      "       0.81761006, 0.81761006, 0.82389937, 0.81132075, 0.81132075,\n",
      "       0.83018868, 0.82389937, 0.82389937, 0.81132075, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81132075, 0.81132075, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.82389937, 0.81132075, 0.81761006, 0.82389937, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.80503145, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81761006, 0.81761006, 0.81132075,\n",
      "       0.81132075, 0.82389937, 0.81761006, 0.81761006, 0.81132075,\n",
      "       0.79874214, 0.81132075, 0.80503145, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81761006, 0.81761006,\n",
      "       0.79874214, 0.80503145, 0.81761006, 0.81132075, 0.81132075,\n",
      "       0.81761006, 0.81761006, 0.81132075, 0.81761006, 0.80503145,\n",
      "       0.81132075, 0.81761006, 0.81132075, 0.81761006, 0.81132075,\n",
      "       0.80503145, 0.81132075, 0.78616352, 0.81761006, 0.81132075,\n",
      "       0.80503145, 0.79245283, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.79874214, 0.80503145, 0.81132075, 0.79245283, 0.81132075,\n",
      "       0.79245283, 0.80503145, 0.79245283, 0.80503145, 0.80503145,\n",
      "       0.81761006, 0.81132075, 0.81132075, 0.79245283, 0.80503145,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81761006, 0.81761006, 0.79245283, 0.79874214,\n",
      "       0.81132075, 0.81132075, 0.79874214, 0.81132075, 0.79245283,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.80503145, 0.81132075,\n",
      "       0.80503145, 0.81132075, 0.81132075, 0.81132075, 0.79874214,\n",
      "       0.79245283, 0.78616352, 0.81761006, 0.81132075, 0.79245283,\n",
      "       0.79874214, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81761006, 0.81132075, 0.79874214,\n",
      "       0.78616352, 0.77987421, 0.81132075, 0.81761006, 0.79874214,\n",
      "       0.79245283, 0.79874214, 0.81132075, 0.81761006, 0.80503145,\n",
      "       0.80503145, 0.81132075, 0.81761006, 0.79874214, 0.81132075,\n",
      "       0.81132075, 0.77987421, 0.79245283, 0.79874214, 0.81761006,\n",
      "       0.79245283, 0.79874214, 0.81132075, 0.81761006, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81761006, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.78616352, 0.79874214, 0.79245283,\n",
      "       0.81132075, 0.80503145, 0.78616352, 0.81132075, 0.81132075,\n",
      "       0.79874214, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81761006, 0.81132075, 0.81761006, 0.79874214, 0.78616352,\n",
      "       0.81132075, 0.81761006, 0.81132075, 0.81132075, 0.79874214,\n",
      "       0.80503145, 0.81132075, 0.81132075, 0.80503145, 0.81132075,\n",
      "       0.79874214, 0.80503145, 0.81761006, 0.81132075, 0.77987421,\n",
      "       0.78616352, 0.80503145, 0.81132075, 0.79245283, 0.79874214,\n",
      "       0.81761006, 0.81132075, 0.81132075, 0.80503145, 0.81132075,\n",
      "       0.81132075, 0.80503145, 0.81761006, 0.80503145, 0.81761006]), 'split1_test_score': array([0.80503145, 0.80503145, 0.78616352, 0.80503145, 0.77358491,\n",
      "       0.76100629, 0.78616352, 0.76100629, 0.77358491, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.81132075, 0.80503145, 0.79874214,\n",
      "       0.77358491, 0.81132075, 0.81132075, 0.81761006, 0.81761006,\n",
      "       0.81132075, 0.81132075, 0.81761006, 0.8427673 , 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81761006, 0.80503145, 0.80503145,\n",
      "       0.81132075, 0.81132075, 0.88050314, 0.8490566 , 0.88050314,\n",
      "       0.8427673 , 0.88679245, 0.86792453, 0.86163522, 0.8427673 ,\n",
      "       0.86792453, 0.87421384, 0.86792453, 0.85534591, 0.86163522,\n",
      "       0.88679245, 0.85534591, 0.8427673 , 0.89308176, 0.87421384,\n",
      "       0.88679245, 0.89308176, 0.88050314, 0.89308176, 0.88679245,\n",
      "       0.88050314, 0.88679245, 0.88679245, 0.88679245, 0.88679245,\n",
      "       0.88679245, 0.88679245, 0.88679245, 0.88679245, 0.87421384,\n",
      "       0.89308176, 0.87421384, 0.89308176, 0.87421384, 0.88050314,\n",
      "       0.88679245, 0.88050314, 0.88679245, 0.88679245, 0.88679245,\n",
      "       0.88679245, 0.88679245, 0.88050314, 0.88679245, 0.88679245,\n",
      "       0.88050314, 0.87421384, 0.88050314, 0.87421384, 0.87421384,\n",
      "       0.87421384, 0.87421384, 0.88050314, 0.88679245, 0.88679245,\n",
      "       0.88050314, 0.88050314, 0.88679245, 0.88050314, 0.88679245,\n",
      "       0.88679245, 0.87421384, 0.87421384, 0.88679245, 0.88050314,\n",
      "       0.88050314, 0.88050314, 0.88050314, 0.87421384, 0.87421384,\n",
      "       0.88679245, 0.88679245, 0.88679245, 0.88679245, 0.88050314,\n",
      "       0.88679245, 0.88679245, 0.86792453, 0.87421384, 0.88050314,\n",
      "       0.86792453, 0.87421384, 0.88050314, 0.87421384, 0.88050314,\n",
      "       0.87421384, 0.88050314, 0.87421384, 0.87421384, 0.88050314,\n",
      "       0.88679245, 0.88050314, 0.88050314, 0.88050314, 0.88050314,\n",
      "       0.87421384, 0.87421384, 0.87421384, 0.87421384, 0.87421384,\n",
      "       0.87421384, 0.88050314, 0.88050314, 0.88050314, 0.88050314,\n",
      "       0.88050314, 0.88679245, 0.88679245, 0.88679245, 0.86792453,\n",
      "       0.88050314, 0.88679245, 0.88050314, 0.88679245, 0.87421384,\n",
      "       0.87421384, 0.87421384, 0.88050314, 0.88050314, 0.87421384,\n",
      "       0.88679245, 0.88679245, 0.88679245, 0.88679245, 0.88679245,\n",
      "       0.83018868, 0.83647799, 0.88050314, 0.88050314, 0.87421384,\n",
      "       0.8490566 , 0.86163522, 0.88050314, 0.88679245, 0.87421384,\n",
      "       0.87421384, 0.88050314, 0.88050314, 0.88679245, 0.88050314,\n",
      "       0.88050314, 0.81761006, 0.8490566 , 0.86163522, 0.88050314,\n",
      "       0.8427673 , 0.8490566 , 0.88679245, 0.87421384, 0.87421384,\n",
      "       0.87421384, 0.88050314, 0.88050314, 0.88679245, 0.88679245,\n",
      "       0.87421384, 0.88679245, 0.80503145, 0.83018868, 0.85534591,\n",
      "       0.88050314, 0.8490566 , 0.8490566 , 0.87421384, 0.86792453,\n",
      "       0.87421384, 0.87421384, 0.87421384, 0.88050314, 0.88679245,\n",
      "       0.88679245, 0.88050314, 0.88679245, 0.80503145, 0.81132075,\n",
      "       0.8490566 , 0.86792453, 0.81132075, 0.8427673 , 0.86163522,\n",
      "       0.87421384, 0.87421384, 0.88050314, 0.87421384, 0.88050314,\n",
      "       0.88679245, 0.88050314, 0.88050314, 0.88679245, 0.78616352,\n",
      "       0.77987421, 0.8490566 , 0.86792453, 0.80503145, 0.85534591,\n",
      "       0.86792453, 0.87421384, 0.87421384, 0.88679245, 0.88050314,\n",
      "       0.87421384, 0.88050314, 0.88679245, 0.88679245, 0.88050314,\n",
      "       0.77358491, 0.79245283, 0.8490566 , 0.86792453, 0.79874214,\n",
      "       0.81761006, 0.87421384, 0.86792453, 0.87421384, 0.88050314,\n",
      "       0.87421384, 0.87421384, 0.88050314, 0.88050314, 0.88050314,\n",
      "       0.88679245, 0.77987421, 0.79245283, 0.85534591, 0.87421384,\n",
      "       0.80503145, 0.79874214, 0.88050314, 0.87421384, 0.88050314,\n",
      "       0.88050314, 0.86792453, 0.88050314, 0.88679245, 0.88050314,\n",
      "       0.88679245, 0.88050314, 0.78616352, 0.77987421, 0.83018868,\n",
      "       0.86792453, 0.79245283, 0.81132075, 0.85534591, 0.86792453,\n",
      "       0.88050314, 0.88050314, 0.88050314, 0.87421384, 0.88679245,\n",
      "       0.88679245, 0.88050314, 0.88679245, 0.77358491, 0.78616352,\n",
      "       0.83647799, 0.86792453, 0.81132075, 0.82389937, 0.82389937,\n",
      "       0.87421384, 0.88679245, 0.88050314, 0.87421384, 0.87421384,\n",
      "       0.88050314, 0.88050314, 0.88679245, 0.88050314, 0.77987421,\n",
      "       0.78616352, 0.8490566 , 0.88050314, 0.81761006, 0.79874214,\n",
      "       0.85534591, 0.86792453, 0.88679245, 0.87421384, 0.87421384,\n",
      "       0.88679245, 0.88679245, 0.88050314, 0.88679245, 0.88050314]), 'split2_test_score': array([0.80503145, 0.79245283, 0.80503145, 0.80503145, 0.78616352,\n",
      "       0.78616352, 0.75471698, 0.79245283, 0.80503145, 0.79874214,\n",
      "       0.79874214, 0.80503145, 0.80503145, 0.81132075, 0.79874214,\n",
      "       0.80503145, 0.80503145, 0.81132075, 0.81132075, 0.81761006,\n",
      "       0.81132075, 0.82389937, 0.80503145, 0.80503145, 0.83018868,\n",
      "       0.80503145, 0.81761006, 0.81132075, 0.81132075, 0.81761006,\n",
      "       0.80503145, 0.82389937, 0.81132075, 0.81761006, 0.81132075,\n",
      "       0.81761006, 0.81132075, 0.81132075, 0.81132075, 0.81761006,\n",
      "       0.81132075, 0.81761006, 0.81132075, 0.81132075, 0.81761006,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81761006, 0.81132075,\n",
      "       0.81761006, 0.81761006, 0.81132075, 0.81132075, 0.81761006,\n",
      "       0.81761006, 0.81132075, 0.81761006, 0.81761006, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81761006, 0.81132075, 0.81132075,\n",
      "       0.81761006, 0.81761006, 0.81132075, 0.81761006, 0.81761006,\n",
      "       0.81132075, 0.81761006, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81132075, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81132075, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.80503145, 0.82389937, 0.81761006, 0.81761006,\n",
      "       0.81132075, 0.79874214, 0.81761006, 0.81132075, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81132075, 0.81761006,\n",
      "       0.81761006, 0.81132075, 0.81132075, 0.81761006, 0.81761006,\n",
      "       0.79874214, 0.79245283, 0.81132075, 0.81761006, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.81132075, 0.81761006, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.80503145, 0.80503145, 0.81132075, 0.81761006, 0.79874214,\n",
      "       0.81132075, 0.81761006, 0.79874214, 0.80503145, 0.81761006,\n",
      "       0.81761006, 0.80503145, 0.81132075, 0.81132075, 0.77358491,\n",
      "       0.78616352, 0.79245283, 0.79245283, 0.79874214, 0.81132075,\n",
      "       0.79874214, 0.82389937, 0.81132075, 0.81761006, 0.81132075,\n",
      "       0.81761006, 0.81132075, 0.81132075, 0.81761006, 0.81132075,\n",
      "       0.78616352, 0.7672956 , 0.77987421, 0.79874214, 0.7672956 ,\n",
      "       0.77987421, 0.77987421, 0.79245283, 0.79874214, 0.79874214,\n",
      "       0.79245283, 0.81132075, 0.81761006, 0.81132075, 0.81761006,\n",
      "       0.81132075, 0.76100629, 0.74842767, 0.77358491, 0.81132075,\n",
      "       0.76100629, 0.74213836, 0.79874214, 0.79245283, 0.79245283,\n",
      "       0.80503145, 0.81132075, 0.81761006, 0.81132075, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.74842767, 0.74842767, 0.76100629,\n",
      "       0.79245283, 0.74842767, 0.74842767, 0.75471698, 0.80503145,\n",
      "       0.79874214, 0.81132075, 0.80503145, 0.81132075, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.74842767, 0.7672956 ,\n",
      "       0.74842767, 0.79874214, 0.74842767, 0.73584906, 0.78616352,\n",
      "       0.79874214, 0.80503145, 0.78616352, 0.81132075, 0.79874214,\n",
      "       0.79874214, 0.81761006, 0.81761006, 0.81761006, 0.74842767,\n",
      "       0.73584906, 0.74213836, 0.77987421, 0.74842767, 0.73584906,\n",
      "       0.76100629, 0.80503145, 0.81761006, 0.80503145, 0.78616352,\n",
      "       0.81132075, 0.81132075, 0.81761006, 0.79874214, 0.81761006,\n",
      "       0.73584906, 0.73584906, 0.75471698, 0.80503145, 0.74842767,\n",
      "       0.74213836, 0.74842767, 0.77987421, 0.80503145, 0.77987421,\n",
      "       0.79245283, 0.81132075, 0.81761006, 0.81761006, 0.81132075,\n",
      "       0.81761006, 0.74842767, 0.72955975, 0.74842767, 0.78616352,\n",
      "       0.74213836, 0.73584906, 0.75471698, 0.79874214, 0.79245283,\n",
      "       0.80503145, 0.79874214, 0.81761006, 0.81761006, 0.79874214,\n",
      "       0.81132075, 0.81761006, 0.73584906, 0.75471698, 0.74213836,\n",
      "       0.77987421, 0.73584906, 0.74213836, 0.75471698, 0.78616352,\n",
      "       0.79874214, 0.79245283, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81761006, 0.81761006, 0.80503145, 0.73584906, 0.74213836,\n",
      "       0.75471698, 0.79245283, 0.74842767, 0.74842767, 0.75471698,\n",
      "       0.77358491, 0.79245283, 0.81132075, 0.78616352, 0.79874214,\n",
      "       0.81132075, 0.81132075, 0.79245283, 0.81761006, 0.72955975,\n",
      "       0.75471698, 0.74842767, 0.79245283, 0.74842767, 0.74842767,\n",
      "       0.75471698, 0.77987421, 0.79874214, 0.81132075, 0.81132075,\n",
      "       0.79874214, 0.81132075, 0.81132075, 0.81761006, 0.80503145]), 'split3_test_score': array([0.79245283, 0.77987421, 0.79245283, 0.77987421, 0.79245283,\n",
      "       0.79245283, 0.79245283, 0.77987421, 0.79245283, 0.77987421,\n",
      "       0.77987421, 0.79245283, 0.77987421, 0.79245283, 0.77987421,\n",
      "       0.79245283, 0.79874214, 0.79245283, 0.79245283, 0.79874214,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.79245283, 0.77987421,\n",
      "       0.77987421, 0.79874214, 0.78616352, 0.77987421, 0.79245283,\n",
      "       0.77358491, 0.79245283, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.79245283, 0.81761006, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.79874214, 0.80503145, 0.80503145, 0.79874214, 0.80503145,\n",
      "       0.79874214, 0.79874214, 0.80503145, 0.81761006, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.81132075, 0.79874214, 0.81132075, 0.80503145, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.80503145,\n",
      "       0.80503145, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.80503145, 0.81761006, 0.80503145, 0.80503145, 0.81761006,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81761006, 0.81761006, 0.80503145, 0.81132075, 0.80503145,\n",
      "       0.80503145, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.80503145, 0.80503145, 0.81761006, 0.81132075, 0.81761006,\n",
      "       0.81132075, 0.81761006, 0.81761006, 0.80503145, 0.81761006,\n",
      "       0.80503145, 0.80503145, 0.81761006, 0.80503145, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81761006, 0.81761006, 0.79874214,\n",
      "       0.81132075, 0.81761006, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.80503145, 0.81132075, 0.81761006, 0.81132075,\n",
      "       0.81761006, 0.81132075, 0.81132075, 0.79245283, 0.79874214,\n",
      "       0.81132075, 0.81132075, 0.81761006, 0.81132075, 0.81761006,\n",
      "       0.81132075, 0.81761006, 0.81761006, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81761006, 0.81132075, 0.79874214,\n",
      "       0.80503145, 0.81761006, 0.81132075, 0.79245283, 0.81132075,\n",
      "       0.79245283, 0.80503145, 0.81132075, 0.81761006, 0.80503145,\n",
      "       0.81761006, 0.81761006, 0.81132075, 0.80503145, 0.81761006,\n",
      "       0.77987421, 0.79245283, 0.80503145, 0.81761006, 0.79245283,\n",
      "       0.81761006, 0.79245283, 0.79874214, 0.81761006, 0.81132075,\n",
      "       0.81132075, 0.80503145, 0.81132075, 0.80503145, 0.81132075,\n",
      "       0.81132075, 0.79245283, 0.79245283, 0.79874214, 0.81132075,\n",
      "       0.81132075, 0.79874214, 0.81761006, 0.80503145, 0.80503145,\n",
      "       0.81132075, 0.79874214, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.77987421, 0.81132075, 0.80503145,\n",
      "       0.80503145, 0.79245283, 0.79874214, 0.79245283, 0.81761006,\n",
      "       0.80503145, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.80503145, 0.81761006, 0.78616352, 0.79245283,\n",
      "       0.79874214, 0.79874214, 0.82389937, 0.79874214, 0.77987421,\n",
      "       0.81761006, 0.80503145, 0.80503145, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81761006, 0.81761006, 0.77358491,\n",
      "       0.77987421, 0.79874214, 0.80503145, 0.79245283, 0.79874214,\n",
      "       0.79245283, 0.81132075, 0.81132075, 0.81132075, 0.81761006,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.78616352, 0.80503145, 0.81132075, 0.81761006, 0.79874214,\n",
      "       0.80503145, 0.79245283, 0.81132075, 0.81132075, 0.79245283,\n",
      "       0.80503145, 0.81761006, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.77358491, 0.78616352, 0.79874214, 0.81761006,\n",
      "       0.79245283, 0.79245283, 0.77987421, 0.81761006, 0.81132075,\n",
      "       0.80503145, 0.79874214, 0.81761006, 0.80503145, 0.80503145,\n",
      "       0.81761006, 0.81132075, 0.77987421, 0.77987421, 0.81132075,\n",
      "       0.81132075, 0.78616352, 0.79245283, 0.80503145, 0.81132075,\n",
      "       0.79874214, 0.81761006, 0.81132075, 0.81132075, 0.81761006,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.77987421, 0.79245283,\n",
      "       0.79874214, 0.80503145, 0.79245283, 0.79874214, 0.79245283,\n",
      "       0.81761006, 0.81132075, 0.79245283, 0.81761006, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.80503145, 0.80503145, 0.7672956 ,\n",
      "       0.78616352, 0.79245283, 0.81132075, 0.80503145, 0.81132075,\n",
      "       0.78616352, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81761006, 0.81761006, 0.80503145, 0.81132075, 0.81132075]), 'split4_test_score': array([0.72955975, 0.72955975, 0.73584906, 0.74213836, 0.72327044,\n",
      "       0.72955975, 0.72955975, 0.72955975, 0.72327044, 0.72955975,\n",
      "       0.72955975, 0.72955975, 0.72327044, 0.72955975, 0.74213836,\n",
      "       0.73584906, 0.72327044, 0.73584906, 0.73584906, 0.72327044,\n",
      "       0.73584906, 0.73584906, 0.73584906, 0.72327044, 0.72327044,\n",
      "       0.73584906, 0.72955975, 0.72327044, 0.72327044, 0.72955975,\n",
      "       0.72327044, 0.73584906, 0.74842767, 0.77358491, 0.75471698,\n",
      "       0.77358491, 0.77987421, 0.7672956 , 0.77358491, 0.7672956 ,\n",
      "       0.77987421, 0.77358491, 0.76100629, 0.76100629, 0.77358491,\n",
      "       0.77358491, 0.75471698, 0.7672956 , 0.78616352, 0.78616352,\n",
      "       0.77987421, 0.78616352, 0.77358491, 0.77987421, 0.77987421,\n",
      "       0.78616352, 0.77987421, 0.78616352, 0.77987421, 0.78616352,\n",
      "       0.77987421, 0.77987421, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.77987421, 0.78616352, 0.78616352, 0.78616352, 0.77987421,\n",
      "       0.78616352, 0.78616352, 0.79874214, 0.78616352, 0.78616352,\n",
      "       0.79245283, 0.78616352, 0.77987421, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.77987421, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.77987421,\n",
      "       0.77987421, 0.79245283, 0.79245283, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.79245283, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.79245283, 0.78616352, 0.78616352, 0.78616352, 0.77987421,\n",
      "       0.77987421, 0.78616352, 0.79874214, 0.79245283, 0.79245283,\n",
      "       0.78616352, 0.77987421, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.77987421, 0.78616352, 0.80503145,\n",
      "       0.77987421, 0.78616352, 0.79245283, 0.78616352, 0.79874214,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.77987421, 0.80503145,\n",
      "       0.79874214, 0.78616352, 0.77987421, 0.79245283, 0.79245283,\n",
      "       0.79245283, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.77987421, 0.77987421, 0.78616352,\n",
      "       0.79874214, 0.79874214, 0.78616352, 0.78616352, 0.79245283,\n",
      "       0.78616352, 0.78616352, 0.79245283, 0.79245283, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.77987421, 0.80503145, 0.78616352, 0.77987421, 0.77358491,\n",
      "       0.77987421, 0.78616352, 0.77358491, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.79874214, 0.81761006, 0.77987421,\n",
      "       0.78616352, 0.79874214, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.77987421,\n",
      "       0.78616352, 0.78616352, 0.77987421, 0.77987421, 0.77987421,\n",
      "       0.78616352, 0.77987421, 0.79874214, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.79245283, 0.79245283, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.79245283,\n",
      "       0.78616352, 0.79245283, 0.78616352, 0.78616352, 0.79245283,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.79245283,\n",
      "       0.77987421, 0.78616352, 0.78616352, 0.78616352, 0.77987421,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.79245283, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.77987421, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.77358491, 0.78616352,\n",
      "       0.77358491, 0.81761006, 0.77987421, 0.78616352, 0.78616352,\n",
      "       0.79874214, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.79245283, 0.78616352, 0.78616352, 0.78616352, 0.77987421,\n",
      "       0.78616352, 0.77987421, 0.80503145, 0.78616352, 0.77987421,\n",
      "       0.79245283, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.77987421, 0.78616352, 0.77987421, 0.78616352,\n",
      "       0.78616352, 0.77987421, 0.80503145, 0.77987421, 0.79245283,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.77987421, 0.77987421, 0.78616352,\n",
      "       0.80503145, 0.77358491, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.79874214, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352]), 'split5_test_score': array([0.74213836, 0.73584906, 0.74213836, 0.74213836, 0.74213836,\n",
      "       0.74213836, 0.73584906, 0.72327044, 0.74213836, 0.74213836,\n",
      "       0.72955975, 0.73584906, 0.74842767, 0.75471698, 0.74213836,\n",
      "       0.74213836, 0.75471698, 0.75471698, 0.75471698, 0.74842767,\n",
      "       0.74213836, 0.74842767, 0.74842767, 0.74213836, 0.76100629,\n",
      "       0.75471698, 0.73584906, 0.75471698, 0.74842767, 0.73584906,\n",
      "       0.74842767, 0.74213836, 0.80503145, 0.77358491, 0.79874214,\n",
      "       0.79245283, 0.81132075, 0.81761006, 0.79245283, 0.78616352,\n",
      "       0.77987421, 0.78616352, 0.79245283, 0.78616352, 0.78616352,\n",
      "       0.79874214, 0.79245283, 0.79245283, 0.81761006, 0.82389937,\n",
      "       0.80503145, 0.81761006, 0.79874214, 0.80503145, 0.82389937,\n",
      "       0.81132075, 0.81132075, 0.82389937, 0.80503145, 0.81761006,\n",
      "       0.81132075, 0.81132075, 0.81761006, 0.80503145, 0.82389937,\n",
      "       0.83018868, 0.82389937, 0.83018868, 0.81761006, 0.82389937,\n",
      "       0.82389937, 0.82389937, 0.81132075, 0.81132075, 0.80503145,\n",
      "       0.81132075, 0.81132075, 0.80503145, 0.80503145, 0.81761006,\n",
      "       0.83018868, 0.82389937, 0.83018868, 0.81761006, 0.82389937,\n",
      "       0.82389937, 0.82389937, 0.83018868, 0.81132075, 0.82389937,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81761006, 0.81132075,\n",
      "       0.81761006, 0.83647799, 0.81761006, 0.83647799, 0.81761006,\n",
      "       0.83018868, 0.82389937, 0.82389937, 0.82389937, 0.81132075,\n",
      "       0.81761006, 0.82389937, 0.83018868, 0.81132075, 0.80503145,\n",
      "       0.81761006, 0.81132075, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.83647799, 0.83018868, 0.82389937, 0.81132075, 0.83018868,\n",
      "       0.82389937, 0.81761006, 0.81132075, 0.81761006, 0.81761006,\n",
      "       0.80503145, 0.81761006, 0.80503145, 0.82389937, 0.81761006,\n",
      "       0.80503145, 0.81761006, 0.80503145, 0.81132075, 0.79874214,\n",
      "       0.83018868, 0.81761006, 0.83018868, 0.81132075, 0.81761006,\n",
      "       0.81132075, 0.81132075, 0.81761006, 0.81761006, 0.79245283,\n",
      "       0.80503145, 0.81761006, 0.81132075, 0.79874214, 0.80503145,\n",
      "       0.80503145, 0.83018868, 0.80503145, 0.81761006, 0.82389937,\n",
      "       0.81132075, 0.82389937, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.78616352, 0.80503145, 0.81761006, 0.81132075, 0.79874214,\n",
      "       0.80503145, 0.78616352, 0.79245283, 0.82389937, 0.80503145,\n",
      "       0.80503145, 0.81761006, 0.81132075, 0.81761006, 0.81761006,\n",
      "       0.80503145, 0.77987421, 0.77358491, 0.79874214, 0.80503145,\n",
      "       0.78616352, 0.79245283, 0.79245283, 0.79874214, 0.80503145,\n",
      "       0.81132075, 0.82389937, 0.81132075, 0.81761006, 0.81761006,\n",
      "       0.82389937, 0.81761006, 0.76100629, 0.7672956 , 0.78616352,\n",
      "       0.79874214, 0.77987421, 0.77987421, 0.79874214, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81761006, 0.81132075, 0.81132075,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.76100629, 0.77987421,\n",
      "       0.80503145, 0.81761006, 0.77358491, 0.7672956 , 0.79245283,\n",
      "       0.79874214, 0.80503145, 0.80503145, 0.81132075, 0.81761006,\n",
      "       0.81761006, 0.81132075, 0.81761006, 0.81132075, 0.74213836,\n",
      "       0.76100629, 0.77987421, 0.81761006, 0.77358491, 0.77987421,\n",
      "       0.78616352, 0.80503145, 0.81761006, 0.80503145, 0.81132075,\n",
      "       0.80503145, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.73584906, 0.76100629, 0.78616352, 0.79874214, 0.75471698,\n",
      "       0.75471698, 0.79245283, 0.79874214, 0.81761006, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81761006, 0.81761006, 0.81132075,\n",
      "       0.81761006, 0.72955975, 0.74213836, 0.77358491, 0.80503145,\n",
      "       0.75471698, 0.7672956 , 0.77358491, 0.80503145, 0.81132075,\n",
      "       0.80503145, 0.81132075, 0.81761006, 0.81132075, 0.82389937,\n",
      "       0.81761006, 0.81761006, 0.73584906, 0.74213836, 0.76100629,\n",
      "       0.80503145, 0.76100629, 0.76100629, 0.79245283, 0.80503145,\n",
      "       0.79874214, 0.80503145, 0.80503145, 0.81132075, 0.81761006,\n",
      "       0.82389937, 0.81132075, 0.81132075, 0.74213836, 0.73584906,\n",
      "       0.78616352, 0.78616352, 0.77358491, 0.7672956 , 0.77987421,\n",
      "       0.81761006, 0.80503145, 0.80503145, 0.79874214, 0.81761006,\n",
      "       0.81761006, 0.81132075, 0.80503145, 0.81761006, 0.72955975,\n",
      "       0.74842767, 0.77358491, 0.81132075, 0.76100629, 0.76100629,\n",
      "       0.77358491, 0.80503145, 0.81761006, 0.79874214, 0.80503145,\n",
      "       0.81761006, 0.82389937, 0.81132075, 0.81132075, 0.81132075]), 'split6_test_score': array([0.78616352, 0.78616352, 0.79874214, 0.78616352, 0.79245283,\n",
      "       0.74842767, 0.79245283, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.79245283,\n",
      "       0.78616352, 0.79874214, 0.80503145, 0.79874214, 0.79874214,\n",
      "       0.80503145, 0.80503145, 0.79245283, 0.79245283, 0.79874214,\n",
      "       0.79874214, 0.80503145, 0.79874214, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.78616352, 0.83018868, 0.82389937, 0.83018868,\n",
      "       0.83647799, 0.8427673 , 0.83647799, 0.8427673 , 0.8427673 ,\n",
      "       0.80503145, 0.8427673 , 0.83647799, 0.83018868, 0.8427673 ,\n",
      "       0.83647799, 0.83018868, 0.83647799, 0.8427673 , 0.83647799,\n",
      "       0.83647799, 0.8427673 , 0.83647799, 0.8427673 , 0.83018868,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.83647799, 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.83647799, 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.83018868, 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.83647799, 0.8427673 ,\n",
      "       0.83647799, 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.83647799, 0.8427673 , 0.83647799, 0.8427673 ,\n",
      "       0.8427673 , 0.83647799, 0.83647799, 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.83647799, 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.83647799, 0.8427673 , 0.8427673 , 0.8427673 , 0.83647799,\n",
      "       0.8427673 , 0.8427673 , 0.83647799, 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.83647799, 0.8490566 ,\n",
      "       0.83647799, 0.83647799, 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.83647799, 0.83647799,\n",
      "       0.8427673 , 0.8427673 , 0.83647799, 0.8427673 , 0.83018868,\n",
      "       0.83018868, 0.8427673 , 0.83647799, 0.8490566 , 0.8490566 ,\n",
      "       0.8427673 , 0.83647799, 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.83647799, 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.81132075, 0.83647799, 0.8427673 , 0.83018868, 0.8490566 ,\n",
      "       0.8427673 , 0.83647799, 0.8427673 , 0.83018868, 0.8427673 ,\n",
      "       0.8427673 , 0.83647799, 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.81132075, 0.8427673 , 0.83018868, 0.8427673 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.83018868, 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.83647799, 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.78616352, 0.82389937, 0.8490566 ,\n",
      "       0.82389937, 0.83647799, 0.83647799, 0.8427673 , 0.83018868,\n",
      "       0.8427673 , 0.8490566 , 0.83018868, 0.83647799, 0.8427673 ,\n",
      "       0.8427673 , 0.83647799, 0.83647799, 0.81132075, 0.8427673 ,\n",
      "       0.83647799, 0.8427673 , 0.8427673 , 0.8490566 , 0.8490566 ,\n",
      "       0.8427673 , 0.83647799, 0.83647799, 0.83018868, 0.83647799,\n",
      "       0.8427673 , 0.8427673 , 0.8490566 , 0.8427673 , 0.79245283,\n",
      "       0.81132075, 0.8490566 , 0.82389937, 0.83018868, 0.81761006,\n",
      "       0.8490566 , 0.8427673 , 0.83647799, 0.8427673 , 0.83647799,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.80503145, 0.83018868, 0.81761006, 0.83018868, 0.8427673 ,\n",
      "       0.83018868, 0.8427673 , 0.8427673 , 0.83647799, 0.8490566 ,\n",
      "       0.83647799, 0.83018868, 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.83647799, 0.79874214, 0.81132075, 0.8427673 , 0.83647799,\n",
      "       0.81132075, 0.83647799, 0.83018868, 0.83647799, 0.8490566 ,\n",
      "       0.8427673 , 0.83647799, 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.83647799, 0.79874214, 0.81132075, 0.8427673 ,\n",
      "       0.8427673 , 0.83018868, 0.82389937, 0.83018868, 0.83647799,\n",
      "       0.83647799, 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.81132075, 0.79874214,\n",
      "       0.81761006, 0.8427673 , 0.83018868, 0.81761006, 0.83647799,\n",
      "       0.82389937, 0.8427673 , 0.83647799, 0.83647799, 0.83647799,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.79245283,\n",
      "       0.81761006, 0.83647799, 0.82389937, 0.81761006, 0.83647799,\n",
      "       0.83647799, 0.8427673 , 0.83647799, 0.8427673 , 0.8490566 ,\n",
      "       0.83647799, 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ]), 'split7_test_score': array([0.76100629, 0.76100629, 0.76100629, 0.76100629, 0.74842767,\n",
      "       0.76100629, 0.74842767, 0.76100629, 0.77358491, 0.76100629,\n",
      "       0.76100629, 0.7672956 , 0.74842767, 0.76100629, 0.74842767,\n",
      "       0.76100629, 0.77358491, 0.77987421, 0.78616352, 0.77358491,\n",
      "       0.78616352, 0.77358491, 0.77987421, 0.77987421, 0.77358491,\n",
      "       0.78616352, 0.77987421, 0.77358491, 0.7672956 , 0.77358491,\n",
      "       0.77987421, 0.7672956 , 0.80503145, 0.79245283, 0.81132075,\n",
      "       0.79874214, 0.80503145, 0.80503145, 0.81132075, 0.79245283,\n",
      "       0.79245283, 0.79874214, 0.81761006, 0.81132075, 0.79874214,\n",
      "       0.7672956 , 0.81761006, 0.79245283, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.80503145, 0.81132075, 0.82389937, 0.81132075,\n",
      "       0.80503145, 0.81132075, 0.81761006, 0.81132075, 0.81761006,\n",
      "       0.81132075, 0.80503145, 0.81761006, 0.81761006, 0.82389937,\n",
      "       0.82389937, 0.81132075, 0.81132075, 0.82389937, 0.81761006,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81761006, 0.82389937, 0.82389937, 0.81132075, 0.82389937,\n",
      "       0.80503145, 0.81132075, 0.81761006, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.80503145, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.82389937, 0.82389937, 0.82389937, 0.81132075,\n",
      "       0.82389937, 0.82389937, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.80503145,\n",
      "       0.80503145, 0.81761006, 0.81761006, 0.82389937, 0.81761006,\n",
      "       0.81761006, 0.82389937, 0.81761006, 0.82389937, 0.81761006,\n",
      "       0.80503145, 0.81132075, 0.81132075, 0.81132075, 0.80503145,\n",
      "       0.81132075, 0.80503145, 0.79874214, 0.81132075, 0.81761006,\n",
      "       0.81761006, 0.82389937, 0.81132075, 0.82389937, 0.82389937,\n",
      "       0.81761006, 0.81132075, 0.81132075, 0.80503145, 0.81132075,\n",
      "       0.81132075, 0.79874214, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.82389937, 0.82389937, 0.81132075, 0.82389937, 0.81761006,\n",
      "       0.82389937, 0.81132075, 0.81132075, 0.81132075, 0.80503145,\n",
      "       0.81132075, 0.81132075, 0.80503145, 0.80503145, 0.81761006,\n",
      "       0.80503145, 0.82389937, 0.82389937, 0.82389937, 0.83018868,\n",
      "       0.81761006, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.79874214, 0.81132075,\n",
      "       0.80503145, 0.81132075, 0.81761006, 0.81132075, 0.81761006,\n",
      "       0.81761006, 0.82389937, 0.80503145, 0.82389937, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81761006, 0.81132075, 0.81761006,\n",
      "       0.81132075, 0.80503145, 0.79874214, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81761006, 0.80503145,\n",
      "       0.81761006, 0.81132075, 0.81132075, 0.79874214, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.79874214, 0.81761006,\n",
      "       0.81132075, 0.82389937, 0.81761006, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.80503145,\n",
      "       0.79245283, 0.81761006, 0.81132075, 0.81132075, 0.77358491,\n",
      "       0.79245283, 0.81761006, 0.82389937, 0.78616352, 0.81761006,\n",
      "       0.83018868, 0.81761006, 0.81132075, 0.81132075, 0.81761006,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.81761006, 0.81132075,\n",
      "       0.77358491, 0.78616352, 0.81761006, 0.81132075, 0.80503145,\n",
      "       0.78616352, 0.80503145, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.80503145,\n",
      "       0.81132075, 0.78616352, 0.79245283, 0.82389937, 0.81132075,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.82389937, 0.81132075,\n",
      "       0.81761006, 0.81132075, 0.81132075, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.81132075, 0.7672956 , 0.79245283, 0.80503145,\n",
      "       0.81132075, 0.80503145, 0.80503145, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81761006, 0.81132075, 0.80503145,\n",
      "       0.80503145, 0.79874214, 0.80503145, 0.77987421, 0.79874214,\n",
      "       0.79874214, 0.82389937, 0.79874214, 0.78616352, 0.81761006,\n",
      "       0.81761006, 0.81132075, 0.81132075, 0.81132075, 0.81761006,\n",
      "       0.81132075, 0.81761006, 0.81132075, 0.81132075, 0.76100629,\n",
      "       0.79245283, 0.81761006, 0.81761006, 0.80503145, 0.79874214,\n",
      "       0.81761006, 0.81761006, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.80503145, 0.81132075, 0.81132075, 0.81132075]), 'split8_test_score': array([0.75471698, 0.75471698, 0.74842767, 0.75471698, 0.75471698,\n",
      "       0.74842767, 0.71698113, 0.80503145, 0.77987421, 0.74842767,\n",
      "       0.75471698, 0.75471698, 0.75471698, 0.75471698, 0.73584906,\n",
      "       0.75471698, 0.75471698, 0.75471698, 0.75471698, 0.75471698,\n",
      "       0.75471698, 0.75471698, 0.75471698, 0.75471698, 0.75471698,\n",
      "       0.75471698, 0.75471698, 0.75471698, 0.75471698, 0.75471698,\n",
      "       0.75471698, 0.75471698, 0.79874214, 0.77987421, 0.77358491,\n",
      "       0.79245283, 0.79245283, 0.80503145, 0.77987421, 0.81132075,\n",
      "       0.79874214, 0.77358491, 0.79245283, 0.77358491, 0.79874214,\n",
      "       0.7672956 , 0.78616352, 0.83018868, 0.83018868, 0.82389937,\n",
      "       0.82389937, 0.83018868, 0.8490566 , 0.80503145, 0.82389937,\n",
      "       0.81761006, 0.83018868, 0.83018868, 0.83647799, 0.82389937,\n",
      "       0.81761006, 0.81761006, 0.82389937, 0.81761006, 0.83018868,\n",
      "       0.83018868, 0.8490566 , 0.83647799, 0.8427673 , 0.82389937,\n",
      "       0.83647799, 0.83647799, 0.83018868, 0.83647799, 0.83647799,\n",
      "       0.8490566 , 0.82389937, 0.82389937, 0.82389937, 0.82389937,\n",
      "       0.8490566 , 0.83647799, 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8490566 , 0.8490566 , 0.8427673 , 0.8490566 , 0.83647799,\n",
      "       0.83647799, 0.8490566 , 0.8490566 , 0.83647799, 0.83647799,\n",
      "       0.83647799, 0.8490566 , 0.83647799, 0.8427673 , 0.8427673 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.8427673 , 0.8490566 ,\n",
      "       0.8490566 , 0.8427673 , 0.8490566 , 0.83647799, 0.83647799,\n",
      "       0.8490566 , 0.8427673 , 0.8490566 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8490566 , 0.8490566 , 0.8427673 , 0.8427673 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.83018868, 0.83647799, 0.8427673 , 0.83647799, 0.83647799,\n",
      "       0.83647799, 0.8427673 , 0.8427673 , 0.8427673 , 0.83647799,\n",
      "       0.8427673 , 0.8490566 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8490566 , 0.83647799, 0.8490566 , 0.8427673 , 0.83018868,\n",
      "       0.8427673 , 0.83647799, 0.8427673 , 0.83647799, 0.8427673 ,\n",
      "       0.8490566 , 0.83647799, 0.8427673 , 0.83647799, 0.8490566 ,\n",
      "       0.8490566 , 0.8490566 , 0.8490566 , 0.8427673 , 0.83647799,\n",
      "       0.83018868, 0.82389937, 0.8427673 , 0.83647799, 0.8427673 ,\n",
      "       0.83647799, 0.83018868, 0.83647799, 0.8427673 , 0.83647799,\n",
      "       0.83647799, 0.8490566 , 0.8427673 , 0.8427673 , 0.8490566 ,\n",
      "       0.8427673 , 0.81132075, 0.81132075, 0.8427673 , 0.83647799,\n",
      "       0.83647799, 0.83018868, 0.8427673 , 0.83018868, 0.83647799,\n",
      "       0.83018868, 0.83018868, 0.83018868, 0.82389937, 0.8427673 ,\n",
      "       0.83647799, 0.8490566 , 0.82389937, 0.82389937, 0.83018868,\n",
      "       0.83647799, 0.8427673 , 0.83647799, 0.8427673 , 0.83647799,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.83647799, 0.83018868,\n",
      "       0.83647799, 0.8427673 , 0.83018868, 0.83018868, 0.82389937,\n",
      "       0.82389937, 0.83647799, 0.8427673 , 0.83647799, 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.83647799, 0.83018868, 0.83647799,\n",
      "       0.83647799, 0.8490566 , 0.83647799, 0.8427673 , 0.78616352,\n",
      "       0.81132075, 0.83018868, 0.83647799, 0.8490566 , 0.83647799,\n",
      "       0.83018868, 0.83647799, 0.83647799, 0.83647799, 0.8427673 ,\n",
      "       0.8427673 , 0.8490566 , 0.8427673 , 0.83018868, 0.83647799,\n",
      "       0.83018868, 0.81132075, 0.83018868, 0.82389937, 0.83018868,\n",
      "       0.8490566 , 0.8490566 , 0.83018868, 0.8427673 , 0.8427673 ,\n",
      "       0.83647799, 0.83647799, 0.8490566 , 0.8490566 , 0.8490566 ,\n",
      "       0.82389937, 0.81761006, 0.83018868, 0.83647799, 0.83018868,\n",
      "       0.83018868, 0.8427673 , 0.8427673 , 0.8427673 , 0.8490566 ,\n",
      "       0.83018868, 0.83018868, 0.83018868, 0.8490566 , 0.83647799,\n",
      "       0.8427673 , 0.8490566 , 0.80503145, 0.81132075, 0.83018868,\n",
      "       0.83647799, 0.83647799, 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.83018868, 0.83018868, 0.8427673 , 0.8490566 ,\n",
      "       0.8427673 , 0.83018868, 0.83647799, 0.79874214, 0.81132075,\n",
      "       0.8427673 , 0.83647799, 0.83018868, 0.8427673 , 0.83647799,\n",
      "       0.83647799, 0.83647799, 0.83647799, 0.8427673 , 0.8427673 ,\n",
      "       0.83018868, 0.8427673 , 0.83018868, 0.83018868, 0.80503145,\n",
      "       0.79874214, 0.83018868, 0.83647799, 0.83647799, 0.82389937,\n",
      "       0.83647799, 0.83647799, 0.83018868, 0.83018868, 0.8427673 ,\n",
      "       0.8427673 , 0.83647799, 0.8427673 , 0.8427673 , 0.8427673 ]), 'split9_test_score': array([0.76582278, 0.7721519 , 0.7721519 , 0.7721519 , 0.7721519 ,\n",
      "       0.7721519 , 0.76582278, 0.7721519 , 0.7721519 , 0.7721519 ,\n",
      "       0.73417722, 0.7721519 , 0.78481013, 0.7721519 , 0.76582278,\n",
      "       0.76582278, 0.7721519 , 0.7721519 , 0.7721519 , 0.8164557 ,\n",
      "       0.79113924, 0.7721519 , 0.76582278, 0.7721519 , 0.78481013,\n",
      "       0.78481013, 0.77848101, 0.7721519 , 0.76582278, 0.7721519 ,\n",
      "       0.76582278, 0.79113924, 0.83544304, 0.8164557 , 0.85443038,\n",
      "       0.84810127, 0.84177215, 0.85443038, 0.85443038, 0.82911392,\n",
      "       0.85443038, 0.79746835, 0.84810127, 0.82911392, 0.84177215,\n",
      "       0.84177215, 0.82911392, 0.82278481, 0.85443038, 0.84810127,\n",
      "       0.85443038, 0.86075949, 0.86075949, 0.85443038, 0.85443038,\n",
      "       0.82911392, 0.85443038, 0.85443038, 0.84810127, 0.85443038,\n",
      "       0.84177215, 0.85443038, 0.85443038, 0.86075949, 0.86075949,\n",
      "       0.85443038, 0.86075949, 0.84810127, 0.86075949, 0.85443038,\n",
      "       0.86075949, 0.86075949, 0.86075949, 0.85443038, 0.85443038,\n",
      "       0.85443038, 0.84810127, 0.82911392, 0.84177215, 0.85443038,\n",
      "       0.85443038, 0.85443038, 0.85443038, 0.86075949, 0.86075949,\n",
      "       0.86075949, 0.85443038, 0.86075949, 0.86075949, 0.86075949,\n",
      "       0.86075949, 0.85443038, 0.85443038, 0.85443038, 0.86075949,\n",
      "       0.84810127, 0.83544304, 0.84810127, 0.85443038, 0.84810127,\n",
      "       0.84810127, 0.86075949, 0.84810127, 0.85443038, 0.86075949,\n",
      "       0.85443038, 0.86075949, 0.85443038, 0.85443038, 0.86075949,\n",
      "       0.85443038, 0.85443038, 0.84810127, 0.84810127, 0.84177215,\n",
      "       0.86075949, 0.84810127, 0.84177215, 0.84810127, 0.85443038,\n",
      "       0.84810127, 0.85443038, 0.85443038, 0.84177215, 0.84810127,\n",
      "       0.84810127, 0.84177215, 0.85443038, 0.84177215, 0.84177215,\n",
      "       0.83544304, 0.84810127, 0.84177215, 0.84177215, 0.84810127,\n",
      "       0.85443038, 0.84177215, 0.84810127, 0.86075949, 0.84810127,\n",
      "       0.85443038, 0.85443038, 0.84810127, 0.84810127, 0.82278481,\n",
      "       0.83544304, 0.83544304, 0.83544304, 0.84177215, 0.82911392,\n",
      "       0.84177215, 0.84810127, 0.85443038, 0.84177215, 0.84810127,\n",
      "       0.84177215, 0.85443038, 0.85443038, 0.85443038, 0.86075949,\n",
      "       0.79746835, 0.81012658, 0.82911392, 0.83544304, 0.8164557 ,\n",
      "       0.80379747, 0.82911392, 0.84810127, 0.85443038, 0.84810127,\n",
      "       0.84177215, 0.84810127, 0.85443038, 0.84810127, 0.84810127,\n",
      "       0.84810127, 0.82278481, 0.81012658, 0.82911392, 0.84810127,\n",
      "       0.8164557 , 0.82278481, 0.82278481, 0.84177215, 0.85443038,\n",
      "       0.84177215, 0.84810127, 0.84810127, 0.83544304, 0.84810127,\n",
      "       0.85443038, 0.84177215, 0.81012658, 0.81012658, 0.82278481,\n",
      "       0.83544304, 0.80379747, 0.82911392, 0.8164557 , 0.83544304,\n",
      "       0.84177215, 0.84810127, 0.85443038, 0.85443038, 0.84810127,\n",
      "       0.85443038, 0.85443038, 0.85443038, 0.78481013, 0.81012658,\n",
      "       0.8164557 , 0.83544304, 0.81012658, 0.81012658, 0.82278481,\n",
      "       0.84177215, 0.84810127, 0.82278481, 0.83544304, 0.84810127,\n",
      "       0.84810127, 0.84177215, 0.86075949, 0.85443038, 0.80379747,\n",
      "       0.80379747, 0.80379747, 0.82911392, 0.80379747, 0.8164557 ,\n",
      "       0.81012658, 0.84177215, 0.82911392, 0.82911392, 0.83544304,\n",
      "       0.84810127, 0.84810127, 0.84810127, 0.84177215, 0.84177215,\n",
      "       0.7721519 , 0.79746835, 0.81012658, 0.82278481, 0.81012658,\n",
      "       0.80379747, 0.81012658, 0.83544304, 0.84810127, 0.82911392,\n",
      "       0.84177215, 0.84177215, 0.85443038, 0.85443038, 0.86075949,\n",
      "       0.84177215, 0.78481013, 0.81012658, 0.80379747, 0.82911392,\n",
      "       0.80379747, 0.79746835, 0.82278481, 0.84177215, 0.82278481,\n",
      "       0.82911392, 0.84177215, 0.84810127, 0.86075949, 0.85443038,\n",
      "       0.84810127, 0.84810127, 0.79746835, 0.79746835, 0.82278481,\n",
      "       0.82911392, 0.80379747, 0.79113924, 0.8164557 , 0.83544304,\n",
      "       0.85443038, 0.84177215, 0.83544304, 0.84810127, 0.84810127,\n",
      "       0.84810127, 0.86075949, 0.86075949, 0.79113924, 0.78481013,\n",
      "       0.79746835, 0.83544304, 0.81012658, 0.81012658, 0.83544304,\n",
      "       0.84177215, 0.84177215, 0.85443038, 0.8164557 , 0.83544304,\n",
      "       0.86075949, 0.85443038, 0.84177215, 0.84810127, 0.78481013,\n",
      "       0.79746835, 0.80379747, 0.8164557 , 0.81012658, 0.81012658,\n",
      "       0.8164557 , 0.82911392, 0.84810127, 0.84810127, 0.84177215,\n",
      "       0.83544304, 0.83544304, 0.84177215, 0.84177215, 0.85443038]), 'mean_test_score': array([0.76966404, 0.7652655 , 0.76652337, 0.76652337, 0.76086299,\n",
      "       0.75646047, 0.75645649, 0.76337871, 0.76778123, 0.76400764,\n",
      "       0.75958124, 0.76652337, 0.76653133, 0.76903909, 0.7627458 ,\n",
      "       0.76400366, 0.77407054, 0.77658626, 0.77721519, 0.77975878,\n",
      "       0.77471141, 0.7753284 , 0.77343762, 0.7753284 , 0.77470743,\n",
      "       0.7740785 , 0.77407452, 0.7734416 , 0.76903511, 0.7734416 ,\n",
      "       0.77029297, 0.77534034, 0.80681474, 0.80177136, 0.8112292 ,\n",
      "       0.8087095 , 0.81751055, 0.81500279, 0.8112292 , 0.80743969,\n",
      "       0.80745562, 0.805533  , 0.81185415, 0.80492397, 0.80933445,\n",
      "       0.80556086, 0.80743969, 0.80554892, 0.82695247, 0.82191704,\n",
      "       0.82443675, 0.82632752, 0.82318287, 0.82380782, 0.82443675,\n",
      "       0.82127617, 0.82254996, 0.8275814 , 0.82317491, 0.82569461,\n",
      "       0.8206552 , 0.82066316, 0.82569461, 0.82444073, 0.82758538,\n",
      "       0.83072606, 0.82947218, 0.82820635, 0.83010111, 0.8275814 ,\n",
      "       0.82821431, 0.82821431, 0.82758538, 0.8275814 , 0.82632354,\n",
      "       0.82569461, 0.82317491, 0.82253403, 0.822542  , 0.82632354,\n",
      "       0.83198392, 0.82883926, 0.83072606, 0.82758538, 0.83010111,\n",
      "       0.82884324, 0.8294682 , 0.82947218, 0.82884324, 0.82884324,\n",
      "       0.82758538, 0.8275814 , 0.82883926, 0.82569461, 0.82758538,\n",
      "       0.82631956, 0.82819839, 0.82946421, 0.83198392, 0.82820635,\n",
      "       0.83135101, 0.83135897, 0.82946421, 0.82695247, 0.82884324,\n",
      "       0.82883926, 0.82947218, 0.83135499, 0.82632354, 0.82506966,\n",
      "       0.8275814 , 0.82821033, 0.82946421, 0.82883528, 0.82568665,\n",
      "       0.82947218, 0.82820635, 0.82820237, 0.82694849, 0.8294682 ,\n",
      "       0.82694849, 0.8275814 , 0.82695247, 0.82694451, 0.82757742,\n",
      "       0.82569063, 0.82568665, 0.82443675, 0.82379986, 0.82757344,\n",
      "       0.82253801, 0.82569063, 0.82568665, 0.82757344, 0.82569063,\n",
      "       0.82883926, 0.82820237, 0.82631956, 0.82506966, 0.82631956,\n",
      "       0.8275814 , 0.82443675, 0.82820635, 0.82694849, 0.81435395,\n",
      "       0.82190908, 0.8263116 , 0.82190908, 0.82379986, 0.82442083,\n",
      "       0.82191306, 0.82631956, 0.82506568, 0.82631558, 0.82569063,\n",
      "       0.82757344, 0.82883926, 0.82695247, 0.82695247, 0.82947218,\n",
      "       0.80238834, 0.80994348, 0.82253403, 0.82316695, 0.81749463,\n",
      "       0.81559987, 0.81310007, 0.82065918, 0.8275814 , 0.82191704,\n",
      "       0.82128413, 0.82631956, 0.82695247, 0.82569063, 0.82757742,\n",
      "       0.82317491, 0.80240427, 0.80176738, 0.81435793, 0.82380384,\n",
      "       0.81057639, 0.80869358, 0.82001433, 0.81939734, 0.82192103,\n",
      "       0.82128413, 0.82380384, 0.8250617 , 0.82190908, 0.82820635,\n",
      "       0.82506568, 0.82631558, 0.79044662, 0.80554096, 0.8112093 ,\n",
      "       0.81939336, 0.8080527 , 0.80932649, 0.81183425, 0.82002229,\n",
      "       0.82317093, 0.82569063, 0.82443675, 0.82380782, 0.8250617 ,\n",
      "       0.8275814 , 0.82695247, 0.82695247, 0.78980177, 0.80239631,\n",
      "       0.80868959, 0.82128015, 0.80679882, 0.80491203, 0.81246716,\n",
      "       0.822542  , 0.82254598, 0.81875647, 0.82128015, 0.82317491,\n",
      "       0.82254598, 0.82694451, 0.82884324, 0.82821033, 0.77975082,\n",
      "       0.78541119, 0.80490805, 0.81876045, 0.79861874, 0.80428708,\n",
      "       0.81120134, 0.82317093, 0.82316296, 0.82253403, 0.82253801,\n",
      "       0.82380384, 0.82569063, 0.82694849, 0.82379986, 0.82442879,\n",
      "       0.77784412, 0.78855187, 0.80742775, 0.81812754, 0.79673593,\n",
      "       0.79673195, 0.80994348, 0.81750657, 0.82569063, 0.81876045,\n",
      "       0.82002627, 0.82317093, 0.82883926, 0.82632354, 0.82695645,\n",
      "       0.82442879, 0.77848101, 0.78730197, 0.80553698, 0.81938938,\n",
      "       0.79232943, 0.80050155, 0.80932251, 0.82442879, 0.82253005,\n",
      "       0.82253403, 0.81939734, 0.82631956, 0.82821431, 0.82443675,\n",
      "       0.82757742, 0.82694849, 0.77786004, 0.78540721, 0.80177534,\n",
      "       0.81813152, 0.79358729, 0.79609506, 0.81057639, 0.81876443,\n",
      "       0.82129209, 0.82191306, 0.82316695, 0.8250617 , 0.82757742,\n",
      "       0.82820635, 0.82444073, 0.82632752, 0.77911392, 0.7822546 ,\n",
      "       0.80301728, 0.81876443, 0.80113844, 0.79862272, 0.80681474,\n",
      "       0.81939734, 0.822542  , 0.82254996, 0.81749463, 0.82316695,\n",
      "       0.82506966, 0.82632354, 0.82128413, 0.82443277, 0.77156277,\n",
      "       0.78729401, 0.80302126, 0.81875249, 0.79799379, 0.79736486,\n",
      "       0.80806066, 0.81876045, 0.82380384, 0.82317491, 0.82442879,\n",
      "       0.82442481, 0.82505374, 0.82505772, 0.82568665, 0.82632354]), 'std_test_score': array([0.02489142, 0.02480527, 0.02715681, 0.02715681, 0.02508916,\n",
      "       0.02150505, 0.02557462, 0.02796569, 0.02581963, 0.0260732 ,\n",
      "       0.0282448 , 0.02815795, 0.02987306, 0.02839452, 0.02667004,\n",
      "       0.02470627, 0.02748595, 0.02629311, 0.0267366 , 0.03279063,\n",
      "       0.03122372, 0.02911368, 0.02566452, 0.03317772, 0.03224563,\n",
      "       0.02727878, 0.0327132 , 0.02896134, 0.02965259, 0.02936822,\n",
      "       0.02887495, 0.02861541, 0.03807902, 0.02432691, 0.03524152,\n",
      "       0.02439704, 0.03047277, 0.02940248, 0.03029209, 0.02477667,\n",
      "       0.02869789, 0.03025298, 0.03023636, 0.02702641, 0.02966296,\n",
      "       0.03737011, 0.02647462, 0.02769442, 0.02890407, 0.0247462 ,\n",
      "       0.02780788, 0.03021867, 0.03088932, 0.03046022, 0.02752192,\n",
      "       0.02419118, 0.02990598, 0.0267675 , 0.02920808, 0.02717903,\n",
      "       0.02850486, 0.02956094, 0.02746856, 0.02863358, 0.02475413,\n",
      "       0.02739884, 0.02527466, 0.02792327, 0.02424649, 0.02461186,\n",
      "       0.02845114, 0.02551952, 0.02748029, 0.02691486, 0.02834238,\n",
      "       0.02817938, 0.02796269, 0.02295521, 0.02687602, 0.02676319,\n",
      "       0.02395243, 0.02322759, 0.02560788, 0.02475413, 0.02424649,\n",
      "       0.02517054, 0.024173  , 0.02649712, 0.02924152, 0.02757052,\n",
      "       0.02645352, 0.02616972, 0.02758679, 0.02568247, 0.02860866,\n",
      "       0.02751003, 0.02264994, 0.02047447, 0.02601082, 0.02461027,\n",
      "       0.02458228, 0.02580002, 0.0248391 , 0.02493684, 0.0254829 ,\n",
      "       0.02656414, 0.02780822, 0.02657281, 0.02763575, 0.02840667,\n",
      "       0.02848564, 0.02718751, 0.02028036, 0.02202593, 0.02429889,\n",
      "       0.02480071, 0.02631895, 0.02430919, 0.02382125, 0.02529251,\n",
      "       0.02479754, 0.0267675 , 0.02540826, 0.0236775 , 0.02588475,\n",
      "       0.02660881, 0.02462231, 0.02851024, 0.02570729, 0.0233352 ,\n",
      "       0.02410539, 0.0239487 , 0.02295969, 0.02282101, 0.02361606,\n",
      "       0.024064  , 0.02463247, 0.02663335, 0.02770169, 0.02494621,\n",
      "       0.02661931, 0.02878638, 0.02646882, 0.02766277, 0.02435811,\n",
      "       0.02572991, 0.026527  , 0.02693171, 0.02889478, 0.02324652,\n",
      "       0.02720286, 0.02347581, 0.02728586, 0.02416271, 0.02554704,\n",
      "       0.02665829, 0.02715323, 0.02931175, 0.0287669 , 0.02694124,\n",
      "       0.0164823 , 0.02023912, 0.02778822, 0.02437732, 0.0302953 ,\n",
      "       0.02167775, 0.02540783, 0.02848673, 0.0264703 , 0.0258409 ,\n",
      "       0.02557411, 0.02588011, 0.02617508, 0.028056  , 0.02573148,\n",
      "       0.02796269, 0.01814367, 0.02922755, 0.02621003, 0.02775898,\n",
      "       0.0270167 , 0.03116716, 0.03082503, 0.02507468, 0.02716632,\n",
      "       0.02462861, 0.02629544, 0.02439622, 0.02707819, 0.02631895,\n",
      "       0.02594838, 0.02752963, 0.02150164, 0.02520363, 0.02849823,\n",
      "       0.02602556, 0.02914406, 0.02956633, 0.03271649, 0.02192874,\n",
      "       0.02515263, 0.02507823, 0.02480034, 0.026725  , 0.02744808,\n",
      "       0.02691486, 0.02571773, 0.02692007, 0.02256275, 0.02195868,\n",
      "       0.02637886, 0.02432869, 0.027692  , 0.03325924, 0.02833613,\n",
      "       0.02567162, 0.0253409 , 0.02588146, 0.021571  , 0.02621029,\n",
      "       0.02938829, 0.02529298, 0.02639782, 0.02718751, 0.01953385,\n",
      "       0.02212176, 0.03132269, 0.02378416, 0.02695189, 0.03120406,\n",
      "       0.03106896, 0.02419067, 0.0220171 , 0.02662511, 0.02660164,\n",
      "       0.02537684, 0.02675705, 0.02708476, 0.02691009, 0.02484116,\n",
      "       0.02686541, 0.02498279, 0.02485706, 0.02072699, 0.02807449,\n",
      "       0.03065833, 0.03442249, 0.02555016, 0.02310811, 0.02996584,\n",
      "       0.02541404, 0.02267132, 0.02596169, 0.02834238, 0.02805524,\n",
      "       0.02531435, 0.02328957, 0.02897108, 0.03249655, 0.02448353,\n",
      "       0.02647865, 0.03004805, 0.03587184, 0.02419584, 0.02738251,\n",
      "       0.02346647, 0.02327483, 0.0244659 , 0.029138  , 0.02752192,\n",
      "       0.0261886 , 0.02542759, 0.02326196, 0.02142858, 0.03102152,\n",
      "       0.02517899, 0.02860967, 0.02760783, 0.02745242, 0.02552428,\n",
      "       0.028742  , 0.02646583, 0.02453904, 0.02455782, 0.0275144 ,\n",
      "       0.02661784, 0.02835595, 0.02874275, 0.02285556, 0.0230384 ,\n",
      "       0.0243925 , 0.02658696, 0.02368531, 0.02692477, 0.02627829,\n",
      "       0.02690116, 0.02830956, 0.02770904, 0.02593379, 0.02371938,\n",
      "       0.02741462, 0.02661498, 0.02904997, 0.02621487, 0.02396151,\n",
      "       0.02017563, 0.03003215, 0.02465728, 0.02548024, 0.02537617,\n",
      "       0.03016113, 0.02507937, 0.02703712, 0.02367281, 0.02499989,\n",
      "       0.0265569 , 0.02631247, 0.02552688, 0.02692442, 0.02661498]), 'rank_test_score': array([304, 312, 309, 309, 317, 319, 320, 315, 307, 313, 318, 309, 308,\n",
      "       305, 316, 314, 298, 290, 289, 283, 294, 292, 301, 292, 295, 296,\n",
      "       297, 299, 306, 299, 303, 291, 244, 262, 224, 235, 212, 217, 224,\n",
      "       241, 240, 251, 222, 252, 232, 247, 241, 248,  69, 178, 128,  83,\n",
      "       150, 142, 128, 191, 164,  56, 151, 100, 194, 192, 100, 126,  46,\n",
      "         6,  10,  37,   8,  56,  32,  32,  46,  51,  85, 100, 151, 172,\n",
      "       167,  86,   2,  25,   6,  46,   8,  20,  15,  10,  20,  20,  46,\n",
      "        56,  25, 100,  46,  96,  45,  17,   1,  37,   5,   3,  17,  68,\n",
      "        20,  25,  10,   4,  86, 116,  51,  35,  17,  31, 112,  10,  37,\n",
      "        43,  76,  15,  76,  51,  69,  81,  60, 104, 113, 128, 147,  64,\n",
      "       170, 104, 113,  64, 104,  25,  43,  91, 116,  91,  56, 128,  37,\n",
      "        76, 219, 182,  99, 182, 147, 140, 180,  91, 119,  97, 111,  64,\n",
      "        25,  69,  69,  10, 260, 230, 173, 159, 214, 216, 220, 193,  51,\n",
      "       178, 186,  91,  69, 104,  60, 151, 258, 263, 218, 143, 228, 236,\n",
      "       197, 198, 177, 186, 143, 121, 184,  37, 119,  98, 275, 249, 226,\n",
      "       201, 239, 233, 223, 196, 156, 104, 128, 141, 121,  51,  69,  69,\n",
      "       276, 259, 237, 189, 246, 253, 221, 167, 165, 208, 190, 151, 165,\n",
      "        81,  20,  35, 284, 280, 254, 205, 267, 255, 227, 156, 162, 173,\n",
      "       170, 143, 104,  76, 147, 135, 288, 277, 243, 211, 270, 271, 230,\n",
      "       213, 104, 205, 195, 156,  25,  86,  67, 135, 286, 278, 250, 202,\n",
      "       274, 265, 234, 135, 176, 173, 199,  91,  32, 128,  60,  76, 287,\n",
      "       281, 261, 210, 273, 272, 228, 203, 185, 180, 159, 121,  60,  37,\n",
      "       126,  83, 285, 282, 257, 203, 264, 266, 244, 199, 167, 163, 214,\n",
      "       159, 116,  86, 186, 134, 302, 279, 256, 209, 268, 269, 238, 205,\n",
      "       143, 151, 135, 139, 125, 124, 113,  86])}\n",
      "Resultados para OverSampler:\n",
      "{'mean_fit_time': array([0.11585567, 0.11902146, 0.11636107, 0.11431005, 0.11626961,\n",
      "       0.11890123, 0.11549587, 0.11476877, 0.11556656, 0.11509876,\n",
      "       0.11350675, 0.11372106, 0.11319206, 0.1171382 , 0.11412895,\n",
      "       0.11445627, 0.12167118, 0.11949451, 0.11966827, 0.11906331,\n",
      "       0.11888044, 0.1194267 , 0.12107432, 0.11968606, 0.12088745,\n",
      "       0.1217437 , 0.13399868, 0.13495691, 0.13064137, 0.13104367,\n",
      "       0.12031209, 0.12021906, 0.12671156, 0.12523839, 0.12303901,\n",
      "       0.12708728, 0.12770746, 0.12572339, 0.12309835, 0.12926083,\n",
      "       0.12591333, 0.12555671, 0.12278018, 0.12319021, 0.1238796 ,\n",
      "       0.12371881, 0.12240126, 0.1246181 , 0.13091948, 0.12773352,\n",
      "       0.13418677, 0.12844622, 0.18210769, 0.14005911, 0.13817379,\n",
      "       0.14050317, 0.13693223, 0.14113355, 0.14633205, 0.13178754,\n",
      "       0.12485602, 0.12098956, 0.12188063, 0.12338846, 0.12975738,\n",
      "       0.12636347, 0.12468231, 0.12529073, 0.12478495, 0.12488427,\n",
      "       0.12609355, 0.12604325, 0.12437928, 0.12443645, 0.12529807,\n",
      "       0.12451313, 0.12559719, 0.12439244, 0.12389555, 0.12414868,\n",
      "       0.12997479, 0.12843773, 0.13189428, 0.12828219, 0.12870076,\n",
      "       0.12836618, 0.12807665, 0.12718997, 0.12780881, 0.13295197,\n",
      "       0.13285809, 0.12816694, 0.12940381, 0.12678528, 0.13435988,\n",
      "       0.13825252, 0.14163716, 0.13717136, 0.14069934, 0.13586957,\n",
      "       0.14839463, 0.13854017, 0.14132512, 0.13335519, 0.13329885,\n",
      "       0.13178468, 0.13452482, 0.13155956, 0.13136315, 0.13022039,\n",
      "       0.1297816 , 0.13037159, 0.15124741, 0.13900397, 0.13797748,\n",
      "       0.1368716 , 0.14270341, 0.13798819, 0.1350378 , 0.13351607,\n",
      "       0.13716457, 0.13458254, 0.13791056, 0.13309116, 0.13154783,\n",
      "       0.13324118, 0.13397634, 0.13477061, 0.14392176, 0.14729042,\n",
      "       0.14228745, 0.13834562, 0.14471853, 0.14560213, 0.14685276,\n",
      "       0.13732612, 0.13883269, 0.14095111, 0.13984787, 0.13591971,\n",
      "       0.13429182, 0.13579645, 0.13386137, 0.13724592, 0.15557063,\n",
      "       0.14946661, 0.14284575, 0.13833613, 0.144102  , 0.14307096,\n",
      "       0.14175875, 0.13837841, 0.13995461, 0.13919647, 0.14272876,\n",
      "       0.14017372, 0.14410813, 0.13722122, 0.14231358, 0.134953  ,\n",
      "       0.15196362, 0.14896629, 0.1635916 , 0.14552636, 0.15611603,\n",
      "       0.17844627, 0.17060883, 0.16034441, 0.15958173, 0.15407715,\n",
      "       0.15118036, 0.14544387, 0.15132205, 0.16226873, 0.15604   ,\n",
      "       0.14859502, 0.159987  , 0.15320725, 0.15506053, 0.14125602,\n",
      "       0.15510864, 0.14885192, 0.14653213, 0.15620146, 0.14748464,\n",
      "       0.14912107, 0.14840209, 0.14555228, 0.14254212, 0.14170227,\n",
      "       0.14305894, 0.14903045, 0.17921371, 0.17086871, 0.17314649,\n",
      "       0.15885248, 0.16293604, 0.17717776, 0.16967747, 0.16023214,\n",
      "       0.14950294, 0.16331625, 0.15205951, 0.14720821, 0.14330025,\n",
      "       0.14553065, 0.1458117 , 0.14323583, 0.17062836, 0.16544628,\n",
      "       0.1622298 , 0.1494173 , 0.16450887, 0.16018198, 0.15787411,\n",
      "       0.15069001, 0.15116425, 0.15102363, 0.14984117, 0.14720826,\n",
      "       0.14156635, 0.14201384, 0.14447927, 0.14316928, 0.1712132 ,\n",
      "       0.16683261, 0.15684984, 0.16772392, 0.16799071, 0.16902246,\n",
      "       0.15564344, 0.15088639, 0.15262761, 0.15045455, 0.15404902,\n",
      "       0.14628851, 0.14335799, 0.14257066, 0.14248166, 0.14927001,\n",
      "       0.17195973, 0.16701574, 0.16007807, 0.15034077, 0.16248982,\n",
      "       0.16229305, 0.16446211, 0.16590419, 0.16320784, 0.15687718,\n",
      "       0.1535219 , 0.15018578, 0.14514699, 0.14749212, 0.14557669,\n",
      "       0.1432101 , 0.17483113, 0.16579452, 0.15814505, 0.16271644,\n",
      "       0.16572011, 0.16117036, 0.15745764, 0.14890792, 0.14921856,\n",
      "       0.15537899, 0.15167406, 0.14624259, 0.14514959, 0.14727645,\n",
      "       0.14413288, 0.14319909, 0.17700129, 0.16774209, 0.16033461,\n",
      "       0.14966595, 0.16300046, 0.16399515, 0.16584532, 0.15126438,\n",
      "       0.14866745, 0.15170529, 0.15120811, 0.14756594, 0.141554  ,\n",
      "       0.14544151, 0.14225936, 0.14180565, 0.17508378, 0.17006698,\n",
      "       0.15951195, 0.15270655, 0.16492932, 0.16350844, 0.15526705,\n",
      "       0.1493212 , 0.14970076, 0.1489773 , 0.14976654, 0.14651551,\n",
      "       0.14257059, 0.14161716, 0.1456244 , 0.15574117, 0.17631466,\n",
      "       0.16793129, 0.16089127, 0.15158365, 0.16403358, 0.16618123,\n",
      "       0.1590039 , 0.15354474, 0.14791651, 0.15038383, 0.15691953,\n",
      "       0.14525001, 0.14201486, 0.14889529, 0.16581311, 0.15796218]), 'std_fit_time': array([0.00361707, 0.00905846, 0.00182887, 0.0013524 , 0.00307782,\n",
      "       0.00404688, 0.00070974, 0.00113721, 0.00164048, 0.00083147,\n",
      "       0.00065609, 0.00197217, 0.00046986, 0.00562607, 0.00176646,\n",
      "       0.00132667, 0.00202986, 0.00167364, 0.00230645, 0.00055395,\n",
      "       0.00065763, 0.00237994, 0.00385601, 0.00096607, 0.00376781,\n",
      "       0.00514931, 0.01124416, 0.01330199, 0.01050138, 0.00957077,\n",
      "       0.00267259, 0.00158434, 0.00141903, 0.00437977, 0.00083786,\n",
      "       0.00678827, 0.00640153, 0.0037492 , 0.0022967 , 0.00623259,\n",
      "       0.00128561, 0.00133169, 0.00083597, 0.00061846, 0.00062308,\n",
      "       0.0021571 , 0.00090527, 0.00160394, 0.00487932, 0.00118773,\n",
      "       0.01322233, 0.00318969, 0.03962382, 0.00699371, 0.01146965,\n",
      "       0.00849357, 0.00535133, 0.00426337, 0.01526742, 0.01234019,\n",
      "       0.00537218, 0.00235179, 0.00177767, 0.00732751, 0.00500496,\n",
      "       0.005014  , 0.00048635, 0.00083308, 0.00058174, 0.00054119,\n",
      "       0.00378282, 0.00471362, 0.00046123, 0.00069206, 0.00293707,\n",
      "       0.00045701, 0.00421676, 0.00053081, 0.00057273, 0.00061576,\n",
      "       0.0029977 , 0.00071285, 0.00700377, 0.00196851, 0.00087385,\n",
      "       0.0005856 , 0.00041331, 0.00040875, 0.0008033 , 0.00398867,\n",
      "       0.00322908, 0.00092774, 0.00381625, 0.00132504, 0.00889901,\n",
      "       0.00593873, 0.00573941, 0.00319801, 0.00883213, 0.00374523,\n",
      "       0.01402954, 0.00534761, 0.01267202, 0.00261993, 0.00345738,\n",
      "       0.0010513 , 0.00381226, 0.00190477, 0.00236279, 0.00149311,\n",
      "       0.00057694, 0.00128294, 0.01061911, 0.00159495, 0.00160595,\n",
      "       0.00200587, 0.0083681 , 0.001124  , 0.00092699, 0.00090961,\n",
      "       0.00108667, 0.00081413, 0.00307751, 0.00106284, 0.00082835,\n",
      "       0.00168989, 0.00305398, 0.00776682, 0.00152121, 0.00515513,\n",
      "       0.00333372, 0.00178762, 0.00572278, 0.00971213, 0.01433222,\n",
      "       0.00139002, 0.00159128, 0.00351752, 0.00414097, 0.0013077 ,\n",
      "       0.00266071, 0.0022234 , 0.00052295, 0.00306366, 0.00879161,\n",
      "       0.00607472, 0.00165781, 0.0003917 , 0.00065963, 0.00042853,\n",
      "       0.00064066, 0.00102619, 0.00107038, 0.00091067, 0.00145756,\n",
      "       0.00438163, 0.00531007, 0.00278909, 0.00812126, 0.00297718,\n",
      "       0.00086812, 0.00070971, 0.01748006, 0.00133446, 0.00422461,\n",
      "       0.0111863 , 0.00329735, 0.0029371 , 0.00310455, 0.00570361,\n",
      "       0.00503798, 0.00165781, 0.00855829, 0.00997097, 0.00857048,\n",
      "       0.00482966, 0.00350648, 0.00178623, 0.01499542, 0.00069477,\n",
      "       0.00734872, 0.00080117, 0.00427831, 0.00630329, 0.00096546,\n",
      "       0.00285053, 0.00110372, 0.00213923, 0.00266984, 0.00098156,\n",
      "       0.00140437, 0.00676355, 0.01738144, 0.00624755, 0.01759726,\n",
      "       0.02795088, 0.0137141 , 0.01856876, 0.00982294, 0.01470281,\n",
      "       0.00315453, 0.02123545, 0.0019453 , 0.00141857, 0.00151524,\n",
      "       0.00749089, 0.00544553, 0.00526103, 0.00492636, 0.00391772,\n",
      "       0.00867875, 0.00081458, 0.00594287, 0.00385115, 0.00606681,\n",
      "       0.00069176, 0.00073307, 0.00331714, 0.00086078, 0.00348479,\n",
      "       0.00081817, 0.00133699, 0.0036967 , 0.00109132, 0.00374879,\n",
      "       0.00454132, 0.00165446, 0.01828588, 0.00652912, 0.01669658,\n",
      "       0.00102789, 0.00389771, 0.00417583, 0.00074651, 0.00410594,\n",
      "       0.00208877, 0.00375876, 0.00188404, 0.00089451, 0.0183582 ,\n",
      "       0.00176678, 0.00409771, 0.00223664, 0.00316964, 0.0007277 ,\n",
      "       0.00098299, 0.00736984, 0.01089461, 0.01301585, 0.00542263,\n",
      "       0.00260126, 0.00381151, 0.00183391, 0.00465211, 0.00529488,\n",
      "       0.00312476, 0.00357244, 0.00181386, 0.00122455, 0.02018381,\n",
      "       0.00341013, 0.00155054, 0.00353558, 0.00193423, 0.00355602,\n",
      "       0.00890705, 0.0024971 , 0.00166061, 0.00259106, 0.01341183,\n",
      "       0.00692064, 0.00060914, 0.00651707, 0.001298  , 0.00651355,\n",
      "       0.00381369, 0.00117851, 0.00534635, 0.02400437, 0.00428276,\n",
      "       0.00109781, 0.00511982, 0.00392814, 0.00351393, 0.00241091,\n",
      "       0.00486518, 0.00089095, 0.00210642, 0.00315096, 0.00417432,\n",
      "       0.00113486, 0.00533641, 0.00473372, 0.00395418, 0.00073888,\n",
      "       0.0022993 , 0.00130463, 0.00118027, 0.00225215, 0.00267696,\n",
      "       0.00109037, 0.00163062, 0.00428006, 0.02046964, 0.00484094,\n",
      "       0.00145431, 0.00463798, 0.00262624, 0.00142966, 0.00626172,\n",
      "       0.0033212 , 0.00643891, 0.00145634, 0.00394688, 0.02132123,\n",
      "       0.00210351, 0.00174502, 0.01337793, 0.01093453, 0.00979534]), 'mean_score_time': array([0.0081531 , 0.00845006, 0.00863774, 0.00820937, 0.0081964 ,\n",
      "       0.00848289, 0.00786176, 0.00840044, 0.00829985, 0.0082001 ,\n",
      "       0.00799906, 0.00780525, 0.00814965, 0.00798042, 0.00800719,\n",
      "       0.00799401, 0.00849509, 0.00851016, 0.00839725, 0.00815337,\n",
      "       0.00828843, 0.0082695 , 0.00836599, 0.00802641, 0.00858505,\n",
      "       0.0080395 , 0.00897233, 0.00957565, 0.00859585, 0.00884981,\n",
      "       0.00845327, 0.00840161, 0.00885055, 0.00825605, 0.00825713,\n",
      "       0.00839136, 0.00816641, 0.00856352, 0.00836623, 0.00893056,\n",
      "       0.00829244, 0.00854793, 0.00850322, 0.00850918, 0.00858524,\n",
      "       0.00820372, 0.00849967, 0.00809364, 0.00855436, 0.00835104,\n",
      "       0.00906498, 0.00859985, 0.01131041, 0.00928683, 0.00881937,\n",
      "       0.00923107, 0.00893729, 0.0098604 , 0.00959406, 0.00818758,\n",
      "       0.00802808, 0.00820444, 0.00826511, 0.00793703, 0.00832474,\n",
      "       0.00843918, 0.00818996, 0.00782917, 0.0083766 , 0.00815837,\n",
      "       0.00816569, 0.00834422, 0.00835435, 0.00818493, 0.00815368,\n",
      "       0.00807319, 0.00821459, 0.00798411, 0.00815353, 0.00833549,\n",
      "       0.00865419, 0.00833366, 0.00829751, 0.00837996, 0.00828369,\n",
      "       0.00833383, 0.00813591, 0.00842745, 0.00797741, 0.00828505,\n",
      "       0.00911472, 0.00836294, 0.0083874 , 0.00823636, 0.00889366,\n",
      "       0.00876076, 0.00865636, 0.00862522, 0.0085932 , 0.00866067,\n",
      "       0.00871391, 0.00879881, 0.00960813, 0.00874517, 0.00826907,\n",
      "       0.00844448, 0.00840287, 0.00827625, 0.008641  , 0.00839305,\n",
      "       0.00854309, 0.00836051, 0.0088743 , 0.00920715, 0.00871725,\n",
      "       0.00865366, 0.00900652, 0.00858514, 0.00867057, 0.00867674,\n",
      "       0.00870516, 0.00850954, 0.00901973, 0.00866346, 0.00831404,\n",
      "       0.00872171, 0.00878854, 0.0085804 , 0.0090838 , 0.00908775,\n",
      "       0.00873702, 0.00870843, 0.00894835, 0.00903623, 0.00974045,\n",
      "       0.00874779, 0.00912113, 0.00869105, 0.0085242 , 0.00850589,\n",
      "       0.00853548, 0.00859528, 0.0086225 , 0.00897155, 0.00952282,\n",
      "       0.00938137, 0.00878751, 0.00846884, 0.00880747, 0.00883434,\n",
      "       0.00896685, 0.00882831, 0.00882878, 0.00867448, 0.00901735,\n",
      "       0.00893466, 0.00902209, 0.00846136, 0.00910139, 0.0089287 ,\n",
      "       0.00914764, 0.00923209, 0.00988185, 0.00911229, 0.00946746,\n",
      "       0.01063983, 0.01073184, 0.01022875, 0.00986252, 0.00940206,\n",
      "       0.00940058, 0.00889046, 0.00954075, 0.01020963, 0.01007164,\n",
      "       0.00931864, 0.0100378 , 0.00942597, 0.00946226, 0.00866697,\n",
      "       0.00946946, 0.00946472, 0.00923941, 0.00942619, 0.00930455,\n",
      "       0.00941975, 0.00932968, 0.00915477, 0.00904863, 0.00916533,\n",
      "       0.00891087, 0.00937185, 0.01105773, 0.01020377, 0.01047399,\n",
      "       0.00964551, 0.01013947, 0.01043944, 0.01064556, 0.0098191 ,\n",
      "       0.00957277, 0.00947945, 0.00967419, 0.00905738, 0.00939519,\n",
      "       0.00863807, 0.00900552, 0.00952332, 0.01038735, 0.01002386,\n",
      "       0.01016846, 0.00933251, 0.00986264, 0.01002886, 0.00977941,\n",
      "       0.00932999, 0.00945747, 0.00926461, 0.00917263, 0.00943153,\n",
      "       0.00891595, 0.00887427, 0.00927863, 0.00932913, 0.01023059,\n",
      "       0.00990179, 0.00926456, 0.01049957, 0.01018326, 0.01049693,\n",
      "       0.00967326, 0.01021655, 0.00913944, 0.00982563, 0.00933418,\n",
      "       0.00916741, 0.009038  , 0.00923979, 0.0092562 , 0.00966454,\n",
      "       0.01012015, 0.01016088, 0.00989413, 0.00943022, 0.01050117,\n",
      "       0.00964036, 0.01033275, 0.0106864 , 0.0098577 , 0.00972733,\n",
      "       0.00944138, 0.00936277, 0.00912318, 0.0090548 , 0.00943565,\n",
      "       0.00907965, 0.01044888, 0.0102437 , 0.00982351, 0.01063302,\n",
      "       0.01015122, 0.00984037, 0.00980258, 0.00916724, 0.00947847,\n",
      "       0.00955505, 0.00937138, 0.0093828 , 0.00969687, 0.00961719,\n",
      "       0.00907295, 0.0093482 , 0.0105155 , 0.01012316, 0.00928423,\n",
      "       0.00943596, 0.01002431, 0.01023479, 0.01094091, 0.00938599,\n",
      "       0.00930591, 0.00933845, 0.00919111, 0.00940132, 0.00902143,\n",
      "       0.0090255 , 0.00877528, 0.00883937, 0.01043351, 0.01011357,\n",
      "       0.01013243, 0.00951014, 0.00975714, 0.00971825, 0.00928113,\n",
      "       0.00939069, 0.00959015, 0.00938432, 0.00984173, 0.00949132,\n",
      "       0.00880306, 0.00912449, 0.00924904, 0.0100045 , 0.01047299,\n",
      "       0.01033177, 0.01055624, 0.00961676, 0.00992377, 0.01022277,\n",
      "       0.0097764 , 0.0098274 , 0.00949225, 0.00946305, 0.01005485,\n",
      "       0.00924375, 0.00985491, 0.00989511, 0.01037524, 0.01006005]), 'std_score_time': array([0.00047375, 0.00042699, 0.00134493, 0.00030803, 0.00036291,\n",
      "       0.00109462, 0.00079085, 0.00048902, 0.0004584 , 0.00040016,\n",
      "       0.0003757 , 0.00047224, 0.00031106, 0.00042399, 0.00031585,\n",
      "       0.00052386, 0.00049533, 0.00041493, 0.00033833, 0.00060958,\n",
      "       0.00082218, 0.00073883, 0.0005893 , 0.00030458, 0.00040432,\n",
      "       0.00035099, 0.00138139, 0.00137402, 0.00099844, 0.00071792,\n",
      "       0.00055611, 0.00043374, 0.00080408, 0.00044927, 0.00037936,\n",
      "       0.00037438, 0.00034751, 0.00063088, 0.00036876, 0.00075169,\n",
      "       0.00036773, 0.00056911, 0.0004883 , 0.00038565, 0.00049729,\n",
      "       0.00050694, 0.00044412, 0.00041163, 0.00050814, 0.00079444,\n",
      "       0.00121297, 0.00055548, 0.00215507, 0.00105436, 0.00065923,\n",
      "       0.00055825, 0.00062435, 0.0011104 , 0.00195777, 0.0003628 ,\n",
      "       0.00036324, 0.0002901 , 0.0005449 , 0.00016545, 0.0005658 ,\n",
      "       0.00052878, 0.00056666, 0.00037282, 0.00041364, 0.00038973,\n",
      "       0.0002255 , 0.00063711, 0.00032638, 0.00040649, 0.00072517,\n",
      "       0.00050997, 0.00043161, 0.00043193, 0.00043734, 0.00047918,\n",
      "       0.00056093, 0.00051775, 0.00043892, 0.00071717, 0.00046122,\n",
      "       0.00034931, 0.00044372, 0.00032252, 0.00044771, 0.00035363,\n",
      "       0.0006301 , 0.00044422, 0.00044603, 0.00032657, 0.00109023,\n",
      "       0.00032289, 0.00098219, 0.00036686, 0.00042225, 0.00074023,\n",
      "       0.00035194, 0.00083534, 0.00225186, 0.00098784, 0.00057118,\n",
      "       0.0003182 , 0.00041043, 0.00050351, 0.00042343, 0.0004809 ,\n",
      "       0.00030781, 0.00052875, 0.00067684, 0.00114276, 0.00058805,\n",
      "       0.00039063, 0.00050362, 0.00042722, 0.00030198, 0.0004756 ,\n",
      "       0.00035166, 0.00044623, 0.0012497 , 0.00054114, 0.00047254,\n",
      "       0.00033391, 0.00062422, 0.00043583, 0.00052772, 0.00062288,\n",
      "       0.00049571, 0.00052201, 0.00041387, 0.00073289, 0.00129731,\n",
      "       0.00056249, 0.00028938, 0.00037123, 0.0004183 , 0.00041107,\n",
      "       0.00036609, 0.00043508, 0.0003746 , 0.00120286, 0.00046353,\n",
      "       0.000545  , 0.00025781, 0.00037032, 0.00022684, 0.00028983,\n",
      "       0.00037889, 0.00038832, 0.00038874, 0.00037291, 0.00050327,\n",
      "       0.00027035, 0.00137764, 0.00040292, 0.00040328, 0.00039597,\n",
      "       0.00046039, 0.00044188, 0.00111214, 0.0003803 , 0.00048928,\n",
      "       0.00152682, 0.00081115, 0.00075394, 0.00081097, 0.00053739,\n",
      "       0.0004901 , 0.00018166, 0.0007463 , 0.00114606, 0.0007269 ,\n",
      "       0.00081696, 0.00106539, 0.00049998, 0.00148416, 0.00044247,\n",
      "       0.00043728, 0.00106634, 0.00064915, 0.0005194 , 0.00040292,\n",
      "       0.00049848, 0.00036804, 0.00046492, 0.00022384, 0.00044506,\n",
      "       0.00032506, 0.00064905, 0.00122528, 0.00086068, 0.00137116,\n",
      "       0.00047127, 0.00078702, 0.00087414, 0.00119769, 0.00095624,\n",
      "       0.00050109, 0.00076869, 0.00060791, 0.00045532, 0.00076683,\n",
      "       0.00047093, 0.00053375, 0.00038129, 0.00057031, 0.00046671,\n",
      "       0.0008643 , 0.00049718, 0.00062611, 0.0002746 , 0.00062503,\n",
      "       0.00051994, 0.00054493, 0.00046646, 0.00071964, 0.0005551 ,\n",
      "       0.00049077, 0.00047172, 0.00062056, 0.00072072, 0.00057405,\n",
      "       0.00039134, 0.00051356, 0.00282186, 0.00081231, 0.00144978,\n",
      "       0.00039827, 0.00245341, 0.00023359, 0.00030754, 0.00063174,\n",
      "       0.0003626 , 0.00090799, 0.00041587, 0.0002369 , 0.00123571,\n",
      "       0.00055192, 0.00050997, 0.00049631, 0.00059926, 0.0007485 ,\n",
      "       0.00044275, 0.00077651, 0.00178215, 0.00112174, 0.00045531,\n",
      "       0.00059539, 0.00057807, 0.00029868, 0.00044866, 0.00044797,\n",
      "       0.00037097, 0.00049708, 0.00059437, 0.00051999, 0.00188029,\n",
      "       0.00050934, 0.00044403, 0.00059721, 0.00057389, 0.00050175,\n",
      "       0.0005322 , 0.00042862, 0.00048506, 0.00082647, 0.00069909,\n",
      "       0.0003503 , 0.00057284, 0.0003747 , 0.00051274, 0.00049047,\n",
      "       0.00043938, 0.00055243, 0.00075259, 0.00223549, 0.00053257,\n",
      "       0.00040278, 0.00047142, 0.0004194 , 0.00045576, 0.00056311,\n",
      "       0.00033062, 0.00041799, 0.00052159, 0.00043992, 0.00072204,\n",
      "       0.00061231, 0.00053399, 0.00062025, 0.00034269, 0.00042588,\n",
      "       0.00065547, 0.0006078 , 0.00090583, 0.00124205, 0.00044792,\n",
      "       0.00055208, 0.00027447, 0.0006265 , 0.00210524, 0.00063952,\n",
      "       0.0003798 , 0.00164667, 0.00039505, 0.00049209, 0.000405  ,\n",
      "       0.00034877, 0.00159185, 0.0008539 , 0.00042831, 0.00171795,\n",
      "       0.00053724, 0.00241885, 0.00197699, 0.0008064 , 0.00116335]), 'param_classifier__max_depth': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
      "                   2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3,\n",
      "                   3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4,\n",
      "                   4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "                   6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "                   7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "                   8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
      "                   11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
      "                   12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13,\n",
      "                   13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14,\n",
      "                   14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15,\n",
      "                   15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16,\n",
      "                   16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "                   17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "                   17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
      "                   18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
      "                   19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "                   20, 20, 20, 20, 20, 20, 20, 20],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_classifier__min_samples_leaf': masked_array(data=[1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1,\n",
      "                   1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1,\n",
      "                   1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1,\n",
      "                   1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1,\n",
      "                   2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2,\n",
      "                   2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2,\n",
      "                   2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2,\n",
      "                   2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "                   5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5,\n",
      "                   5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5,\n",
      "                   5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5,\n",
      "                   5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5,\n",
      "                   10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10,\n",
      "                   10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10,\n",
      "                   10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10,\n",
      "                   10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10,\n",
      "                   1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1,\n",
      "                   1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1,\n",
      "                   1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_classifier__min_samples_split': masked_array(data=[2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'classifier__max_depth': 1, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}], 'split0_test_score': array([0.72327044, 0.72327044, 0.74842767, 0.71698113, 0.74842767,\n",
      "       0.72327044, 0.72327044, 0.72327044, 0.72955975, 0.74842767,\n",
      "       0.73584906, 0.74213836, 0.71698113, 0.71698113, 0.72327044,\n",
      "       0.72955975, 0.73584906, 0.74842767, 0.72955975, 0.74842767,\n",
      "       0.73584906, 0.74213836, 0.72955975, 0.73584906, 0.72327044,\n",
      "       0.74842767, 0.72955975, 0.74213836, 0.72327044, 0.74213836,\n",
      "       0.73584906, 0.74842767, 0.79245283, 0.79245283, 0.78616352,\n",
      "       0.79874214, 0.80503145, 0.76100629, 0.77987421, 0.75471698,\n",
      "       0.79874214, 0.77987421, 0.77987421, 0.78616352, 0.77358491,\n",
      "       0.79874214, 0.79245283, 0.78616352, 0.81132075, 0.81132075,\n",
      "       0.79245283, 0.79874214, 0.79874214, 0.81132075, 0.81132075,\n",
      "       0.79245283, 0.81132075, 0.81132075, 0.79874214, 0.81761006,\n",
      "       0.7672956 , 0.81132075, 0.81132075, 0.78616352, 0.81761006,\n",
      "       0.81761006, 0.80503145, 0.81761006, 0.81132075, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81761006, 0.79874214, 0.81761006, 0.80503145,\n",
      "       0.82389937, 0.82389937, 0.82389937, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.82389937, 0.79874214, 0.81761006, 0.82389937,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.82389937, 0.81132075,\n",
      "       0.81761006, 0.83018868, 0.82389937, 0.82389937, 0.82389937,\n",
      "       0.80503145, 0.81761006, 0.82389937, 0.82389937, 0.81132075,\n",
      "       0.81761006, 0.81132075, 0.81132075, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81132075, 0.81132075, 0.82389937, 0.83018868,\n",
      "       0.81761006, 0.80503145, 0.80503145, 0.82389937, 0.79874214,\n",
      "       0.81761006, 0.81132075, 0.81132075, 0.81132075, 0.80503145,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81761006, 0.82389937, 0.81761006, 0.80503145, 0.82389937,\n",
      "       0.79874214, 0.81132075, 0.81761006, 0.81132075, 0.80503145,\n",
      "       0.81761006, 0.80503145, 0.81761006, 0.81132075, 0.80503145,\n",
      "       0.81132075, 0.80503145, 0.81132075, 0.81761006, 0.80503145,\n",
      "       0.81132075, 0.81132075, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.79874214, 0.81132075, 0.81761006, 0.79874214, 0.81761006,\n",
      "       0.81132075, 0.78616352, 0.80503145, 0.81132075, 0.80503145,\n",
      "       0.80503145, 0.79245283, 0.81132075, 0.79874214, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.79245283, 0.81761006, 0.81132075,\n",
      "       0.82389937, 0.77358491, 0.81132075, 0.77987421, 0.81132075,\n",
      "       0.80503145, 0.80503145, 0.79245283, 0.79245283, 0.79874214,\n",
      "       0.80503145, 0.79874214, 0.78616352, 0.81132075, 0.80503145,\n",
      "       0.81132075, 0.79874214, 0.79874214, 0.77987421, 0.80503145,\n",
      "       0.80503145, 0.79874214, 0.80503145, 0.80503145, 0.79874214,\n",
      "       0.79245283, 0.80503145, 0.80503145, 0.79874214, 0.81132075,\n",
      "       0.80503145, 0.79874214, 0.81761006, 0.77358491, 0.77358491,\n",
      "       0.79245283, 0.79874214, 0.79874214, 0.77987421, 0.77987421,\n",
      "       0.81132075, 0.81132075, 0.79874214, 0.79245283, 0.81761006,\n",
      "       0.81132075, 0.80503145, 0.80503145, 0.81132075, 0.79245283,\n",
      "       0.79874214, 0.78616352, 0.78616352, 0.79874214, 0.80503145,\n",
      "       0.82389937, 0.83018868, 0.80503145, 0.79245283, 0.79245283,\n",
      "       0.81761006, 0.81761006, 0.81132075, 0.81761006, 0.80503145,\n",
      "       0.77358491, 0.79245283, 0.77987421, 0.79245283, 0.79874214,\n",
      "       0.80503145, 0.81132075, 0.80503145, 0.80503145, 0.81132075,\n",
      "       0.79245283, 0.80503145, 0.80503145, 0.80503145, 0.81132075,\n",
      "       0.79874214, 0.77358491, 0.77987421, 0.80503145, 0.79245283,\n",
      "       0.77987421, 0.77358491, 0.78616352, 0.79874214, 0.79245283,\n",
      "       0.79245283, 0.81132075, 0.80503145, 0.81761006, 0.81132075,\n",
      "       0.79245283, 0.80503145, 0.79245283, 0.77358491, 0.81132075,\n",
      "       0.79874214, 0.78616352, 0.78616352, 0.78616352, 0.80503145,\n",
      "       0.79874214, 0.81132075, 0.79874214, 0.79874214, 0.81761006,\n",
      "       0.81132075, 0.81132075, 0.82389937, 0.7672956 , 0.77987421,\n",
      "       0.78616352, 0.79874214, 0.77987421, 0.79245283, 0.78616352,\n",
      "       0.81132075, 0.79245283, 0.79874214, 0.79874214, 0.81132075,\n",
      "       0.80503145, 0.80503145, 0.81132075, 0.81761006, 0.79874214,\n",
      "       0.79245283, 0.78616352, 0.81761006, 0.77358491, 0.79245283,\n",
      "       0.79874214, 0.82389937, 0.79245283, 0.79874214, 0.81132075,\n",
      "       0.80503145, 0.81132075, 0.81761006, 0.80503145, 0.80503145]), 'split1_test_score': array([0.79874214, 0.77358491, 0.81132075, 0.80503145, 0.80503145,\n",
      "       0.77987421, 0.77358491, 0.79874214, 0.80503145, 0.77358491,\n",
      "       0.78616352, 0.80503145, 0.77358491, 0.77358491, 0.80503145,\n",
      "       0.77987421, 0.80503145, 0.81761006, 0.81761006, 0.81132075,\n",
      "       0.80503145, 0.81132075, 0.81761006, 0.80503145, 0.80503145,\n",
      "       0.81132075, 0.81132075, 0.82389937, 0.81761006, 0.81761006,\n",
      "       0.82389937, 0.81132075, 0.81761006, 0.88679245, 0.87421384,\n",
      "       0.88679245, 0.88050314, 0.87421384, 0.87421384, 0.87421384,\n",
      "       0.8490566 , 0.88050314, 0.88050314, 0.87421384, 0.87421384,\n",
      "       0.85534591, 0.88050314, 0.88679245, 0.89308176, 0.89308176,\n",
      "       0.88050314, 0.88050314, 0.89308176, 0.88679245, 0.88679245,\n",
      "       0.88050314, 0.88679245, 0.88679245, 0.88679245, 0.88679245,\n",
      "       0.88679245, 0.88679245, 0.87421384, 0.88050314, 0.88050314,\n",
      "       0.88050314, 0.89308176, 0.88050314, 0.88050314, 0.87421384,\n",
      "       0.88679245, 0.88050314, 0.88050314, 0.88679245, 0.89308176,\n",
      "       0.89308176, 0.88679245, 0.88679245, 0.88050314, 0.88679245,\n",
      "       0.88050314, 0.87421384, 0.88050314, 0.86792453, 0.88050314,\n",
      "       0.88050314, 0.88679245, 0.87421384, 0.89308176, 0.87421384,\n",
      "       0.88679245, 0.88050314, 0.88679245, 0.88050314, 0.87421384,\n",
      "       0.88679245, 0.87421384, 0.86792453, 0.88050314, 0.88050314,\n",
      "       0.88679245, 0.88050314, 0.88050314, 0.88679245, 0.88050314,\n",
      "       0.88050314, 0.87421384, 0.88679245, 0.87421384, 0.88050314,\n",
      "       0.88050314, 0.88679245, 0.88050314, 0.87421384, 0.86792453,\n",
      "       0.88679245, 0.88050314, 0.87421384, 0.88050314, 0.87421384,\n",
      "       0.88050314, 0.88050314, 0.87421384, 0.87421384, 0.87421384,\n",
      "       0.86792453, 0.88679245, 0.88050314, 0.86792453, 0.87421384,\n",
      "       0.88050314, 0.86792453, 0.89308176, 0.88050314, 0.86792453,\n",
      "       0.88050314, 0.87421384, 0.87421384, 0.88050314, 0.88050314,\n",
      "       0.88050314, 0.88050314, 0.88050314, 0.88679245, 0.8490566 ,\n",
      "       0.8427673 , 0.86163522, 0.87421384, 0.86163522, 0.86792453,\n",
      "       0.86163522, 0.87421384, 0.86163522, 0.86792453, 0.86792453,\n",
      "       0.88679245, 0.88050314, 0.88679245, 0.88050314, 0.88050314,\n",
      "       0.82389937, 0.81761006, 0.83647799, 0.86163522, 0.87421384,\n",
      "       0.83018868, 0.86163522, 0.88050314, 0.88050314, 0.87421384,\n",
      "       0.86792453, 0.86163522, 0.88679245, 0.87421384, 0.87421384,\n",
      "       0.88679245, 0.83018868, 0.81761006, 0.86163522, 0.8427673 ,\n",
      "       0.83647799, 0.8427673 , 0.86792453, 0.85534591, 0.8427673 ,\n",
      "       0.86163522, 0.87421384, 0.87421384, 0.88050314, 0.87421384,\n",
      "       0.88679245, 0.88679245, 0.80503145, 0.79245283, 0.83018868,\n",
      "       0.86163522, 0.82389937, 0.81761006, 0.8490566 , 0.87421384,\n",
      "       0.86163522, 0.86163522, 0.85534591, 0.86792453, 0.88679245,\n",
      "       0.87421384, 0.88679245, 0.88679245, 0.77987421, 0.78616352,\n",
      "       0.83018868, 0.8490566 , 0.81132075, 0.79874214, 0.81761006,\n",
      "       0.83647799, 0.86163522, 0.87421384, 0.86163522, 0.88050314,\n",
      "       0.88679245, 0.87421384, 0.88050314, 0.88050314, 0.79245283,\n",
      "       0.79874214, 0.83018868, 0.8490566 , 0.80503145, 0.7672956 ,\n",
      "       0.8427673 , 0.86792453, 0.8490566 , 0.88679245, 0.86163522,\n",
      "       0.88679245, 0.88679245, 0.88679245, 0.88679245, 0.88050314,\n",
      "       0.76100629, 0.77987421, 0.82389937, 0.83018868, 0.78616352,\n",
      "       0.81132075, 0.86792453, 0.8427673 , 0.8427673 , 0.87421384,\n",
      "       0.87421384, 0.86163522, 0.86792453, 0.88050314, 0.87421384,\n",
      "       0.88050314, 0.76100629, 0.78616352, 0.81132075, 0.85534591,\n",
      "       0.79245283, 0.79874214, 0.78616352, 0.83018868, 0.86792453,\n",
      "       0.85534591, 0.85534591, 0.86792453, 0.87421384, 0.88050314,\n",
      "       0.88679245, 0.88679245, 0.7672956 , 0.79245283, 0.78616352,\n",
      "       0.86792453, 0.80503145, 0.76100629, 0.81132075, 0.8427673 ,\n",
      "       0.87421384, 0.86163522, 0.86163522, 0.87421384, 0.88679245,\n",
      "       0.87421384, 0.88050314, 0.88679245, 0.77987421, 0.78616352,\n",
      "       0.79245283, 0.86163522, 0.79245283, 0.78616352, 0.81132075,\n",
      "       0.8490566 , 0.88050314, 0.86163522, 0.8427673 , 0.8490566 ,\n",
      "       0.88050314, 0.86163522, 0.88679245, 0.88050314, 0.77358491,\n",
      "       0.79874214, 0.81761006, 0.85534591, 0.78616352, 0.79245283,\n",
      "       0.83647799, 0.83647799, 0.8490566 , 0.85534591, 0.8490566 ,\n",
      "       0.86163522, 0.88679245, 0.88050314, 0.87421384, 0.89308176]), 'split2_test_score': array([0.79245283, 0.79245283, 0.79245283, 0.80503145, 0.80503145,\n",
      "       0.81132075, 0.80503145, 0.80503145, 0.81132075, 0.81761006,\n",
      "       0.80503145, 0.79245283, 0.80503145, 0.80503145, 0.81132075,\n",
      "       0.81761006, 0.81132075, 0.82389937, 0.81132075, 0.80503145,\n",
      "       0.81132075, 0.82389937, 0.82389937, 0.81132075, 0.82389937,\n",
      "       0.81761006, 0.81132075, 0.82389937, 0.80503145, 0.80503145,\n",
      "       0.81132075, 0.82389937, 0.80503145, 0.81132075, 0.81761006,\n",
      "       0.81132075, 0.81761006, 0.81761006, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81761006, 0.81132075, 0.81132075, 0.81132075, 0.81761006,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.81761006,\n",
      "       0.81132075, 0.81761006, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81761006, 0.81132075,\n",
      "       0.81761006, 0.81132075, 0.81132075, 0.81132075, 0.81761006,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.82389937, 0.81761006,\n",
      "       0.81132075, 0.81761006, 0.82389937, 0.81761006, 0.81132075,\n",
      "       0.82389937, 0.81132075, 0.81132075, 0.81761006, 0.79245283,\n",
      "       0.81761006, 0.81132075, 0.81132075, 0.81761006, 0.81132075,\n",
      "       0.81761006, 0.79874214, 0.81761006, 0.81761006, 0.81132075,\n",
      "       0.81132075, 0.82389937, 0.82389937, 0.79874214, 0.81132075,\n",
      "       0.79245283, 0.79245283, 0.81761006, 0.80503145, 0.81132075,\n",
      "       0.81761006, 0.82389937, 0.81132075, 0.81761006, 0.81761006,\n",
      "       0.81132075, 0.81761006, 0.82389937, 0.80503145, 0.79245283,\n",
      "       0.79245283, 0.79874214, 0.78616352, 0.79245283, 0.79874214,\n",
      "       0.79874214, 0.79245283, 0.81761006, 0.81761006, 0.81132075,\n",
      "       0.81761006, 0.81132075, 0.81761006, 0.82389937, 0.80503145,\n",
      "       0.81761006, 0.77358491, 0.79874214, 0.81132075, 0.79245283,\n",
      "       0.77987421, 0.81132075, 0.81132075, 0.79874214, 0.79245283,\n",
      "       0.79874214, 0.79874214, 0.81761006, 0.79874214, 0.78616352,\n",
      "       0.77358491, 0.77987421, 0.79245283, 0.7672956 , 0.7672956 ,\n",
      "       0.80503145, 0.78616352, 0.79874214, 0.80503145, 0.77987421,\n",
      "       0.77987421, 0.81132075, 0.81761006, 0.81761006, 0.82389937,\n",
      "       0.77987421, 0.79245283, 0.78616352, 0.77987421, 0.7672956 ,\n",
      "       0.75471698, 0.78616352, 0.7672956 , 0.81132075, 0.81132075,\n",
      "       0.77987421, 0.81132075, 0.82389937, 0.79245283, 0.81132075,\n",
      "       0.81761006, 0.76100629, 0.76100629, 0.75471698, 0.79874214,\n",
      "       0.73584906, 0.72327044, 0.78616352, 0.79245283, 0.79245283,\n",
      "       0.77987421, 0.74213836, 0.79874214, 0.80503145, 0.81761006,\n",
      "       0.81761006, 0.81132075, 0.74842767, 0.75471698, 0.74842767,\n",
      "       0.81132075, 0.74213836, 0.76100629, 0.77358491, 0.79874214,\n",
      "       0.77358491, 0.78616352, 0.77358491, 0.78616352, 0.79245283,\n",
      "       0.77987421, 0.79874214, 0.79245283, 0.75471698, 0.76100629,\n",
      "       0.74842767, 0.76100629, 0.75471698, 0.73584906, 0.76100629,\n",
      "       0.77358491, 0.7672956 , 0.80503145, 0.79245283, 0.81132075,\n",
      "       0.80503145, 0.81761006, 0.81761006, 0.81132075, 0.71698113,\n",
      "       0.74842767, 0.74842767, 0.75471698, 0.72955975, 0.7672956 ,\n",
      "       0.74213836, 0.78616352, 0.77987421, 0.75471698, 0.77358491,\n",
      "       0.79245283, 0.81132075, 0.80503145, 0.80503145, 0.81761006,\n",
      "       0.72955975, 0.74213836, 0.74213836, 0.7672956 , 0.74213836,\n",
      "       0.73584906, 0.74842767, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.7672956 , 0.7672956 , 0.80503145, 0.79245283, 0.79874214,\n",
      "       0.79245283, 0.72327044, 0.72327044, 0.73584906, 0.78616352,\n",
      "       0.74842767, 0.74842767, 0.70440252, 0.77358491, 0.77358491,\n",
      "       0.78616352, 0.77358491, 0.78616352, 0.80503145, 0.79874214,\n",
      "       0.81132075, 0.79874214, 0.71698113, 0.72955975, 0.74842767,\n",
      "       0.75471698, 0.74213836, 0.73584906, 0.77358491, 0.77358491,\n",
      "       0.79874214, 0.77358491, 0.77987421, 0.78616352, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.81132075, 0.73584906, 0.74213836,\n",
      "       0.76100629, 0.7672956 , 0.75471698, 0.74213836, 0.72955975,\n",
      "       0.78616352, 0.7672956 , 0.79245283, 0.79245283, 0.7672956 ,\n",
      "       0.81761006, 0.79874214, 0.81761006, 0.79245283, 0.72327044,\n",
      "       0.74213836, 0.75471698, 0.78616352, 0.74842767, 0.72327044,\n",
      "       0.77987421, 0.75471698, 0.7672956 , 0.79245283, 0.7672956 ,\n",
      "       0.80503145, 0.79874214, 0.79874214, 0.81761006, 0.81132075]), 'split3_test_score': array([0.79245283, 0.78616352, 0.77987421, 0.79874214, 0.79245283,\n",
      "       0.79245283, 0.79245283, 0.79245283, 0.78616352, 0.79245283,\n",
      "       0.78616352, 0.77358491, 0.77987421, 0.77358491, 0.79245283,\n",
      "       0.79245283, 0.79245283, 0.77987421, 0.77358491, 0.79245283,\n",
      "       0.78616352, 0.79245283, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.77987421, 0.78616352, 0.78616352, 0.79245283,\n",
      "       0.77987421, 0.77987421, 0.81132075, 0.81132075, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.81761006, 0.80503145, 0.80503145,\n",
      "       0.81132075, 0.79874214, 0.80503145, 0.79874214, 0.79245283,\n",
      "       0.81132075, 0.79245283, 0.78616352, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.80503145, 0.80503145, 0.81761006,\n",
      "       0.81761006, 0.81132075, 0.81132075, 0.81761006, 0.80503145,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.80503145, 0.81132075,\n",
      "       0.81761006, 0.80503145, 0.81132075, 0.80503145, 0.81132075,\n",
      "       0.81132075, 0.81761006, 0.80503145, 0.80503145, 0.81132075,\n",
      "       0.81132075, 0.81761006, 0.81132075, 0.80503145, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.80503145, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.80503145, 0.81761006, 0.81132075,\n",
      "       0.81761006, 0.80503145, 0.81132075, 0.81132075, 0.80503145,\n",
      "       0.80503145, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81761006, 0.81132075, 0.81132075,\n",
      "       0.80503145, 0.80503145, 0.81132075, 0.81132075, 0.80503145,\n",
      "       0.81761006, 0.80503145, 0.81761006, 0.79874214, 0.81761006,\n",
      "       0.79245283, 0.79874214, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81132075, 0.80503145,\n",
      "       0.80503145, 0.81132075, 0.81132075, 0.78616352, 0.80503145,\n",
      "       0.81132075, 0.80503145, 0.80503145, 0.80503145, 0.79874214,\n",
      "       0.81761006, 0.80503145, 0.81132075, 0.81761006, 0.81761006,\n",
      "       0.79245283, 0.81132075, 0.81132075, 0.81132075, 0.78616352,\n",
      "       0.81132075, 0.79874214, 0.81761006, 0.81132075, 0.79874214,\n",
      "       0.77987421, 0.79245283, 0.79874214, 0.80503145, 0.78616352,\n",
      "       0.79874214, 0.81132075, 0.81132075, 0.81132075, 0.80503145,\n",
      "       0.78616352, 0.79245283, 0.78616352, 0.81132075, 0.79245283,\n",
      "       0.80503145, 0.79874214, 0.79245283, 0.79874214, 0.79245283,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.80503145, 0.78616352, 0.78616352, 0.80503145,\n",
      "       0.81761006, 0.79245283, 0.83647799, 0.81132075, 0.79245283,\n",
      "       0.79245283, 0.78616352, 0.82389937, 0.80503145, 0.80503145,\n",
      "       0.81761006, 0.81132075, 0.77358491, 0.80503145, 0.79245283,\n",
      "       0.79874214, 0.79874214, 0.80503145, 0.81132075, 0.79874214,\n",
      "       0.81132075, 0.81761006, 0.79245283, 0.81132075, 0.81132075,\n",
      "       0.79245283, 0.80503145, 0.79245283, 0.77358491, 0.79245283,\n",
      "       0.79874214, 0.79245283, 0.81132075, 0.80503145, 0.78616352,\n",
      "       0.79874214, 0.79874214, 0.80503145, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81132075, 0.80503145, 0.81132075, 0.77987421,\n",
      "       0.79245283, 0.79874214, 0.82389937, 0.80503145, 0.77987421,\n",
      "       0.79874214, 0.81761006, 0.82389937, 0.79245283, 0.77987421,\n",
      "       0.80503145, 0.80503145, 0.81132075, 0.81132075, 0.81761006,\n",
      "       0.7672956 , 0.78616352, 0.79874214, 0.81761006, 0.79874214,\n",
      "       0.79245283, 0.79245283, 0.83018868, 0.79245283, 0.81132075,\n",
      "       0.81761006, 0.7672956 , 0.79245283, 0.80503145, 0.81761006,\n",
      "       0.81132075, 0.77987421, 0.79245283, 0.82389937, 0.81761006,\n",
      "       0.82389937, 0.78616352, 0.80503145, 0.79874214, 0.79245283,\n",
      "       0.81761006, 0.79874214, 0.80503145, 0.79874214, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.77358491, 0.78616352, 0.81132075,\n",
      "       0.78616352, 0.78616352, 0.77987421, 0.79874214, 0.80503145,\n",
      "       0.80503145, 0.81132075, 0.78616352, 0.81132075, 0.80503145,\n",
      "       0.80503145, 0.81132075, 0.81132075, 0.79245283, 0.77987421,\n",
      "       0.76100629, 0.79874214, 0.81132075, 0.76100629, 0.78616352,\n",
      "       0.80503145, 0.79245283, 0.81761006, 0.82389937, 0.79874214,\n",
      "       0.80503145, 0.81761006, 0.81132075, 0.79245283, 0.77987421,\n",
      "       0.77358491, 0.76100629, 0.81761006, 0.79874214, 0.78616352,\n",
      "       0.80503145, 0.81132075, 0.81132075, 0.78616352, 0.77358491,\n",
      "       0.79245283, 0.81132075, 0.81132075, 0.81132075, 0.80503145]), 'split4_test_score': array([0.73584906, 0.72955975, 0.72955975, 0.69811321, 0.72955975,\n",
      "       0.72955975, 0.72955975, 0.72955975, 0.72955975, 0.72955975,\n",
      "       0.72327044, 0.72955975, 0.72955975, 0.72955975, 0.72327044,\n",
      "       0.72955975, 0.72327044, 0.72327044, 0.72327044, 0.73584906,\n",
      "       0.72327044, 0.72327044, 0.76100629, 0.73584906, 0.73584906,\n",
      "       0.74213836, 0.73584906, 0.72327044, 0.74213836, 0.72327044,\n",
      "       0.72327044, 0.74213836, 0.77987421, 0.76100629, 0.77358491,\n",
      "       0.76100629, 0.76100629, 0.7672956 , 0.77987421, 0.77987421,\n",
      "       0.78616352, 0.74842767, 0.76100629, 0.74213836, 0.76100629,\n",
      "       0.76100629, 0.77987421, 0.77358491, 0.78616352, 0.78616352,\n",
      "       0.77987421, 0.78616352, 0.78616352, 0.77987421, 0.77987421,\n",
      "       0.78616352, 0.77987421, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.77987421, 0.77987421, 0.78616352, 0.77987421, 0.78616352,\n",
      "       0.78616352, 0.77987421, 0.78616352, 0.79874214, 0.77987421,\n",
      "       0.77987421, 0.77987421, 0.77987421, 0.79245283, 0.79245283,\n",
      "       0.78616352, 0.79245283, 0.79245283, 0.77987421, 0.78616352,\n",
      "       0.77987421, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.77987421, 0.78616352, 0.78616352, 0.77987421, 0.78616352,\n",
      "       0.78616352, 0.79874214, 0.79245283, 0.77987421, 0.78616352,\n",
      "       0.79245283, 0.78616352, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.79245283, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.78616352, 0.78616352, 0.79245283,\n",
      "       0.78616352, 0.77987421, 0.79245283, 0.77987421, 0.79245283,\n",
      "       0.77987421, 0.77358491, 0.7672956 , 0.77358491, 0.78616352,\n",
      "       0.78616352, 0.77987421, 0.78616352, 0.81132075, 0.80503145,\n",
      "       0.78616352, 0.77987421, 0.78616352, 0.80503145, 0.79874214,\n",
      "       0.79245283, 0.77358491, 0.77987421, 0.77987421, 0.78616352,\n",
      "       0.79245283, 0.78616352, 0.78616352, 0.78616352, 0.79874214,\n",
      "       0.79245283, 0.78616352, 0.78616352, 0.80503145, 0.77987421,\n",
      "       0.7672956 , 0.80503145, 0.78616352, 0.79245283, 0.77358491,\n",
      "       0.78616352, 0.77987421, 0.77358491, 0.78616352, 0.77987421,\n",
      "       0.77358491, 0.79245283, 0.78616352, 0.77358491, 0.7672956 ,\n",
      "       0.7672956 , 0.77987421, 0.77987421, 0.77987421, 0.78616352,\n",
      "       0.79245283, 0.77987421, 0.77987421, 0.78616352, 0.78616352,\n",
      "       0.76100629, 0.77987421, 0.80503145, 0.76100629, 0.7672956 ,\n",
      "       0.76100629, 0.79874214, 0.77987421, 0.78616352, 0.76100629,\n",
      "       0.77987421, 0.77358491, 0.77987421, 0.77987421, 0.79245283,\n",
      "       0.78616352, 0.78616352, 0.77987421, 0.7672956 , 0.78616352,\n",
      "       0.77987421, 0.77987421, 0.79874214, 0.79874214, 0.77987421,\n",
      "       0.78616352, 0.7672956 , 0.78616352, 0.7672956 , 0.78616352,\n",
      "       0.79245283, 0.78616352, 0.77987421, 0.76100629, 0.79245283,\n",
      "       0.77987421, 0.77358491, 0.7672956 , 0.78616352, 0.7672956 ,\n",
      "       0.7672956 , 0.77987421, 0.77987421, 0.77358491, 0.78616352,\n",
      "       0.77987421, 0.77987421, 0.79245283, 0.78616352, 0.75471698,\n",
      "       0.77358491, 0.76100629, 0.77987421, 0.74842767, 0.78616352,\n",
      "       0.74842767, 0.75471698, 0.78616352, 0.77987421, 0.78616352,\n",
      "       0.77987421, 0.79245283, 0.78616352, 0.79245283, 0.78616352,\n",
      "       0.79245283, 0.73584906, 0.73584906, 0.77987421, 0.79874214,\n",
      "       0.82389937, 0.76100629, 0.77987421, 0.74213836, 0.77358491,\n",
      "       0.79245283, 0.7672956 , 0.77358491, 0.79245283, 0.77358491,\n",
      "       0.78616352, 0.75471698, 0.76100629, 0.76100629, 0.79245283,\n",
      "       0.7672956 , 0.7672956 , 0.7672956 , 0.77987421, 0.78616352,\n",
      "       0.77987421, 0.78616352, 0.77987421, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.74842767, 0.79245283, 0.79245283,\n",
      "       0.77358491, 0.76100629, 0.80503145, 0.79245283, 0.77358491,\n",
      "       0.77358491, 0.78616352, 0.76100629, 0.78616352, 0.78616352,\n",
      "       0.79245283, 0.77987421, 0.78616352, 0.75471698, 0.78616352,\n",
      "       0.7672956 , 0.77358491, 0.77358491, 0.76100629, 0.79245283,\n",
      "       0.77987421, 0.7672956 , 0.77987421, 0.77358491, 0.78616352,\n",
      "       0.77987421, 0.77987421, 0.78616352, 0.78616352, 0.76100629,\n",
      "       0.77358491, 0.77987421, 0.76100629, 0.74842767, 0.79245283,\n",
      "       0.7672956 , 0.77987421, 0.7672956 , 0.78616352, 0.77987421,\n",
      "       0.77358491, 0.78616352, 0.77358491, 0.77358491, 0.78616352]), 'split5_test_score': array([0.74213836, 0.74213836, 0.72955975, 0.74213836, 0.73584906,\n",
      "       0.74213836, 0.73584906, 0.74213836, 0.71698113, 0.74213836,\n",
      "       0.74213836, 0.73584906, 0.74842767, 0.74213836, 0.74213836,\n",
      "       0.74213836, 0.74842767, 0.74842767, 0.74213836, 0.74213836,\n",
      "       0.74842767, 0.73584906, 0.74842767, 0.76100629, 0.74842767,\n",
      "       0.74213836, 0.75471698, 0.75471698, 0.73584906, 0.75471698,\n",
      "       0.74842767, 0.75471698, 0.79874214, 0.78616352, 0.78616352,\n",
      "       0.79874214, 0.79245283, 0.79874214, 0.79874214, 0.75471698,\n",
      "       0.79245283, 0.79245283, 0.79874214, 0.79245283, 0.77358491,\n",
      "       0.77987421, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.81761006, 0.81132075, 0.82389937, 0.82389937, 0.80503145,\n",
      "       0.80503145, 0.81761006, 0.82389937, 0.80503145, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81761006, 0.79874214, 0.82389937,\n",
      "       0.83018868, 0.82389937, 0.80503145, 0.81132075, 0.82389937,\n",
      "       0.81761006, 0.83018868, 0.80503145, 0.81761006, 0.81132075,\n",
      "       0.81761006, 0.81761006, 0.81132075, 0.81132075, 0.81761006,\n",
      "       0.83018868, 0.83018868, 0.83018868, 0.82389937, 0.81761006,\n",
      "       0.83018868, 0.83018868, 0.82389937, 0.82389937, 0.81132075,\n",
      "       0.81132075, 0.81761006, 0.81132075, 0.81132075, 0.82389937,\n",
      "       0.81132075, 0.83018868, 0.81761006, 0.83647799, 0.82389937,\n",
      "       0.83018868, 0.82389937, 0.82389937, 0.81761006, 0.82389937,\n",
      "       0.81132075, 0.81132075, 0.79874214, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.80503145, 0.81132075, 0.81761006,\n",
      "       0.81761006, 0.80503145, 0.82389937, 0.81132075, 0.80503145,\n",
      "       0.81761006, 0.81761006, 0.82389937, 0.81761006, 0.81761006,\n",
      "       0.81132075, 0.81761006, 0.81761006, 0.77358491, 0.79874214,\n",
      "       0.81132075, 0.77987421, 0.80503145, 0.83018868, 0.79874214,\n",
      "       0.83647799, 0.79874214, 0.82389937, 0.81132075, 0.78616352,\n",
      "       0.81132075, 0.81761006, 0.79874214, 0.79874214, 0.78616352,\n",
      "       0.79874214, 0.77987421, 0.79874214, 0.79245283, 0.77358491,\n",
      "       0.79874214, 0.79874214, 0.81132075, 0.81132075, 0.79874214,\n",
      "       0.79874214, 0.81132075, 0.82389937, 0.80503145, 0.81132075,\n",
      "       0.77358491, 0.79245283, 0.79245283, 0.79874214, 0.81132075,\n",
      "       0.78616352, 0.77987421, 0.79874214, 0.78616352, 0.78616352,\n",
      "       0.79874214, 0.80503145, 0.81132075, 0.81132075, 0.80503145,\n",
      "       0.81132075, 0.75471698, 0.78616352, 0.78616352, 0.79245283,\n",
      "       0.77358491, 0.78616352, 0.7672956 , 0.79245283, 0.81761006,\n",
      "       0.78616352, 0.79874214, 0.79874214, 0.79245283, 0.81132075,\n",
      "       0.81761006, 0.81132075, 0.76100629, 0.74842767, 0.77987421,\n",
      "       0.78616352, 0.77358491, 0.75471698, 0.78616352, 0.79874214,\n",
      "       0.77987421, 0.81132075, 0.77358491, 0.79245283, 0.81132075,\n",
      "       0.79874214, 0.81132075, 0.81132075, 0.75471698, 0.74842767,\n",
      "       0.7672956 , 0.79874214, 0.73584906, 0.79245283, 0.77358491,\n",
      "       0.80503145, 0.79245283, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79245283, 0.81761006, 0.81132075, 0.81132075, 0.72955975,\n",
      "       0.73584906, 0.77358491, 0.79874214, 0.75471698, 0.74842767,\n",
      "       0.77987421, 0.79245283, 0.77987421, 0.7672956 , 0.77987421,\n",
      "       0.79874214, 0.81761006, 0.80503145, 0.82389937, 0.79874214,\n",
      "       0.71069182, 0.72327044, 0.75471698, 0.81132075, 0.75471698,\n",
      "       0.74213836, 0.76100629, 0.80503145, 0.77358491, 0.74213836,\n",
      "       0.78616352, 0.82389937, 0.79874214, 0.81132075, 0.81132075,\n",
      "       0.80503145, 0.6918239 , 0.74842767, 0.74213836, 0.80503145,\n",
      "       0.74842767, 0.74213836, 0.77358491, 0.78616352, 0.78616352,\n",
      "       0.75471698, 0.77987421, 0.79874214, 0.81132075, 0.79874214,\n",
      "       0.80503145, 0.78616352, 0.71698113, 0.74213836, 0.77358491,\n",
      "       0.79874214, 0.76100629, 0.7672956 , 0.77358491, 0.78616352,\n",
      "       0.78616352, 0.77358491, 0.79245283, 0.82389937, 0.80503145,\n",
      "       0.81761006, 0.82389937, 0.81761006, 0.73584906, 0.71698113,\n",
      "       0.77987421, 0.77358491, 0.7672956 , 0.74213836, 0.74213836,\n",
      "       0.77358491, 0.79874214, 0.76100629, 0.79245283, 0.78616352,\n",
      "       0.81761006, 0.80503145, 0.81132075, 0.79245283, 0.71698113,\n",
      "       0.74213836, 0.77358491, 0.77987421, 0.72327044, 0.7672956 ,\n",
      "       0.77358491, 0.79874214, 0.80503145, 0.77987421, 0.77358491,\n",
      "       0.79874214, 0.81761006, 0.80503145, 0.80503145, 0.81132075]), 'split6_test_score': array([0.79245283, 0.79245283, 0.7672956 , 0.79245283, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.77358491, 0.75471698, 0.77987421,\n",
      "       0.78616352, 0.7672956 , 0.79245283, 0.77358491, 0.78616352,\n",
      "       0.78616352, 0.79874214, 0.83647799, 0.79874214, 0.78616352,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.81132075, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.79874214, 0.80503145, 0.80503145,\n",
      "       0.79874214, 0.79874214, 0.83647799, 0.83647799, 0.80503145,\n",
      "       0.83647799, 0.8427673 , 0.81132075, 0.8427673 , 0.83647799,\n",
      "       0.83018868, 0.83647799, 0.83647799, 0.81761006, 0.81132075,\n",
      "       0.83018868, 0.83018868, 0.83647799, 0.8427673 , 0.83647799,\n",
      "       0.83018868, 0.83647799, 0.8427673 , 0.8427673 , 0.83647799,\n",
      "       0.8427673 , 0.83647799, 0.8427673 , 0.83018868, 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.83647799, 0.8427673 , 0.8490566 ,\n",
      "       0.83647799, 0.83647799, 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.83647799, 0.8427673 , 0.8427673 , 0.83647799, 0.83647799,\n",
      "       0.8427673 , 0.83647799, 0.83018868, 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.83647799, 0.83647799, 0.83647799,\n",
      "       0.83647799, 0.8427673 , 0.83647799, 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.83647799, 0.8427673 , 0.83647799,\n",
      "       0.83647799, 0.85534591, 0.83647799, 0.83647799, 0.8427673 ,\n",
      "       0.83647799, 0.8427673 , 0.8427673 , 0.83647799, 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.83647799, 0.83647799, 0.83018868, 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.83647799, 0.83647799, 0.8427673 , 0.8427673 ,\n",
      "       0.83018868, 0.83647799, 0.8427673 , 0.83647799, 0.83647799,\n",
      "       0.8427673 , 0.8427673 , 0.83647799, 0.83647799, 0.83647799,\n",
      "       0.8427673 , 0.82389937, 0.8490566 , 0.8427673 , 0.83018868,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.83647799, 0.83647799,\n",
      "       0.8427673 , 0.8427673 , 0.83647799, 0.8427673 , 0.81761006,\n",
      "       0.85534591, 0.81132075, 0.83647799, 0.83647799, 0.82389937,\n",
      "       0.8490566 , 0.8427673 , 0.8427673 , 0.8427673 , 0.83647799,\n",
      "       0.83647799, 0.83647799, 0.83647799, 0.8427673 , 0.8490566 ,\n",
      "       0.79874214, 0.82389937, 0.83647799, 0.83018868, 0.83018868,\n",
      "       0.83018868, 0.83018868, 0.83018868, 0.83647799, 0.85534591,\n",
      "       0.8490566 , 0.83647799, 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.82389937, 0.81761006, 0.8427673 , 0.85534591,\n",
      "       0.83018868, 0.83647799, 0.83647799, 0.83018868, 0.81132075,\n",
      "       0.8490566 , 0.83647799, 0.8427673 , 0.83018868, 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.79874214, 0.85534591, 0.81761006,\n",
      "       0.83647799, 0.83018868, 0.81132075, 0.8427673 , 0.81761006,\n",
      "       0.83018868, 0.82389937, 0.85534591, 0.8427673 , 0.83647799,\n",
      "       0.83647799, 0.8427673 , 0.8490566 , 0.79245283, 0.81132075,\n",
      "       0.80503145, 0.83018868, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.83647799, 0.8427673 , 0.83018868, 0.83018868, 0.8427673 ,\n",
      "       0.8427673 , 0.83647799, 0.83018868, 0.82389937, 0.78616352,\n",
      "       0.79874214, 0.81761006, 0.81132075, 0.79245283, 0.81761006,\n",
      "       0.82389937, 0.83018868, 0.83647799, 0.81761006, 0.85534591,\n",
      "       0.8427673 , 0.83647799, 0.8490566 , 0.8427673 , 0.81761006,\n",
      "       0.78616352, 0.80503145, 0.80503145, 0.83647799, 0.80503145,\n",
      "       0.79874214, 0.83018868, 0.81761006, 0.83018868, 0.82389937,\n",
      "       0.8490566 , 0.82389937, 0.83647799, 0.8427673 , 0.83647799,\n",
      "       0.83018868, 0.77358491, 0.79874214, 0.81761006, 0.83647799,\n",
      "       0.80503145, 0.79245283, 0.8490566 , 0.8427673 , 0.83018868,\n",
      "       0.82389937, 0.8427673 , 0.8490566 , 0.83018868, 0.83647799,\n",
      "       0.8427673 , 0.8427673 , 0.79245283, 0.81761006, 0.83647799,\n",
      "       0.82389937, 0.79874214, 0.81761006, 0.80503145, 0.82389937,\n",
      "       0.83647799, 0.83018868, 0.83647799, 0.83647799, 0.8427673 ,\n",
      "       0.82389937, 0.83018868, 0.83647799, 0.79245283, 0.79874214,\n",
      "       0.83647799, 0.83018868, 0.82389937, 0.82389937, 0.81761006,\n",
      "       0.85534591, 0.8427673 , 0.8490566 , 0.82389937, 0.8427673 ,\n",
      "       0.8427673 , 0.83018868, 0.83018868, 0.8427673 , 0.77358491,\n",
      "       0.79245283, 0.81761006, 0.82389937, 0.82389937, 0.81761006,\n",
      "       0.79245283, 0.83647799, 0.83018868, 0.81761006, 0.82389937,\n",
      "       0.83647799, 0.81761006, 0.8490566 , 0.83647799, 0.83647799]), 'split7_test_score': array([0.76100629, 0.74842767, 0.76100629, 0.74842767, 0.74842767,\n",
      "       0.77358491, 0.76100629, 0.74842767, 0.76100629, 0.76100629,\n",
      "       0.76100629, 0.74842767, 0.76100629, 0.76100629, 0.76100629,\n",
      "       0.76100629, 0.76100629, 0.76100629, 0.77358491, 0.77358491,\n",
      "       0.79245283, 0.77358491, 0.77987421, 0.80503145, 0.77987421,\n",
      "       0.77987421, 0.7672956 , 0.77358491, 0.77987421, 0.77358491,\n",
      "       0.7672956 , 0.7672956 , 0.80503145, 0.81132075, 0.81132075,\n",
      "       0.79245283, 0.81132075, 0.79245283, 0.79874214, 0.79874214,\n",
      "       0.81132075, 0.81132075, 0.77987421, 0.79874214, 0.80503145,\n",
      "       0.79874214, 0.80503145, 0.77358491, 0.81761006, 0.81132075,\n",
      "       0.81132075, 0.80503145, 0.81761006, 0.81132075, 0.80503145,\n",
      "       0.81132075, 0.81132075, 0.81761006, 0.81132075, 0.79874214,\n",
      "       0.80503145, 0.80503145, 0.79245283, 0.80503145, 0.81761006,\n",
      "       0.82389937, 0.82389937, 0.81132075, 0.81132075, 0.82389937,\n",
      "       0.81761006, 0.81132075, 0.81132075, 0.81761006, 0.81132075,\n",
      "       0.81132075, 0.81761006, 0.81761006, 0.81132075, 0.79874214,\n",
      "       0.81761006, 0.81132075, 0.82389937, 0.81761006, 0.82389937,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.80503145, 0.80503145, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81761006, 0.82389937, 0.82389937, 0.81761006,\n",
      "       0.81761006, 0.82389937, 0.82389937, 0.81761006, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.80503145, 0.80503145, 0.81132075,\n",
      "       0.80503145, 0.80503145, 0.81761006, 0.82389937, 0.82389937,\n",
      "       0.82389937, 0.80503145, 0.81761006, 0.82389937, 0.81761006,\n",
      "       0.80503145, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81761006, 0.81761006, 0.79245283, 0.80503145, 0.81761006,\n",
      "       0.81761006, 0.83018868, 0.82389937, 0.81761006, 0.82389937,\n",
      "       0.81761006, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.82389937,\n",
      "       0.81761006, 0.81761006, 0.81761006, 0.81132075, 0.78616352,\n",
      "       0.81761006, 0.80503145, 0.80503145, 0.81132075, 0.80503145,\n",
      "       0.78616352, 0.80503145, 0.80503145, 0.81132075, 0.81132075,\n",
      "       0.78616352, 0.80503145, 0.81132075, 0.81761006, 0.80503145,\n",
      "       0.80503145, 0.82389937, 0.82389937, 0.79874214, 0.80503145,\n",
      "       0.81132075, 0.78616352, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.79245283, 0.76100629, 0.79874214, 0.81132075, 0.81132075,\n",
      "       0.81761006, 0.79245283, 0.77987421, 0.82389937, 0.79245283,\n",
      "       0.80503145, 0.81761006, 0.79874214, 0.81132075, 0.81132075,\n",
      "       0.79245283, 0.79874214, 0.77987421, 0.80503145, 0.81132075,\n",
      "       0.81132075, 0.79874214, 0.81761006, 0.80503145, 0.81132075,\n",
      "       0.79874214, 0.81761006, 0.80503145, 0.81761006, 0.81132075,\n",
      "       0.81132075, 0.79245283, 0.81132075, 0.76100629, 0.79874214,\n",
      "       0.81761006, 0.81132075, 0.79874214, 0.77987421, 0.78616352,\n",
      "       0.78616352, 0.81132075, 0.81761006, 0.80503145, 0.81761006,\n",
      "       0.80503145, 0.80503145, 0.81132075, 0.81132075, 0.7672956 ,\n",
      "       0.79245283, 0.79245283, 0.81761006, 0.80503145, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.80503145, 0.79245283, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.81132075, 0.80503145, 0.81761006,\n",
      "       0.77358491, 0.81761006, 0.81132075, 0.78616352, 0.82389937,\n",
      "       0.81761006, 0.79245283, 0.80503145, 0.79245283, 0.81132075,\n",
      "       0.77358491, 0.81132075, 0.80503145, 0.80503145, 0.81132075,\n",
      "       0.80503145, 0.77987421, 0.79874214, 0.79874214, 0.83018868,\n",
      "       0.81132075, 0.79245283, 0.81132075, 0.80503145, 0.78616352,\n",
      "       0.81132075, 0.80503145, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.80503145, 0.79245283, 0.76100629, 0.76100629, 0.79245283,\n",
      "       0.80503145, 0.81132075, 0.79874214, 0.80503145, 0.79874214,\n",
      "       0.81132075, 0.79874214, 0.81132075, 0.81761006, 0.79874214,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.77987421, 0.79245283,\n",
      "       0.77358491, 0.81761006, 0.78616352, 0.77358491, 0.79245283,\n",
      "       0.81132075, 0.79245283, 0.77987421, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.80503145, 0.81132075, 0.80503145, 0.76100629,\n",
      "       0.80503145, 0.7672956 , 0.81132075, 0.80503145, 0.77987421,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.80503145, 0.79874214,\n",
      "       0.81132075, 0.80503145, 0.80503145, 0.79874214, 0.81132075]), 'split8_test_score': array([0.75471698, 0.71698113, 0.75471698, 0.75471698, 0.74842767,\n",
      "       0.75471698, 0.75471698, 0.75471698, 0.74842767, 0.75471698,\n",
      "       0.75471698, 0.75471698, 0.76100629, 0.75471698, 0.75471698,\n",
      "       0.75471698, 0.75471698, 0.75471698, 0.76100629, 0.75471698,\n",
      "       0.75471698, 0.77987421, 0.75471698, 0.77987421, 0.75471698,\n",
      "       0.74842767, 0.75471698, 0.75471698, 0.75471698, 0.77358491,\n",
      "       0.75471698, 0.75471698, 0.77987421, 0.79874214, 0.82389937,\n",
      "       0.81132075, 0.79245283, 0.7672956 , 0.76100629, 0.81132075,\n",
      "       0.83647799, 0.81761006, 0.7672956 , 0.79874214, 0.79245283,\n",
      "       0.78616352, 0.82389937, 0.77987421, 0.83018868, 0.8427673 ,\n",
      "       0.78616352, 0.82389937, 0.83018868, 0.80503145, 0.83018868,\n",
      "       0.83018868, 0.83647799, 0.83647799, 0.82389937, 0.83018868,\n",
      "       0.81761006, 0.83018868, 0.8427673 , 0.83018868, 0.83018868,\n",
      "       0.8490566 , 0.81761006, 0.82389937, 0.82389937, 0.82389937,\n",
      "       0.83647799, 0.81132075, 0.83647799, 0.83647799, 0.83647799,\n",
      "       0.83647799, 0.80503145, 0.83647799, 0.83018868, 0.83647799,\n",
      "       0.83647799, 0.83647799, 0.8427673 , 0.8427673 , 0.8490566 ,\n",
      "       0.8427673 , 0.8490566 , 0.8490566 , 0.8427673 , 0.83018868,\n",
      "       0.8427673 , 0.8490566 , 0.83647799, 0.83647799, 0.8427673 ,\n",
      "       0.8490566 , 0.83647799, 0.8490566 , 0.8427673 , 0.83647799,\n",
      "       0.8427673 , 0.8490566 , 0.8427673 , 0.8427673 , 0.8490566 ,\n",
      "       0.8427673 , 0.8427673 , 0.8490566 , 0.8427673 , 0.8427673 ,\n",
      "       0.83647799, 0.8427673 , 0.8490566 , 0.83018868, 0.8427673 ,\n",
      "       0.83647799, 0.8490566 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.8490566 , 0.8490566 , 0.8427673 , 0.83647799, 0.81132075,\n",
      "       0.8490566 , 0.85534591, 0.8490566 , 0.82389937, 0.81761006,\n",
      "       0.83647799, 0.83647799, 0.8490566 , 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.83647799, 0.8427673 , 0.8427673 , 0.83647799,\n",
      "       0.8427673 , 0.80503145, 0.8490566 , 0.8427673 , 0.83018868,\n",
      "       0.83018868, 0.80503145, 0.83018868, 0.8427673 , 0.82389937,\n",
      "       0.83647799, 0.83018868, 0.8427673 , 0.83018868, 0.8427673 ,\n",
      "       0.83647799, 0.83647799, 0.83647799, 0.83647799, 0.8490566 ,\n",
      "       0.83018868, 0.83018868, 0.83018868, 0.82389937, 0.83018868,\n",
      "       0.81761006, 0.83647799, 0.8427673 , 0.8427673 , 0.82389937,\n",
      "       0.8427673 , 0.8427673 , 0.83647799, 0.8490566 , 0.83647799,\n",
      "       0.8490566 , 0.81761006, 0.81132075, 0.81761006, 0.82389937,\n",
      "       0.81761006, 0.82389937, 0.82389937, 0.83647799, 0.8427673 ,\n",
      "       0.83018868, 0.80503145, 0.82389937, 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.83018868, 0.81132075, 0.83647799, 0.80503145,\n",
      "       0.83647799, 0.83018868, 0.82389937, 0.83647799, 0.83018868,\n",
      "       0.82389937, 0.83018868, 0.82389937, 0.83647799, 0.8490566 ,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.81761006, 0.80503145,\n",
      "       0.81132075, 0.82389937, 0.83647799, 0.82389937, 0.8427673 ,\n",
      "       0.81761006, 0.83647799, 0.82389937, 0.82389937, 0.83647799,\n",
      "       0.83647799, 0.8427673 , 0.8490566 , 0.83647799, 0.79245283,\n",
      "       0.82389937, 0.81132075, 0.83018868, 0.83018868, 0.81761006,\n",
      "       0.81761006, 0.83647799, 0.83018868, 0.81761006, 0.8490566 ,\n",
      "       0.8427673 , 0.8427673 , 0.82389937, 0.8490566 , 0.83018868,\n",
      "       0.77358491, 0.83647799, 0.80503145, 0.82389937, 0.83647799,\n",
      "       0.83647799, 0.85534591, 0.81132075, 0.83018868, 0.83018868,\n",
      "       0.83018868, 0.8427673 , 0.83647799, 0.85534591, 0.8427673 ,\n",
      "       0.8427673 , 0.79245283, 0.81132075, 0.79874214, 0.80503145,\n",
      "       0.80503145, 0.82389937, 0.83018868, 0.83018868, 0.83018868,\n",
      "       0.83647799, 0.8427673 , 0.83018868, 0.8490566 , 0.8490566 ,\n",
      "       0.85534591, 0.83647799, 0.77358491, 0.80503145, 0.83018868,\n",
      "       0.83647799, 0.80503145, 0.80503145, 0.83018868, 0.81132075,\n",
      "       0.8490566 , 0.81761006, 0.83647799, 0.82389937, 0.8490566 ,\n",
      "       0.8490566 , 0.83647799, 0.82389937, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.81761006, 0.79874214, 0.83018868, 0.8427673 ,\n",
      "       0.81761006, 0.83018868, 0.83018868, 0.83018868, 0.8427673 ,\n",
      "       0.8490566 , 0.8427673 , 0.8490566 , 0.8490566 , 0.79874214,\n",
      "       0.81761006, 0.83647799, 0.81761006, 0.81761006, 0.83018868,\n",
      "       0.82389937, 0.8490566 , 0.83647799, 0.8427673 , 0.82389937,\n",
      "       0.83647799, 0.83647799, 0.8427673 , 0.8490566 , 0.83018868]), 'split9_test_score': array([0.76582278, 0.7721519 , 0.7721519 , 0.7721519 , 0.76582278,\n",
      "       0.76582278, 0.76582278, 0.7721519 , 0.7721519 , 0.7721519 ,\n",
      "       0.7721519 , 0.76582278, 0.76582278, 0.7721519 , 0.76582278,\n",
      "       0.7721519 , 0.78481013, 0.7721519 , 0.81012658, 0.76582278,\n",
      "       0.78481013, 0.77848101, 0.7721519 , 0.7721519 , 0.7721519 ,\n",
      "       0.77848101, 0.79113924, 0.77848101, 0.78481013, 0.7721519 ,\n",
      "       0.7721519 , 0.7721519 , 0.84810127, 0.8164557 , 0.82911392,\n",
      "       0.84177215, 0.84810127, 0.77848101, 0.83544304, 0.84810127,\n",
      "       0.84177215, 0.83544304, 0.84810127, 0.84810127, 0.83544304,\n",
      "       0.82911392, 0.83544304, 0.82278481, 0.86075949, 0.86075949,\n",
      "       0.84810127, 0.84810127, 0.84810127, 0.84810127, 0.85443038,\n",
      "       0.85443038, 0.85443038, 0.85443038, 0.84810127, 0.85443038,\n",
      "       0.84810127, 0.84810127, 0.84810127, 0.85443038, 0.85443038,\n",
      "       0.86075949, 0.84810127, 0.85443038, 0.86075949, 0.86075949,\n",
      "       0.86075949, 0.84810127, 0.86075949, 0.84810127, 0.84810127,\n",
      "       0.84177215, 0.85443038, 0.86075949, 0.84810127, 0.86075949,\n",
      "       0.86075949, 0.85443038, 0.85443038, 0.86075949, 0.85443038,\n",
      "       0.85443038, 0.85443038, 0.85443038, 0.84810127, 0.84810127,\n",
      "       0.86075949, 0.86075949, 0.86075949, 0.85443038, 0.85443038,\n",
      "       0.85443038, 0.84810127, 0.86075949, 0.84810127, 0.85443038,\n",
      "       0.84810127, 0.84810127, 0.84810127, 0.86075949, 0.84810127,\n",
      "       0.84810127, 0.84177215, 0.84177215, 0.86075949, 0.86075949,\n",
      "       0.84177215, 0.84810127, 0.84810127, 0.84177215, 0.84177215,\n",
      "       0.84177215, 0.84177215, 0.84177215, 0.84810127, 0.83544304,\n",
      "       0.84810127, 0.84177215, 0.84177215, 0.84177215, 0.85443038,\n",
      "       0.86075949, 0.84810127, 0.84177215, 0.82278481, 0.83544304,\n",
      "       0.84177215, 0.84810127, 0.82911392, 0.82911392, 0.84810127,\n",
      "       0.84810127, 0.85443038, 0.82911392, 0.83544304, 0.84810127,\n",
      "       0.85443038, 0.84177215, 0.85443038, 0.84810127, 0.80379747,\n",
      "       0.82278481, 0.82278481, 0.82911392, 0.82278481, 0.8164557 ,\n",
      "       0.8164557 , 0.82278481, 0.82911392, 0.84810127, 0.84177215,\n",
      "       0.83544304, 0.84177215, 0.84177215, 0.84810127, 0.84810127,\n",
      "       0.79746835, 0.8164557 , 0.8164557 , 0.82911392, 0.8164557 ,\n",
      "       0.79113924, 0.81012658, 0.8164557 , 0.85443038, 0.84810127,\n",
      "       0.84177215, 0.82911392, 0.84177215, 0.84177215, 0.84810127,\n",
      "       0.85443038, 0.79113924, 0.81012658, 0.82278481, 0.83544304,\n",
      "       0.80379747, 0.82278481, 0.84177215, 0.85443038, 0.83544304,\n",
      "       0.84177215, 0.83544304, 0.83544304, 0.83544304, 0.83544304,\n",
      "       0.84177215, 0.83544304, 0.77848101, 0.8164557 , 0.80379747,\n",
      "       0.82278481, 0.80379747, 0.81012658, 0.81012658, 0.82911392,\n",
      "       0.82278481, 0.82911392, 0.83544304, 0.82278481, 0.83544304,\n",
      "       0.84810127, 0.85443038, 0.84810127, 0.79113924, 0.77848101,\n",
      "       0.80379747, 0.82911392, 0.79113924, 0.82278481, 0.82911392,\n",
      "       0.81012658, 0.82278481, 0.8164557 , 0.82278481, 0.83544304,\n",
      "       0.83544304, 0.85443038, 0.84810127, 0.84177215, 0.79746835,\n",
      "       0.78481013, 0.79113924, 0.82278481, 0.79113924, 0.79113924,\n",
      "       0.8164557 , 0.83544304, 0.82911392, 0.82911392, 0.81012658,\n",
      "       0.84810127, 0.85443038, 0.85443038, 0.85443038, 0.84177215,\n",
      "       0.76582278, 0.78481013, 0.82278481, 0.82278481, 0.77848101,\n",
      "       0.80379747, 0.82911392, 0.81012658, 0.81012658, 0.82911392,\n",
      "       0.80379747, 0.82911392, 0.84177215, 0.84810127, 0.82911392,\n",
      "       0.83544304, 0.78481013, 0.80379747, 0.79113924, 0.8164557 ,\n",
      "       0.78481013, 0.78481013, 0.78481013, 0.82911392, 0.82911392,\n",
      "       0.83544304, 0.82278481, 0.84177215, 0.84177215, 0.85443038,\n",
      "       0.84177215, 0.84177215, 0.75316456, 0.77848101, 0.81012658,\n",
      "       0.82911392, 0.80379747, 0.81012658, 0.8164557 , 0.81012658,\n",
      "       0.82911392, 0.82911392, 0.82278481, 0.84810127, 0.84177215,\n",
      "       0.86075949, 0.83544304, 0.84177215, 0.76582278, 0.76582278,\n",
      "       0.81012658, 0.84177215, 0.79746835, 0.77848101, 0.8164557 ,\n",
      "       0.8164557 , 0.82911392, 0.82278481, 0.8164557 , 0.83544304,\n",
      "       0.84810127, 0.84810127, 0.84810127, 0.84177215, 0.79113924,\n",
      "       0.80379747, 0.81012658, 0.79746835, 0.79746835, 0.80379747,\n",
      "       0.8164557 , 0.8164557 , 0.82278481, 0.81012658, 0.84177215,\n",
      "       0.8164557 , 0.82278481, 0.83544304, 0.85443038, 0.84177215]), 'mean_test_score': array([0.76589045, 0.75771833, 0.76463657, 0.76337871, 0.76651939,\n",
      "       0.76589045, 0.7627458 , 0.76400764, 0.76149192, 0.7671523 ,\n",
      "       0.7652655 , 0.76148794, 0.76337473, 0.76023406, 0.76651939,\n",
      "       0.76652337, 0.77156277, 0.77658626, 0.77409442, 0.77155083,\n",
      "       0.77470743, 0.77659024, 0.77784412, 0.78035984, 0.7734416 ,\n",
      "       0.77596131, 0.77408248, 0.77596131, 0.77344957, 0.77595733,\n",
      "       0.77155481, 0.7753284 , 0.80745164, 0.81120532, 0.81121328,\n",
      "       0.81436589, 0.81562774, 0.79860282, 0.80870154, 0.80745164,\n",
      "       0.81688162, 0.81121726, 0.80682271, 0.80682271, 0.80304116,\n",
      "       0.80681076, 0.81561978, 0.80617785, 0.82695645, 0.82758538,\n",
      "       0.8168856 , 0.82128811, 0.82569063, 0.82254598, 0.82443675,\n",
      "       0.82317889, 0.82632354, 0.82883926, 0.82254598, 0.82506568,\n",
      "       0.81877239, 0.82443277, 0.82317491, 0.82066316, 0.82821033,\n",
      "       0.83135897, 0.82443277, 0.82443675, 0.8238118 , 0.82821431,\n",
      "       0.82821431, 0.8250617 , 0.82506966, 0.82820635, 0.82569063,\n",
      "       0.82568665, 0.82506568, 0.82569859, 0.82569063, 0.82632752,\n",
      "       0.83135897, 0.82883926, 0.83072606, 0.82695645, 0.82695247,\n",
      "       0.82821033, 0.83072606, 0.82506568, 0.83009315, 0.8250617 ,\n",
      "       0.82821431, 0.82632752, 0.82758538, 0.82695247, 0.82569461,\n",
      "       0.82695247, 0.83260887, 0.83073004, 0.82820635, 0.82883926,\n",
      "       0.82631956, 0.82757742, 0.83072208, 0.82884324, 0.82757742,\n",
      "       0.82631956, 0.82568665, 0.82442879, 0.82695645, 0.82758538,\n",
      "       0.82442879, 0.8250617 , 0.82694849, 0.82379986, 0.82694451,\n",
      "       0.82379986, 0.82002627, 0.82317093, 0.82569063, 0.82190908,\n",
      "       0.82443277, 0.82317093, 0.82505772, 0.82317093, 0.82129209,\n",
      "       0.82695645, 0.82820635, 0.82442879, 0.81624075, 0.82065122,\n",
      "       0.82631558, 0.8168856 , 0.82567869, 0.82693655, 0.82254598,\n",
      "       0.82569063, 0.82192103, 0.82442083, 0.82253801, 0.82003025,\n",
      "       0.82443675, 0.82002627, 0.82632354, 0.82380384, 0.80868163,\n",
      "       0.81561181, 0.80680678, 0.81938938, 0.81686968, 0.80428708,\n",
      "       0.81434997, 0.81686968, 0.81813152, 0.82191704, 0.81373696,\n",
      "       0.81436191, 0.822542  , 0.82505772, 0.82380384, 0.82757742,\n",
      "       0.79609904, 0.80491601, 0.80868959, 0.813729  , 0.80994746,\n",
      "       0.79923971, 0.80994348, 0.81434997, 0.81877637, 0.81940132,\n",
      "       0.8206552 , 0.81750259, 0.82317093, 0.82317093, 0.82317491,\n",
      "       0.82506568, 0.78980575, 0.80050951, 0.80240427, 0.81436191,\n",
      "       0.7998766 , 0.80240427, 0.81122124, 0.81751851, 0.80870154,\n",
      "       0.81310803, 0.80681474, 0.81624871, 0.81939336, 0.82379588,\n",
      "       0.82568665, 0.82128015, 0.78350848, 0.79611098, 0.79798981,\n",
      "       0.81498288, 0.79798981, 0.80050951, 0.81183027, 0.813729  ,\n",
      "       0.80806464, 0.81498686, 0.81058833, 0.81435395, 0.82316695,\n",
      "       0.81814346, 0.82192103, 0.82317491, 0.77596927, 0.78476634,\n",
      "       0.79547409, 0.80681076, 0.79232147, 0.79422817, 0.79611894,\n",
      "       0.8042831 , 0.81246716, 0.8149789 , 0.81183823, 0.82442481,\n",
      "       0.82128015, 0.82443675, 0.8250617 , 0.822542  , 0.7709418 ,\n",
      "       0.78477032, 0.79106361, 0.80743571, 0.78603216, 0.78917682,\n",
      "       0.80051349, 0.81624871, 0.81247114, 0.80303718, 0.80931455,\n",
      "       0.82191704, 0.82695247, 0.82443675, 0.82883926, 0.82128413,\n",
      "       0.76337473, 0.78036781, 0.78793886, 0.80680678, 0.79231351,\n",
      "       0.79673195, 0.80492397, 0.80931455, 0.80050951, 0.80932649,\n",
      "       0.80868163, 0.80995542, 0.81625269, 0.82380384, 0.82064724,\n",
      "       0.81876443, 0.76149988, 0.78037975, 0.78854789, 0.81372104,\n",
      "       0.78665711, 0.78099674, 0.78980177, 0.80743969, 0.80743969,\n",
      "       0.80933047, 0.81183823, 0.81751055, 0.822542  , 0.82380782,\n",
      "       0.82379986, 0.81876841, 0.75959319, 0.7778481 , 0.79925165,\n",
      "       0.80743969, 0.78604012, 0.78667304, 0.79925563, 0.80302524,\n",
      "       0.81624473, 0.80932649, 0.80869358, 0.82065918, 0.82317093,\n",
      "       0.82444073, 0.82190908, 0.82505772, 0.77029297, 0.77469549,\n",
      "       0.78667304, 0.80807659, 0.78855187, 0.77910596, 0.79170846,\n",
      "       0.81057639, 0.80932649, 0.80932251, 0.81057639, 0.81310405,\n",
      "       0.82569063, 0.81940132, 0.82631956, 0.82002627, 0.76779317,\n",
      "       0.78415333, 0.79044662, 0.80679086, 0.78226256, 0.78855585,\n",
      "       0.79925563, 0.81057639, 0.80806464, 0.80742775, 0.804303  ,\n",
      "       0.81372104, 0.8193854 , 0.82190908, 0.82254996, 0.82317093]), 'std_test_score': array([0.02574438, 0.02765919, 0.0246657 , 0.03578377, 0.02704421,\n",
      "       0.02694553, 0.02607004, 0.02740459, 0.03055859, 0.02448723,\n",
      "       0.02496422, 0.02306795, 0.02548283, 0.02419461, 0.03009041,\n",
      "       0.02715681, 0.02930789, 0.03562073, 0.03308271, 0.02519472,\n",
      "       0.02995632, 0.03196569, 0.02926156, 0.02751872, 0.03106986,\n",
      "       0.02785662, 0.02880255, 0.03170824, 0.0308869 , 0.02845027,\n",
      "       0.03093995, 0.02640637, 0.02108708, 0.03167609, 0.02690479,\n",
      "       0.03225983, 0.03210078, 0.03227667, 0.03212946, 0.03658711,\n",
      "       0.02044026, 0.03391027, 0.03635227, 0.03375697, 0.03159588,\n",
      "       0.02629967, 0.02734499, 0.03367194, 0.02956549, 0.02969417,\n",
      "       0.02864028, 0.02601403, 0.02888955, 0.02829104, 0.02823139,\n",
      "       0.02766111, 0.02763575, 0.02641482, 0.02685651, 0.02814222,\n",
      "       0.03183176, 0.02710509, 0.02559951, 0.02942683, 0.02538164,\n",
      "       0.02625594, 0.02894011, 0.02604506, 0.02801014, 0.02391935,\n",
      "       0.02702511, 0.02581425, 0.02770169, 0.02428669, 0.0287523 ,\n",
      "       0.02863315, 0.02743044, 0.02899433, 0.02427679, 0.02846619,\n",
      "       0.02486312, 0.02288447, 0.02351424, 0.0247599 , 0.02735733,\n",
      "       0.02614924, 0.02710857, 0.02640173, 0.02720512, 0.0235716 ,\n",
      "       0.02900193, 0.02888005, 0.02733597, 0.02647559, 0.02490048,\n",
      "       0.02807096, 0.02101334, 0.02192732, 0.02646882, 0.02487231,\n",
      "       0.02751003, 0.02693321, 0.02353578, 0.02757052, 0.02588475,\n",
      "       0.02572681, 0.02313133, 0.02854576, 0.02585401, 0.02704502,\n",
      "       0.02452063, 0.02744808, 0.02527155, 0.02411957, 0.02230102,\n",
      "       0.02875756, 0.02904566, 0.02515263, 0.0277726 , 0.02479036,\n",
      "       0.0273954 , 0.02867963, 0.02673781, 0.02499488, 0.02490812,\n",
      "       0.02523461, 0.0286228 , 0.02668363, 0.02477724, 0.02157715,\n",
      "       0.02416271, 0.02998961, 0.02975893, 0.0227074 , 0.02405977,\n",
      "       0.0287523 , 0.02816712, 0.02391746, 0.02630257, 0.02889137,\n",
      "       0.02794977, 0.0261807 , 0.02705717, 0.02901312, 0.02015231,\n",
      "       0.02282139, 0.02312305, 0.02415825, 0.02519952, 0.02869465,\n",
      "       0.02772628, 0.02519952, 0.02321742, 0.02292058, 0.02996292,\n",
      "       0.03190685, 0.02597795, 0.02775406, 0.0265946 , 0.0275144 ,\n",
      "       0.01910489, 0.01505447, 0.01968025, 0.02432082, 0.02997763,\n",
      "       0.0236497 , 0.02604992, 0.03108896, 0.03131611, 0.02900544,\n",
      "       0.02678794, 0.02397726, 0.02895416, 0.02638074, 0.0249738 ,\n",
      "       0.03341166, 0.0265549 , 0.01704935, 0.03299479, 0.02463069,\n",
      "       0.03089585, 0.03226747, 0.03234198, 0.02502103, 0.02507662,\n",
      "       0.02872742, 0.03493695, 0.02774228, 0.02735927, 0.02331002,\n",
      "       0.02764923, 0.02753212, 0.0189422 , 0.03287222, 0.02165048,\n",
      "       0.02369426, 0.02612169, 0.02245617, 0.02310586, 0.0249629 ,\n",
      "       0.02575103, 0.02432638, 0.02920129, 0.02826669, 0.02814304,\n",
      "       0.02891934, 0.03123045, 0.03129999, 0.01900924, 0.01865695,\n",
      "       0.02318922, 0.02584452, 0.02936772, 0.02503606, 0.02687388,\n",
      "       0.02237038, 0.02777214, 0.02405473, 0.02355385, 0.02486458,\n",
      "       0.02893318, 0.0261965 , 0.02550594, 0.02424525, 0.02702608,\n",
      "       0.02464539, 0.02399482, 0.02634813, 0.02974128, 0.02253034,\n",
      "       0.03176812, 0.03019989, 0.02358862, 0.03550294, 0.03207045,\n",
      "       0.03086343, 0.02692007, 0.02851024, 0.02744303, 0.02462861,\n",
      "       0.02371397, 0.03470845, 0.0312008 , 0.02242836, 0.02719209,\n",
      "       0.03129678, 0.03890532, 0.01756717, 0.02850985, 0.0340436 ,\n",
      "       0.03235604, 0.03160542, 0.02685273, 0.02887646, 0.02577954,\n",
      "       0.02717555, 0.02971744, 0.02649018, 0.02964584, 0.02087918,\n",
      "       0.02459953, 0.02296221, 0.03735128, 0.02295347, 0.02848966,\n",
      "       0.02914259, 0.0269968 , 0.02717947, 0.02504771, 0.02844571,\n",
      "       0.03010163, 0.03083814, 0.02531787, 0.02593234, 0.02501619,\n",
      "       0.03126969, 0.02240066, 0.02447595, 0.01732311, 0.02044158,\n",
      "       0.0291538 , 0.02615917, 0.02920147, 0.0261709 , 0.02949555,\n",
      "       0.02618003, 0.02557572, 0.02521506, 0.02149283, 0.02501622,\n",
      "       0.02262853, 0.02981835, 0.01966742, 0.02874564, 0.0326454 ,\n",
      "       0.02551061, 0.03392721, 0.03076707, 0.01994083, 0.02704451,\n",
      "       0.02762981, 0.02425203, 0.02692875, 0.03024649, 0.027074  ,\n",
      "       0.02458787, 0.02660008, 0.02520934, 0.03140776, 0.02765969,\n",
      "       0.02103543, 0.02716271, 0.0262078 , 0.023717  , 0.02847551,\n",
      "       0.02404869, 0.02592234, 0.02891491, 0.02882845, 0.02812253]), 'rank_test_score': array([306, 320, 309, 311, 304, 307, 314, 310, 316, 302, 308, 317, 313,\n",
      "       318, 304, 303, 296, 284, 292, 298, 290, 283, 282, 279, 295, 286,\n",
      "       293, 287, 294, 288, 297, 289, 210, 186, 185, 165, 159, 245, 201,\n",
      "       210, 151, 184, 217, 217, 231, 220, 160, 225,  30,  22, 149, 122,\n",
      "        49, 107,  76,  94,  41,  10, 107,  60, 141,  78,  95, 126,  18,\n",
      "         2,  77,  72,  85,  14,  14,  65,  59,  19,  49,  57,  60,  47,\n",
      "        49,  39,   2,  10,   5,  28,  33,  17,   5,  60,   8,  65,  14,\n",
      "        39,  22,  32,  48,  33,   1,   4,  19,  10,  43,  25,   7,   9,\n",
      "        25,  43,  55,  80,  28,  22,  80,  64,  36,  90,  37,  90, 132,\n",
      "        98,  49, 118,  78,  98,  69,  98, 121,  30,  19,  80, 158, 129,\n",
      "        46, 149,  58,  38, 107,  49, 115,  84, 113, 131,  72, 132,  41,\n",
      "        87, 205, 161, 222, 138, 152, 229, 169, 152, 145, 116, 171, 166,\n",
      "       110,  68,  87,  25, 251, 227, 204, 172, 192, 244, 193, 169, 140,\n",
      "       135, 128, 148,  98,  98,  95,  60, 259, 237, 234, 166, 240, 234,\n",
      "       183, 146, 201, 176, 219, 155, 137,  93,  55, 125, 274, 250, 246,\n",
      "       163, 246, 237, 182, 172, 208, 162, 187, 168, 105, 144, 114,  95,\n",
      "       285, 272, 252, 220, 254, 253, 249, 230, 179, 164, 180,  83, 124,\n",
      "        72,  65, 110, 299, 271, 257, 215, 270, 261, 236, 155, 178, 232,\n",
      "       199, 116,  33,  72,  10, 123, 312, 278, 265, 222, 255, 248, 226,\n",
      "       199, 239, 195, 205, 191, 154,  87, 130, 143, 315, 277, 264, 174,\n",
      "       268, 276, 260, 212, 212, 194, 180, 147, 110,  86,  90, 142, 319,\n",
      "       281, 243, 212, 269, 266, 241, 233, 157, 195, 203, 127,  98,  71,\n",
      "       118,  69, 300, 291, 266, 207, 263, 280, 256, 188, 195, 198, 188,\n",
      "       177,  54, 136,  43, 132, 301, 273, 258, 224, 275, 262, 241, 188,\n",
      "       208, 216, 228, 174, 139, 118, 106,  98])}\n",
      "Resultados para UnderSampler:\n",
      "{'mean_fit_time': array([0.14836895, 0.12498543, 0.1150809 , 0.1289942 , 0.12114203,\n",
      "       0.12111347, 0.11562226, 0.11241205, 0.1029623 , 0.10306373,\n",
      "       0.10376768, 0.10450733, 0.10309353, 0.10155168, 0.10176356,\n",
      "       0.10170801, 0.10468028, 0.10387349, 0.10452693, 0.10757432,\n",
      "       0.11161304, 0.10621345, 0.10657477, 0.1085659 , 0.10653164,\n",
      "       0.10677042, 0.11336756, 0.10554042, 0.10524321, 0.10470257,\n",
      "       0.10857811, 0.10413086, 0.10696237, 0.10883873, 0.11174085,\n",
      "       0.10945101, 0.10739713, 0.10775549, 0.10952315, 0.10978258,\n",
      "       0.10683398, 0.10612876, 0.10836751, 0.10680239, 0.10740707,\n",
      "       0.10677075, 0.10562775, 0.1057627 , 0.10851877, 0.10927889,\n",
      "       0.10937781, 0.10960114, 0.10928154, 0.11116033, 0.10883224,\n",
      "       0.10957921, 0.10912027, 0.11005907, 0.1089781 , 0.10893936,\n",
      "       0.10906844, 0.10930831, 0.10974243, 0.10861809, 0.11169767,\n",
      "       0.11260533, 0.11152105, 0.11051552, 0.11118202, 0.11081421,\n",
      "       0.11374969, 0.11428106, 0.11465137, 0.1217236 , 0.11454282,\n",
      "       0.11385391, 0.11464236, 0.11449258, 0.11422186, 0.11391721,\n",
      "       0.11799512, 0.11473093, 0.11360111, 0.11440096, 0.11740949,\n",
      "       0.11501992, 0.11500878, 0.11672397, 0.1154248 , 0.11299789,\n",
      "       0.11411891, 0.11614447, 0.11562395, 0.11590292, 0.11548808,\n",
      "       0.11547153, 0.12098224, 0.12040031, 0.11943321, 0.11836562,\n",
      "       0.12027297, 0.11964316, 0.11743786, 0.11509984, 0.11549489,\n",
      "       0.11594737, 0.1160475 , 0.11726241, 0.11538591, 0.11247399,\n",
      "       0.11252751, 0.11293304, 0.12013078, 0.1186774 , 0.11718166,\n",
      "       0.11534913, 0.11826682, 0.11923852, 0.11859589, 0.11684532,\n",
      "       0.11657951, 0.11685197, 0.11667776, 0.11490095, 0.11377962,\n",
      "       0.11360035, 0.11326776, 0.1141221 , 0.12696223, 0.12144308,\n",
      "       0.11851118, 0.11679318, 0.12064106, 0.12120256, 0.11819246,\n",
      "       0.11871881, 0.12678354, 0.1178858 , 0.11800201, 0.11872101,\n",
      "       0.11845458, 0.11809375, 0.11942632, 0.1164571 , 0.12718673,\n",
      "       0.12537825, 0.12278283, 0.11896532, 0.12432535, 0.12937775,\n",
      "       0.12071459, 0.12042129, 0.12183623, 0.1212249 , 0.12032473,\n",
      "       0.11655819, 0.11615796, 0.11929224, 0.1189487 , 0.11785228,\n",
      "       0.13229713, 0.12859082, 0.12238612, 0.1190994 , 0.1256381 ,\n",
      "       0.1254951 , 0.12177587, 0.12114208, 0.13183024, 0.12314241,\n",
      "       0.12127206, 0.12100506, 0.12312901, 0.12104831, 0.12086248,\n",
      "       0.12269599, 0.14180255, 0.1368772 , 0.13242428, 0.12609637,\n",
      "       0.13333242, 0.13792224, 0.12967813, 0.1258312 , 0.12766845,\n",
      "       0.12756939, 0.12759793, 0.13408983, 0.12210796, 0.12210219,\n",
      "       0.12483318, 0.12446222, 0.14243774, 0.13897386, 0.13123181,\n",
      "       0.12589936, 0.13309057, 0.1604682 , 0.13302763, 0.12415867,\n",
      "       0.1246479 , 0.12862213, 0.12722144, 0.12366385, 0.12547274,\n",
      "       0.12246153, 0.12157555, 0.12131355, 0.14084516, 0.13655698,\n",
      "       0.13206489, 0.12769434, 0.15788515, 0.14389303, 0.14354248,\n",
      "       0.13270302, 0.14275305, 0.14163864, 0.14358521, 0.13162725,\n",
      "       0.12776935, 0.12216923, 0.1268193 , 0.13471227, 0.148364  ,\n",
      "       0.13951948, 0.13590462, 0.13352671, 0.13820257, 0.16956351,\n",
      "       0.13310516, 0.13013144, 0.12830973, 0.12790651, 0.14143569,\n",
      "       0.12557254, 0.12361014, 0.12325616, 0.12272375, 0.12195435,\n",
      "       0.14443154, 0.13847291, 0.13354266, 0.12884908, 0.13760643,\n",
      "       0.13585801, 0.13053956, 0.12600958, 0.12703576, 0.12791102,\n",
      "       0.12716103, 0.13738914, 0.13107843, 0.12472939, 0.12627923,\n",
      "       0.12393408, 0.14665475, 0.16441698, 0.13122034, 0.12778497,\n",
      "       0.16342247, 0.14220254, 0.13471649, 0.12463803, 0.1252758 ,\n",
      "       0.12945554, 0.13606775, 0.12834837, 0.12421138, 0.12377119,\n",
      "       0.12419331, 0.12384136, 0.14675105, 0.13850687, 0.13159802,\n",
      "       0.12514567, 0.1360446 , 0.13351595, 0.12985525, 0.12796206,\n",
      "       0.12762218, 0.1279604 , 0.12744582, 0.12532797, 0.12432098,\n",
      "       0.13566775, 0.13266966, 0.1222084 , 0.14610486, 0.13896358,\n",
      "       0.1319279 , 0.1261436 , 0.13638544, 0.13729439, 0.1319828 ,\n",
      "       0.12626686, 0.12837181, 0.12570558, 0.12910013, 0.12886112,\n",
      "       0.12200556, 0.12203038, 0.12460315, 0.12279506, 0.14542367,\n",
      "       0.1404443 , 0.13631876, 0.12600243, 0.13750908, 0.13325162,\n",
      "       0.12858262, 0.12650673, 0.12800491, 0.12911444, 0.12729559,\n",
      "       0.12331421, 0.11980846, 0.12214563, 0.12552962, 0.12452765]), 'std_fit_time': array([0.01011361, 0.01055191, 0.00594209, 0.01206179, 0.00594179,\n",
      "       0.01279474, 0.00656502, 0.00661428, 0.00178164, 0.00282824,\n",
      "       0.00225737, 0.00077084, 0.001923  , 0.00056596, 0.00073258,\n",
      "       0.00070206, 0.00105022, 0.00143255, 0.00139117, 0.00350473,\n",
      "       0.00344706, 0.00169507, 0.00263881, 0.00324895, 0.00051557,\n",
      "       0.00156591, 0.0162389 , 0.00213731, 0.00178814, 0.00192049,\n",
      "       0.00144747, 0.00050297, 0.00086266, 0.00103311, 0.00363323,\n",
      "       0.00407488, 0.00073281, 0.00132747, 0.00261329, 0.00402196,\n",
      "       0.00036948, 0.00061752, 0.0019628 , 0.00043865, 0.00043191,\n",
      "       0.00054933, 0.00077086, 0.00046384, 0.00055106, 0.00083786,\n",
      "       0.00065357, 0.000619  , 0.00054351, 0.00162836, 0.00251334,\n",
      "       0.00311977, 0.00085149, 0.00175867, 0.00074941, 0.00070307,\n",
      "       0.00061365, 0.00212116, 0.00186906, 0.0008782 , 0.00071131,\n",
      "       0.00226333, 0.00206644, 0.00074309, 0.00065465, 0.00087799,\n",
      "       0.00135715, 0.00054293, 0.00074189, 0.01079618, 0.00057748,\n",
      "       0.00069298, 0.00168563, 0.00139511, 0.00074283, 0.00051163,\n",
      "       0.00062085, 0.00080518, 0.00058254, 0.00152353, 0.00077562,\n",
      "       0.00128271, 0.00189508, 0.00219558, 0.00195064, 0.00073768,\n",
      "       0.00160802, 0.00111056, 0.00149111, 0.00083152, 0.00048768,\n",
      "       0.00082833, 0.00063491, 0.00080001, 0.00073399, 0.00096876,\n",
      "       0.00076183, 0.00086465, 0.00146843, 0.00058358, 0.00068335,\n",
      "       0.00069468, 0.00114336, 0.00109169, 0.00126715, 0.00065887,\n",
      "       0.00038707, 0.00090033, 0.00067335, 0.00080383, 0.00081195,\n",
      "       0.00085325, 0.00084916, 0.0015389 , 0.00084756, 0.00063802,\n",
      "       0.00085353, 0.00100048, 0.00071865, 0.00073696, 0.0006594 ,\n",
      "       0.00069982, 0.0006088 , 0.00150536, 0.00104124, 0.00091525,\n",
      "       0.00061005, 0.00056396, 0.00080888, 0.00086205, 0.0006335 ,\n",
      "       0.00302623, 0.00452224, 0.0011674 , 0.00104717, 0.002401  ,\n",
      "       0.00047226, 0.00109472, 0.00292197, 0.0020916 , 0.00057752,\n",
      "       0.00096792, 0.00087018, 0.00074849, 0.00087521, 0.00989856,\n",
      "       0.00090968, 0.00414181, 0.00160427, 0.00053078, 0.00097591,\n",
      "       0.00047136, 0.00317528, 0.00165811, 0.00063747, 0.00076506,\n",
      "       0.00087135, 0.0012707 , 0.0006923 , 0.00074675, 0.00084575,\n",
      "       0.00093085, 0.00081661, 0.0039582 , 0.02379567, 0.00613523,\n",
      "       0.0035642 , 0.00281909, 0.00436157, 0.0012394 , 0.0013944 ,\n",
      "       0.00129624, 0.00423544, 0.00172582, 0.00455316, 0.00121164,\n",
      "       0.00087063, 0.0097027 , 0.00121754, 0.00087463, 0.00500934,\n",
      "       0.00108012, 0.002143  , 0.01577079, 0.00087292, 0.00185228,\n",
      "       0.00075582, 0.00239058, 0.00119334, 0.00382354, 0.00140849,\n",
      "       0.00191188, 0.00162381, 0.01675744, 0.00358423, 0.00119568,\n",
      "       0.00243729, 0.00353784, 0.00140125, 0.00119328, 0.00838209,\n",
      "       0.00187135, 0.00169124, 0.00186692, 0.00125044, 0.00135006,\n",
      "       0.00135523, 0.00112877, 0.01334348, 0.00851098, 0.00547149,\n",
      "       0.00486814, 0.01279467, 0.0084148 , 0.01159145, 0.00522732,\n",
      "       0.00905475, 0.00247306, 0.01008468, 0.01019448, 0.00630724,\n",
      "       0.00262271, 0.00463284, 0.01419462, 0.00255134, 0.03878825,\n",
      "       0.00237936, 0.0041742 , 0.0018659 , 0.00140688, 0.02006701,\n",
      "       0.00110638, 0.00235668, 0.00478438, 0.00150375, 0.00162778,\n",
      "       0.00385303, 0.00233011, 0.00256981, 0.00509564, 0.00281708,\n",
      "       0.00204715, 0.00086981, 0.00161075, 0.00320836, 0.00115595,\n",
      "       0.00337042, 0.01104624, 0.01558046, 0.00436407, 0.00570634,\n",
      "       0.00275787, 0.00245179, 0.03483307, 0.00151849, 0.00461725,\n",
      "       0.02802094, 0.01884272, 0.00992319, 0.00177022, 0.00104404,\n",
      "       0.00640047, 0.01302724, 0.00866338, 0.00160504, 0.00304673,\n",
      "       0.00212965, 0.00344877, 0.00269791, 0.00496763, 0.00174251,\n",
      "       0.0009255 , 0.00122101, 0.00189383, 0.00169079, 0.00118342,\n",
      "       0.00220877, 0.0012869 , 0.00458748, 0.00236807, 0.00510345,\n",
      "       0.01282979, 0.01807924, 0.00093974, 0.00393437, 0.00179586,\n",
      "       0.00197338, 0.00451221, 0.00107907, 0.00179937, 0.00243985,\n",
      "       0.00201074, 0.0034548 , 0.00148303, 0.0017461 , 0.00500519,\n",
      "       0.00398734, 0.00238905, 0.004147  , 0.00164441, 0.0008699 ,\n",
      "       0.00356578, 0.00144217, 0.00267843, 0.00505445, 0.00160585,\n",
      "       0.00121832, 0.00327362, 0.00581665, 0.00539869, 0.00091509,\n",
      "       0.00181583, 0.00145407, 0.00253914, 0.00094429, 0.01104986]), 'mean_score_time': array([0.01167102, 0.00937324, 0.00924361, 0.00921981, 0.00903049,\n",
      "       0.00952668, 0.00883985, 0.00840306, 0.00769799, 0.00781939,\n",
      "       0.00846856, 0.00799379, 0.00793273, 0.00767934, 0.00785952,\n",
      "       0.00768461, 0.0078553 , 0.00791564, 0.00788872, 0.00817511,\n",
      "       0.00818198, 0.00819654, 0.007884  , 0.00785916, 0.00790107,\n",
      "       0.00810084, 0.00830567, 0.00796592, 0.00799446, 0.00792589,\n",
      "       0.0079601 , 0.0076472 , 0.00796633, 0.00806401, 0.00847466,\n",
      "       0.00801008, 0.00806124, 0.0079998 , 0.00830061, 0.00809963,\n",
      "       0.00798712, 0.00797217, 0.00806861, 0.00799856, 0.00800211,\n",
      "       0.00783162, 0.0078609 , 0.00795848, 0.00815108, 0.00820248,\n",
      "       0.00798371, 0.00817699, 0.008375  , 0.00840001, 0.00821629,\n",
      "       0.0078712 , 0.0079541 , 0.0080663 , 0.00827923, 0.00787103,\n",
      "       0.00817766, 0.00828948, 0.00805933, 0.0080508 , 0.00798719,\n",
      "       0.0082607 , 0.00782702, 0.00809011, 0.00795467, 0.00840912,\n",
      "       0.00815289, 0.00861852, 0.00857503, 0.00928657, 0.0086257 ,\n",
      "       0.00821974, 0.00861757, 0.00835164, 0.00855312, 0.00859942,\n",
      "       0.00840013, 0.00857687, 0.00840771, 0.00818064, 0.00859945,\n",
      "       0.00843639, 0.00848134, 0.00900412, 0.0085006 , 0.00850132,\n",
      "       0.00820067, 0.00839922, 0.00859935, 0.00839641, 0.00857785,\n",
      "       0.0087992 , 0.0087992 , 0.00879917, 0.00860026, 0.00872386,\n",
      "       0.00880492, 0.00889928, 0.0084003 , 0.00816376, 0.00857069,\n",
      "       0.00816464, 0.00883598, 0.00841985, 0.00834291, 0.00823202,\n",
      "       0.00827405, 0.00840199, 0.00856743, 0.00849953, 0.00838876,\n",
      "       0.00855522, 0.00857425, 0.00889049, 0.00845528, 0.00855954,\n",
      "       0.00831454, 0.00845411, 0.00844033, 0.00829816, 0.00851376,\n",
      "       0.00847034, 0.00871432, 0.00845549, 0.00920188, 0.00889208,\n",
      "       0.00866244, 0.0082001 , 0.00858915, 0.0086303 , 0.00862572,\n",
      "       0.00870085, 0.00914352, 0.00865936, 0.00852449, 0.00865114,\n",
      "       0.00859914, 0.00866544, 0.00900018, 0.00881314, 0.00911343,\n",
      "       0.00891614, 0.00880156, 0.00870321, 0.0090992 , 0.0097297 ,\n",
      "       0.00894923, 0.01017122, 0.00898852, 0.00866723, 0.00871623,\n",
      "       0.00836046, 0.00848672, 0.00900984, 0.00844719, 0.00857272,\n",
      "       0.00917797, 0.00911415, 0.00888653, 0.00871305, 0.00889573,\n",
      "       0.00883412, 0.00889924, 0.00856497, 0.00886445, 0.00895817,\n",
      "       0.00900114, 0.00885224, 0.00878022, 0.00870044, 0.00901494,\n",
      "       0.00922568, 0.00966966, 0.0096077 , 0.00997255, 0.00922418,\n",
      "       0.00940509, 0.0097244 , 0.00955915, 0.00958588, 0.00935829,\n",
      "       0.00913825, 0.00929494, 0.00969975, 0.00870564, 0.00901172,\n",
      "       0.00898285, 0.00946   , 0.01013083, 0.00985322, 0.00969248,\n",
      "       0.00914607, 0.0090343 , 0.01059124, 0.00978353, 0.00890906,\n",
      "       0.00902119, 0.01030123, 0.00943921, 0.00899639, 0.00901816,\n",
      "       0.00907059, 0.00867634, 0.00912421, 0.01022296, 0.0094461 ,\n",
      "       0.00954058, 0.00899293, 0.01167941, 0.01067271, 0.01002629,\n",
      "       0.009288  , 0.01015117, 0.01037862, 0.01019962, 0.00964954,\n",
      "       0.00959778, 0.00893366, 0.00913723, 0.00986147, 0.0105047 ,\n",
      "       0.01037436, 0.00952501, 0.00953069, 0.00998323, 0.01107366,\n",
      "       0.0098609 , 0.00945423, 0.00925846, 0.0091218 , 0.0104672 ,\n",
      "       0.00944471, 0.00936637, 0.00884597, 0.00875003, 0.00888226,\n",
      "       0.01041725, 0.00979834, 0.00990837, 0.00962374, 0.00965548,\n",
      "       0.00956774, 0.00969818, 0.00902975, 0.00931532, 0.00885129,\n",
      "       0.00898902, 0.01067936, 0.00920475, 0.0091594 , 0.00895572,\n",
      "       0.00925381, 0.01006908, 0.01111262, 0.00931249, 0.00921657,\n",
      "       0.01153595, 0.0096    , 0.00980265, 0.00895486, 0.00875983,\n",
      "       0.00922389, 0.00959277, 0.00904241, 0.00940428, 0.00916293,\n",
      "       0.00895598, 0.00923173, 0.0095005 , 0.01004248, 0.00927956,\n",
      "       0.00890045, 0.00950005, 0.00985734, 0.00923185, 0.00936987,\n",
      "       0.00930021, 0.00951874, 0.00920849, 0.00911078, 0.00872378,\n",
      "       0.01011479, 0.00977356, 0.0089747 , 0.01004281, 0.00995109,\n",
      "       0.00955529, 0.009442  , 0.01000166, 0.00959241, 0.00942836,\n",
      "       0.00930023, 0.00927446, 0.00942564, 0.00940282, 0.00936391,\n",
      "       0.00919199, 0.00891349, 0.00971432, 0.00890911, 0.00988557,\n",
      "       0.00974567, 0.0096133 , 0.00891788, 0.00936394, 0.0091006 ,\n",
      "       0.00930579, 0.00902555, 0.00925026, 0.00905533, 0.00942693,\n",
      "       0.00903025, 0.00891151, 0.00900755, 0.00914605, 0.00873725]), 'std_score_time': array([2.20363402e-03, 1.53080173e-03, 1.45691957e-03, 1.21955470e-03,\n",
      "       7.71649348e-04, 1.42913831e-03, 1.01033364e-03, 8.97793979e-04,\n",
      "       4.34077217e-04, 3.18390931e-04, 1.51139652e-03, 4.79207753e-04,\n",
      "       3.66797652e-04, 4.47171689e-04, 2.97988638e-04, 4.50176809e-04,\n",
      "       2.99066458e-04, 3.07267649e-04, 4.84092108e-04, 3.53895314e-04,\n",
      "       4.18735115e-04, 4.60353627e-04, 6.78595833e-04, 4.63689580e-04,\n",
      "       3.00632995e-04, 7.00333854e-04, 6.51686771e-04, 3.88083161e-04,\n",
      "       5.53056323e-04, 3.18443054e-04, 3.65148783e-04, 4.45293060e-04,\n",
      "       3.78193883e-04, 1.95511767e-04, 7.63356751e-04, 4.47837288e-04,\n",
      "       5.58495560e-04, 4.47397621e-04, 4.59111361e-04, 3.00386387e-04,\n",
      "       3.78485424e-04, 3.90013359e-04, 2.03312142e-04, 5.83146696e-06,\n",
      "       4.55878519e-06, 3.42107264e-04, 4.75101316e-04, 9.03372401e-05,\n",
      "       3.21001810e-04, 4.00891267e-04, 1.35097840e-04, 4.19003743e-04,\n",
      "       5.10072076e-04, 4.90330456e-04, 3.45597483e-04, 3.02589150e-04,\n",
      "       1.07247740e-04, 4.90338564e-04, 4.30838458e-04, 3.03061644e-04,\n",
      "       4.16461030e-04, 4.43551661e-04, 2.59666469e-04, 1.50090858e-04,\n",
      "       4.10870757e-05, 6.45183410e-04, 5.04989647e-04, 6.11506225e-04,\n",
      "       3.03756349e-04, 2.51018335e-04, 3.27788993e-04, 3.05781714e-04,\n",
      "       4.29135098e-04, 1.34713980e-03, 4.51999961e-04, 5.10230537e-04,\n",
      "       3.75503071e-04, 5.47567725e-04, 4.72320904e-04, 4.86160484e-04,\n",
      "       4.88732873e-04, 4.75750077e-04, 4.36768798e-04, 3.37167850e-04,\n",
      "       4.90513279e-04, 4.51380660e-04, 4.85446493e-04, 7.79030108e-04,\n",
      "       5.00709106e-04, 5.08606251e-04, 4.02983902e-04, 4.91619347e-04,\n",
      "       4.89843223e-04, 4.87590610e-04, 4.76627202e-04, 4.00245665e-04,\n",
      "       4.00126193e-04, 4.00054614e-04, 4.90984677e-04, 4.24254406e-04,\n",
      "       4.03345955e-04, 2.96702166e-04, 4.89320875e-04, 3.37462411e-04,\n",
      "       4.73451185e-04, 3.41132616e-04, 5.48613271e-04, 5.60281411e-04,\n",
      "       4.80863524e-04, 6.41788612e-04, 4.43043995e-04, 4.92201067e-04,\n",
      "       4.66056211e-04, 4.99537292e-04, 4.43468222e-04, 4.84633157e-04,\n",
      "       4.72981181e-04, 3.78747393e-04, 4.49437956e-04, 4.71038260e-04,\n",
      "       4.08852968e-04, 4.72597063e-04, 5.02755786e-04, 4.55737560e-04,\n",
      "       4.87772274e-04, 4.62193547e-04, 4.26552537e-04, 5.27093748e-04,\n",
      "       3.11262340e-04, 2.99218251e-04, 3.77859593e-04, 4.00042676e-04,\n",
      "       4.42913195e-04, 4.41442844e-04, 5.00546204e-04, 4.58126322e-04,\n",
      "       5.48365189e-04, 3.86761043e-04, 4.93944989e-04, 6.64805617e-04,\n",
      "       4.90106052e-04, 4.47558494e-04, 2.30478144e-06, 3.30512445e-04,\n",
      "       6.63037690e-04, 1.50958391e-04, 3.99828003e-04, 4.65234433e-04,\n",
      "       3.01806032e-04, 1.19829725e-03, 3.99792638e-04, 2.32961276e-03,\n",
      "       4.54859952e-04, 3.20252920e-04, 4.02602909e-04, 2.67262804e-04,\n",
      "       5.51354359e-04, 4.78594641e-04, 4.55404806e-04, 1.49986216e-04,\n",
      "       5.52508273e-04, 3.75742314e-04, 4.91560448e-04, 5.07839989e-04,\n",
      "       4.77146659e-04, 3.06527026e-04, 2.99714619e-04, 5.39134794e-04,\n",
      "       5.78309118e-04, 1.66205888e-03, 5.06039008e-04, 5.36068490e-04,\n",
      "       4.67795862e-04, 4.57679672e-04, 5.20586541e-04, 6.23801097e-04,\n",
      "       6.38386306e-04, 4.90270150e-04, 9.82363657e-04, 6.39382107e-04,\n",
      "       7.25369160e-04, 8.58513009e-04, 7.11612131e-04, 5.17030195e-04,\n",
      "       8.88602608e-04, 4.73782617e-04, 8.51601060e-04, 1.20243437e-03,\n",
      "       5.21067669e-04, 5.88425935e-04, 6.36010067e-04, 1.33484653e-03,\n",
      "       6.93609991e-04, 5.47634306e-04, 5.44930078e-04, 5.33136998e-04,\n",
      "       3.47477297e-04, 1.81192960e-03, 5.25266383e-04, 7.62815652e-04,\n",
      "       2.91522172e-04, 2.40054026e-03, 8.45269289e-04, 4.44646357e-04,\n",
      "       1.00057844e-03, 5.72392669e-04, 8.60085108e-04, 4.63213567e-04,\n",
      "       4.91520134e-04, 4.98062630e-04, 7.44791421e-04, 3.27122167e-04,\n",
      "       1.13413773e-03, 8.10428422e-04, 1.11970982e-03, 5.06678300e-04,\n",
      "       1.04655729e-03, 9.68360922e-04, 7.29128291e-04, 1.13707090e-03,\n",
      "       8.79164849e-04, 8.04721839e-04, 8.15678436e-04, 1.53701558e-03,\n",
      "       6.12518428e-04, 1.21682366e-03, 7.48769479e-04, 1.24379571e-03,\n",
      "       7.77601551e-04, 2.64573540e-03, 7.70164317e-04, 9.17297216e-04,\n",
      "       2.93080771e-04, 2.39319606e-04, 1.78771917e-03, 4.45874998e-04,\n",
      "       4.77778950e-04, 4.33345743e-04, 3.32124544e-04, 6.05628624e-04,\n",
      "       8.08582391e-04, 6.44048540e-04, 1.26358551e-03, 9.96422614e-04,\n",
      "       6.15966883e-04, 5.05545433e-04, 7.08984094e-04, 4.20774916e-04,\n",
      "       4.96175872e-04, 5.59548941e-04, 4.22953512e-04, 1.27610602e-03,\n",
      "       1.29683550e-03, 4.62581151e-04, 8.90738538e-04, 6.40798161e-04,\n",
      "       7.24615526e-04, 2.64821146e-03, 3.69766912e-04, 9.32033736e-04,\n",
      "       2.82457881e-03, 6.63227111e-04, 1.18991548e-03, 4.75762135e-04,\n",
      "       6.41933753e-04, 4.81202455e-04, 8.56659978e-04, 3.30566568e-04,\n",
      "       7.56674226e-04, 1.29150478e-03, 7.35475119e-04, 8.82448919e-04,\n",
      "       4.99584079e-04, 1.08445504e-03, 4.28320050e-04, 7.00107474e-04,\n",
      "       5.00130744e-04, 7.75929125e-04, 4.23856883e-04, 8.58454244e-04,\n",
      "       7.81789939e-04, 7.00562389e-04, 5.97676535e-04, 8.57339401e-04,\n",
      "       4.26035813e-04, 1.26256125e-03, 1.55203920e-03, 3.95955053e-04,\n",
      "       5.48668260e-04, 9.06509191e-04, 4.82020669e-04, 5.36701926e-04,\n",
      "       8.98561479e-04, 4.85138332e-04, 5.56964062e-04, 6.40214335e-04,\n",
      "       6.16544088e-04, 6.20469463e-04, 6.61580850e-04, 7.86962983e-04,\n",
      "       1.23222590e-03, 3.37490058e-04, 1.62539068e-03, 4.00958431e-04,\n",
      "       5.14579758e-04, 4.73316932e-04, 5.03539457e-04, 4.99203028e-04,\n",
      "       4.39617312e-04, 2.99958583e-04, 4.79517722e-04, 4.57543969e-04,\n",
      "       3.96309073e-04, 5.45859020e-04, 9.50681139e-04, 4.03927589e-04,\n",
      "       8.09727294e-04, 5.53193584e-04, 4.01290711e-04, 6.80971929e-04]), 'param_classifier__max_depth': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
      "                   2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3,\n",
      "                   3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4,\n",
      "                   4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "                   6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "                   7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "                   8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
      "                   11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
      "                   12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13,\n",
      "                   13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14,\n",
      "                   14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15,\n",
      "                   15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16,\n",
      "                   16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "                   17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "                   17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
      "                   18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
      "                   19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "                   20, 20, 20, 20, 20, 20, 20, 20],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_classifier__min_samples_leaf': masked_array(data=[1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1,\n",
      "                   1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1,\n",
      "                   1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1,\n",
      "                   1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1,\n",
      "                   2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2,\n",
      "                   2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2,\n",
      "                   2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2,\n",
      "                   2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "                   5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5,\n",
      "                   5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5,\n",
      "                   5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5,\n",
      "                   5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5,\n",
      "                   10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10,\n",
      "                   10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10,\n",
      "                   10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10,\n",
      "                   10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10,\n",
      "                   1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1,\n",
      "                   1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1,\n",
      "                   1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_classifier__min_samples_split': masked_array(data=[2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'classifier__max_depth': 1, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}], 'split0_test_score': array([0.71698113, 0.72327044, 0.76100629, 0.72955975, 0.72327044,\n",
      "       0.72955975, 0.72327044, 0.72327044, 0.72955975, 0.72327044,\n",
      "       0.72327044, 0.72327044, 0.73584906, 0.72327044, 0.74213836,\n",
      "       0.71698113, 0.74842767, 0.74213836, 0.74213836, 0.74213836,\n",
      "       0.73584906, 0.74213836, 0.73584906, 0.76100629, 0.74213836,\n",
      "       0.72327044, 0.72955975, 0.74213836, 0.74842767, 0.75471698,\n",
      "       0.74213836, 0.74842767, 0.78616352, 0.77987421, 0.79874214,\n",
      "       0.74213836, 0.74842767, 0.79245283, 0.79245283, 0.7672956 ,\n",
      "       0.77358491, 0.78616352, 0.78616352, 0.77358491, 0.75471698,\n",
      "       0.78616352, 0.79245283, 0.79245283, 0.81132075, 0.81761006,\n",
      "       0.77987421, 0.79874214, 0.79245283, 0.79874214, 0.78616352,\n",
      "       0.79245283, 0.79245283, 0.79245283, 0.79245283, 0.81132075,\n",
      "       0.80503145, 0.78616352, 0.79245283, 0.81132075, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.81132075, 0.79245283,\n",
      "       0.81761006, 0.81132075, 0.81132075, 0.80503145, 0.81761006,\n",
      "       0.79874214, 0.79874214, 0.81132075, 0.81132075, 0.80503145,\n",
      "       0.81761006, 0.80503145, 0.81132075, 0.81132075, 0.81761006,\n",
      "       0.79245283, 0.81761006, 0.81761006, 0.81761006, 0.80503145,\n",
      "       0.81132075, 0.81761006, 0.81761006, 0.78616352, 0.79245283,\n",
      "       0.81132075, 0.81761006, 0.79245283, 0.80503145, 0.78616352,\n",
      "       0.81132075, 0.81761006, 0.82389937, 0.79245283, 0.79874214,\n",
      "       0.81132075, 0.79874214, 0.80503145, 0.80503145, 0.78616352,\n",
      "       0.81761006, 0.81132075, 0.79245283, 0.79245283, 0.79245283,\n",
      "       0.81761006, 0.81132075, 0.80503145, 0.78616352, 0.80503145,\n",
      "       0.81132075, 0.80503145, 0.81132075, 0.79874214, 0.79874214,\n",
      "       0.80503145, 0.81761006, 0.81132075, 0.78616352, 0.7672956 ,\n",
      "       0.79245283, 0.81132075, 0.81761006, 0.77987421, 0.78616352,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.81132075, 0.81132075,\n",
      "       0.78616352, 0.79874214, 0.81761006, 0.81132075, 0.81761006,\n",
      "       0.79245283, 0.79245283, 0.80503145, 0.79245283, 0.79245283,\n",
      "       0.79245283, 0.81132075, 0.80503145, 0.79874214, 0.81132075,\n",
      "       0.79874214, 0.80503145, 0.79245283, 0.81761006, 0.77987421,\n",
      "       0.81132075, 0.81132075, 0.77358491, 0.79874214, 0.79245283,\n",
      "       0.79874214, 0.79874214, 0.7672956 , 0.79245283, 0.79245283,\n",
      "       0.80503145, 0.79874214, 0.81132075, 0.81132075, 0.78616352,\n",
      "       0.81132075, 0.79245283, 0.77987421, 0.79874214, 0.81132075,\n",
      "       0.78616352, 0.81132075, 0.78616352, 0.77987421, 0.78616352,\n",
      "       0.79874214, 0.78616352, 0.76100629, 0.80503145, 0.79245283,\n",
      "       0.81132075, 0.81761006, 0.79874214, 0.78616352, 0.81132075,\n",
      "       0.79245283, 0.7672956 , 0.81761006, 0.81132075, 0.79874214,\n",
      "       0.79874214, 0.78616352, 0.81132075, 0.80503145, 0.81132075,\n",
      "       0.79245283, 0.79874214, 0.78616352, 0.75471698, 0.79245283,\n",
      "       0.7672956 , 0.78616352, 0.77987421, 0.77358491, 0.79245283,\n",
      "       0.81132075, 0.79874214, 0.81132075, 0.79874214, 0.80503145,\n",
      "       0.7672956 , 0.79245283, 0.79874214, 0.81132075, 0.7672956 ,\n",
      "       0.77358491, 0.76100629, 0.77358491, 0.78616352, 0.77987421,\n",
      "       0.78616352, 0.80503145, 0.79874214, 0.81761006, 0.81132075,\n",
      "       0.81132075, 0.79245283, 0.79874214, 0.79245283, 0.81132075,\n",
      "       0.74213836, 0.77358491, 0.7672956 , 0.79874214, 0.81132075,\n",
      "       0.79245283, 0.81132075, 0.77987421, 0.80503145, 0.79874214,\n",
      "       0.79245283, 0.80503145, 0.81761006, 0.81132075, 0.81132075,\n",
      "       0.81761006, 0.77358491, 0.7672956 , 0.79245283, 0.79874214,\n",
      "       0.7672956 , 0.77358491, 0.77358491, 0.78616352, 0.80503145,\n",
      "       0.81132075, 0.78616352, 0.81761006, 0.81132075, 0.81761006,\n",
      "       0.80503145, 0.79245283, 0.75471698, 0.74842767, 0.79874214,\n",
      "       0.75471698, 0.79874214, 0.78616352, 0.78616352, 0.79874214,\n",
      "       0.79874214, 0.80503145, 0.78616352, 0.81132075, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.81761006, 0.7672956 , 0.7672956 ,\n",
      "       0.7672956 , 0.79874214, 0.7672956 , 0.7672956 , 0.74842767,\n",
      "       0.77358491, 0.79874214, 0.81761006, 0.79245283, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.78616352, 0.80503145, 0.74842767,\n",
      "       0.73584906, 0.78616352, 0.79874214, 0.76100629, 0.77358491,\n",
      "       0.77987421, 0.80503145, 0.78616352, 0.80503145, 0.81132075,\n",
      "       0.80503145, 0.79874214, 0.81132075, 0.81761006, 0.80503145]), 'split1_test_score': array([0.77358491, 0.81132075, 0.77358491, 0.80503145, 0.80503145,\n",
      "       0.81132075, 0.77358491, 0.80503145, 0.77358491, 0.79245283,\n",
      "       0.77358491, 0.79874214, 0.78616352, 0.77358491, 0.81132075,\n",
      "       0.77987421, 0.81761006, 0.81132075, 0.81132075, 0.81761006,\n",
      "       0.81132075, 0.81132075, 0.81761006, 0.81132075, 0.83647799,\n",
      "       0.81132075, 0.8490566 , 0.81132075, 0.80503145, 0.83018868,\n",
      "       0.83018868, 0.81132075, 0.87421384, 0.88050314, 0.87421384,\n",
      "       0.86792453, 0.88679245, 0.87421384, 0.8427673 , 0.87421384,\n",
      "       0.85534591, 0.87421384, 0.88050314, 0.86163522, 0.86792453,\n",
      "       0.87421384, 0.86163522, 0.88050314, 0.87421384, 0.87421384,\n",
      "       0.87421384, 0.86792453, 0.88050314, 0.88050314, 0.88050314,\n",
      "       0.87421384, 0.88679245, 0.87421384, 0.88050314, 0.88679245,\n",
      "       0.88679245, 0.86792453, 0.88050314, 0.88050314, 0.86792453,\n",
      "       0.88679245, 0.87421384, 0.88050314, 0.87421384, 0.87421384,\n",
      "       0.88679245, 0.88050314, 0.88679245, 0.88679245, 0.88679245,\n",
      "       0.88679245, 0.88679245, 0.88050314, 0.88679245, 0.88050314,\n",
      "       0.88050314, 0.87421384, 0.88679245, 0.88679245, 0.88679245,\n",
      "       0.88679245, 0.87421384, 0.88050314, 0.88679245, 0.88050314,\n",
      "       0.89308176, 0.88050314, 0.87421384, 0.88050314, 0.88679245,\n",
      "       0.88050314, 0.88679245, 0.87421384, 0.88679245, 0.86792453,\n",
      "       0.89308176, 0.86792453, 0.87421384, 0.86163522, 0.88050314,\n",
      "       0.86792453, 0.88679245, 0.88679245, 0.88050314, 0.87421384,\n",
      "       0.88679245, 0.88050314, 0.86792453, 0.87421384, 0.87421384,\n",
      "       0.87421384, 0.86163522, 0.87421384, 0.88050314, 0.88050314,\n",
      "       0.87421384, 0.88679245, 0.88050314, 0.86792453, 0.87421384,\n",
      "       0.87421384, 0.87421384, 0.88679245, 0.86792453, 0.8490566 ,\n",
      "       0.86792453, 0.88050314, 0.88050314, 0.86163522, 0.86792453,\n",
      "       0.87421384, 0.87421384, 0.88679245, 0.87421384, 0.88679245,\n",
      "       0.87421384, 0.88679245, 0.88050314, 0.87421384, 0.82389937,\n",
      "       0.8427673 , 0.81761006, 0.88050314, 0.86163522, 0.85534591,\n",
      "       0.83647799, 0.87421384, 0.88050314, 0.87421384, 0.88679245,\n",
      "       0.88679245, 0.87421384, 0.88050314, 0.88050314, 0.86792453,\n",
      "       0.81761006, 0.81761006, 0.85534591, 0.87421384, 0.8427673 ,\n",
      "       0.86163522, 0.86163522, 0.86792453, 0.86792453, 0.87421384,\n",
      "       0.86792453, 0.87421384, 0.88050314, 0.88050314, 0.87421384,\n",
      "       0.87421384, 0.7672956 , 0.79874214, 0.82389937, 0.88050314,\n",
      "       0.8490566 , 0.83647799, 0.85534591, 0.86792453, 0.88050314,\n",
      "       0.86792453, 0.86792453, 0.88050314, 0.88679245, 0.88050314,\n",
      "       0.88050314, 0.88679245, 0.77987421, 0.77987421, 0.83018868,\n",
      "       0.86792453, 0.82389937, 0.81761006, 0.8490566 , 0.86792453,\n",
      "       0.86163522, 0.85534591, 0.87421384, 0.88050314, 0.88050314,\n",
      "       0.87421384, 0.88050314, 0.86792453, 0.77358491, 0.78616352,\n",
      "       0.8490566 , 0.85534591, 0.78616352, 0.80503145, 0.83647799,\n",
      "       0.87421384, 0.87421384, 0.88050314, 0.87421384, 0.87421384,\n",
      "       0.86792453, 0.89308176, 0.88050314, 0.88050314, 0.70440252,\n",
      "       0.7672956 , 0.83018868, 0.8490566 , 0.79245283, 0.80503145,\n",
      "       0.85534591, 0.86163522, 0.86792453, 0.8490566 , 0.86792453,\n",
      "       0.88679245, 0.87421384, 0.88050314, 0.88679245, 0.88050314,\n",
      "       0.76100629, 0.77358491, 0.8427673 , 0.87421384, 0.77987421,\n",
      "       0.82389937, 0.86163522, 0.86163522, 0.86163522, 0.87421384,\n",
      "       0.85534591, 0.88050314, 0.87421384, 0.88050314, 0.87421384,\n",
      "       0.88679245, 0.7672956 , 0.7672956 , 0.79874214, 0.86163522,\n",
      "       0.79245283, 0.79245283, 0.82389937, 0.85534591, 0.87421384,\n",
      "       0.85534591, 0.87421384, 0.86792453, 0.88679245, 0.88679245,\n",
      "       0.87421384, 0.88050314, 0.74213836, 0.74842767, 0.82389937,\n",
      "       0.86792453, 0.77987421, 0.79874214, 0.82389937, 0.8490566 ,\n",
      "       0.88050314, 0.86792453, 0.88679245, 0.86792453, 0.88050314,\n",
      "       0.88050314, 0.88050314, 0.88679245, 0.72327044, 0.74213836,\n",
      "       0.85534591, 0.86792453, 0.78616352, 0.77358491, 0.86163522,\n",
      "       0.8490566 , 0.86792453, 0.86163522, 0.85534591, 0.87421384,\n",
      "       0.88679245, 0.88050314, 0.87421384, 0.88679245, 0.74213836,\n",
      "       0.77987421, 0.83018868, 0.8490566 , 0.79245283, 0.79245283,\n",
      "       0.86792453, 0.87421384, 0.85534591, 0.88050314, 0.88050314,\n",
      "       0.88050314, 0.88679245, 0.88679245, 0.88050314, 0.87421384]), 'split2_test_score': array([0.80503145, 0.80503145, 0.80503145, 0.81132075, 0.80503145,\n",
      "       0.79874214, 0.79874214, 0.78616352, 0.79874214, 0.80503145,\n",
      "       0.80503145, 0.78616352, 0.79245283, 0.79874214, 0.79245283,\n",
      "       0.79874214, 0.80503145, 0.80503145, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.77987421, 0.81761006, 0.82389937, 0.81132075,\n",
      "       0.79245283, 0.80503145, 0.82389937, 0.81132075, 0.80503145,\n",
      "       0.79874214, 0.81761006, 0.81132075, 0.81761006, 0.81132075,\n",
      "       0.80503145, 0.81761006, 0.81761006, 0.81761006, 0.81132075,\n",
      "       0.81132075, 0.81761006, 0.81132075, 0.81761006, 0.81132075,\n",
      "       0.81761006, 0.82389937, 0.81761006, 0.81761006, 0.81132075,\n",
      "       0.81761006, 0.80503145, 0.81132075, 0.81132075, 0.80503145,\n",
      "       0.81132075, 0.81761006, 0.81132075, 0.81132075, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81132075, 0.81132075, 0.80503145,\n",
      "       0.80503145, 0.79874214, 0.82389937, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81132075, 0.79245283, 0.79874214, 0.81761006,\n",
      "       0.81132075, 0.81132075, 0.81761006, 0.81132075, 0.81132075,\n",
      "       0.80503145, 0.81761006, 0.81761006, 0.79245283, 0.80503145,\n",
      "       0.80503145, 0.81132075, 0.81132075, 0.79245283, 0.81761006,\n",
      "       0.79874214, 0.79874214, 0.81761006, 0.79245283, 0.81132075,\n",
      "       0.78616352, 0.83647799, 0.81132075, 0.79245283, 0.81132075,\n",
      "       0.80503145, 0.79874214, 0.77987421, 0.79245283, 0.79245283,\n",
      "       0.81132075, 0.78616352, 0.81132075, 0.81761006, 0.79245283,\n",
      "       0.81761006, 0.81761006, 0.78616352, 0.79245283, 0.78616352,\n",
      "       0.81132075, 0.81761006, 0.81132075, 0.79874214, 0.79874214,\n",
      "       0.81761006, 0.79245283, 0.81761006, 0.79874214, 0.80503145,\n",
      "       0.80503145, 0.81132075, 0.81761006, 0.77987421, 0.82389937,\n",
      "       0.79874214, 0.78616352, 0.79245283, 0.7672956 , 0.77358491,\n",
      "       0.77358491, 0.79245283, 0.79874214, 0.81761006, 0.80503145,\n",
      "       0.81132075, 0.81761006, 0.80503145, 0.79874214, 0.79874214,\n",
      "       0.77358491, 0.77358491, 0.80503145, 0.79874214, 0.77987421,\n",
      "       0.76100629, 0.81132075, 0.80503145, 0.81761006, 0.77987421,\n",
      "       0.80503145, 0.79245283, 0.79874214, 0.79874214, 0.80503145,\n",
      "       0.73584906, 0.71698113, 0.78616352, 0.80503145, 0.77358491,\n",
      "       0.7672956 , 0.77987421, 0.79245283, 0.77987421, 0.80503145,\n",
      "       0.79874214, 0.79245283, 0.80503145, 0.79245283, 0.81761006,\n",
      "       0.79245283, 0.72955975, 0.71698113, 0.74213836, 0.81761006,\n",
      "       0.77987421, 0.71069182, 0.75471698, 0.78616352, 0.79874214,\n",
      "       0.81132075, 0.77987421, 0.81761006, 0.79245283, 0.79874214,\n",
      "       0.79874214, 0.81761006, 0.75471698, 0.71069182, 0.77987421,\n",
      "       0.78616352, 0.74842767, 0.72955975, 0.75471698, 0.78616352,\n",
      "       0.81132075, 0.74842767, 0.78616352, 0.81761006, 0.79245283,\n",
      "       0.81761006, 0.81132075, 0.79874214, 0.71069182, 0.74213836,\n",
      "       0.77358491, 0.80503145, 0.74213836, 0.75471698, 0.72955975,\n",
      "       0.80503145, 0.81132075, 0.77987421, 0.79245283, 0.80503145,\n",
      "       0.80503145, 0.82389937, 0.79874214, 0.81761006, 0.70440252,\n",
      "       0.73584906, 0.74213836, 0.78616352, 0.72955975, 0.74842767,\n",
      "       0.75471698, 0.78616352, 0.81761006, 0.79245283, 0.82389937,\n",
      "       0.79245283, 0.82389937, 0.81761006, 0.79245283, 0.76100629,\n",
      "       0.74213836, 0.73584906, 0.7672956 , 0.78616352, 0.71698113,\n",
      "       0.74213836, 0.75471698, 0.79245283, 0.77987421, 0.79245283,\n",
      "       0.79245283, 0.79874214, 0.79874214, 0.81761006, 0.79874214,\n",
      "       0.79874214, 0.71069182, 0.69811321, 0.77358491, 0.7672956 ,\n",
      "       0.73584906, 0.71069182, 0.74842767, 0.80503145, 0.81132075,\n",
      "       0.81132075, 0.79245283, 0.78616352, 0.77987421, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.71698113, 0.67295597, 0.74213836,\n",
      "       0.79245283, 0.75471698, 0.74213836, 0.77358491, 0.78616352,\n",
      "       0.79245283, 0.81132075, 0.81132075, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.81132075, 0.82389937, 0.71698113, 0.72327044,\n",
      "       0.7672956 , 0.77987421, 0.74842767, 0.75471698, 0.75471698,\n",
      "       0.76100629, 0.80503145, 0.79245283, 0.79874214, 0.79245283,\n",
      "       0.80503145, 0.79245283, 0.80503145, 0.81132075, 0.74842767,\n",
      "       0.74213836, 0.75471698, 0.7672956 , 0.72955975, 0.71698113,\n",
      "       0.74842767, 0.80503145, 0.79874214, 0.81132075, 0.77987421,\n",
      "       0.81132075, 0.79874214, 0.81132075, 0.81761006, 0.77358491]), 'split3_test_score': array([0.79245283, 0.78616352, 0.79874214, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.79245283, 0.79245283, 0.78616352,\n",
      "       0.78616352, 0.79245283, 0.78616352, 0.79245283, 0.77987421,\n",
      "       0.79245283, 0.79245283, 0.80503145, 0.79874214, 0.79874214,\n",
      "       0.77987421, 0.77987421, 0.79874214, 0.79245283, 0.77358491,\n",
      "       0.79245283, 0.79245283, 0.78616352, 0.79245283, 0.78616352,\n",
      "       0.78616352, 0.79245283, 0.80503145, 0.79874214, 0.81132075,\n",
      "       0.79874214, 0.80503145, 0.80503145, 0.81132075, 0.81132075,\n",
      "       0.79245283, 0.80503145, 0.81132075, 0.79245283, 0.81761006,\n",
      "       0.80503145, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.80503145, 0.81132075, 0.81132075,\n",
      "       0.80503145, 0.81132075, 0.80503145, 0.77358491, 0.81132075,\n",
      "       0.80503145, 0.77358491, 0.78616352, 0.81132075, 0.80503145,\n",
      "       0.80503145, 0.81761006, 0.81132075, 0.80503145, 0.81132075,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.81132075, 0.81761006,\n",
      "       0.80503145, 0.79874214, 0.80503145, 0.79874214, 0.81132075,\n",
      "       0.81761006, 0.81761006, 0.81132075, 0.81132075, 0.81761006,\n",
      "       0.81132075, 0.79874214, 0.81132075, 0.81132075, 0.80503145,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81761006, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.80503145, 0.81761006,\n",
      "       0.80503145, 0.81761006, 0.81761006, 0.81132075, 0.81132075,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.81132075, 0.81132075,\n",
      "       0.80503145, 0.81132075, 0.80503145, 0.81761006, 0.81132075,\n",
      "       0.81761006, 0.82389937, 0.78616352, 0.79874214, 0.79245283,\n",
      "       0.80503145, 0.82389937, 0.80503145, 0.81132075, 0.80503145,\n",
      "       0.79874214, 0.79874214, 0.80503145, 0.77987421, 0.78616352,\n",
      "       0.81132075, 0.80503145, 0.79245283, 0.78616352, 0.79245283,\n",
      "       0.79874214, 0.82389937, 0.80503145, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81132075, 0.79874214,\n",
      "       0.79245283, 0.79874214, 0.79245283, 0.79874214, 0.78616352,\n",
      "       0.77987421, 0.79245283, 0.78616352, 0.77987421, 0.79245283,\n",
      "       0.79245283, 0.80503145, 0.81132075, 0.81132075, 0.80503145,\n",
      "       0.78616352, 0.76100629, 0.77987421, 0.80503145, 0.82389937,\n",
      "       0.79874214, 0.79245283, 0.79874214, 0.81761006, 0.81132075,\n",
      "       0.79245283, 0.79874214, 0.80503145, 0.80503145, 0.79874214,\n",
      "       0.80503145, 0.76100629, 0.73584906, 0.80503145, 0.79245283,\n",
      "       0.77358491, 0.77987421, 0.81132075, 0.79874214, 0.81132075,\n",
      "       0.80503145, 0.80503145, 0.81132075, 0.81761006, 0.82389937,\n",
      "       0.80503145, 0.78616352, 0.76100629, 0.80503145, 0.82389937,\n",
      "       0.78616352, 0.78616352, 0.79245283, 0.83018868, 0.81132075,\n",
      "       0.79245283, 0.79245283, 0.79245283, 0.77358491, 0.78616352,\n",
      "       0.79874214, 0.81761006, 0.81132075, 0.7672956 , 0.80503145,\n",
      "       0.74842767, 0.80503145, 0.79874214, 0.77987421, 0.81132075,\n",
      "       0.79245283, 0.81132075, 0.79874214, 0.81761006, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.81132075, 0.80503145, 0.72327044,\n",
      "       0.7672956 , 0.81132075, 0.82389937, 0.76100629, 0.77358491,\n",
      "       0.79874214, 0.80503145, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.81132075, 0.81761006, 0.81761006, 0.80503145, 0.81761006,\n",
      "       0.79245283, 0.79245283, 0.77358491, 0.80503145, 0.79874214,\n",
      "       0.77987421, 0.79245283, 0.81132075, 0.81132075, 0.79874214,\n",
      "       0.80503145, 0.81132075, 0.81132075, 0.81761006, 0.81132075,\n",
      "       0.79874214, 0.73584906, 0.78616352, 0.79874214, 0.79874214,\n",
      "       0.77987421, 0.77358491, 0.79874214, 0.81132075, 0.79874214,\n",
      "       0.80503145, 0.81132075, 0.81132075, 0.80503145, 0.81132075,\n",
      "       0.81132075, 0.79874214, 0.74842767, 0.79874214, 0.79245283,\n",
      "       0.79874214, 0.77987421, 0.78616352, 0.77987421, 0.79245283,\n",
      "       0.81132075, 0.80503145, 0.80503145, 0.81761006, 0.80503145,\n",
      "       0.81132075, 0.80503145, 0.80503145, 0.7672956 , 0.77987421,\n",
      "       0.75471698, 0.81132075, 0.79245283, 0.7672956 , 0.81761006,\n",
      "       0.81761006, 0.79874214, 0.79874214, 0.81132075, 0.81761006,\n",
      "       0.81132075, 0.80503145, 0.79245283, 0.81132075, 0.75471698,\n",
      "       0.74842767, 0.82389937, 0.82389937, 0.79245283, 0.78616352,\n",
      "       0.78616352, 0.79245283, 0.81132075, 0.77987421, 0.80503145,\n",
      "       0.80503145, 0.7672956 , 0.81132075, 0.77358491, 0.80503145]), 'split4_test_score': array([0.72955975, 0.74213836, 0.72955975, 0.72955975, 0.72955975,\n",
      "       0.72955975, 0.72955975, 0.72955975, 0.73584906, 0.72955975,\n",
      "       0.72955975, 0.72955975, 0.73584906, 0.72955975, 0.72327044,\n",
      "       0.72327044, 0.72955975, 0.72327044, 0.73584906, 0.72955975,\n",
      "       0.73584906, 0.72955975, 0.72955975, 0.74213836, 0.72955975,\n",
      "       0.73584906, 0.73584906, 0.73584906, 0.73584906, 0.72327044,\n",
      "       0.72327044, 0.72327044, 0.75471698, 0.74213836, 0.75471698,\n",
      "       0.75471698, 0.76100629, 0.77358491, 0.77358491, 0.72955975,\n",
      "       0.77358491, 0.76100629, 0.76100629, 0.75471698, 0.76100629,\n",
      "       0.75471698, 0.75471698, 0.74842767, 0.7672956 , 0.78616352,\n",
      "       0.77358491, 0.77358491, 0.77987421, 0.77987421, 0.78616352,\n",
      "       0.77987421, 0.77358491, 0.77358491, 0.76100629, 0.79245283,\n",
      "       0.77358491, 0.77358491, 0.77987421, 0.7672956 , 0.78616352,\n",
      "       0.77987421, 0.78616352, 0.78616352, 0.77987421, 0.77987421,\n",
      "       0.77358491, 0.79245283, 0.77987421, 0.77358491, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.77987421, 0.77358491, 0.77987421,\n",
      "       0.77987421, 0.78616352, 0.7672956 , 0.77987421, 0.76100629,\n",
      "       0.79245283, 0.77358491, 0.7672956 , 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.77987421, 0.77987421, 0.78616352,\n",
      "       0.78616352, 0.79245283, 0.79874214, 0.78616352, 0.77987421,\n",
      "       0.77358491, 0.77987421, 0.77987421, 0.7672956 , 0.77358491,\n",
      "       0.77987421, 0.78616352, 0.7672956 , 0.77987421, 0.7672956 ,\n",
      "       0.77358491, 0.78616352, 0.77358491, 0.79245283, 0.78616352,\n",
      "       0.77987421, 0.7672956 , 0.77987421, 0.77987421, 0.7672956 ,\n",
      "       0.7672956 , 0.77987421, 0.78616352, 0.78616352, 0.77358491,\n",
      "       0.77987421, 0.77987421, 0.77358491, 0.72955975, 0.78616352,\n",
      "       0.7672956 , 0.7672956 , 0.7672956 , 0.74213836, 0.75471698,\n",
      "       0.77358491, 0.78616352, 0.77987421, 0.7672956 , 0.77358491,\n",
      "       0.7672956 , 0.78616352, 0.77987421, 0.78616352, 0.73584906,\n",
      "       0.74213836, 0.75471698, 0.7672956 , 0.75471698, 0.77358491,\n",
      "       0.76100629, 0.77358491, 0.77358491, 0.77358491, 0.7672956 ,\n",
      "       0.77987421, 0.77987421, 0.77987421, 0.78616352, 0.78616352,\n",
      "       0.74842767, 0.75471698, 0.74213836, 0.76100629, 0.77358491,\n",
      "       0.77358491, 0.7672956 , 0.79245283, 0.77358491, 0.77987421,\n",
      "       0.77358491, 0.77358491, 0.77987421, 0.78616352, 0.77358491,\n",
      "       0.7672956 , 0.74842767, 0.7672956 , 0.76100629, 0.74213836,\n",
      "       0.76100629, 0.7672956 , 0.7672956 , 0.7672956 , 0.7672956 ,\n",
      "       0.77987421, 0.75471698, 0.7672956 , 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.77987421, 0.74842767, 0.73584906, 0.78616352,\n",
      "       0.77358491, 0.76100629, 0.7672956 , 0.76100629, 0.7672956 ,\n",
      "       0.77358491, 0.7672956 , 0.77358491, 0.77358491, 0.7672956 ,\n",
      "       0.77987421, 0.77358491, 0.77358491, 0.72955975, 0.72955975,\n",
      "       0.75471698, 0.77358491, 0.74842767, 0.76100629, 0.77358491,\n",
      "       0.78616352, 0.7672956 , 0.7672956 , 0.76100629, 0.78616352,\n",
      "       0.77358491, 0.79245283, 0.78616352, 0.7672956 , 0.74213836,\n",
      "       0.74842767, 0.76100629, 0.76100629, 0.74842767, 0.77987421,\n",
      "       0.75471698, 0.74213836, 0.78616352, 0.7672956 , 0.77358491,\n",
      "       0.78616352, 0.77987421, 0.77987421, 0.7672956 , 0.78616352,\n",
      "       0.71698113, 0.71069182, 0.73584906, 0.77358491, 0.77358491,\n",
      "       0.74842767, 0.77358491, 0.76100629, 0.77358491, 0.78616352,\n",
      "       0.77358491, 0.78616352, 0.77987421, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.71069182, 0.72955975, 0.75471698, 0.74842767,\n",
      "       0.74842767, 0.76100629, 0.74213836, 0.76100629, 0.77358491,\n",
      "       0.75471698, 0.74842767, 0.77987421, 0.7672956 , 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.71698113, 0.71069182, 0.75471698,\n",
      "       0.76100629, 0.72955975, 0.76100629, 0.7672956 , 0.76100629,\n",
      "       0.77358491, 0.77358491, 0.77987421, 0.77987421, 0.77987421,\n",
      "       0.78616352, 0.77987421, 0.77987421, 0.73584906, 0.71069182,\n",
      "       0.75471698, 0.73584906, 0.73584906, 0.76100629, 0.7672956 ,\n",
      "       0.74842767, 0.77987421, 0.74213836, 0.77358491, 0.78616352,\n",
      "       0.7672956 , 0.77987421, 0.7672956 , 0.77358491, 0.71698113,\n",
      "       0.72955975, 0.77358491, 0.77358491, 0.74842767, 0.76100629,\n",
      "       0.75471698, 0.78616352, 0.77987421, 0.77987421, 0.78616352,\n",
      "       0.77987421, 0.77987421, 0.77358491, 0.7672956 , 0.77358491]), 'split5_test_score': array([0.74842767, 0.73584906, 0.72327044, 0.73584906, 0.73584906,\n",
      "       0.74213836, 0.73584906, 0.73584906, 0.74213836, 0.73584906,\n",
      "       0.71698113, 0.73584906, 0.73584906, 0.74213836, 0.73584906,\n",
      "       0.73584906, 0.75471698, 0.74842767, 0.72955975, 0.75471698,\n",
      "       0.77358491, 0.74842767, 0.75471698, 0.74213836, 0.75471698,\n",
      "       0.74213836, 0.75471698, 0.74842767, 0.74213836, 0.74842767,\n",
      "       0.74842767, 0.74213836, 0.79245283, 0.77358491, 0.78616352,\n",
      "       0.75471698, 0.79874214, 0.7672956 , 0.7672956 , 0.77358491,\n",
      "       0.79245283, 0.77987421, 0.78616352, 0.79245283, 0.79245283,\n",
      "       0.77987421, 0.78616352, 0.74842767, 0.81132075, 0.79245283,\n",
      "       0.82389937, 0.80503145, 0.82389937, 0.80503145, 0.79874214,\n",
      "       0.81132075, 0.79874214, 0.81132075, 0.78616352, 0.80503145,\n",
      "       0.81132075, 0.79874214, 0.81132075, 0.79874214, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.81132075, 0.83647799, 0.81132075,\n",
      "       0.81132075, 0.81761006, 0.81761006, 0.81132075, 0.79874214,\n",
      "       0.81132075, 0.81132075, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.81761006, 0.83647799, 0.81132075, 0.81132075, 0.81761006,\n",
      "       0.79245283, 0.82389937, 0.81132075, 0.80503145, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.81761006, 0.80503145, 0.81761006,\n",
      "       0.81132075, 0.81761006, 0.82389937, 0.83647799, 0.83018868,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.83018868, 0.79874214,\n",
      "       0.81761006, 0.81132075, 0.82389937, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.79245283, 0.77987421, 0.81132075,\n",
      "       0.83018868, 0.83018868, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.80503145, 0.83018868, 0.82389937, 0.80503145, 0.81132075,\n",
      "       0.79874214, 0.79874214, 0.80503145, 0.77987421, 0.78616352,\n",
      "       0.79874214, 0.80503145, 0.81132075, 0.80503145, 0.79874214,\n",
      "       0.78616352, 0.81132075, 0.79874214, 0.80503145, 0.80503145,\n",
      "       0.82389937, 0.81132075, 0.81132075, 0.82389937, 0.75471698,\n",
      "       0.77358491, 0.78616352, 0.80503145, 0.78616352, 0.77358491,\n",
      "       0.80503145, 0.81132075, 0.79874214, 0.79245283, 0.81761006,\n",
      "       0.81761006, 0.81132075, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.74213836, 0.76100629, 0.79874214, 0.80503145, 0.75471698,\n",
      "       0.7672956 , 0.77987421, 0.81132075, 0.80503145, 0.82389937,\n",
      "       0.81132075, 0.81761006, 0.81761006, 0.79245283, 0.80503145,\n",
      "       0.80503145, 0.77987421, 0.77358491, 0.79245283, 0.75471698,\n",
      "       0.76100629, 0.75471698, 0.77987421, 0.81132075, 0.79874214,\n",
      "       0.80503145, 0.80503145, 0.82389937, 0.81132075, 0.82389937,\n",
      "       0.81132075, 0.79874214, 0.72955975, 0.7672956 , 0.80503145,\n",
      "       0.77987421, 0.76100629, 0.77987421, 0.78616352, 0.78616352,\n",
      "       0.81761006, 0.77358491, 0.79874214, 0.83018868, 0.79874214,\n",
      "       0.83018868, 0.81132075, 0.81132075, 0.72955975, 0.76100629,\n",
      "       0.77358491, 0.79245283, 0.75471698, 0.76100629, 0.77987421,\n",
      "       0.82389937, 0.78616352, 0.81132075, 0.79874214, 0.79874214,\n",
      "       0.81132075, 0.81132075, 0.83018868, 0.79245283, 0.69811321,\n",
      "       0.71698113, 0.7672956 , 0.78616352, 0.75471698, 0.75471698,\n",
      "       0.74213836, 0.79245283, 0.80503145, 0.79245283, 0.79874214,\n",
      "       0.79245283, 0.79874214, 0.81761006, 0.79245283, 0.80503145,\n",
      "       0.68553459, 0.72327044, 0.77358491, 0.78616352, 0.71698113,\n",
      "       0.76100629, 0.74842767, 0.80503145, 0.81132075, 0.80503145,\n",
      "       0.77358491, 0.81761006, 0.81761006, 0.80503145, 0.79874214,\n",
      "       0.81132075, 0.6918239 , 0.73584906, 0.7672956 , 0.80503145,\n",
      "       0.72955975, 0.74213836, 0.77987421, 0.79245283, 0.81132075,\n",
      "       0.78616352, 0.78616352, 0.81132075, 0.81761006, 0.79245283,\n",
      "       0.81132075, 0.81761006, 0.70440252, 0.74213836, 0.78616352,\n",
      "       0.77987421, 0.76100629, 0.74213836, 0.76100629, 0.79874214,\n",
      "       0.77987421, 0.79245283, 0.80503145, 0.82389937, 0.81761006,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.70440252, 0.72327044,\n",
      "       0.72955975, 0.79245283, 0.74842767, 0.76100629, 0.75471698,\n",
      "       0.77358491, 0.81132075, 0.80503145, 0.81761006, 0.78616352,\n",
      "       0.81132075, 0.81761006, 0.78616352, 0.81132075, 0.6918239 ,\n",
      "       0.73584906, 0.74213836, 0.77987421, 0.74213836, 0.74213836,\n",
      "       0.77358491, 0.80503145, 0.79874214, 0.78616352, 0.79245283,\n",
      "       0.81132075, 0.79245283, 0.81132075, 0.81761006, 0.80503145]), 'split6_test_score': array([0.7672956 , 0.77358491, 0.79245283, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.74842767, 0.74213836, 0.78616352, 0.79245283,\n",
      "       0.78616352, 0.79245283, 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.78616352, 0.80503145, 0.81761006, 0.80503145, 0.79874214,\n",
      "       0.78616352, 0.79874214, 0.80503145, 0.80503145, 0.79874214,\n",
      "       0.78616352, 0.80503145, 0.78616352, 0.79874214, 0.79874214,\n",
      "       0.80503145, 0.78616352, 0.83018868, 0.83647799, 0.83018868,\n",
      "       0.80503145, 0.83647799, 0.83647799, 0.83018868, 0.83018868,\n",
      "       0.83018868, 0.83647799, 0.83647799, 0.8427673 , 0.83647799,\n",
      "       0.82389937, 0.8427673 , 0.79874214, 0.83647799, 0.82389937,\n",
      "       0.83018868, 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.83647799, 0.83018868, 0.83647799, 0.83018868, 0.81132075,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.83647799, 0.83018868, 0.8427673 , 0.83018868, 0.83647799,\n",
      "       0.8427673 , 0.83647799, 0.8427673 , 0.83647799, 0.8427673 ,\n",
      "       0.83647799, 0.81132075, 0.83647799, 0.8427673 , 0.8427673 ,\n",
      "       0.8427673 , 0.8427673 , 0.83018868, 0.83647799, 0.83647799,\n",
      "       0.82389937, 0.8427673 , 0.8427673 , 0.8427673 , 0.8427673 ,\n",
      "       0.83647799, 0.83018868, 0.82389937, 0.8490566 , 0.83647799,\n",
      "       0.8427673 , 0.8427673 , 0.8427673 , 0.83647799, 0.83647799,\n",
      "       0.83018868, 0.8427673 , 0.83647799, 0.83018868, 0.8427673 ,\n",
      "       0.83647799, 0.8427673 , 0.8427673 , 0.83647799, 0.8427673 ,\n",
      "       0.83647799, 0.8427673 , 0.83647799, 0.8427673 , 0.82389937,\n",
      "       0.83018868, 0.83647799, 0.82389937, 0.83647799, 0.83647799,\n",
      "       0.83647799, 0.8427673 , 0.8427673 , 0.83647799, 0.8427673 ,\n",
      "       0.83647799, 0.8427673 , 0.8427673 , 0.82389937, 0.8427673 ,\n",
      "       0.83018868, 0.83647799, 0.80503145, 0.82389937, 0.80503145,\n",
      "       0.81132075, 0.85534591, 0.83018868, 0.8490566 , 0.83647799,\n",
      "       0.83647799, 0.8427673 , 0.8427673 , 0.8427673 , 0.81132075,\n",
      "       0.82389937, 0.81132075, 0.81761006, 0.83018868, 0.8427673 ,\n",
      "       0.82389937, 0.82389937, 0.8427673 , 0.83018868, 0.83018868,\n",
      "       0.83647799, 0.83647799, 0.83018868, 0.83647799, 0.82389937,\n",
      "       0.79874214, 0.78616352, 0.79245283, 0.83647799, 0.79874214,\n",
      "       0.78616352, 0.83018868, 0.81132075, 0.83018868, 0.8427673 ,\n",
      "       0.83647799, 0.8427673 , 0.8427673 , 0.8427673 , 0.82389937,\n",
      "       0.83647799, 0.82389937, 0.79874214, 0.77987421, 0.8427673 ,\n",
      "       0.79245283, 0.81761006, 0.83647799, 0.81761006, 0.83018868,\n",
      "       0.83647799, 0.83647799, 0.8427673 , 0.83647799, 0.82389937,\n",
      "       0.8427673 , 0.83018868, 0.79245283, 0.81761006, 0.80503145,\n",
      "       0.81132075, 0.79874214, 0.83647799, 0.81132075, 0.81761006,\n",
      "       0.81132075, 0.8427673 , 0.8427673 , 0.83018868, 0.82389937,\n",
      "       0.83647799, 0.83647799, 0.8427673 , 0.72327044, 0.81132075,\n",
      "       0.81132075, 0.81761006, 0.81132075, 0.80503145, 0.83018868,\n",
      "       0.83647799, 0.8427673 , 0.83647799, 0.81132075, 0.82389937,\n",
      "       0.83018868, 0.83018868, 0.81132075, 0.8427673 , 0.77987421,\n",
      "       0.79874214, 0.79874214, 0.82389937, 0.83018868, 0.83647799,\n",
      "       0.81132075, 0.83018868, 0.81761006, 0.83018868, 0.81132075,\n",
      "       0.83647799, 0.83018868, 0.83647799, 0.83018868, 0.8427673 ,\n",
      "       0.79245283, 0.75471698, 0.8427673 , 0.81761006, 0.83647799,\n",
      "       0.81132075, 0.82389937, 0.81761006, 0.83018868, 0.82389937,\n",
      "       0.82389937, 0.83647799, 0.83647799, 0.8427673 , 0.83647799,\n",
      "       0.83018868, 0.7672956 , 0.81761006, 0.79245283, 0.83018868,\n",
      "       0.81761006, 0.83018868, 0.81761006, 0.83018868, 0.82389937,\n",
      "       0.82389937, 0.83018868, 0.83018868, 0.83018868, 0.83647799,\n",
      "       0.83647799, 0.83647799, 0.74842767, 0.80503145, 0.79874214,\n",
      "       0.83018868, 0.78616352, 0.79874214, 0.83018868, 0.8427673 ,\n",
      "       0.82389937, 0.83018868, 0.81761006, 0.82389937, 0.83647799,\n",
      "       0.81761006, 0.8490566 , 0.83647799, 0.75471698, 0.79874214,\n",
      "       0.81132075, 0.82389937, 0.83647799, 0.79245283, 0.81761006,\n",
      "       0.82389937, 0.8427673 , 0.8427673 , 0.82389937, 0.81761006,\n",
      "       0.8490566 , 0.83647799, 0.8427673 , 0.83647799, 0.7672956 ,\n",
      "       0.77358491, 0.78616352, 0.83647799, 0.79874214, 0.80503145,\n",
      "       0.8427673 , 0.82389937, 0.8427673 , 0.82389937, 0.82389937,\n",
      "       0.83647799, 0.83018868, 0.8427673 , 0.83647799, 0.83647799]), 'split7_test_score': array([0.74213836, 0.76100629, 0.76100629, 0.7672956 , 0.77358491,\n",
      "       0.76100629, 0.76100629, 0.76100629, 0.74842767, 0.74842767,\n",
      "       0.76100629, 0.76100629, 0.76100629, 0.76100629, 0.76100629,\n",
      "       0.75471698, 0.77358491, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.76100629, 0.78616352, 0.77358491, 0.77987421, 0.7672956 ,\n",
      "       0.77358491, 0.77358491, 0.78616352, 0.77358491, 0.77987421,\n",
      "       0.7672956 , 0.77987421, 0.79874214, 0.79245283, 0.80503145,\n",
      "       0.81132075, 0.78616352, 0.81132075, 0.79245283, 0.79874214,\n",
      "       0.80503145, 0.79874214, 0.79245283, 0.79874214, 0.80503145,\n",
      "       0.81132075, 0.79874214, 0.79245283, 0.80503145, 0.79874214,\n",
      "       0.81761006, 0.81132075, 0.81761006, 0.79245283, 0.80503145,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.81761006, 0.81761006,\n",
      "       0.80503145, 0.81132075, 0.80503145, 0.77358491, 0.81132075,\n",
      "       0.81761006, 0.81761006, 0.81132075, 0.81132075, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.80503145, 0.81132075, 0.81132075,\n",
      "       0.79874214, 0.81132075, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.81132075, 0.81132075, 0.81132075, 0.78616352,\n",
      "       0.80503145, 0.81132075, 0.81132075, 0.81132075, 0.80503145,\n",
      "       0.81132075, 0.81132075, 0.78616352, 0.79874214, 0.80503145,\n",
      "       0.81132075, 0.80503145, 0.81132075, 0.80503145, 0.79874214,\n",
      "       0.78616352, 0.81132075, 0.81132075, 0.81761006, 0.80503145,\n",
      "       0.80503145, 0.81132075, 0.79874214, 0.79874214, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.81132075, 0.80503145,\n",
      "       0.81761006, 0.81132075, 0.81761006, 0.80503145, 0.79245283,\n",
      "       0.81132075, 0.80503145, 0.79245283, 0.79874214, 0.80503145,\n",
      "       0.81132075, 0.79245283, 0.79245283, 0.78616352, 0.81761006,\n",
      "       0.80503145, 0.80503145, 0.78616352, 0.82389937, 0.80503145,\n",
      "       0.81132075, 0.80503145, 0.80503145, 0.81132075, 0.81132075,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.80503145, 0.77987421,\n",
      "       0.80503145, 0.81132075, 0.80503145, 0.80503145, 0.81132075,\n",
      "       0.81761006, 0.79874214, 0.79245283, 0.81132075, 0.81132075,\n",
      "       0.81761006, 0.79874214, 0.81132075, 0.81761006, 0.81132075,\n",
      "       0.75471698, 0.79245283, 0.81132075, 0.80503145, 0.77358491,\n",
      "       0.80503145, 0.81761006, 0.80503145, 0.80503145, 0.77987421,\n",
      "       0.81132075, 0.80503145, 0.79245283, 0.80503145, 0.78616352,\n",
      "       0.79245283, 0.77358491, 0.77987421, 0.79874214, 0.81132075,\n",
      "       0.77987421, 0.80503145, 0.7672956 , 0.80503145, 0.80503145,\n",
      "       0.81761006, 0.79874214, 0.80503145, 0.79245283, 0.80503145,\n",
      "       0.80503145, 0.79874214, 0.76100629, 0.79874214, 0.7672956 ,\n",
      "       0.80503145, 0.79245283, 0.79874214, 0.79874214, 0.81132075,\n",
      "       0.80503145, 0.80503145, 0.79874214, 0.81132075, 0.81132075,\n",
      "       0.79874214, 0.79245283, 0.80503145, 0.71069182, 0.80503145,\n",
      "       0.79874214, 0.81132075, 0.79245283, 0.75471698, 0.79245283,\n",
      "       0.77987421, 0.77987421, 0.79245283, 0.81132075, 0.79245283,\n",
      "       0.81132075, 0.79874214, 0.81132075, 0.79245283, 0.74842767,\n",
      "       0.76100629, 0.80503145, 0.80503145, 0.78616352, 0.78616352,\n",
      "       0.81132075, 0.79874214, 0.80503145, 0.77358491, 0.81132075,\n",
      "       0.79874214, 0.80503145, 0.79874214, 0.81132075, 0.80503145,\n",
      "       0.74842767, 0.75471698, 0.80503145, 0.80503145, 0.74842767,\n",
      "       0.77987421, 0.80503145, 0.78616352, 0.80503145, 0.77987421,\n",
      "       0.81761006, 0.79874214, 0.79245283, 0.79874214, 0.81132075,\n",
      "       0.81132075, 0.74842767, 0.7672956 , 0.79245283, 0.79874214,\n",
      "       0.75471698, 0.77987421, 0.79245283, 0.80503145, 0.79874214,\n",
      "       0.81132075, 0.80503145, 0.81132075, 0.80503145, 0.81132075,\n",
      "       0.79245283, 0.80503145, 0.76100629, 0.75471698, 0.76100629,\n",
      "       0.79245283, 0.77987421, 0.78616352, 0.81132075, 0.77358491,\n",
      "       0.81132075, 0.79245283, 0.79245283, 0.79874214, 0.79874214,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.7672956 , 0.73584906,\n",
      "       0.81132075, 0.80503145, 0.77987421, 0.79245283, 0.78616352,\n",
      "       0.79245283, 0.81132075, 0.80503145, 0.80503145, 0.80503145,\n",
      "       0.79245283, 0.80503145, 0.80503145, 0.81132075, 0.72327044,\n",
      "       0.73584906, 0.78616352, 0.79245283, 0.7672956 , 0.80503145,\n",
      "       0.78616352, 0.79245283, 0.78616352, 0.79874214, 0.80503145,\n",
      "       0.80503145, 0.81132075, 0.81132075, 0.77987421, 0.79874214]), 'split8_test_score': array([0.76100629, 0.75471698, 0.76100629, 0.76100629, 0.74842767,\n",
      "       0.74213836, 0.76100629, 0.75471698, 0.74842767, 0.75471698,\n",
      "       0.75471698, 0.75471698, 0.75471698, 0.75471698, 0.75471698,\n",
      "       0.74213836, 0.7672956 , 0.75471698, 0.7672956 , 0.75471698,\n",
      "       0.75471698, 0.74842767, 0.77358491, 0.74842767, 0.7672956 ,\n",
      "       0.75471698, 0.75471698, 0.75471698, 0.74842767, 0.75471698,\n",
      "       0.75471698, 0.78616352, 0.80503145, 0.79874214, 0.79245283,\n",
      "       0.81132075, 0.75471698, 0.79245283, 0.79245283, 0.78616352,\n",
      "       0.77987421, 0.76100629, 0.76100629, 0.83018868, 0.79874214,\n",
      "       0.78616352, 0.79245283, 0.77358491, 0.81132075, 0.83018868,\n",
      "       0.83647799, 0.81132075, 0.81761006, 0.81761006, 0.79874214,\n",
      "       0.8427673 , 0.83018868, 0.8427673 , 0.81132075, 0.80503145,\n",
      "       0.83647799, 0.81761006, 0.82389937, 0.82389937, 0.82389937,\n",
      "       0.83647799, 0.83018868, 0.82389937, 0.81132075, 0.82389937,\n",
      "       0.83647799, 0.83647799, 0.8490566 , 0.82389937, 0.83018868,\n",
      "       0.82389937, 0.8427673 , 0.81761006, 0.80503145, 0.83018868,\n",
      "       0.83647799, 0.83018868, 0.81761006, 0.83018868, 0.83647799,\n",
      "       0.83647799, 0.83647799, 0.83647799, 0.81761006, 0.83647799,\n",
      "       0.83018868, 0.82389937, 0.8427673 , 0.81761006, 0.8490566 ,\n",
      "       0.8427673 , 0.8427673 , 0.83018868, 0.8427673 , 0.83018868,\n",
      "       0.81132075, 0.83018868, 0.83018868, 0.8427673 , 0.8490566 ,\n",
      "       0.79874214, 0.8490566 , 0.82389937, 0.83018868, 0.81761006,\n",
      "       0.79874214, 0.8427673 , 0.83018868, 0.83647799, 0.83647799,\n",
      "       0.83018868, 0.8427673 , 0.8490566 , 0.8490566 , 0.83018868,\n",
      "       0.85534591, 0.82389937, 0.79874214, 0.82389937, 0.81132075,\n",
      "       0.83018868, 0.83647799, 0.83018868, 0.83018868, 0.82389937,\n",
      "       0.8490566 , 0.8427673 , 0.8427673 , 0.83647799, 0.81761006,\n",
      "       0.83018868, 0.83018868, 0.81132075, 0.79874214, 0.80503145,\n",
      "       0.82389937, 0.83647799, 0.81132075, 0.82389937, 0.82389937,\n",
      "       0.80503145, 0.81761006, 0.8427673 , 0.79874214, 0.83647799,\n",
      "       0.82389937, 0.81761006, 0.8427673 , 0.80503145, 0.83647799,\n",
      "       0.81761006, 0.81761006, 0.83647799, 0.83647799, 0.83647799,\n",
      "       0.79245283, 0.82389937, 0.8427673 , 0.78616352, 0.83647799,\n",
      "       0.81132075, 0.83018868, 0.82389937, 0.83647799, 0.8427673 ,\n",
      "       0.80503145, 0.83647799, 0.83018868, 0.83018868, 0.79874214,\n",
      "       0.82389937, 0.81132075, 0.81761006, 0.81761006, 0.83018868,\n",
      "       0.83647799, 0.81761006, 0.81761006, 0.81761006, 0.83647799,\n",
      "       0.83018868, 0.81761006, 0.83018868, 0.83018868, 0.81761006,\n",
      "       0.82389937, 0.80503145, 0.81132075, 0.77358491, 0.79874214,\n",
      "       0.81761006, 0.81132075, 0.83018868, 0.8427673 , 0.83647799,\n",
      "       0.83647799, 0.83647799, 0.82389937, 0.8490566 , 0.81132075,\n",
      "       0.83647799, 0.83018868, 0.82389937, 0.77987421, 0.8427673 ,\n",
      "       0.81132075, 0.80503145, 0.81761006, 0.83018868, 0.83647799,\n",
      "       0.81761006, 0.82389937, 0.80503145, 0.83647799, 0.83647799,\n",
      "       0.81761006, 0.8427673 , 0.82389937, 0.82389937, 0.80503145,\n",
      "       0.81132075, 0.81761006, 0.81132075, 0.8490566 , 0.81132075,\n",
      "       0.81132075, 0.82389937, 0.82389937, 0.8427673 , 0.83647799,\n",
      "       0.8427673 , 0.82389937, 0.8490566 , 0.82389937, 0.83018868,\n",
      "       0.78616352, 0.79245283, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.82389937, 0.8490566 , 0.8427673 , 0.82389937, 0.81132075,\n",
      "       0.81761006, 0.83018868, 0.8490566 , 0.8427673 , 0.8427673 ,\n",
      "       0.79874214, 0.75471698, 0.78616352, 0.82389937, 0.8427673 ,\n",
      "       0.82389937, 0.82389937, 0.81132075, 0.83647799, 0.82389937,\n",
      "       0.83647799, 0.83018868, 0.8427673 , 0.83647799, 0.83647799,\n",
      "       0.82389937, 0.83647799, 0.77987421, 0.81761006, 0.83647799,\n",
      "       0.83018868, 0.83647799, 0.83018868, 0.79245283, 0.83018868,\n",
      "       0.83018868, 0.8490566 , 0.83647799, 0.82389937, 0.81761006,\n",
      "       0.83018868, 0.81761006, 0.83647799, 0.75471698, 0.77358491,\n",
      "       0.81132075, 0.83647799, 0.83647799, 0.81132075, 0.81132075,\n",
      "       0.82389937, 0.83647799, 0.81761006, 0.83018868, 0.85534591,\n",
      "       0.82389937, 0.82389937, 0.83018868, 0.81132075, 0.77987421,\n",
      "       0.79245283, 0.81132075, 0.80503145, 0.83018868, 0.81132075,\n",
      "       0.8490566 , 0.83647799, 0.81761006, 0.83647799, 0.82389937,\n",
      "       0.83018868, 0.8427673 , 0.82389937, 0.83647799, 0.8427673 ]), 'split9_test_score': array([0.76582278, 0.76582278, 0.70253165, 0.76582278, 0.7721519 ,\n",
      "       0.76582278, 0.76582278, 0.74683544, 0.74050633, 0.76582278,\n",
      "       0.7721519 , 0.7721519 , 0.7721519 , 0.7721519 , 0.7721519 ,\n",
      "       0.77848101, 0.76582278, 0.78481013, 0.77848101, 0.7721519 ,\n",
      "       0.7721519 , 0.79113924, 0.77848101, 0.79113924, 0.7721519 ,\n",
      "       0.76582278, 0.7721519 , 0.78481013, 0.76582278, 0.79746835,\n",
      "       0.79113924, 0.77848101, 0.84810127, 0.85443038, 0.82278481,\n",
      "       0.82911392, 0.82911392, 0.81012658, 0.84177215, 0.82911392,\n",
      "       0.82278481, 0.8164557 , 0.85443038, 0.83544304, 0.83544304,\n",
      "       0.82278481, 0.83544304, 0.82278481, 0.84810127, 0.85443038,\n",
      "       0.84810127, 0.86075949, 0.84177215, 0.84177215, 0.85443038,\n",
      "       0.84177215, 0.86075949, 0.84177215, 0.84810127, 0.84177215,\n",
      "       0.84810127, 0.84177215, 0.84810127, 0.84810127, 0.84810127,\n",
      "       0.83544304, 0.83544304, 0.86075949, 0.85443038, 0.82278481,\n",
      "       0.85443038, 0.84810127, 0.85443038, 0.85443038, 0.85443038,\n",
      "       0.82911392, 0.84177215, 0.82911392, 0.84810127, 0.84810127,\n",
      "       0.84810127, 0.85443038, 0.82911392, 0.83544304, 0.85443038,\n",
      "       0.84177215, 0.84810127, 0.85443038, 0.84810127, 0.85443038,\n",
      "       0.83544304, 0.83544304, 0.82911392, 0.84810127, 0.84810127,\n",
      "       0.85443038, 0.82911392, 0.81012658, 0.85443038, 0.82278481,\n",
      "       0.82911392, 0.82911392, 0.84810127, 0.85443038, 0.84810127,\n",
      "       0.82911392, 0.82911392, 0.85443038, 0.84810127, 0.8164557 ,\n",
      "       0.84810127, 0.84177215, 0.82278481, 0.81012658, 0.84177215,\n",
      "       0.84810127, 0.86075949, 0.84177215, 0.82278481, 0.8164557 ,\n",
      "       0.85443038, 0.84177215, 0.82278481, 0.83544304, 0.82278481,\n",
      "       0.82911392, 0.84177215, 0.84810127, 0.79746835, 0.82278481,\n",
      "       0.8164557 , 0.82911392, 0.82278481, 0.81012658, 0.8164557 ,\n",
      "       0.83544304, 0.84810127, 0.82911392, 0.83544304, 0.83544304,\n",
      "       0.84810127, 0.84177215, 0.83544304, 0.82911392, 0.79746835,\n",
      "       0.8164557 , 0.80379747, 0.82911392, 0.8164557 , 0.79746835,\n",
      "       0.81012658, 0.84810127, 0.82278481, 0.84810127, 0.8164557 ,\n",
      "       0.83544304, 0.8164557 , 0.82911392, 0.83544304, 0.84810127,\n",
      "       0.77848101, 0.79113924, 0.78481013, 0.8164557 , 0.80379747,\n",
      "       0.80379747, 0.79746835, 0.83544304, 0.84177215, 0.84177215,\n",
      "       0.82911392, 0.85443038, 0.79113924, 0.86075949, 0.82911392,\n",
      "       0.84177215, 0.74683544, 0.78481013, 0.80379747, 0.82278481,\n",
      "       0.77848101, 0.80379747, 0.83544304, 0.81012658, 0.83544304,\n",
      "       0.82911392, 0.82911392, 0.85443038, 0.85443038, 0.8164557 ,\n",
      "       0.84810127, 0.82911392, 0.77848101, 0.81012658, 0.8164557 ,\n",
      "       0.84177215, 0.79746835, 0.79746835, 0.79746835, 0.79113924,\n",
      "       0.84810127, 0.83544304, 0.82911392, 0.83544304, 0.84810127,\n",
      "       0.84177215, 0.82911392, 0.85443038, 0.7721519 , 0.75316456,\n",
      "       0.79113924, 0.82278481, 0.79113924, 0.78481013, 0.80379747,\n",
      "       0.84810127, 0.84810127, 0.82911392, 0.82278481, 0.8164557 ,\n",
      "       0.84177215, 0.84177215, 0.82911392, 0.84177215, 0.76582278,\n",
      "       0.78481013, 0.79746835, 0.8164557 , 0.77848101, 0.75949367,\n",
      "       0.82911392, 0.82278481, 0.84177215, 0.79746835, 0.82278481,\n",
      "       0.82278481, 0.84810127, 0.83544304, 0.84177215, 0.84810127,\n",
      "       0.74683544, 0.77848101, 0.79746835, 0.8164557 , 0.79113924,\n",
      "       0.76582278, 0.81012658, 0.82911392, 0.83544304, 0.82911392,\n",
      "       0.84177215, 0.84177215, 0.8164557 , 0.82278481, 0.84810127,\n",
      "       0.83544304, 0.73417722, 0.77848101, 0.76582278, 0.82911392,\n",
      "       0.76582278, 0.80379747, 0.81012658, 0.8164557 , 0.86075949,\n",
      "       0.84177215, 0.83544304, 0.8164557 , 0.82278481, 0.84810127,\n",
      "       0.84177215, 0.83544304, 0.74050633, 0.75316456, 0.79746835,\n",
      "       0.80379747, 0.80379747, 0.79113924, 0.79746835, 0.81012658,\n",
      "       0.84177215, 0.84177215, 0.83544304, 0.83544304, 0.82278481,\n",
      "       0.82911392, 0.83544304, 0.86075949, 0.74050633, 0.77848101,\n",
      "       0.79113924, 0.81012658, 0.80379747, 0.78481013, 0.8164557 ,\n",
      "       0.84810127, 0.82278481, 0.82278481, 0.84810127, 0.83544304,\n",
      "       0.85443038, 0.85443038, 0.83544304, 0.85443038, 0.74050633,\n",
      "       0.75949367, 0.78481013, 0.82278481, 0.79113924, 0.78481013,\n",
      "       0.82911392, 0.79113924, 0.84810127, 0.83544304, 0.86075949,\n",
      "       0.82278481, 0.84177215, 0.84177215, 0.83544304, 0.83544304]), 'mean_test_score': array([0.76023008, 0.76589045, 0.7608192 , 0.76777725, 0.76652337,\n",
      "       0.76526152, 0.75834328, 0.75770241, 0.75958522, 0.76337473,\n",
      "       0.76086299, 0.76463657, 0.76463657, 0.76337871, 0.76589444,\n",
      "       0.76086697, 0.77595335, 0.77659422, 0.77407452, 0.77407054,\n",
      "       0.77092588, 0.77156675, 0.77847703, 0.77974285, 0.7753284 ,\n",
      "       0.76777725, 0.77721519, 0.77596529, 0.77217976, 0.77786004,\n",
      "       0.77471141, 0.77659024, 0.81059629, 0.80745562, 0.80869358,\n",
      "       0.79800573, 0.80240825, 0.80805668, 0.80618979, 0.80115039,\n",
      "       0.80366213, 0.80365815, 0.80808455, 0.8099594 , 0.80807261,\n",
      "       0.80617785, 0.8099594 , 0.79863068, 0.81940132, 0.82003423,\n",
      "       0.82128811, 0.81878035, 0.82128413, 0.81813948, 0.81688958,\n",
      "       0.8206552 , 0.82129608, 0.82002627, 0.81122522, 0.82002627,\n",
      "       0.82317491, 0.81310803, 0.81814346, 0.8168856 , 0.82128811,\n",
      "       0.82253801, 0.82128015, 0.82569859, 0.82317889, 0.81812754,\n",
      "       0.82569461, 0.8250617 , 0.82443675, 0.82129209, 0.82632354,\n",
      "       0.81876045, 0.82002627, 0.81876045, 0.81877239, 0.82191704,\n",
      "       0.8250617 , 0.8275814 , 0.81938938, 0.82065122, 0.82192103,\n",
      "       0.81876841, 0.82380384, 0.82443675, 0.82191704, 0.82443675,\n",
      "       0.82253801, 0.82065122, 0.82001831, 0.81751453, 0.82443277,\n",
      "       0.82380782, 0.82819441, 0.8206353 , 0.82506568, 0.81812754,\n",
      "       0.81561579, 0.82064724, 0.82128811, 0.82003423, 0.82003025,\n",
      "       0.81624473, 0.82064724, 0.82192103, 0.82191704, 0.81246318,\n",
      "       0.82003025, 0.82505772, 0.8112093 , 0.81497492, 0.81688162,\n",
      "       0.82569063, 0.82632752, 0.81876841, 0.81561181, 0.81183425,\n",
      "       0.82380782, 0.82317093, 0.81812754, 0.81624871, 0.81498288,\n",
      "       0.81687366, 0.81939734, 0.82128811, 0.79609904, 0.81058037,\n",
      "       0.81372104, 0.81687366, 0.81183823, 0.80365417, 0.80177136,\n",
      "       0.8099594 , 0.82317491, 0.81498686, 0.8181355 , 0.8181355 ,\n",
      "       0.81814346, 0.82317093, 0.81939336, 0.82064724, 0.79421224,\n",
      "       0.79673991, 0.79673195, 0.81498686, 0.80428708, 0.80490407,\n",
      "       0.80113844, 0.81625667, 0.81498288, 0.81311201, 0.8149789 ,\n",
      "       0.81876443, 0.81372104, 0.81813152, 0.82316695, 0.81751453,\n",
      "       0.77659024, 0.78162965, 0.79672001, 0.80931853, 0.79736088,\n",
      "       0.79736088, 0.805533  , 0.81058833, 0.81499483, 0.81939734,\n",
      "       0.81310007, 0.8194053 , 0.81559191, 0.82066714, 0.80932649,\n",
      "       0.81499483, 0.77342568, 0.77533636, 0.79232943, 0.81058037,\n",
      "       0.78979779, 0.79044264, 0.80115437, 0.80616989, 0.81499084,\n",
      "       0.81813152, 0.80806863, 0.8194053 , 0.82003423, 0.81560783,\n",
      "       0.82003025, 0.81498686, 0.77155879, 0.77849693, 0.80240029,\n",
      "       0.80618979, 0.78477828, 0.79672797, 0.80427514, 0.80741581,\n",
      "       0.81562774, 0.80429902, 0.81310007, 0.82065122, 0.81311201,\n",
      "       0.8206552 , 0.81813152, 0.81751851, 0.74513972, 0.78286363,\n",
      "       0.78791896, 0.80743571, 0.78225858, 0.78099674, 0.79861874,\n",
      "       0.81751453, 0.81436988, 0.81121328, 0.81246716, 0.81434997,\n",
      "       0.81310803, 0.82317093, 0.81813152, 0.81751055, 0.74387788,\n",
      "       0.76653133, 0.7891808 , 0.80365815, 0.78162169, 0.78349654,\n",
      "       0.79549001, 0.80680678, 0.81688162, 0.80679086, 0.81624075,\n",
      "       0.81812754, 0.81940132, 0.82316695, 0.81436589, 0.81877239,\n",
      "       0.7514131 , 0.75898018, 0.79232545, 0.80806066, 0.77911392,\n",
      "       0.78287159, 0.80302524, 0.80869756, 0.81373298, 0.80995542,\n",
      "       0.80933445, 0.8206552 , 0.81938142, 0.82253005, 0.82191704,\n",
      "       0.81750657, 0.73945546, 0.76338269, 0.78601624, 0.80806863,\n",
      "       0.77155083, 0.77912189, 0.78981769, 0.80994746, 0.81815142,\n",
      "       0.81373696, 0.8099594 , 0.81749463, 0.81624075, 0.82254598,\n",
      "       0.81813948, 0.81876443, 0.74134623, 0.75519067, 0.7891808 ,\n",
      "       0.80113446, 0.78100868, 0.78225858, 0.79232545, 0.8042831 ,\n",
      "       0.81436589, 0.81688162, 0.81561978, 0.81876443, 0.81686968,\n",
      "       0.81813152, 0.82002229, 0.82632752, 0.74323302, 0.7533198 ,\n",
      "       0.78540323, 0.80616989, 0.7835244 , 0.77659422, 0.79359526,\n",
      "       0.80116233, 0.81749861, 0.81058037, 0.81562774, 0.81876443,\n",
      "       0.82192103, 0.82129209, 0.81247512, 0.82129209, 0.74134623,\n",
      "       0.75330786, 0.78791497, 0.80491999, 0.77534034, 0.77785208,\n",
      "       0.80177932, 0.8111894 , 0.81248308, 0.81373298, 0.81689356,\n",
      "       0.81875647, 0.81499483, 0.822542  , 0.81624871, 0.81499084]), 'std_test_score': array([0.02565808, 0.02738239, 0.03215763, 0.0281966 , 0.02885178,\n",
      "       0.02784458, 0.02317622, 0.02663262, 0.02428632, 0.02785591,\n",
      "       0.02806577, 0.0266691 , 0.02195038, 0.02465839, 0.02616684,\n",
      "       0.02845626, 0.02691244, 0.03144001, 0.02844446, 0.02734166,\n",
      "       0.02355465, 0.02598944, 0.03000175, 0.02835103, 0.03057169,\n",
      "       0.02705106, 0.03460378, 0.02810927, 0.02668506, 0.03047559,\n",
      "       0.03135014, 0.02856777, 0.03176366, 0.03878043, 0.02960505,\n",
      "       0.03630316, 0.04051225, 0.02938814, 0.02545322, 0.03798941,\n",
      "       0.02535255, 0.03309053, 0.03722588, 0.03158724, 0.03262226,\n",
      "       0.03085198, 0.02991504, 0.03681317, 0.02702888, 0.02599157,\n",
      "       0.02820277, 0.02782433, 0.02707666, 0.02796362, 0.02997455,\n",
      "       0.02649098, 0.03136059, 0.02750688, 0.03388052, 0.02525792,\n",
      "       0.02974485, 0.02967562, 0.02972869, 0.03239888, 0.02345533,\n",
      "       0.02733501, 0.02281853, 0.02672254, 0.02542579, 0.0240815 ,\n",
      "       0.02941559, 0.02439622, 0.03116176, 0.029955  , 0.02749225,\n",
      "       0.02690553, 0.02793496, 0.0252366 , 0.03030393, 0.02732879,\n",
      "       0.02656936, 0.0242883 , 0.02781164, 0.02782275, 0.03319516,\n",
      "       0.0282963 , 0.02674292, 0.0291957 , 0.02832385, 0.02708732,\n",
      "       0.02790783, 0.02417105, 0.02530456, 0.03071487, 0.02907647,\n",
      "       0.02885986, 0.02500138, 0.02259797, 0.03004563, 0.02456933,\n",
      "       0.03051061, 0.02285137, 0.0273483 , 0.02832205, 0.03151083,\n",
      "       0.02275256, 0.03003193, 0.03148275, 0.02689107, 0.02822047,\n",
      "       0.02943392, 0.02552688, 0.02678089, 0.02746205, 0.02650666,\n",
      "       0.02327866, 0.02614855, 0.02787377, 0.02987703, 0.02967327,\n",
      "       0.02980385, 0.02881722, 0.02612973, 0.02341205, 0.02577328,\n",
      "       0.02517362, 0.02748303, 0.030494  , 0.03537001, 0.02594551,\n",
      "       0.02757344, 0.03017613, 0.03044018, 0.03358613, 0.02865693,\n",
      "       0.02924644, 0.02724622, 0.02767339, 0.02769938, 0.02826482,\n",
      "       0.02919162, 0.02798152, 0.02632778, 0.02353358, 0.02797529,\n",
      "       0.02733636, 0.01944856, 0.02906763, 0.02669509, 0.02857603,\n",
      "       0.02530029, 0.02683413, 0.03067816, 0.02939127, 0.03146437,\n",
      "       0.02831606, 0.0248575 , 0.02670379, 0.02469971, 0.02581696,\n",
      "       0.02800845, 0.0315363 , 0.0313756 , 0.02838235, 0.02806778,\n",
      "       0.02632237, 0.02751402, 0.02605133, 0.02805836, 0.0295632 ,\n",
      "       0.02477728, 0.02992941, 0.02796337, 0.03020881, 0.02734211,\n",
      "       0.0287546 , 0.02799152, 0.02836541, 0.023804  , 0.03826588,\n",
      "       0.0282076 , 0.03564613, 0.03295629, 0.02603262, 0.03024794,\n",
      "       0.02304642, 0.03024955, 0.03470305, 0.03162144, 0.02668477,\n",
      "       0.02861623, 0.02879418, 0.02383044, 0.03204819, 0.01882062,\n",
      "       0.02825202, 0.02325733, 0.03042462, 0.029985  , 0.02737416,\n",
      "       0.02519735, 0.03463382, 0.02849018, 0.03092022, 0.03057853,\n",
      "       0.02708166, 0.02757823, 0.02842546, 0.02581653, 0.03368019,\n",
      "       0.02908401, 0.02118916, 0.02466266, 0.02413795, 0.03142403,\n",
      "       0.02787957, 0.0317501 , 0.0303586 , 0.02819619, 0.02438653,\n",
      "       0.02817127, 0.02936114, 0.02470321, 0.03034268, 0.0342416 ,\n",
      "       0.02680216, 0.02769648, 0.02537817, 0.03469265, 0.0260975 ,\n",
      "       0.03425489, 0.02997641, 0.02229159, 0.02628476, 0.02346535,\n",
      "       0.02913581, 0.02628697, 0.0272867 , 0.03176558, 0.03195578,\n",
      "       0.03224219, 0.02688134, 0.03325801, 0.02623325, 0.03877306,\n",
      "       0.02810696, 0.0352223 , 0.02890786, 0.02462002, 0.02597207,\n",
      "       0.02581264, 0.02619064, 0.02640315, 0.0255904 , 0.02599352,\n",
      "       0.02719986, 0.02644372, 0.03227171, 0.01943126, 0.03239635,\n",
      "       0.03045462, 0.03440923, 0.0269151 , 0.02556198, 0.02833652,\n",
      "       0.02733982, 0.03293593, 0.02419793, 0.03101611, 0.02978934,\n",
      "       0.02651138, 0.02845541, 0.02168751, 0.04157629, 0.02812167,\n",
      "       0.03244937, 0.02771177, 0.02576091, 0.02229219, 0.02745157,\n",
      "       0.03010329, 0.02795915, 0.02970247, 0.02220962, 0.02566611,\n",
      "       0.02405419, 0.02679929, 0.02901669, 0.0215829 , 0.02839143,\n",
      "       0.03549309, 0.03312076, 0.03334523, 0.01709675, 0.03525579,\n",
      "       0.03433939, 0.02433189, 0.03017452, 0.0237425 , 0.02775166,\n",
      "       0.03222778, 0.02818613, 0.03083517, 0.02942206, 0.02410608,\n",
      "       0.02077137, 0.0265548 , 0.02615664, 0.02929842, 0.02865484,\n",
      "       0.03982619, 0.02572415, 0.02622413, 0.02984869, 0.03048468,\n",
      "       0.02541882, 0.03381228, 0.02816949, 0.03295569, 0.03024794]), 'rank_test_score': array([306, 296, 305, 291, 294, 297, 309, 310, 307, 302, 304, 298, 298,\n",
      "       301, 295, 303, 278, 274, 283, 284, 290, 287, 269, 265, 281, 291,\n",
      "       272, 277, 286, 270, 282, 275, 176, 198, 191, 231, 220, 197, 203,\n",
      "       226, 215, 216, 192, 182, 193, 205, 181, 229,  75,  61,  44,  81,\n",
      "        48,  96, 118,  51,  40,  67, 172,  69,  21, 162,  94, 119,  44,\n",
      "        30,  49,   6,  20, 105,   7,  10,  13,  41,   5,  90,  67,  90,\n",
      "        82,  36,  10,   2,  79,  54,  33,  84,  19,  13,  36,  13,  30,\n",
      "        54,  71, 110,  16,  17,   1,  60,   9, 105, 135,  57,  44,  61,\n",
      "        65, 129,  57,  33,  36, 169,  65,  12, 174, 150, 120,   8,   3,\n",
      "        84, 136, 171,  17,  23, 105, 127, 147, 123,  76,  44, 238, 179,\n",
      "       158, 123, 170, 218, 223, 182,  21, 144,  98,  98,  94,  23,  78,\n",
      "        57, 240, 234, 235, 144, 212, 210, 227, 126, 147, 160, 149,  86,\n",
      "       158, 100,  26, 110, 275, 261, 237, 189, 232, 233, 208, 177, 139,\n",
      "        76, 165,  72, 138,  50, 188, 140, 285, 280, 242, 179, 247, 245,\n",
      "       225, 206, 142, 100, 194,  72,  61, 137,  64, 144, 288, 268, 221,\n",
      "       204, 254, 236, 214, 200, 132, 211, 164,  54, 160,  51, 100, 109,\n",
      "       315, 258, 250, 199, 259, 264, 230, 110, 151, 173, 168, 154, 162,\n",
      "        23, 100, 113, 316, 293, 248, 216, 262, 256, 239, 201, 120, 202,\n",
      "       130, 105,  74,  26, 152,  82, 314, 308, 244, 196, 267, 257, 219,\n",
      "       190, 156, 185, 187,  51,  80,  32,  36, 114, 320, 300, 252, 194,\n",
      "       289, 266, 246, 186,  93, 155, 182, 116, 130,  28,  96,  87, 318,\n",
      "       311, 248, 228, 263, 259, 243, 213, 152, 120, 134,  87, 125, 100,\n",
      "        70,   4, 317, 312, 253, 206, 255, 273, 241, 224, 115, 178, 132,\n",
      "        87,  33,  41, 167,  41, 318, 313, 251, 209, 279, 271, 222, 175,\n",
      "       166, 156, 117,  92, 140,  29, 127, 142])}\n",
      "Resultados para SMOTEENN:\n",
      "{'mean_fit_time': array([0.12729621, 0.12415059, 0.12485905, 0.12521918, 0.12552118,\n",
      "       0.12443771, 0.12430208, 0.12553523, 0.13379767, 0.12722716,\n",
      "       0.13119624, 0.12710619, 0.13592849, 0.12647009, 0.12727664,\n",
      "       0.12720833, 0.12949097, 0.1575541 , 0.12994337, 0.14097624,\n",
      "       0.13069568, 0.13230097, 0.13048921, 0.12949071, 0.13058386,\n",
      "       0.13102987, 0.12997115, 0.13368094, 0.12968459, 0.12919226,\n",
      "       0.12979751, 0.12969382, 0.13182812, 0.1339467 , 0.13245449,\n",
      "       0.13244302, 0.14142108, 0.13419695, 0.13324003, 0.13480256,\n",
      "       0.13371005, 0.14454212, 0.13369429, 0.13156917, 0.13111567,\n",
      "       0.13316226, 0.13115153, 0.13085353, 0.13576047, 0.13556924,\n",
      "       0.1352705 , 0.13559511, 0.13982291, 0.13628402, 0.13433981,\n",
      "       0.13295085, 0.13204069, 0.13324962, 0.13440833, 0.1343406 ,\n",
      "       0.13354297, 0.13330386, 0.13524156, 0.13440211, 0.13953998,\n",
      "       0.1351141 , 0.13722596, 0.13708339, 0.13701603, 0.13654988,\n",
      "       0.13761752, 0.13435109, 0.13462143, 0.13622866, 0.13499892,\n",
      "       0.13711317, 0.13457732, 0.13554177, 0.13572788, 0.13342643,\n",
      "       0.13733695, 0.13907311, 0.13723879, 0.13465466, 0.13713613,\n",
      "       0.13528199, 0.1373266 , 0.13684812, 0.13757017, 0.13807015,\n",
      "       0.13685493, 0.1357511 , 0.13645101, 0.13553834, 0.13532245,\n",
      "       0.13931894, 0.14035561, 0.14027333, 0.14107373, 0.1384408 ,\n",
      "       0.14022558, 0.14066534, 0.1398174 , 0.14113438, 0.13741915,\n",
      "       0.1380511 , 0.13897631, 0.13882885, 0.138535  , 0.13776774,\n",
      "       0.13707511, 0.13700752, 0.14156899, 0.14229646, 0.14031703,\n",
      "       0.14853215, 0.14823227, 0.16086769, 0.20144186, 0.19612265,\n",
      "       0.19452863, 0.19366202, 0.19509089, 0.19389639, 0.19634721,\n",
      "       0.19339619, 0.19563653, 0.19432294, 0.19815903, 0.20076818,\n",
      "       0.19657438, 0.19108031, 0.19832089, 0.19938412, 0.14493549,\n",
      "       0.13940158, 0.13889525, 0.13753855, 0.13935194, 0.13742068,\n",
      "       0.13663142, 0.1368444 , 0.13937471, 0.13986759, 0.14506185,\n",
      "       0.1435559 , 0.13994429, 0.14149787, 0.16072092, 0.14276667,\n",
      "       0.17920189, 0.14396183, 0.14631295, 0.14475858, 0.13998837,\n",
      "       0.13863466, 0.13749614, 0.13917856, 0.13556011, 0.13970284,\n",
      "       0.14473608, 0.14500837, 0.14292724, 0.1388685 , 0.14295061,\n",
      "       0.14621296, 0.16502693, 0.13883758, 0.1386318 , 0.13831744,\n",
      "       0.14062922, 0.13757148, 0.13804173, 0.13830492, 0.13667324,\n",
      "       0.13633811, 0.14386885, 0.14305758, 0.14339442, 0.13866882,\n",
      "       0.14226367, 0.1425653 , 0.14083259, 0.13882506, 0.14065273,\n",
      "       0.13944001, 0.14010897, 0.15417864, 0.14853444, 0.13729911,\n",
      "       0.13777299, 0.13783154, 0.14465806, 0.14356966, 0.1423209 ,\n",
      "       0.14019978, 0.14281437, 0.14352458, 0.14225218, 0.13837683,\n",
      "       0.13885036, 0.1400955 , 0.14047523, 0.13879273, 0.13777599,\n",
      "       0.13859267, 0.13677549, 0.13666685, 0.14418838, 0.14232953,\n",
      "       0.14262607, 0.14013793, 0.14020808, 0.15281651, 0.15282547,\n",
      "       0.13953519, 0.13870158, 0.14719651, 0.14003041, 0.13980238,\n",
      "       0.1378772 , 0.13873873, 0.13654544, 0.16651649, 0.1436007 ,\n",
      "       0.14204698, 0.14532998, 0.15966983, 0.14186776, 0.14159884,\n",
      "       0.14130759, 0.13996539, 0.13756316, 0.13823569, 0.14081807,\n",
      "       0.13852181, 0.1384145 , 0.13763371, 0.14133382, 0.13859484,\n",
      "       0.14271352, 0.14350705, 0.14713147, 0.1406426 , 0.14284048,\n",
      "       0.14470654, 0.1549999 , 0.14102919, 0.14022775, 0.13986909,\n",
      "       0.142011  , 0.13978355, 0.14047902, 0.1383853 , 0.13731596,\n",
      "       0.13676515, 0.14320071, 0.14254875, 0.14205623, 0.14114726,\n",
      "       0.14385488, 0.14361608, 0.14059834, 0.14150329, 0.13877769,\n",
      "       0.13875108, 0.14081042, 0.13839419, 0.13883986, 0.13445835,\n",
      "       0.13719923, 0.13764014, 0.1416177 , 0.14346323, 0.14344628,\n",
      "       0.13956301, 0.14088564, 0.1425936 , 0.14184833, 0.14145458,\n",
      "       0.13945642, 0.14062748, 0.1411042 , 0.13873873, 0.14405806,\n",
      "       0.15434184, 0.16810784, 0.14604576, 0.15769889, 0.14321902,\n",
      "       0.13823822, 0.13209114, 0.13407404, 0.13422122, 0.13251636,\n",
      "       0.13215423, 0.13139935, 0.13141816, 0.13143389, 0.131043  ,\n",
      "       0.12953656, 0.12972982, 0.12981908, 0.13079627, 0.13757629,\n",
      "       0.13998036, 0.14527934, 0.13265193, 0.13392916, 0.1439862 ,\n",
      "       0.14265289, 0.14142268, 0.14165034, 0.14013758, 0.14454174,\n",
      "       0.15342693, 0.14277775, 0.13843744, 0.14235535, 0.13939967]), 'std_fit_time': array([0.00896374, 0.00132499, 0.00219574, 0.00093201, 0.0020332 ,\n",
      "       0.0013224 , 0.00166308, 0.00217995, 0.01580371, 0.00424229,\n",
      "       0.01212236, 0.00393563, 0.02778198, 0.00168024, 0.00099677,\n",
      "       0.00132216, 0.00148803, 0.02629645, 0.00209155, 0.01558013,\n",
      "       0.00328749, 0.00250282, 0.00218565, 0.00121486, 0.0019641 ,\n",
      "       0.00399888, 0.00174181, 0.00488872, 0.00261396, 0.00230334,\n",
      "       0.00179605, 0.00108955, 0.00066753, 0.00249166, 0.00182238,\n",
      "       0.00220845, 0.01185829, 0.00358103, 0.0021461 , 0.00286019,\n",
      "       0.00306396, 0.01802448, 0.00316323, 0.00090036, 0.00195134,\n",
      "       0.00654307, 0.00139352, 0.00082082, 0.00395415, 0.00204407,\n",
      "       0.00225937, 0.002867  , 0.00706758, 0.00447522, 0.00203003,\n",
      "       0.00198623, 0.00212195, 0.00147803, 0.00146219, 0.00154702,\n",
      "       0.00163756, 0.00143782, 0.0035319 , 0.00173544, 0.00427907,\n",
      "       0.0018567 , 0.00175141, 0.00473862, 0.00168806, 0.00145273,\n",
      "       0.00408166, 0.0012964 , 0.00212619, 0.00505617, 0.0015696 ,\n",
      "       0.00325632, 0.00263677, 0.00174774, 0.00307432, 0.00202856,\n",
      "       0.00224132, 0.00364723, 0.0022374 , 0.00153043, 0.00235159,\n",
      "       0.00166445, 0.00486546, 0.00092755, 0.00182138, 0.00423901,\n",
      "       0.00183976, 0.00168757, 0.00292872, 0.00232641, 0.00189859,\n",
      "       0.00507165, 0.00240262, 0.00398499, 0.00357354, 0.00129824,\n",
      "       0.00172879, 0.0009126 , 0.00106494, 0.00634986, 0.0011595 ,\n",
      "       0.0018877 , 0.00186163, 0.00194248, 0.00193685, 0.00118369,\n",
      "       0.00138825, 0.00402412, 0.00226047, 0.00594106, 0.00191395,\n",
      "       0.01918722, 0.01373025, 0.02565531, 0.00464647, 0.00398102,\n",
      "       0.00509555, 0.0053393 , 0.00424494, 0.00914409, 0.00459443,\n",
      "       0.00657118, 0.00548051, 0.005737  , 0.00930569, 0.00670377,\n",
      "       0.01151651, 0.01130937, 0.00514792, 0.00805715, 0.01032676,\n",
      "       0.00220956, 0.00230053, 0.00271545, 0.00191734, 0.00190599,\n",
      "       0.00169822, 0.00151783, 0.00367927, 0.00217527, 0.00335801,\n",
      "       0.00243071, 0.00150117, 0.004817  , 0.02006418, 0.00394446,\n",
      "       0.03201221, 0.00906927, 0.01105834, 0.01509301, 0.00256784,\n",
      "       0.00199242, 0.00192607, 0.00304914, 0.00226181, 0.00767022,\n",
      "       0.00431253, 0.00252304, 0.00375426, 0.00208243, 0.00302519,\n",
      "       0.00567511, 0.02789379, 0.0014885 , 0.00212804, 0.00200211,\n",
      "       0.00387563, 0.00136633, 0.0016126 , 0.00159794, 0.00159745,\n",
      "       0.00090562, 0.00268717, 0.00193111, 0.00390982, 0.00212146,\n",
      "       0.00366517, 0.00216808, 0.00142871, 0.00159958, 0.00151919,\n",
      "       0.00091644, 0.00136149, 0.03204397, 0.01980395, 0.00361514,\n",
      "       0.00245313, 0.00189737, 0.00325156, 0.00128171, 0.00236709,\n",
      "       0.00238764, 0.00089482, 0.00267854, 0.0042655 , 0.00206182,\n",
      "       0.00182771, 0.00225951, 0.00142026, 0.00126179, 0.00253998,\n",
      "       0.00209774, 0.00149186, 0.00112736, 0.00180684, 0.00194718,\n",
      "       0.00254531, 0.0019003 , 0.00211702, 0.01748765, 0.02573395,\n",
      "       0.00192852, 0.00116963, 0.01442735, 0.00543814, 0.00187264,\n",
      "       0.00380526, 0.00395882, 0.00169286, 0.01995937, 0.00108676,\n",
      "       0.00059684, 0.00881122, 0.01776489, 0.00372022, 0.00201589,\n",
      "       0.00195111, 0.00550744, 0.00154562, 0.00207686, 0.00251965,\n",
      "       0.00158305, 0.00342446, 0.0022384 , 0.0019676 , 0.00195701,\n",
      "       0.001775  , 0.00257817, 0.00429451, 0.00145882, 0.00485759,\n",
      "       0.00551174, 0.01847932, 0.00206641, 0.00198226, 0.00223462,\n",
      "       0.00417978, 0.00160651, 0.00628526, 0.00259711, 0.00153243,\n",
      "       0.00123834, 0.0024222 , 0.00173191, 0.00464724, 0.00332404,\n",
      "       0.00560714, 0.00221307, 0.00161245, 0.0042676 , 0.00356621,\n",
      "       0.00115121, 0.00218274, 0.00168971, 0.00378668, 0.00194842,\n",
      "       0.00292969, 0.00226219, 0.00186349, 0.00214382, 0.00378559,\n",
      "       0.00270192, 0.00227702, 0.00187502, 0.00202089, 0.00387972,\n",
      "       0.00234707, 0.00151338, 0.00202584, 0.0029138 , 0.01142443,\n",
      "       0.01360503, 0.02417885, 0.01042015, 0.00691331, 0.00482578,\n",
      "       0.00251541, 0.00178821, 0.00101394, 0.00140098, 0.00149752,\n",
      "       0.00210835, 0.00067071, 0.00092889, 0.00075548, 0.00114774,\n",
      "       0.00044119, 0.00157883, 0.00050312, 0.00121781, 0.00140265,\n",
      "       0.00759365, 0.01109009, 0.00134271, 0.00076696, 0.00650523,\n",
      "       0.00112932, 0.00477243, 0.00257985, 0.00312687, 0.00624397,\n",
      "       0.02137252, 0.01032252, 0.00201676, 0.00855553, 0.00230258]), 'mean_score_time': array([0.00809875, 0.00814626, 0.00817153, 0.0082001 , 0.0080678 ,\n",
      "       0.0082484 , 0.00803039, 0.0082315 , 0.00826783, 0.00820465,\n",
      "       0.00835276, 0.00798528, 0.00789914, 0.00770965, 0.00820765,\n",
      "       0.00839322, 0.00822594, 0.01060028, 0.00852447, 0.00926466,\n",
      "       0.00841978, 0.00839319, 0.00830302, 0.00840738, 0.00856652,\n",
      "       0.00842204, 0.00853586, 0.0087826 , 0.00808825, 0.00852168,\n",
      "       0.00847166, 0.00852735, 0.00834129, 0.0088598 , 0.00839748,\n",
      "       0.00844963, 0.00925725, 0.00817337, 0.00838537, 0.00844765,\n",
      "       0.00850213, 0.00912774, 0.00805593, 0.00860934, 0.0083761 ,\n",
      "       0.00880692, 0.00881326, 0.00875013, 0.00858591, 0.00867393,\n",
      "       0.00914135, 0.00899258, 0.00878308, 0.00860255, 0.00842199,\n",
      "       0.00881557, 0.00838766, 0.00848975, 0.00836008, 0.00849304,\n",
      "       0.0085326 , 0.00858393, 0.00869458, 0.008483  , 0.00853741,\n",
      "       0.00860789, 0.00898044, 0.00834434, 0.0087585 , 0.00873985,\n",
      "       0.00858743, 0.00844295, 0.00865226, 0.00871215, 0.00824773,\n",
      "       0.00892205, 0.00885777, 0.00872841, 0.00867972, 0.00845864,\n",
      "       0.00878286, 0.00855103, 0.00837908, 0.00868897, 0.00895157,\n",
      "       0.00846565, 0.00875571, 0.00890303, 0.00869617, 0.00891867,\n",
      "       0.00874763, 0.00873687, 0.00887077, 0.0083992 , 0.0087286 ,\n",
      "       0.00867567, 0.00902443, 0.00885458, 0.00889482, 0.00907204,\n",
      "       0.0089694 , 0.00927246, 0.00867085, 0.00914345, 0.00874798,\n",
      "       0.00896716, 0.00881379, 0.00908165, 0.00890472, 0.00884047,\n",
      "       0.00854015, 0.00908339, 0.00877807, 0.00881529, 0.00865591,\n",
      "       0.00964088, 0.00900559, 0.01037207, 0.01265044, 0.01224113,\n",
      "       0.01271296, 0.01245883, 0.01219802, 0.01133842, 0.01212094,\n",
      "       0.01265264, 0.01239681, 0.01220272, 0.01259918, 0.01277192,\n",
      "       0.01255851, 0.01247537, 0.01281636, 0.01225452, 0.00882754,\n",
      "       0.00869379, 0.00906186, 0.00876517, 0.00914471, 0.00856135,\n",
      "       0.00852754, 0.00856087, 0.00892828, 0.00916629, 0.00948384,\n",
      "       0.00884697, 0.00876632, 0.00897942, 0.00944026, 0.00915315,\n",
      "       0.01132877, 0.0088614 , 0.00886869, 0.0089154 , 0.00876503,\n",
      "       0.00915792, 0.00903707, 0.00906475, 0.00851831, 0.00868099,\n",
      "       0.00921879, 0.00923893, 0.00886855, 0.00862021, 0.00935509,\n",
      "       0.00932174, 0.01067953, 0.00892673, 0.00905488, 0.00888665,\n",
      "       0.00874047, 0.00858204, 0.00879052, 0.00901623, 0.00879514,\n",
      "       0.00898595, 0.00912967, 0.00915849, 0.00921531, 0.00897818,\n",
      "       0.00926397, 0.00928895, 0.00888586, 0.00910063, 0.00959284,\n",
      "       0.00895801, 0.00886886, 0.01009102, 0.00926671, 0.0086148 ,\n",
      "       0.00905852, 0.00881138, 0.0092936 , 0.00911036, 0.00885403,\n",
      "       0.00924449, 0.00876288, 0.00924802, 0.00893123, 0.00880182,\n",
      "       0.00905008, 0.00885522, 0.00889347, 0.00882053, 0.00876203,\n",
      "       0.0089457 , 0.00871067, 0.00847361, 0.00915868, 0.00949008,\n",
      "       0.00938516, 0.00893857, 0.00908647, 0.00985489, 0.00979288,\n",
      "       0.00942867, 0.00912697, 0.00972445, 0.00916693, 0.00894094,\n",
      "       0.00887027, 0.00893462, 0.0085567 , 0.01072068, 0.00906363,\n",
      "       0.00947855, 0.00903509, 0.00972388, 0.00906973, 0.0089536 ,\n",
      "       0.00894704, 0.0091414 , 0.00848985, 0.00878596, 0.00946326,\n",
      "       0.00882659, 0.00885072, 0.00932286, 0.00903187, 0.00883877,\n",
      "       0.0092984 , 0.00880921, 0.00960155, 0.00900903, 0.00903382,\n",
      "       0.00891907, 0.01025617, 0.00910518, 0.00936682, 0.00882018,\n",
      "       0.00892935, 0.00913887, 0.00883822, 0.00891464, 0.00885546,\n",
      "       0.00896854, 0.00947833, 0.00906255, 0.00894899, 0.00916812,\n",
      "       0.00912504, 0.00879986, 0.00919285, 0.00902178, 0.00905492,\n",
      "       0.00915716, 0.00893273, 0.00906789, 0.00902684, 0.00887489,\n",
      "       0.00875947, 0.00875084, 0.00920022, 0.00889945, 0.00909295,\n",
      "       0.00894616, 0.00947556, 0.00934565, 0.00878232, 0.00933619,\n",
      "       0.0088521 , 0.00853276, 0.00891941, 0.00878806, 0.00931506,\n",
      "       0.00974321, 0.00990031, 0.00941327, 0.00998113, 0.00940843,\n",
      "       0.00874794, 0.00868745, 0.00856564, 0.00847752, 0.00838513,\n",
      "       0.00839696, 0.0084372 , 0.00869889, 0.00865335, 0.00852528,\n",
      "       0.00828822, 0.00870478, 0.00848169, 0.00870955, 0.00857112,\n",
      "       0.00872049, 0.01029193, 0.00835469, 0.0083395 , 0.00891955,\n",
      "       0.00906298, 0.00933878, 0.00883372, 0.00880687, 0.00898731,\n",
      "       0.00958974, 0.00937471, 0.00891955, 0.00922847, 0.00898869]), 'std_score_time': array([0.00079858, 0.00055805, 0.00151917, 0.00050661, 0.00042733,\n",
      "       0.00056219, 0.00037846, 0.00077391, 0.00055957, 0.00039124,\n",
      "       0.00051601, 0.00046918, 0.00046716, 0.00058199, 0.00060094,\n",
      "       0.00034827, 0.0006248 , 0.00261331, 0.00076858, 0.00195754,\n",
      "       0.00070993, 0.00061796, 0.00050733, 0.00041897, 0.00072852,\n",
      "       0.00083555, 0.00063232, 0.00084378, 0.00039669, 0.00053596,\n",
      "       0.00043468, 0.00059367, 0.00065691, 0.00049153, 0.00063671,\n",
      "       0.00031253, 0.00265915, 0.0005233 , 0.00033856, 0.00059709,\n",
      "       0.00079648, 0.00140129, 0.0003894 , 0.00056132, 0.00063016,\n",
      "       0.00097447, 0.00085641, 0.00058381, 0.00057043, 0.00048556,\n",
      "       0.0011571 , 0.00060485, 0.0009519 , 0.00072918, 0.00044755,\n",
      "       0.00055691, 0.00054838, 0.00041852, 0.00037869, 0.00046135,\n",
      "       0.00038102, 0.00046501, 0.00056577, 0.0004122 , 0.00022757,\n",
      "       0.00041797, 0.00088554, 0.00073334, 0.0007888 , 0.00072595,\n",
      "       0.00048048, 0.00047108, 0.00049164, 0.00038848, 0.00049584,\n",
      "       0.0010254 , 0.00033723, 0.00061714, 0.00061935, 0.00041404,\n",
      "       0.00050033, 0.00071401, 0.00054105, 0.00048575, 0.00048207,\n",
      "       0.000573  , 0.00032323, 0.00052035, 0.0003957 , 0.00070582,\n",
      "       0.00059455, 0.00038317, 0.00030162, 0.00053478, 0.00066063,\n",
      "       0.00061833, 0.000652  , 0.00063793, 0.00030978, 0.00032019,\n",
      "       0.0004286 , 0.00059125, 0.00039205, 0.00139759, 0.00039584,\n",
      "       0.00089024, 0.00098543, 0.00053587, 0.00064329, 0.00039517,\n",
      "       0.00069028, 0.00097309, 0.0005384 , 0.00052605, 0.00047469,\n",
      "       0.00155877, 0.00016683, 0.00227008, 0.00097521, 0.00131678,\n",
      "       0.00062398, 0.0011755 , 0.00116415, 0.00150465, 0.00132898,\n",
      "       0.00098822, 0.00097571, 0.00183583, 0.00066717, 0.00109736,\n",
      "       0.0006767 , 0.0015884 , 0.00089558, 0.00148369, 0.00069597,\n",
      "       0.00045072, 0.00068119, 0.00039502, 0.00077506, 0.00021986,\n",
      "       0.00063382, 0.00092381, 0.0006307 , 0.00048795, 0.00117515,\n",
      "       0.00046483, 0.00031645, 0.00046981, 0.00079118, 0.00048914,\n",
      "       0.00278551, 0.00091354, 0.00083298, 0.0005027 , 0.0005198 ,\n",
      "       0.00079273, 0.00078661, 0.00061152, 0.00061673, 0.00050044,\n",
      "       0.00040274, 0.00073228, 0.00065674, 0.00086391, 0.00029323,\n",
      "       0.00080794, 0.00253391, 0.00053787, 0.00047386, 0.00031294,\n",
      "       0.00050682, 0.00047034, 0.00065325, 0.00054456, 0.00041598,\n",
      "       0.00087782, 0.00075493, 0.00052937, 0.00069619, 0.00074921,\n",
      "       0.00046931, 0.00038733, 0.00053397, 0.00048565, 0.00076688,\n",
      "       0.00064073, 0.00038339, 0.00245925, 0.00127231, 0.00045273,\n",
      "       0.00047211, 0.00043469, 0.00037491, 0.0005166 , 0.00063142,\n",
      "       0.00076673, 0.00038466, 0.00097366, 0.00037002, 0.00045826,\n",
      "       0.0003511 , 0.00019414, 0.00054766, 0.00054129, 0.00046509,\n",
      "       0.00032941, 0.00089647, 0.00053296, 0.00026636, 0.00071564,\n",
      "       0.00060806, 0.0003731 , 0.00175551, 0.00164547, 0.00222072,\n",
      "       0.00085669, 0.00068226, 0.00165655, 0.00074017, 0.00082299,\n",
      "       0.00046371, 0.00037568, 0.00028637, 0.0024924 , 0.0007001 ,\n",
      "       0.00060937, 0.00052215, 0.00163544, 0.00081836, 0.0005883 ,\n",
      "       0.00054531, 0.00140159, 0.00038828, 0.0002375 , 0.00162995,\n",
      "       0.00029779, 0.00050465, 0.00086058, 0.00038077, 0.00057466,\n",
      "       0.00063382, 0.00050067, 0.00101302, 0.00046204, 0.00063009,\n",
      "       0.00098257, 0.00174233, 0.00057577, 0.00061972, 0.00050822,\n",
      "       0.00059151, 0.0010975 , 0.00073199, 0.00072743, 0.00075773,\n",
      "       0.00081887, 0.00050316, 0.00043338, 0.00032318, 0.0004096 ,\n",
      "       0.00035451, 0.00040004, 0.00040413, 0.00063855, 0.00056304,\n",
      "       0.00084095, 0.00055403, 0.00059262, 0.00100962, 0.00083108,\n",
      "       0.00030721, 0.00067866, 0.00040001, 0.00053823, 0.00030351,\n",
      "       0.00059892, 0.00077975, 0.00063887, 0.0003742 , 0.00086466,\n",
      "       0.00059657, 0.00066515, 0.00046219, 0.00059711, 0.00090158,\n",
      "       0.00133339, 0.0013573 , 0.00061702, 0.00087587, 0.00099678,\n",
      "       0.0004692 , 0.00032843, 0.0003705 , 0.00021019, 0.00039743,\n",
      "       0.00027823, 0.00034271, 0.00047498, 0.00054647, 0.00028355,\n",
      "       0.00052536, 0.00037984, 0.0003715 , 0.0004181 , 0.00054554,\n",
      "       0.00043344, 0.00283788, 0.00042843, 0.00045348, 0.00060575,\n",
      "       0.00063068, 0.00079165, 0.0010222 , 0.00044427, 0.00078622,\n",
      "       0.00254125, 0.00123809, 0.00052173, 0.0006656 , 0.00071341]), 'param_classifier__max_depth': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
      "                   2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3,\n",
      "                   3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4,\n",
      "                   4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "                   6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "                   7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "                   8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
      "                   11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
      "                   12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13,\n",
      "                   13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14,\n",
      "                   14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15,\n",
      "                   15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16,\n",
      "                   16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "                   17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "                   17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
      "                   18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
      "                   19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "                   20, 20, 20, 20, 20, 20, 20, 20],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_classifier__min_samples_leaf': masked_array(data=[1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1,\n",
      "                   1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1,\n",
      "                   1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1,\n",
      "                   1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1,\n",
      "                   2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2,\n",
      "                   2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2,\n",
      "                   2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2,\n",
      "                   2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "                   5, 5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5,\n",
      "                   5, 5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5,\n",
      "                   5, 5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5,\n",
      "                   5, 10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5,\n",
      "                   10, 10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10,\n",
      "                   10, 10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10,\n",
      "                   10, 10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10,\n",
      "                   10, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10,\n",
      "                   1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1,\n",
      "                   1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10, 1, 1,\n",
      "                   1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 10, 10, 10, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_classifier__min_samples_split': masked_array(data=[2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20,\n",
      "                   2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20, 2, 5, 10, 20],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'classifier__max_depth': 1, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 1, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 2, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 3, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 4, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 7, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 8, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 11, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 12, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 13, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 14, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 16, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 17, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 18, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 19, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 20}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 2}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 5}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 10}, {'classifier__max_depth': 20, 'classifier__min_samples_leaf': 10, 'classifier__min_samples_split': 20}], 'split0_test_score': array([0.72955975, 0.72327044, 0.71698113, 0.71698113, 0.69811321,\n",
      "       0.69811321, 0.74213836, 0.74842767, 0.71698113, 0.72327044,\n",
      "       0.71698113, 0.71698113, 0.7672956 , 0.68553459, 0.69811321,\n",
      "       0.68553459, 0.74213836, 0.73584906, 0.74842767, 0.74842767,\n",
      "       0.71698113, 0.72955975, 0.72955975, 0.74842767, 0.75471698,\n",
      "       0.73584906, 0.74842767, 0.74842767, 0.76100629, 0.74842767,\n",
      "       0.74842767, 0.74842767, 0.77987421, 0.78616352, 0.77987421,\n",
      "       0.76100629, 0.76100629, 0.74842767, 0.79245283, 0.78616352,\n",
      "       0.77987421, 0.78616352, 0.77358491, 0.73584906, 0.79245283,\n",
      "       0.77987421, 0.77358491, 0.78616352, 0.79874214, 0.78616352,\n",
      "       0.77987421, 0.79245283, 0.79874214, 0.78616352, 0.79245283,\n",
      "       0.78616352, 0.77987421, 0.78616352, 0.77987421, 0.78616352,\n",
      "       0.78616352, 0.78616352, 0.79245283, 0.77987421, 0.81132075,\n",
      "       0.79245283, 0.77358491, 0.77987421, 0.79245283, 0.77987421,\n",
      "       0.78616352, 0.77987421, 0.78616352, 0.79874214, 0.77358491,\n",
      "       0.79245283, 0.77987421, 0.78616352, 0.78616352, 0.77987421,\n",
      "       0.79874214, 0.78616352, 0.79245283, 0.77987421, 0.79245283,\n",
      "       0.77987421, 0.78616352, 0.79245283, 0.79874214, 0.79874214,\n",
      "       0.78616352, 0.77358491, 0.79245283, 0.79245283, 0.80503145,\n",
      "       0.79874214, 0.78616352, 0.79245283, 0.79245283, 0.82389937,\n",
      "       0.77358491, 0.79245283, 0.77358491, 0.79245283, 0.77987421,\n",
      "       0.77987421, 0.77987421, 0.79245283, 0.78616352, 0.78616352,\n",
      "       0.79874214, 0.80503145, 0.79245283, 0.78616352, 0.7672956 ,\n",
      "       0.79245283, 0.79245283, 0.77358491, 0.79245283, 0.78616352,\n",
      "       0.81132075, 0.77987421, 0.7672956 , 0.79874214, 0.79245283,\n",
      "       0.79245283, 0.77358491, 0.79874214, 0.77358491, 0.77358491,\n",
      "       0.78616352, 0.78616352, 0.7672956 , 0.78616352, 0.79245283,\n",
      "       0.77358491, 0.79245283, 0.77358491, 0.79874214, 0.77358491,\n",
      "       0.77358491, 0.79245283, 0.77987421, 0.75471698, 0.77987421,\n",
      "       0.76100629, 0.79245283, 0.77358491, 0.7672956 , 0.79245283,\n",
      "       0.81761006, 0.77358491, 0.77987421, 0.79874214, 0.7672956 ,\n",
      "       0.77987421, 0.78616352, 0.77987421, 0.77358491, 0.78616352,\n",
      "       0.77358491, 0.77987421, 0.7672956 , 0.76100629, 0.79245283,\n",
      "       0.76100629, 0.77987421, 0.79874214, 0.76100629, 0.80503145,\n",
      "       0.79874214, 0.79245283, 0.79874214, 0.79245283, 0.78616352,\n",
      "       0.80503145, 0.77358491, 0.77358491, 0.73584906, 0.74213836,\n",
      "       0.77987421, 0.77987421, 0.81132075, 0.77358491, 0.77987421,\n",
      "       0.80503145, 0.77358491, 0.78616352, 0.77358491, 0.77987421,\n",
      "       0.79245283, 0.77987421, 0.78616352, 0.77358491, 0.77987421,\n",
      "       0.79874214, 0.75471698, 0.74842767, 0.77358491, 0.77987421,\n",
      "       0.78616352, 0.79245283, 0.76100629, 0.78616352, 0.79874214,\n",
      "       0.79874214, 0.77358491, 0.78616352, 0.74842767, 0.77358491,\n",
      "       0.77987421, 0.77987421, 0.75471698, 0.78616352, 0.7672956 ,\n",
      "       0.79245283, 0.77358491, 0.78616352, 0.78616352, 0.77987421,\n",
      "       0.79874214, 0.80503145, 0.79245283, 0.79245283, 0.77987421,\n",
      "       0.76100629, 0.75471698, 0.7672956 , 0.77358491, 0.75471698,\n",
      "       0.77358491, 0.77987421, 0.79245283, 0.81761006, 0.77358491,\n",
      "       0.80503145, 0.79245283, 0.80503145, 0.79245283, 0.80503145,\n",
      "       0.77987421, 0.7672956 , 0.77358491, 0.77987421, 0.79874214,\n",
      "       0.77358491, 0.77358491, 0.79874214, 0.76100629, 0.79245283,\n",
      "       0.77987421, 0.80503145, 0.79245283, 0.79245283, 0.78616352,\n",
      "       0.78616352, 0.76100629, 0.76100629, 0.77987421, 0.77987421,\n",
      "       0.77987421, 0.78616352, 0.79245283, 0.79245283, 0.78616352,\n",
      "       0.79245283, 0.7672956 , 0.78616352, 0.78616352, 0.78616352,\n",
      "       0.79245283, 0.80503145, 0.7672956 , 0.77358491, 0.77358491,\n",
      "       0.79874214, 0.7672956 , 0.77987421, 0.77987421, 0.78616352,\n",
      "       0.79245283, 0.77358491, 0.81132075, 0.77987421, 0.79874214,\n",
      "       0.78616352, 0.80503145, 0.81132075, 0.7672956 , 0.77358491,\n",
      "       0.77358491, 0.77358491, 0.77987421, 0.74842767, 0.77358491,\n",
      "       0.79245283, 0.7672956 , 0.79874214, 0.77987421, 0.79874214,\n",
      "       0.79245283, 0.77358491, 0.79245283, 0.79245283, 0.77358491,\n",
      "       0.77987421, 0.77358491, 0.81132075, 0.7672956 , 0.77358491,\n",
      "       0.77358491, 0.80503145, 0.7672956 , 0.77987421, 0.77987421,\n",
      "       0.80503145, 0.79874214, 0.77987421, 0.78616352, 0.79245283]), 'split1_test_score': array([0.79874214, 0.81132075, 0.79245283, 0.77358491, 0.81132075,\n",
      "       0.78616352, 0.7672956 , 0.79874214, 0.77987421, 0.78616352,\n",
      "       0.77987421, 0.78616352, 0.80503145, 0.77987421, 0.80503145,\n",
      "       0.78616352, 0.80503145, 0.81761006, 0.81761006, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.83018868, 0.81761006, 0.83647799,\n",
      "       0.8427673 , 0.8427673 , 0.83647799, 0.8427673 , 0.85534591,\n",
      "       0.83647799, 0.81761006, 0.8490566 , 0.86163522, 0.86792453,\n",
      "       0.85534591, 0.83647799, 0.87421384, 0.86792453, 0.87421384,\n",
      "       0.8490566 , 0.83018868, 0.87421384, 0.86792453, 0.88050314,\n",
      "       0.83647799, 0.85534591, 0.83647799, 0.88679245, 0.88050314,\n",
      "       0.88050314, 0.88050314, 0.88050314, 0.88050314, 0.8490566 ,\n",
      "       0.87421384, 0.86792453, 0.86163522, 0.86792453, 0.85534591,\n",
      "       0.88050314, 0.88050314, 0.88050314, 0.87421384, 0.88679245,\n",
      "       0.88679245, 0.88050314, 0.88050314, 0.86792453, 0.88050314,\n",
      "       0.87421384, 0.87421384, 0.86163522, 0.87421384, 0.86792453,\n",
      "       0.87421384, 0.87421384, 0.88050314, 0.88050314, 0.88050314,\n",
      "       0.87421384, 0.86163522, 0.86163522, 0.87421384, 0.87421384,\n",
      "       0.88050314, 0.88050314, 0.87421384, 0.86792453, 0.88050314,\n",
      "       0.88050314, 0.88050314, 0.87421384, 0.86792453, 0.87421384,\n",
      "       0.88050314, 0.88050314, 0.86792453, 0.85534591, 0.88050314,\n",
      "       0.87421384, 0.86792453, 0.86163522, 0.87421384, 0.88050314,\n",
      "       0.88050314, 0.87421384, 0.86792453, 0.86792453, 0.88050314,\n",
      "       0.87421384, 0.87421384, 0.86163522, 0.87421384, 0.88050314,\n",
      "       0.86792453, 0.86792453, 0.88050314, 0.8427673 , 0.87421384,\n",
      "       0.87421384, 0.85534591, 0.87421384, 0.87421384, 0.86792453,\n",
      "       0.88050314, 0.86163522, 0.88050314, 0.86163522, 0.87421384,\n",
      "       0.87421384, 0.85534591, 0.86163522, 0.8490566 , 0.87421384,\n",
      "       0.86792453, 0.86792453, 0.86163522, 0.8490566 , 0.86163522,\n",
      "       0.86163522, 0.87421384, 0.87421384, 0.86792453, 0.86792453,\n",
      "       0.87421384, 0.87421384, 0.87421384, 0.8490566 , 0.86163522,\n",
      "       0.87421384, 0.86163522, 0.87421384, 0.86792453, 0.86792453,\n",
      "       0.87421384, 0.86792453, 0.87421384, 0.87421384, 0.87421384,\n",
      "       0.86792453, 0.87421384, 0.88050314, 0.82389937, 0.85534591,\n",
      "       0.87421384, 0.85534591, 0.86792453, 0.87421384, 0.86792453,\n",
      "       0.87421384, 0.87421384, 0.86792453, 0.88050314, 0.87421384,\n",
      "       0.87421384, 0.8427673 , 0.86792453, 0.86792453, 0.88679245,\n",
      "       0.86792453, 0.8427673 , 0.8427673 , 0.87421384, 0.87421384,\n",
      "       0.87421384, 0.87421384, 0.86163522, 0.85534591, 0.87421384,\n",
      "       0.87421384, 0.88050314, 0.8427673 , 0.8490566 , 0.86163522,\n",
      "       0.86163522, 0.88050314, 0.85534591, 0.85534591, 0.86792453,\n",
      "       0.87421384, 0.87421384, 0.86792453, 0.87421384, 0.88050314,\n",
      "       0.88050314, 0.87421384, 0.87421384, 0.85534591, 0.86163522,\n",
      "       0.86792453, 0.86163522, 0.8427673 , 0.87421384, 0.88050314,\n",
      "       0.86792453, 0.86792453, 0.87421384, 0.86792453, 0.86792453,\n",
      "       0.88050314, 0.88050314, 0.87421384, 0.86792453, 0.8490566 ,\n",
      "       0.88679245, 0.85534591, 0.86163522, 0.8490566 , 0.87421384,\n",
      "       0.85534591, 0.86792453, 0.87421384, 0.87421384, 0.86792453,\n",
      "       0.86163522, 0.86792453, 0.88050314, 0.88050314, 0.86792453,\n",
      "       0.86792453, 0.86163522, 0.86792453, 0.85534591, 0.86163522,\n",
      "       0.8427673 , 0.88050314, 0.86792453, 0.86163522, 0.86163522,\n",
      "       0.88050314, 0.87421384, 0.88050314, 0.87421384, 0.86792453,\n",
      "       0.86792453, 0.83018868, 0.8490566 , 0.88050314, 0.86163522,\n",
      "       0.86792453, 0.85534591, 0.86792453, 0.85534591, 0.86792453,\n",
      "       0.86792453, 0.86792453, 0.87421384, 0.87421384, 0.88679245,\n",
      "       0.88050314, 0.88050314, 0.8490566 , 0.8490566 , 0.88050314,\n",
      "       0.86163522, 0.87421384, 0.8427673 , 0.88050314, 0.8427673 ,\n",
      "       0.87421384, 0.86792453, 0.86792453, 0.88050314, 0.88050314,\n",
      "       0.88679245, 0.88050314, 0.87421384, 0.80503145, 0.8427673 ,\n",
      "       0.85534591, 0.87421384, 0.88050314, 0.8490566 , 0.86792453,\n",
      "       0.87421384, 0.86792453, 0.86792453, 0.87421384, 0.87421384,\n",
      "       0.88050314, 0.87421384, 0.85534591, 0.88050314, 0.8490566 ,\n",
      "       0.85534591, 0.88050314, 0.86792453, 0.83647799, 0.85534591,\n",
      "       0.87421384, 0.86792453, 0.86792453, 0.88050314, 0.86792453,\n",
      "       0.86792453, 0.87421384, 0.88050314, 0.88050314, 0.8490566 ]), 'split2_test_score': array([0.81132075, 0.81761006, 0.74842767, 0.79874214, 0.80503145,\n",
      "       0.79874214, 0.77358491, 0.79874214, 0.76100629, 0.79245283,\n",
      "       0.79245283, 0.79874214, 0.81132075, 0.78616352, 0.80503145,\n",
      "       0.79245283, 0.79874214, 0.79874214, 0.80503145, 0.79245283,\n",
      "       0.81132075, 0.81761006, 0.79245283, 0.81761006, 0.82389937,\n",
      "       0.79245283, 0.81761006, 0.80503145, 0.79874214, 0.81132075,\n",
      "       0.82389937, 0.82389937, 0.82389937, 0.80503145, 0.81761006,\n",
      "       0.81132075, 0.81761006, 0.81761006, 0.78616352, 0.81761006,\n",
      "       0.82389937, 0.80503145, 0.81761006, 0.78616352, 0.81761006,\n",
      "       0.79245283, 0.81132075, 0.82389937, 0.82389937, 0.81761006,\n",
      "       0.81132075, 0.81761006, 0.82389937, 0.81761006, 0.81761006,\n",
      "       0.80503145, 0.81761006, 0.82389937, 0.82389937, 0.80503145,\n",
      "       0.81761006, 0.81761006, 0.82389937, 0.7672956 , 0.82389937,\n",
      "       0.79874214, 0.81132075, 0.82389937, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.81761006, 0.83018868, 0.80503145, 0.82389937,\n",
      "       0.78616352, 0.81132075, 0.81132075, 0.81132075, 0.82389937,\n",
      "       0.81132075, 0.81132075, 0.81761006, 0.81132075, 0.82389937,\n",
      "       0.79245283, 0.82389937, 0.79245283, 0.81761006, 0.7672956 ,\n",
      "       0.77987421, 0.80503145, 0.79245283, 0.81761006, 0.82389937,\n",
      "       0.78616352, 0.81761006, 0.79874214, 0.79874214, 0.81761006,\n",
      "       0.79874214, 0.83018868, 0.78616352, 0.79245283, 0.80503145,\n",
      "       0.80503145, 0.82389937, 0.81132075, 0.79874214, 0.78616352,\n",
      "       0.80503145, 0.82389937, 0.81761006, 0.80503145, 0.81132075,\n",
      "       0.81761006, 0.80503145, 0.80503145, 0.81761006, 0.77987421,\n",
      "       0.79245283, 0.81132075, 0.80503145, 0.81761006, 0.77358491,\n",
      "       0.82389937, 0.81761006, 0.79245283, 0.81761006, 0.79874214,\n",
      "       0.79245283, 0.81132075, 0.78616352, 0.79245283, 0.81132075,\n",
      "       0.81761006, 0.79874214, 0.80503145, 0.78616352, 0.77358491,\n",
      "       0.80503145, 0.81761006, 0.79245283, 0.78616352, 0.78616352,\n",
      "       0.79245283, 0.79874214, 0.82389937, 0.80503145, 0.80503145,\n",
      "       0.81132075, 0.82389937, 0.77987421, 0.81132075, 0.82389937,\n",
      "       0.81132075, 0.77987421, 0.82389937, 0.78616352, 0.81761006,\n",
      "       0.77987421, 0.77987421, 0.76100629, 0.79874214, 0.79245283,\n",
      "       0.77987421, 0.80503145, 0.81761006, 0.81761006, 0.79245283,\n",
      "       0.82389937, 0.78616352, 0.81132075, 0.80503145, 0.79874214,\n",
      "       0.79245283, 0.7672956 , 0.78616352, 0.78616352, 0.77358491,\n",
      "       0.78616352, 0.78616352, 0.81761006, 0.81761006, 0.80503145,\n",
      "       0.78616352, 0.80503145, 0.81761006, 0.80503145, 0.77987421,\n",
      "       0.81132075, 0.78616352, 0.77358491, 0.79874214, 0.7672956 ,\n",
      "       0.79874214, 0.81132075, 0.82389937, 0.78616352, 0.81761006,\n",
      "       0.81761006, 0.80503145, 0.82389937, 0.79874214, 0.77987421,\n",
      "       0.80503145, 0.80503145, 0.79245283, 0.77358491, 0.79874214,\n",
      "       0.79245283, 0.79245283, 0.79874214, 0.81132075, 0.79245283,\n",
      "       0.79874214, 0.81132075, 0.81132075, 0.80503145, 0.80503145,\n",
      "       0.80503145, 0.81761006, 0.80503145, 0.80503145, 0.7672956 ,\n",
      "       0.78616352, 0.78616352, 0.79874214, 0.78616352, 0.77987421,\n",
      "       0.81132075, 0.82389937, 0.77987421, 0.77987421, 0.77987421,\n",
      "       0.79874214, 0.80503145, 0.79874214, 0.79245283, 0.82389937,\n",
      "       0.74842767, 0.77987421, 0.77987421, 0.79245283, 0.79874214,\n",
      "       0.79245283, 0.79245283, 0.79245283, 0.79874214, 0.82389937,\n",
      "       0.78616352, 0.79245283, 0.78616352, 0.82389937, 0.79245283,\n",
      "       0.82389937, 0.78616352, 0.78616352, 0.80503145, 0.82389937,\n",
      "       0.78616352, 0.81132075, 0.79245283, 0.82389937, 0.81132075,\n",
      "       0.78616352, 0.79874214, 0.79874214, 0.81132075, 0.80503145,\n",
      "       0.82389937, 0.81761006, 0.79245283, 0.79245283, 0.75471698,\n",
      "       0.79245283, 0.78616352, 0.80503145, 0.80503145, 0.81761006,\n",
      "       0.80503145, 0.78616352, 0.7672956 , 0.81132075, 0.79245283,\n",
      "       0.79874214, 0.79874214, 0.81761006, 0.7672956 , 0.7672956 ,\n",
      "       0.78616352, 0.80503145, 0.79245283, 0.79874214, 0.80503145,\n",
      "       0.78616352, 0.81761006, 0.76100629, 0.81132075, 0.79245283,\n",
      "       0.81761006, 0.80503145, 0.77987421, 0.79874214, 0.79245283,\n",
      "       0.79874214, 0.78616352, 0.82389937, 0.78616352, 0.79245283,\n",
      "       0.78616352, 0.79874214, 0.79245283, 0.81132075, 0.79874214,\n",
      "       0.78616352, 0.81132075, 0.80503145, 0.82389937, 0.79245283]), 'split3_test_score': array([0.79245283, 0.79245283, 0.79245283, 0.74213836, 0.78616352,\n",
      "       0.76100629, 0.78616352, 0.77987421, 0.79245283, 0.78616352,\n",
      "       0.77358491, 0.79245283, 0.76100629, 0.79874214, 0.77987421,\n",
      "       0.79245283, 0.77987421, 0.79245283, 0.78616352, 0.79245283,\n",
      "       0.76100629, 0.76100629, 0.76100629, 0.78616352, 0.77987421,\n",
      "       0.75471698, 0.79874214, 0.79245283, 0.78616352, 0.79874214,\n",
      "       0.77987421, 0.78616352, 0.80503145, 0.80503145, 0.7672956 ,\n",
      "       0.79874214, 0.81132075, 0.79245283, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.80503145, 0.79245283,\n",
      "       0.81132075, 0.81132075, 0.78616352, 0.79874214, 0.80503145,\n",
      "       0.79874214, 0.80503145, 0.79874214, 0.80503145, 0.80503145,\n",
      "       0.79245283, 0.79874214, 0.79874214, 0.80503145, 0.79874214,\n",
      "       0.79245283, 0.79245283, 0.81132075, 0.79874214, 0.79245283,\n",
      "       0.81132075, 0.79245283, 0.79874214, 0.79245283, 0.79874214,\n",
      "       0.80503145, 0.79245283, 0.80503145, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.80503145, 0.79874214, 0.80503145, 0.79874214,\n",
      "       0.78616352, 0.79874214, 0.80503145, 0.79874214, 0.78616352,\n",
      "       0.79245283, 0.79245283, 0.81761006, 0.79874214, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.79874214, 0.79874214, 0.79245283,\n",
      "       0.81761006, 0.81132075, 0.78616352, 0.80503145, 0.79874214,\n",
      "       0.81132075, 0.79245283, 0.78616352, 0.79874214, 0.81132075,\n",
      "       0.80503145, 0.79874214, 0.78616352, 0.80503145, 0.77358491,\n",
      "       0.80503145, 0.80503145, 0.79245283, 0.77987421, 0.79874214,\n",
      "       0.79245283, 0.80503145, 0.79874214, 0.80503145, 0.79874214,\n",
      "       0.80503145, 0.80503145, 0.79245283, 0.79874214, 0.77987421,\n",
      "       0.81132075, 0.79245283, 0.80503145, 0.81132075, 0.7672956 ,\n",
      "       0.77358491, 0.79874214, 0.77987421, 0.79245283, 0.79874214,\n",
      "       0.79245283, 0.79874214, 0.79874214, 0.80503145, 0.78616352,\n",
      "       0.81132075, 0.77987421, 0.79245283, 0.81132075, 0.78616352,\n",
      "       0.78616352, 0.79245283, 0.77358491, 0.79245283, 0.79874214,\n",
      "       0.79245283, 0.80503145, 0.81132075, 0.80503145, 0.78616352,\n",
      "       0.79874214, 0.81761006, 0.79874214, 0.80503145, 0.80503145,\n",
      "       0.77358491, 0.77358491, 0.77987421, 0.79874214, 0.79245283,\n",
      "       0.77987421, 0.77987421, 0.81132075, 0.79245283, 0.81132075,\n",
      "       0.79245283, 0.79245283, 0.77358491, 0.81132075, 0.80503145,\n",
      "       0.80503145, 0.77987421, 0.77358491, 0.80503145, 0.77358491,\n",
      "       0.77358491, 0.79245283, 0.81132075, 0.78616352, 0.79874214,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.77358491, 0.80503145,\n",
      "       0.79874214, 0.77987421, 0.77987421, 0.79245283, 0.79245283,\n",
      "       0.78616352, 0.77358491, 0.78616352, 0.7672956 , 0.77987421,\n",
      "       0.79245283, 0.79245283, 0.79245283, 0.79874214, 0.79874214,\n",
      "       0.81132075, 0.81132075, 0.80503145, 0.7672956 , 0.77987421,\n",
      "       0.77358491, 0.77987421, 0.79245283, 0.7672956 , 0.78616352,\n",
      "       0.79245283, 0.79874214, 0.79245283, 0.79245283, 0.79874214,\n",
      "       0.79874214, 0.80503145, 0.80503145, 0.7672956 , 0.77358491,\n",
      "       0.78616352, 0.79245283, 0.79245283, 0.79874214, 0.77987421,\n",
      "       0.79245283, 0.79874214, 0.77987421, 0.79245283, 0.78616352,\n",
      "       0.79245283, 0.80503145, 0.80503145, 0.79245283, 0.81132075,\n",
      "       0.80503145, 0.80503145, 0.78616352, 0.78616352, 0.77987421,\n",
      "       0.77987421, 0.77358491, 0.78616352, 0.79874214, 0.77987421,\n",
      "       0.79874214, 0.79874214, 0.78616352, 0.79245283, 0.79245283,\n",
      "       0.79874214, 0.78616352, 0.78616352, 0.79874214, 0.77358491,\n",
      "       0.79874214, 0.78616352, 0.79245283, 0.77358491, 0.81132075,\n",
      "       0.80503145, 0.79874214, 0.79245283, 0.79245283, 0.78616352,\n",
      "       0.79874214, 0.78616352, 0.81132075, 0.7672956 , 0.79245283,\n",
      "       0.77987421, 0.80503145, 0.80503145, 0.78616352, 0.80503145,\n",
      "       0.81761006, 0.78616352, 0.78616352, 0.79874214, 0.78616352,\n",
      "       0.79874214, 0.81132075, 0.78616352, 0.7672956 , 0.81132075,\n",
      "       0.78616352, 0.79874214, 0.79874214, 0.79245283, 0.79874214,\n",
      "       0.79245283, 0.79245283, 0.80503145, 0.79245283, 0.79874214,\n",
      "       0.81132075, 0.79874214, 0.79874214, 0.78616352, 0.79874214,\n",
      "       0.77987421, 0.81132075, 0.79874214, 0.80503145, 0.7672956 ,\n",
      "       0.78616352, 0.79874214, 0.79245283, 0.7672956 , 0.79245283,\n",
      "       0.79874214, 0.79245283, 0.81132075, 0.80503145, 0.78616352]), 'split4_test_score': array([0.72327044, 0.73584906, 0.72955975, 0.69811321, 0.72955975,\n",
      "       0.72955975, 0.72327044, 0.71698113, 0.72955975, 0.72955975,\n",
      "       0.72955975, 0.72955975, 0.72327044, 0.73584906, 0.72327044,\n",
      "       0.72955975, 0.74213836, 0.72327044, 0.73584906, 0.72955975,\n",
      "       0.74842767, 0.73584906, 0.73584906, 0.73584906, 0.73584906,\n",
      "       0.72955975, 0.72327044, 0.73584906, 0.74213836, 0.73584906,\n",
      "       0.73584906, 0.72955975, 0.76100629, 0.76100629, 0.76100629,\n",
      "       0.76100629, 0.76100629, 0.7672956 , 0.76100629, 0.76100629,\n",
      "       0.77358491, 0.74842767, 0.74213836, 0.7672956 , 0.7672956 ,\n",
      "       0.75471698, 0.76100629, 0.74213836, 0.76100629, 0.76100629,\n",
      "       0.7672956 , 0.7672956 , 0.7672956 , 0.76100629, 0.76100629,\n",
      "       0.7672956 , 0.7672956 , 0.76100629, 0.76100629, 0.7672956 ,\n",
      "       0.7672956 , 0.76100629, 0.76100629, 0.7672956 , 0.76100629,\n",
      "       0.76100629, 0.77358491, 0.76100629, 0.7672956 , 0.7672956 ,\n",
      "       0.76100629, 0.76100629, 0.7672956 , 0.76100629, 0.7672956 ,\n",
      "       0.76100629, 0.7672956 , 0.76100629, 0.7672956 , 0.77987421,\n",
      "       0.77987421, 0.7672956 , 0.76100629, 0.76100629, 0.77358491,\n",
      "       0.74842767, 0.77358491, 0.75471698, 0.75471698, 0.7672956 ,\n",
      "       0.75471698, 0.77358491, 0.76100629, 0.76100629, 0.7672956 ,\n",
      "       0.7672956 , 0.78616352, 0.7672956 , 0.76100629, 0.76100629,\n",
      "       0.76100629, 0.77358491, 0.75471698, 0.7672956 , 0.7672956 ,\n",
      "       0.7672956 , 0.76100629, 0.76100629, 0.7672956 , 0.7672956 ,\n",
      "       0.75471698, 0.77987421, 0.76100629, 0.77987421, 0.75471698,\n",
      "       0.75471698, 0.77987421, 0.7672956 , 0.74842767, 0.7672956 ,\n",
      "       0.75471698, 0.77987421, 0.77358491, 0.76100629, 0.76100629,\n",
      "       0.76100629, 0.76100629, 0.7672956 , 0.76100629, 0.77987421,\n",
      "       0.7672956 , 0.77358491, 0.7672956 , 0.77358491, 0.76100629,\n",
      "       0.75471698, 0.77358491, 0.77358491, 0.7672956 , 0.7672956 ,\n",
      "       0.76100629, 0.77358491, 0.76100629, 0.76100629, 0.7672956 ,\n",
      "       0.77358491, 0.77358491, 0.76100629, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.76100629, 0.76100629, 0.77358491, 0.76100629,\n",
      "       0.7672956 , 0.75471698, 0.7672956 , 0.7672956 , 0.76100629,\n",
      "       0.74842767, 0.75471698, 0.75471698, 0.7672956 , 0.75471698,\n",
      "       0.76100629, 0.7672956 , 0.77358491, 0.76100629, 0.77987421,\n",
      "       0.76100629, 0.7672956 , 0.7672956 , 0.7672956 , 0.77358491,\n",
      "       0.7672956 , 0.7672956 , 0.77358491, 0.7672956 , 0.7672956 ,\n",
      "       0.76100629, 0.7672956 , 0.77358491, 0.76100629, 0.74842767,\n",
      "       0.76100629, 0.77358491, 0.7672956 , 0.76100629, 0.7672956 ,\n",
      "       0.7672956 , 0.77358491, 0.72955975, 0.77987421, 0.76100629,\n",
      "       0.76100629, 0.76100629, 0.76100629, 0.74842767, 0.75471698,\n",
      "       0.75471698, 0.77987421, 0.77358491, 0.7672956 , 0.78616352,\n",
      "       0.7672956 , 0.77358491, 0.7672956 , 0.74842767, 0.75471698,\n",
      "       0.75471698, 0.77358491, 0.77358491, 0.77358491, 0.7672956 ,\n",
      "       0.76100629, 0.76100629, 0.77358491, 0.7672956 , 0.7672956 ,\n",
      "       0.7672956 , 0.76100629, 0.7672956 , 0.7672956 , 0.76100629,\n",
      "       0.77987421, 0.77987421, 0.77358491, 0.76100629, 0.7672956 ,\n",
      "       0.7672956 , 0.77358491, 0.7672956 , 0.77358491, 0.7672956 ,\n",
      "       0.76100629, 0.7672956 , 0.76100629, 0.77987421, 0.7672956 ,\n",
      "       0.75471698, 0.7672956 , 0.77987421, 0.7672956 , 0.77987421,\n",
      "       0.76100629, 0.76100629, 0.77358491, 0.77987421, 0.7672956 ,\n",
      "       0.76100629, 0.75471698, 0.77358491, 0.76100629, 0.76100629,\n",
      "       0.76100629, 0.75471698, 0.75471698, 0.7672956 , 0.7672956 ,\n",
      "       0.76100629, 0.7672956 , 0.76100629, 0.7672956 , 0.76100629,\n",
      "       0.7672956 , 0.7672956 , 0.75471698, 0.7672956 , 0.75471698,\n",
      "       0.76100629, 0.7672956 , 0.75471698, 0.7672956 , 0.76100629,\n",
      "       0.77358491, 0.7672956 , 0.77987421, 0.76100629, 0.77358491,\n",
      "       0.76100629, 0.77358491, 0.74213836, 0.7672956 , 0.7672956 ,\n",
      "       0.76100629, 0.76100629, 0.76100629, 0.74842767, 0.73584906,\n",
      "       0.7672956 , 0.74842767, 0.76100629, 0.76100629, 0.7672956 ,\n",
      "       0.7672956 , 0.7672956 , 0.77358491, 0.76100629, 0.77358491,\n",
      "       0.77358491, 0.7672956 , 0.76100629, 0.75471698, 0.75471698,\n",
      "       0.77358491, 0.74842767, 0.7672956 , 0.77987421, 0.76100629,\n",
      "       0.7672956 , 0.7672956 , 0.77358491, 0.7672956 , 0.76100629,\n",
      "       0.7672956 , 0.77987421, 0.77987421, 0.7672956 , 0.76100629]), 'split5_test_score': array([0.74213836, 0.73584906, 0.72955975, 0.72327044, 0.66666667,\n",
      "       0.73584906, 0.74213836, 0.74842767, 0.72955975, 0.74213836,\n",
      "       0.73584906, 0.73584906, 0.71698113, 0.72955975, 0.74213836,\n",
      "       0.73584906, 0.75471698, 0.75471698, 0.77358491, 0.74213836,\n",
      "       0.78616352, 0.77987421, 0.74213836, 0.74842767, 0.77987421,\n",
      "       0.76100629, 0.75471698, 0.74842767, 0.74213836, 0.77987421,\n",
      "       0.74842767, 0.73584906, 0.79874214, 0.77358491, 0.78616352,\n",
      "       0.78616352, 0.79874214, 0.79245283, 0.78616352, 0.7672956 ,\n",
      "       0.77987421, 0.77987421, 0.79874214, 0.79245283, 0.76100629,\n",
      "       0.78616352, 0.7672956 , 0.78616352, 0.79874214, 0.79874214,\n",
      "       0.79245283, 0.78616352, 0.79245283, 0.80503145, 0.79874214,\n",
      "       0.81132075, 0.79245283, 0.79874214, 0.79245283, 0.79245283,\n",
      "       0.79874214, 0.80503145, 0.80503145, 0.81132075, 0.80503145,\n",
      "       0.81132075, 0.81132075, 0.81132075, 0.78616352, 0.79245283,\n",
      "       0.80503145, 0.80503145, 0.79874214, 0.79874214, 0.80503145,\n",
      "       0.79245283, 0.79245283, 0.80503145, 0.79874214, 0.79874214,\n",
      "       0.80503145, 0.80503145, 0.81132075, 0.79874214, 0.78616352,\n",
      "       0.78616352, 0.80503145, 0.81132075, 0.79874214, 0.77987421,\n",
      "       0.80503145, 0.7672956 , 0.79245283, 0.81132075, 0.81132075,\n",
      "       0.80503145, 0.83018868, 0.81132075, 0.79245283, 0.81132075,\n",
      "       0.80503145, 0.80503145, 0.77987421, 0.79874214, 0.79245283,\n",
      "       0.80503145, 0.81132075, 0.79874214, 0.80503145, 0.80503145,\n",
      "       0.79874214, 0.79245283, 0.79245283, 0.79245283, 0.79874214,\n",
      "       0.79874214, 0.77987421, 0.77358491, 0.78616352, 0.78616352,\n",
      "       0.79874214, 0.79874214, 0.79874214, 0.79874214, 0.77987421,\n",
      "       0.78616352, 0.79874214, 0.78616352, 0.78616352, 0.79874214,\n",
      "       0.75471698, 0.78616352, 0.75471698, 0.76100629, 0.78616352,\n",
      "       0.80503145, 0.77987421, 0.7672956 , 0.79874214, 0.79245283,\n",
      "       0.81132075, 0.79874214, 0.80503145, 0.80503145, 0.79245283,\n",
      "       0.77358491, 0.79245283, 0.77358491, 0.79874214, 0.77987421,\n",
      "       0.78616352, 0.81132075, 0.79245283, 0.78616352, 0.77987421,\n",
      "       0.77358491, 0.81761006, 0.79245283, 0.80503145, 0.80503145,\n",
      "       0.74213836, 0.79245283, 0.7672956 , 0.77358491, 0.76100629,\n",
      "       0.74842767, 0.78616352, 0.79874214, 0.79874214, 0.78616352,\n",
      "       0.78616352, 0.79874214, 0.78616352, 0.79874214, 0.79874214,\n",
      "       0.80503145, 0.72955975, 0.75471698, 0.76100629, 0.75471698,\n",
      "       0.78616352, 0.78616352, 0.7672956 , 0.76100629, 0.79245283,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.79874214, 0.79245283,\n",
      "       0.81132075, 0.78616352, 0.7672956 , 0.72955975, 0.77987421,\n",
      "       0.79874214, 0.73584906, 0.77358491, 0.79874214, 0.74842767,\n",
      "       0.80503145, 0.77987421, 0.77987421, 0.79874214, 0.79874214,\n",
      "       0.78616352, 0.79874214, 0.80503145, 0.74213836, 0.78616352,\n",
      "       0.79245283, 0.77358491, 0.77358491, 0.79874214, 0.79245283,\n",
      "       0.81132075, 0.7672956 , 0.78616352, 0.79874214, 0.79874214,\n",
      "       0.81132075, 0.80503145, 0.79874214, 0.79245283, 0.76100629,\n",
      "       0.76100629, 0.7672956 , 0.79245283, 0.72955975, 0.78616352,\n",
      "       0.79245283, 0.81132075, 0.79245283, 0.77358491, 0.79874214,\n",
      "       0.80503145, 0.79874214, 0.79874214, 0.81132075, 0.80503145,\n",
      "       0.77987421, 0.76100629, 0.81132075, 0.79874214, 0.78616352,\n",
      "       0.77358491, 0.75471698, 0.77358491, 0.80503145, 0.79874214,\n",
      "       0.78616352, 0.80503145, 0.79874214, 0.79874214, 0.7672956 ,\n",
      "       0.79245283, 0.79874214, 0.77358491, 0.77987421, 0.80503145,\n",
      "       0.77987421, 0.77358491, 0.79245283, 0.78616352, 0.80503145,\n",
      "       0.79874214, 0.77987421, 0.79874214, 0.78616352, 0.80503145,\n",
      "       0.79874214, 0.80503145, 0.74842767, 0.76100629, 0.77358491,\n",
      "       0.78616352, 0.77987421, 0.79245283, 0.79874214, 0.74842767,\n",
      "       0.79874214, 0.78616352, 0.79245283, 0.78616352, 0.79874214,\n",
      "       0.81132075, 0.79245283, 0.79874214, 0.75471698, 0.79245283,\n",
      "       0.79874214, 0.79874214, 0.78616352, 0.74213836, 0.80503145,\n",
      "       0.79874214, 0.79245283, 0.78616352, 0.77987421, 0.79874214,\n",
      "       0.80503145, 0.81132075, 0.79874214, 0.79874214, 0.76100629,\n",
      "       0.79245283, 0.80503145, 0.77987421, 0.77987421, 0.76100629,\n",
      "       0.79874214, 0.77987421, 0.75471698, 0.78616352, 0.77358491,\n",
      "       0.78616352, 0.79874214, 0.81132075, 0.80503145, 0.79245283]), 'split6_test_score': array([0.78616352, 0.71069182, 0.75471698, 0.7672956 , 0.7672956 ,\n",
      "       0.76100629, 0.7672956 , 0.7672956 , 0.71698113, 0.71698113,\n",
      "       0.72955975, 0.74842767, 0.78616352, 0.78616352, 0.77358491,\n",
      "       0.78616352, 0.79245283, 0.7672956 , 0.77987421, 0.74842767,\n",
      "       0.77987421, 0.77358491, 0.81761006, 0.78616352, 0.77358491,\n",
      "       0.77987421, 0.80503145, 0.81761006, 0.78616352, 0.79874214,\n",
      "       0.77987421, 0.79874214, 0.81761006, 0.83647799, 0.8427673 ,\n",
      "       0.83647799, 0.82389937, 0.83018868, 0.83018868, 0.81132075,\n",
      "       0.83018868, 0.81132075, 0.83018868, 0.81132075, 0.81132075,\n",
      "       0.79245283, 0.79874214, 0.80503145, 0.83647799, 0.81761006,\n",
      "       0.81132075, 0.83018868, 0.83018868, 0.83018868, 0.83647799,\n",
      "       0.83647799, 0.82389937, 0.83018868, 0.83018868, 0.80503145,\n",
      "       0.80503145, 0.81132075, 0.83647799, 0.81761006, 0.81761006,\n",
      "       0.81761006, 0.83647799, 0.83018868, 0.8427673 , 0.83018868,\n",
      "       0.82389937, 0.81132075, 0.83647799, 0.82389937, 0.80503145,\n",
      "       0.83647799, 0.83018868, 0.81132075, 0.82389937, 0.81132075,\n",
      "       0.82389937, 0.83018868, 0.83018868, 0.82389937, 0.83018868,\n",
      "       0.80503145, 0.81761006, 0.83647799, 0.83647799, 0.81761006,\n",
      "       0.83647799, 0.82389937, 0.83018868, 0.83018868, 0.80503145,\n",
      "       0.83647799, 0.83018868, 0.81132075, 0.83647799, 0.81761006,\n",
      "       0.83647799, 0.8427673 , 0.83018868, 0.81761006, 0.82389937,\n",
      "       0.82389937, 0.83647799, 0.81761006, 0.83018868, 0.82389937,\n",
      "       0.81132075, 0.82389937, 0.81761006, 0.81761006, 0.81761006,\n",
      "       0.83647799, 0.81132075, 0.83647799, 0.83018868, 0.83018868,\n",
      "       0.83647799, 0.83647799, 0.8427673 , 0.83647799, 0.83018868,\n",
      "       0.83647799, 0.83018868, 0.83647799, 0.82389937, 0.83018868,\n",
      "       0.81761006, 0.8427673 , 0.82389937, 0.83018868, 0.82389937,\n",
      "       0.83647799, 0.80503145, 0.82389937, 0.83018868, 0.83647799,\n",
      "       0.83018868, 0.83018868, 0.83018868, 0.81132075, 0.83018868,\n",
      "       0.83647799, 0.81761006, 0.82389937, 0.81132075, 0.83647799,\n",
      "       0.82389937, 0.81761006, 0.8427673 , 0.82389937, 0.83647799,\n",
      "       0.83647799, 0.82389937, 0.83018868, 0.83018868, 0.82389937,\n",
      "       0.82389937, 0.81761006, 0.82389937, 0.83647799, 0.81761006,\n",
      "       0.8427673 , 0.82389937, 0.83018868, 0.83647799, 0.8427673 ,\n",
      "       0.83018868, 0.83018868, 0.83018868, 0.82389937, 0.83018868,\n",
      "       0.83018868, 0.80503145, 0.82389937, 0.79245283, 0.81132075,\n",
      "       0.83018868, 0.77987421, 0.83018868, 0.83018868, 0.83018868,\n",
      "       0.83647799, 0.83647799, 0.83018868, 0.83647799, 0.83647799,\n",
      "       0.82389937, 0.79874214, 0.79874214, 0.79245283, 0.82389937,\n",
      "       0.81132075, 0.82389937, 0.82389937, 0.81761006, 0.83647799,\n",
      "       0.81132075, 0.83018868, 0.83647799, 0.79874214, 0.83647799,\n",
      "       0.83018868, 0.82389937, 0.83018868, 0.79245283, 0.82389937,\n",
      "       0.82389937, 0.8427673 , 0.80503145, 0.81132075, 0.82389937,\n",
      "       0.83018868, 0.81761006, 0.81132075, 0.82389937, 0.81761006,\n",
      "       0.79874214, 0.83018868, 0.83018868, 0.83018868, 0.80503145,\n",
      "       0.79874214, 0.83647799, 0.83018868, 0.83018868, 0.83018868,\n",
      "       0.82389937, 0.83647799, 0.83018868, 0.82389937, 0.83018868,\n",
      "       0.83647799, 0.83018868, 0.81132075, 0.81761006, 0.81132075,\n",
      "       0.82389937, 0.82389937, 0.81761006, 0.81761006, 0.82389937,\n",
      "       0.82389937, 0.81761006, 0.83647799, 0.83018868, 0.81761006,\n",
      "       0.83018868, 0.81761006, 0.83018868, 0.81132075, 0.8427673 ,\n",
      "       0.83647799, 0.82389937, 0.83018868, 0.79245283, 0.83647799,\n",
      "       0.8427673 , 0.83647799, 0.81132075, 0.79874214, 0.83647799,\n",
      "       0.83018868, 0.83647799, 0.81761006, 0.81132075, 0.82389937,\n",
      "       0.83647799, 0.8427673 , 0.81132075, 0.81132075, 0.83018868,\n",
      "       0.83018868, 0.82389937, 0.81761006, 0.83018868, 0.81132075,\n",
      "       0.81761006, 0.82389937, 0.83647799, 0.83018868, 0.83018868,\n",
      "       0.83647799, 0.83018868, 0.81761006, 0.79874214, 0.83018868,\n",
      "       0.80503145, 0.83018868, 0.82389937, 0.82389937, 0.81761006,\n",
      "       0.81132075, 0.83018868, 0.83647799, 0.83018868, 0.81761006,\n",
      "       0.82389937, 0.83018868, 0.82389937, 0.81132075, 0.81132075,\n",
      "       0.80503145, 0.81761006, 0.83647799, 0.81761006, 0.81761006,\n",
      "       0.82389937, 0.83647799, 0.83018868, 0.83018868, 0.83018868,\n",
      "       0.81761006, 0.82389937, 0.79874214, 0.80503145, 0.83647799]), 'split7_test_score': array([0.7672956 , 0.76100629, 0.74842767, 0.74842767, 0.76100629,\n",
      "       0.75471698, 0.77358491, 0.75471698, 0.76100629, 0.7672956 ,\n",
      "       0.76100629, 0.76100629, 0.76100629, 0.71698113, 0.77358491,\n",
      "       0.76100629, 0.78616352, 0.77358491, 0.76100629, 0.77358491,\n",
      "       0.7672956 , 0.77987421, 0.77358491, 0.79874214, 0.77358491,\n",
      "       0.76100629, 0.7672956 , 0.7672956 , 0.78616352, 0.77358491,\n",
      "       0.78616352, 0.77358491, 0.77987421, 0.78616352, 0.79245283,\n",
      "       0.79874214, 0.79874214, 0.79245283, 0.77987421, 0.79874214,\n",
      "       0.79874214, 0.77987421, 0.79245283, 0.79245283, 0.78616352,\n",
      "       0.79874214, 0.78616352, 0.79245283, 0.79245283, 0.79874214,\n",
      "       0.80503145, 0.78616352, 0.79874214, 0.79245283, 0.79874214,\n",
      "       0.79874214, 0.79245283, 0.79245283, 0.79874214, 0.79245283,\n",
      "       0.80503145, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.79245283, 0.80503145, 0.78616352, 0.78616352, 0.79874214,\n",
      "       0.78616352, 0.79874214, 0.79245283, 0.79874214, 0.79245283,\n",
      "       0.79245283, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.78616352, 0.79245283, 0.78616352, 0.79874214, 0.79874214,\n",
      "       0.79874214, 0.78616352, 0.78616352, 0.79874214, 0.79874214,\n",
      "       0.79245283, 0.79245283, 0.81132075, 0.79245283, 0.80503145,\n",
      "       0.79245283, 0.79245283, 0.79874214, 0.77358491, 0.80503145,\n",
      "       0.79874214, 0.76100629, 0.79245283, 0.78616352, 0.78616352,\n",
      "       0.79874214, 0.81132075, 0.80503145, 0.79245283, 0.79874214,\n",
      "       0.77987421, 0.80503145, 0.78616352, 0.77987421, 0.79874214,\n",
      "       0.76100629, 0.79874214, 0.79245283, 0.78616352, 0.79874214,\n",
      "       0.79874214, 0.80503145, 0.77987421, 0.77987421, 0.79245283,\n",
      "       0.77358491, 0.79874214, 0.79245283, 0.78616352, 0.77987421,\n",
      "       0.79245283, 0.78616352, 0.78616352, 0.75471698, 0.78616352,\n",
      "       0.77358491, 0.79245283, 0.79245283, 0.79245283, 0.77358491,\n",
      "       0.79245283, 0.79245283, 0.79874214, 0.81132075, 0.78616352,\n",
      "       0.78616352, 0.77358491, 0.79874214, 0.78616352, 0.79245283,\n",
      "       0.77358491, 0.79874214, 0.79245283, 0.77987421, 0.79245283,\n",
      "       0.79245283, 0.79874214, 0.79245283, 0.79874214, 0.79874214,\n",
      "       0.7672956 , 0.77358491, 0.77358491, 0.78616352, 0.75471698,\n",
      "       0.77987421, 0.75471698, 0.77987421, 0.77358491, 0.80503145,\n",
      "       0.77987421, 0.79245283, 0.79874214, 0.80503145, 0.79245283,\n",
      "       0.79245283, 0.80503145, 0.77358491, 0.77358491, 0.77358491,\n",
      "       0.77358491, 0.7672956 , 0.80503145, 0.79245283, 0.79245283,\n",
      "       0.79245283, 0.78616352, 0.79245283, 0.79245283, 0.80503145,\n",
      "       0.79245283, 0.77987421, 0.77358491, 0.77358491, 0.7672956 ,\n",
      "       0.80503145, 0.76100629, 0.79874214, 0.79245283, 0.77987421,\n",
      "       0.78616352, 0.77358491, 0.76100629, 0.78616352, 0.79245283,\n",
      "       0.79245283, 0.79874214, 0.81761006, 0.77987421, 0.74842767,\n",
      "       0.75471698, 0.79874214, 0.77987421, 0.74842767, 0.77987421,\n",
      "       0.78616352, 0.78616352, 0.77358491, 0.79245283, 0.78616352,\n",
      "       0.77987421, 0.79245283, 0.79245283, 0.78616352, 0.7672956 ,\n",
      "       0.76100629, 0.77987421, 0.77987421, 0.77987421, 0.7672956 ,\n",
      "       0.77358491, 0.79245283, 0.78616352, 0.77987421, 0.78616352,\n",
      "       0.79245283, 0.79245283, 0.79874214, 0.79874214, 0.81132075,\n",
      "       0.79874214, 0.7672956 , 0.77358491, 0.78616352, 0.76100629,\n",
      "       0.79874214, 0.78616352, 0.76100629, 0.79245283, 0.79874214,\n",
      "       0.78616352, 0.79245283, 0.80503145, 0.79245283, 0.79245283,\n",
      "       0.80503145, 0.78616352, 0.76100629, 0.75471698, 0.78616352,\n",
      "       0.78616352, 0.77358491, 0.79874214, 0.79874214, 0.77987421,\n",
      "       0.77987421, 0.79245283, 0.79245283, 0.79245283, 0.79245283,\n",
      "       0.79245283, 0.77358491, 0.77987421, 0.76100629, 0.79874214,\n",
      "       0.77358491, 0.76100629, 0.75471698, 0.79874214, 0.78616352,\n",
      "       0.77987421, 0.79245283, 0.78616352, 0.79245283, 0.79874214,\n",
      "       0.79874214, 0.78616352, 0.78616352, 0.77987421, 0.74842767,\n",
      "       0.74213836, 0.80503145, 0.79245283, 0.78616352, 0.78616352,\n",
      "       0.77358491, 0.77987421, 0.79245283, 0.77358491, 0.79245283,\n",
      "       0.80503145, 0.79245283, 0.79874214, 0.80503145, 0.74213836,\n",
      "       0.77987421, 0.79874214, 0.79245283, 0.79245283, 0.76100629,\n",
      "       0.78616352, 0.79245283, 0.77987421, 0.78616352, 0.77987421,\n",
      "       0.77987421, 0.81132075, 0.81132075, 0.77987421, 0.79874214]), 'split8_test_score': array([0.74842767, 0.74842767, 0.72955975, 0.74842767, 0.75471698,\n",
      "       0.74213836, 0.74842767, 0.74842767, 0.74842767, 0.74213836,\n",
      "       0.72327044, 0.76100629, 0.75471698, 0.74842767, 0.74213836,\n",
      "       0.73584906, 0.76100629, 0.74213836, 0.75471698, 0.74842767,\n",
      "       0.75471698, 0.77358491, 0.7672956 , 0.75471698, 0.75471698,\n",
      "       0.77358491, 0.74842767, 0.7672956 , 0.79245283, 0.76100629,\n",
      "       0.76100629, 0.75471698, 0.77987421, 0.80503145, 0.79874214,\n",
      "       0.7672956 , 0.76100629, 0.77987421, 0.77358491, 0.7672956 ,\n",
      "       0.76100629, 0.77358491, 0.81132075, 0.78616352, 0.7672956 ,\n",
      "       0.79874214, 0.77987421, 0.77987421, 0.81132075, 0.81132075,\n",
      "       0.79245283, 0.80503145, 0.81132075, 0.79874214, 0.81132075,\n",
      "       0.78616352, 0.79874214, 0.81132075, 0.80503145, 0.81132075,\n",
      "       0.78616352, 0.78616352, 0.79245283, 0.77987421, 0.81761006,\n",
      "       0.79245283, 0.81132075, 0.79874214, 0.81132075, 0.80503145,\n",
      "       0.81132075, 0.80503145, 0.81761006, 0.81132075, 0.82389937,\n",
      "       0.80503145, 0.80503145, 0.79245283, 0.79874214, 0.79874214,\n",
      "       0.78616352, 0.78616352, 0.81132075, 0.80503145, 0.82389937,\n",
      "       0.81132075, 0.78616352, 0.79245283, 0.80503145, 0.83018868,\n",
      "       0.81132075, 0.80503145, 0.79245283, 0.79874214, 0.79874214,\n",
      "       0.79245283, 0.80503145, 0.79874214, 0.81132075, 0.78616352,\n",
      "       0.81132075, 0.80503145, 0.79874214, 0.79245283, 0.81132075,\n",
      "       0.81132075, 0.79874214, 0.79874214, 0.79874214, 0.78616352,\n",
      "       0.79245283, 0.82389937, 0.79245283, 0.82389937, 0.79874214,\n",
      "       0.77358491, 0.82389937, 0.78616352, 0.80503145, 0.79245283,\n",
      "       0.78616352, 0.79874214, 0.80503145, 0.79874214, 0.79874214,\n",
      "       0.77987421, 0.83018868, 0.80503145, 0.79874214, 0.80503145,\n",
      "       0.80503145, 0.80503145, 0.80503145, 0.77987421, 0.81132075,\n",
      "       0.79874214, 0.80503145, 0.83018868, 0.79874214, 0.80503145,\n",
      "       0.81761006, 0.81132075, 0.80503145, 0.80503145, 0.7672956 ,\n",
      "       0.81132075, 0.79245283, 0.80503145, 0.79874214, 0.80503145,\n",
      "       0.79245283, 0.81761006, 0.80503145, 0.80503145, 0.79874214,\n",
      "       0.79245283, 0.80503145, 0.81132075, 0.81132075, 0.79245283,\n",
      "       0.80503145, 0.7672956 , 0.79874214, 0.80503145, 0.79245283,\n",
      "       0.79874214, 0.80503145, 0.78616352, 0.81761006, 0.79874214,\n",
      "       0.79874214, 0.78616352, 0.79874214, 0.80503145, 0.82389937,\n",
      "       0.81132075, 0.78616352, 0.80503145, 0.79245283, 0.79874214,\n",
      "       0.79874214, 0.80503145, 0.80503145, 0.79874214, 0.80503145,\n",
      "       0.82389937, 0.79874214, 0.80503145, 0.81761006, 0.79245283,\n",
      "       0.79874214, 0.80503145, 0.79874214, 0.80503145, 0.81132075,\n",
      "       0.79245283, 0.79245283, 0.79245283, 0.80503145, 0.79874214,\n",
      "       0.81761006, 0.79245283, 0.79874214, 0.80503145, 0.79245283,\n",
      "       0.79874214, 0.81761006, 0.79874214, 0.82389937, 0.81761006,\n",
      "       0.78616352, 0.78616352, 0.77987421, 0.82389937, 0.80503145,\n",
      "       0.80503145, 0.79245283, 0.78616352, 0.81132075, 0.81761006,\n",
      "       0.78616352, 0.79874214, 0.79245283, 0.79874214, 0.81132075,\n",
      "       0.81132075, 0.81132075, 0.79245283, 0.79874214, 0.79874214,\n",
      "       0.81132075, 0.81761006, 0.80503145, 0.79245283, 0.81132075,\n",
      "       0.78616352, 0.79874214, 0.79874214, 0.79874214, 0.79874214,\n",
      "       0.81132075, 0.82389937, 0.77987421, 0.81132075, 0.79245283,\n",
      "       0.78616352, 0.81761006, 0.81132075, 0.79245283, 0.81761006,\n",
      "       0.80503145, 0.79245283, 0.81132075, 0.81132075, 0.79245283,\n",
      "       0.80503145, 0.81132075, 0.81132075, 0.80503145, 0.79874214,\n",
      "       0.79874214, 0.79245283, 0.82389937, 0.80503145, 0.78616352,\n",
      "       0.82389937, 0.82389937, 0.79245283, 0.80503145, 0.80503145,\n",
      "       0.82389937, 0.79874214, 0.79245283, 0.77358491, 0.79245283,\n",
      "       0.80503145, 0.78616352, 0.79874214, 0.81132075, 0.77987421,\n",
      "       0.81132075, 0.81761006, 0.80503145, 0.79245283, 0.80503145,\n",
      "       0.79245283, 0.79245283, 0.79245283, 0.79874214, 0.79874214,\n",
      "       0.79245283, 0.79245283, 0.80503145, 0.79874214, 0.81761006,\n",
      "       0.81132075, 0.81132075, 0.79245283, 0.79874214, 0.79874214,\n",
      "       0.80503145, 0.81761006, 0.79245283, 0.81132075, 0.78616352,\n",
      "       0.80503145, 0.79245283, 0.80503145, 0.79245283, 0.79245283,\n",
      "       0.78616352, 0.79245283, 0.79874214, 0.79874214, 0.81761006,\n",
      "       0.77358491, 0.79874214, 0.82389937, 0.79874214, 0.80503145]), 'split9_test_score': array([0.7721519 , 0.7721519 , 0.7721519 , 0.74683544, 0.79113924,\n",
      "       0.7278481 , 0.7721519 , 0.80379747, 0.78481013, 0.77848101,\n",
      "       0.77848101, 0.77848101, 0.70253165, 0.7721519 , 0.78481013,\n",
      "       0.69620253, 0.82278481, 0.79746835, 0.79113924, 0.79113924,\n",
      "       0.78481013, 0.78481013, 0.83544304, 0.78481013, 0.78481013,\n",
      "       0.83544304, 0.79113924, 0.76582278, 0.79746835, 0.82278481,\n",
      "       0.79113924, 0.77848101, 0.83544304, 0.83544304, 0.84177215,\n",
      "       0.83544304, 0.83544304, 0.8164557 , 0.82911392, 0.8164557 ,\n",
      "       0.82911392, 0.83544304, 0.82911392, 0.82278481, 0.82911392,\n",
      "       0.8164557 , 0.82911392, 0.81012658, 0.84177215, 0.82911392,\n",
      "       0.82911392, 0.84177215, 0.85443038, 0.82911392, 0.84177215,\n",
      "       0.84177215, 0.82278481, 0.82911392, 0.82911392, 0.82911392,\n",
      "       0.83544304, 0.82278481, 0.84177215, 0.8164557 , 0.82911392,\n",
      "       0.84177215, 0.82911392, 0.83544304, 0.83544304, 0.85443038,\n",
      "       0.83544304, 0.82911392, 0.8164557 , 0.8164557 , 0.82278481,\n",
      "       0.84177215, 0.83544304, 0.83544304, 0.8164557 , 0.84177215,\n",
      "       0.84177215, 0.84177215, 0.82911392, 0.82278481, 0.83544304,\n",
      "       0.84177215, 0.84177215, 0.82278481, 0.84177215, 0.82278481,\n",
      "       0.85443038, 0.82278481, 0.82911392, 0.84177215, 0.82911392,\n",
      "       0.84810127, 0.84177215, 0.83544304, 0.84810127, 0.82911392,\n",
      "       0.83544304, 0.84177215, 0.8164557 , 0.82911392, 0.84177215,\n",
      "       0.82278481, 0.83544304, 0.79113924, 0.82911392, 0.82911392,\n",
      "       0.82911392, 0.82278481, 0.8164557 , 0.83544304, 0.85443038,\n",
      "       0.82278481, 0.82278481, 0.83544304, 0.84177215, 0.8164557 ,\n",
      "       0.82911392, 0.8164557 , 0.82911392, 0.82278481, 0.82911392,\n",
      "       0.83544304, 0.8164557 , 0.84177215, 0.82278481, 0.82911392,\n",
      "       0.82278481, 0.8164557 , 0.82911392, 0.81012658, 0.83544304,\n",
      "       0.84810127, 0.85443038, 0.83544304, 0.77848101, 0.8164557 ,\n",
      "       0.83544304, 0.83544304, 0.82911392, 0.83544304, 0.82278481,\n",
      "       0.84177215, 0.83544304, 0.83544304, 0.83544304, 0.80379747,\n",
      "       0.8164557 , 0.8164557 , 0.83544304, 0.84810127, 0.83544304,\n",
      "       0.8164557 , 0.82278481, 0.84177215, 0.83544304, 0.84177215,\n",
      "       0.79113924, 0.82278481, 0.80379747, 0.84810127, 0.84177215,\n",
      "       0.8164557 , 0.83544304, 0.83544304, 0.84810127, 0.82911392,\n",
      "       0.84177215, 0.82911392, 0.84177215, 0.82278481, 0.8164557 ,\n",
      "       0.8164557 , 0.79746835, 0.81012658, 0.82911392, 0.83544304,\n",
      "       0.82278481, 0.82911392, 0.81012658, 0.80379747, 0.83544304,\n",
      "       0.82911392, 0.8164557 , 0.82278481, 0.82911392, 0.80379747,\n",
      "       0.79746835, 0.83544304, 0.79113924, 0.82278481, 0.83544304,\n",
      "       0.8164557 , 0.8164557 , 0.82278481, 0.82911392, 0.81012658,\n",
      "       0.82278481, 0.82911392, 0.80379747, 0.82278481, 0.82278481,\n",
      "       0.83544304, 0.82911392, 0.84177215, 0.80379747, 0.81012658,\n",
      "       0.84177215, 0.82911392, 0.82278481, 0.82911392, 0.79113924,\n",
      "       0.8164557 , 0.80379747, 0.82911392, 0.84810127, 0.80379747,\n",
      "       0.84177215, 0.82911392, 0.82911392, 0.81012658, 0.84810127,\n",
      "       0.8164557 , 0.82911392, 0.8164557 , 0.83544304, 0.84177215,\n",
      "       0.82278481, 0.82278481, 0.82911392, 0.82278481, 0.82278481,\n",
      "       0.83544304, 0.84177215, 0.83544304, 0.83544304, 0.8164557 ,\n",
      "       0.82278481, 0.82278481, 0.78481013, 0.82911392, 0.82911392,\n",
      "       0.82278481, 0.8164557 , 0.82278481, 0.82911392, 0.84810127,\n",
      "       0.82278481, 0.82911392, 0.82278481, 0.84177215, 0.82911392,\n",
      "       0.8164557 , 0.81012658, 0.80379747, 0.82911392, 0.82278481,\n",
      "       0.79746835, 0.82911392, 0.82911392, 0.82911392, 0.82278481,\n",
      "       0.8164557 , 0.84177215, 0.83544304, 0.8164557 , 0.82911392,\n",
      "       0.85443038, 0.82278481, 0.81012658, 0.8164557 , 0.78481013,\n",
      "       0.84177215, 0.80379747, 0.82278481, 0.82911392, 0.82911392,\n",
      "       0.8164557 , 0.82278481, 0.82911392, 0.83544304, 0.80379747,\n",
      "       0.8164557 , 0.83544304, 0.8164557 , 0.78481013, 0.83544304,\n",
      "       0.82911392, 0.82911392, 0.82911392, 0.79746835, 0.80379747,\n",
      "       0.83544304, 0.83544304, 0.84177215, 0.82278481, 0.8164557 ,\n",
      "       0.83544304, 0.84810127, 0.82278481, 0.80379747, 0.80379747,\n",
      "       0.80379747, 0.79746835, 0.83544304, 0.82278481, 0.84177215,\n",
      "       0.82278481, 0.79113924, 0.83544304, 0.83544304, 0.82278481,\n",
      "       0.82911392, 0.82911392, 0.8164557 , 0.82911392, 0.82278481]), 'mean_test_score': array([0.7671523 , 0.76086299, 0.75142903, 0.74638166, 0.75710135,\n",
      "       0.74951437, 0.75960513, 0.76654327, 0.75206592, 0.75646445,\n",
      "       0.75206194, 0.76086697, 0.75893241, 0.75394475, 0.76275774,\n",
      "       0.7501234 , 0.7785049 , 0.77031287, 0.77534034, 0.76779317,\n",
      "       0.7721917 , 0.77470743, 0.77851286, 0.77785208, 0.77973887,\n",
      "       0.77662606, 0.77974285, 0.77846907, 0.78352042, 0.78856779,\n",
      "       0.77911392, 0.77470345, 0.80304116, 0.80555688, 0.80556086,\n",
      "       0.80115437, 0.80052544, 0.80114242, 0.80052146, 0.79988456,\n",
      "       0.80240825, 0.79486506, 0.80681076, 0.79674389, 0.80052146,\n",
      "       0.79673991, 0.7973768 , 0.79484914, 0.81499483, 0.81058435,\n",
      "       0.80681076, 0.81122124, 0.81563172, 0.81058435, 0.81122124,\n",
      "       0.80996338, 0.80617785, 0.80932649, 0.80932649, 0.80429504,\n",
      "       0.80744367, 0.80617785, 0.81436589, 0.80114242, 0.81435793,\n",
      "       0.81059231, 0.81247114, 0.81058833, 0.8099594 , 0.81248706,\n",
      "       0.81058833, 0.80743969, 0.81120532, 0.80868959, 0.80806464,\n",
      "       0.80807659, 0.8099594 , 0.80807261, 0.80868959, 0.81122124,\n",
      "       0.80933445, 0.80807659, 0.81058435, 0.80743571, 0.81247512,\n",
      "       0.80367407, 0.80933445, 0.80806464, 0.81185017, 0.80680678,\n",
      "       0.81060027, 0.80491999, 0.80743969, 0.81122124, 0.81121328,\n",
      "       0.81248308, 0.81813948, 0.80681474, 0.80745164, 0.81310007,\n",
      "       0.81058833, 0.81122124, 0.79799777, 0.80492397, 0.80996338,\n",
      "       0.80995144, 0.81310405, 0.8030133 , 0.80806863, 0.80366611,\n",
      "       0.80492397, 0.81561181, 0.80302922, 0.80744367, 0.80808455,\n",
      "       0.80177534, 0.80869358, 0.80492795, 0.80556086, 0.80302922,\n",
      "       0.80869756, 0.80868959, 0.80681076, 0.80869358, 0.80052146,\n",
      "       0.80807261, 0.80806066, 0.81059231, 0.80429106, 0.80366611,\n",
      "       0.79863068, 0.80617387, 0.79611894, 0.79296234, 0.80807261,\n",
      "       0.80682271, 0.80682669, 0.80618581, 0.80048961, 0.7986267 ,\n",
      "       0.8099594 , 0.81058833, 0.80681076, 0.80492795, 0.79863068,\n",
      "       0.80367407, 0.80429902, 0.80429902, 0.8017833 , 0.80490805,\n",
      "       0.80617387, 0.80868959, 0.80744367, 0.80996736, 0.80492795,\n",
      "       0.80428708, 0.80743571, 0.81122124, 0.80870154, 0.81059231,\n",
      "       0.78729002, 0.79359924, 0.79107157, 0.79990447, 0.79549797,\n",
      "       0.79422419, 0.79926757, 0.8099594 , 0.80808057, 0.81184221,\n",
      "       0.80870552, 0.80492397, 0.80744766, 0.8112093 , 0.80994746,\n",
      "       0.80994746, 0.78540721, 0.79422021, 0.79108749, 0.7917204 ,\n",
      "       0.79800175, 0.79360322, 0.80742775, 0.7998766 , 0.80618581,\n",
      "       0.81184221, 0.80743173, 0.80932251, 0.80429504, 0.80365019,\n",
      "       0.80679086, 0.80052544, 0.78414537, 0.79171244, 0.79800971,\n",
      "       0.80302922, 0.79107953, 0.79863068, 0.7973768 , 0.79736486,\n",
      "       0.80680678, 0.80492397, 0.7998766 , 0.80366213, 0.80869358,\n",
      "       0.81058833, 0.81058435, 0.81185017, 0.7835244 , 0.79547807,\n",
      "       0.79675583, 0.80177932, 0.79234137, 0.80240825, 0.79861078,\n",
      "       0.80617387, 0.79798981, 0.80240825, 0.80933843, 0.80427912,\n",
      "       0.80681872, 0.81247114, 0.80869756, 0.80176738, 0.7923573 ,\n",
      "       0.79485312, 0.79926359, 0.80051349, 0.79423613, 0.79801369,\n",
      "       0.80240427, 0.81246716, 0.80366611, 0.8030332 , 0.80240427,\n",
      "       0.80744367, 0.80996338, 0.80933047, 0.8099594 , 0.81183425,\n",
      "       0.79925961, 0.79800175, 0.79546214, 0.80240825, 0.80115039,\n",
      "       0.79548603, 0.79736884, 0.80240427, 0.80492397, 0.81059629,\n",
      "       0.80366213, 0.80618183, 0.80869358, 0.80996338, 0.80240825,\n",
      "       0.80931853, 0.79484914, 0.7917005 , 0.79926359, 0.80554892,\n",
      "       0.79987262, 0.80115039, 0.80618183, 0.80303718, 0.80680678,\n",
      "       0.8068028 , 0.80744766, 0.80429902, 0.80428708, 0.80743969,\n",
      "       0.81626065, 0.80995144, 0.79170448, 0.78730595, 0.79420428,\n",
      "       0.804303  , 0.79547409, 0.79988854, 0.80806863, 0.79800573,\n",
      "       0.80743173, 0.8030332 , 0.80240825, 0.80744367, 0.80616591,\n",
      "       0.80868959, 0.80933047, 0.80617387, 0.77722315, 0.7936072 ,\n",
      "       0.79360322, 0.8055529 , 0.80492397, 0.78980973, 0.80427912,\n",
      "       0.80429902, 0.80618581, 0.80556086, 0.80240427, 0.80617387,\n",
      "       0.81499084, 0.81185415, 0.80240427, 0.80427912, 0.78729799,\n",
      "       0.79736088, 0.80113048, 0.81184619, 0.79800175, 0.79235332,\n",
      "       0.80051747, 0.8030133 , 0.79926757, 0.80429902, 0.80240427,\n",
      "       0.80115039, 0.81184221, 0.81183425, 0.80806863, 0.80366213]), 'std_test_score': array([0.02879315, 0.03496852, 0.02538823, 0.02770194, 0.04447657,\n",
      "       0.02794382, 0.01851282, 0.02687095, 0.02669199, 0.02730639,\n",
      "       0.02642219, 0.02658786, 0.0345257 , 0.03476424, 0.03343105,\n",
      "       0.03769527, 0.02616506, 0.02954731, 0.02444037, 0.02633337,\n",
      "       0.02746454, 0.02659916, 0.03691971, 0.02795611, 0.02906799,\n",
      "       0.03598659, 0.03531007, 0.03135158, 0.02822945, 0.03435848,\n",
      "       0.03094327, 0.03102164, 0.02685911, 0.02958728, 0.03381376,\n",
      "       0.03173337, 0.02856263, 0.03360374, 0.03071604, 0.03173468,\n",
      "       0.02776731, 0.02533368, 0.0336852 , 0.03295767, 0.03424758,\n",
      "       0.02094622, 0.02825636, 0.02479656, 0.03262146, 0.02949054,\n",
      "       0.02955719, 0.03122185, 0.03121201, 0.03041495, 0.02503431,\n",
      "       0.03042212, 0.02687794, 0.02675718, 0.02847595, 0.02298181,\n",
      "       0.03009093, 0.03007288, 0.03138979, 0.03025908, 0.03040227,\n",
      "       0.03227271, 0.02994327, 0.03216629, 0.0295157 , 0.03265837,\n",
      "       0.02933644, 0.028766  , 0.02590578, 0.026972  , 0.02738863,\n",
      "       0.03136985, 0.02897468, 0.0302308 , 0.02826107, 0.02912434,\n",
      "       0.0284375 , 0.02732645, 0.02607347, 0.02851123, 0.02898366,\n",
      "       0.03408205, 0.03096776, 0.03091642, 0.02945733, 0.03214146,\n",
      "       0.03540227, 0.03150717, 0.02931087, 0.02843715, 0.02646005,\n",
      "       0.03206059, 0.02767927, 0.02642838, 0.02939306, 0.02944602,\n",
      "       0.0307839 , 0.03197297, 0.02921601, 0.0280322 , 0.03131905,\n",
      "       0.02874211, 0.03022185, 0.0261479 , 0.02663357, 0.03183352,\n",
      "       0.02967722, 0.02416826, 0.02556942, 0.0292916 , 0.03514905,\n",
      "       0.03335633, 0.02448615, 0.03400759, 0.02763401, 0.02918171,\n",
      "       0.03063508, 0.02213947, 0.03162601, 0.02973836, 0.03084455,\n",
      "       0.03462225, 0.02798422, 0.03140303, 0.02783184, 0.03120605,\n",
      "       0.0323524 , 0.02491785, 0.03173333, 0.02811477, 0.02983568,\n",
      "       0.03410669, 0.02894977, 0.02950246, 0.02264205, 0.0296952 ,\n",
      "       0.02800276, 0.02865434, 0.02982364, 0.03134441, 0.03033315,\n",
      "       0.03454316, 0.02917899, 0.03370775, 0.02409012, 0.02484354,\n",
      "       0.02847394, 0.02622848, 0.0326142 , 0.02824853, 0.03282385,\n",
      "       0.03056367, 0.02906087, 0.03032205, 0.03009526, 0.02972047,\n",
      "       0.03542757, 0.03363028, 0.03617153, 0.02779071, 0.03281001,\n",
      "       0.03767144, 0.03009568, 0.02743192, 0.03593976, 0.02592653,\n",
      "       0.03186599, 0.02940944, 0.02967663, 0.02765289, 0.02691867,\n",
      "       0.02662316, 0.0285514 , 0.03164135, 0.03521492, 0.04098138,\n",
      "       0.03116066, 0.02383673, 0.0216232 , 0.03276004, 0.03243995,\n",
      "       0.02949512, 0.02867283, 0.02462592, 0.02892569, 0.02960362,\n",
      "       0.02658403, 0.03171261, 0.02724049, 0.03023586, 0.03200243,\n",
      "       0.02430035, 0.04076367, 0.03135903, 0.02975641, 0.03494938,\n",
      "       0.02971133, 0.02954363, 0.03276004, 0.02716035, 0.02879223,\n",
      "       0.03000303, 0.02769202, 0.0290517 , 0.03439628, 0.03253361,\n",
      "       0.0351196 , 0.02983203, 0.02470154, 0.03427081, 0.03160069,\n",
      "       0.02719495, 0.02926408, 0.02929241, 0.02855975, 0.02599968,\n",
      "       0.03095967, 0.02941012, 0.02793361, 0.02840393, 0.03251558,\n",
      "       0.03608051, 0.03089143, 0.02706151, 0.03467225, 0.03649293,\n",
      "       0.02632684, 0.02660833, 0.0305657 , 0.03022526, 0.02944734,\n",
      "       0.02776645, 0.0274128 , 0.02927801, 0.02786114, 0.0235828 ,\n",
      "       0.03372536, 0.03252704, 0.02806943, 0.02491411, 0.02790456,\n",
      "       0.02507323, 0.03538012, 0.03114466, 0.02717237, 0.02777765,\n",
      "       0.03209976, 0.02925222, 0.0290657 , 0.02963172, 0.03200278,\n",
      "       0.0278193 , 0.02365358, 0.02990634, 0.03370809, 0.0288144 ,\n",
      "       0.0302749 , 0.02874249, 0.02743808, 0.02536523, 0.02930921,\n",
      "       0.02766626, 0.03210939, 0.0305045 , 0.02728135, 0.03311283,\n",
      "       0.03303019, 0.03187436, 0.02894143, 0.02797635, 0.03516962,\n",
      "       0.02888923, 0.0321891 , 0.0237234 , 0.03140438, 0.02691818,\n",
      "       0.02825594, 0.02819397, 0.03427081, 0.03162906, 0.02893855,\n",
      "       0.03206415, 0.03123889, 0.02847394, 0.01842662, 0.0350956 ,\n",
      "       0.03013911, 0.03229015, 0.03148797, 0.0311857 , 0.02660128,\n",
      "       0.0298491 , 0.03081406, 0.03151285, 0.03177335, 0.02554493,\n",
      "       0.02707366, 0.03101135, 0.02477885, 0.02982587, 0.029669  ,\n",
      "       0.02242769, 0.03247372, 0.0283815 , 0.02080945, 0.03313044,\n",
      "       0.03021598, 0.02747567, 0.03333823, 0.03394164, 0.03063243,\n",
      "       0.02887978, 0.02499437, 0.02672771, 0.02998688, 0.02456006]), 'rank_test_score': array([305, 309, 317, 320, 312, 319, 310, 306, 315, 313, 316, 308, 311,\n",
      "       314, 307, 318, 294, 303, 299, 304, 302, 300, 293, 296, 291, 298,\n",
      "       290, 295, 289, 282, 292, 301, 180, 143, 141, 205, 213, 209, 215,\n",
      "       222, 191, 258, 118, 250, 215, 251, 244, 261,   5,  45, 118,  26,\n",
      "         3,  45,  26,  50, 132,  68,  68, 164, 101, 132,   7, 209,   8,\n",
      "        37,  14,  40,  58,  11,  43, 106,  34,  84,  95,  87,  55,  89,\n",
      "        80,  26,  64,  87,  45, 109,  13, 171,  64,  95,  18, 122,  35,\n",
      "       155, 106,  26,  32,  12,   1, 117,  98,  10,  43,  26, 242, 149,\n",
      "        52,  59,   9, 187,  92, 174, 149,   4, 184, 101,  85, 203,  77,\n",
      "       146, 141, 184,  74,  80, 118,  77, 214,  89,  97,  39, 165, 173,\n",
      "       233, 135, 252, 270,  89, 115, 114, 127, 219, 234,  55,  40, 118,\n",
      "       146, 231, 171, 158, 158, 201, 156, 135,  80, 101,  49, 146, 166,\n",
      "       109,  31,  73,  37, 285, 269, 280, 220, 253, 263, 227,  54,  86,\n",
      "        21,  72, 149,  99,  33,  61,  61, 286, 264, 278, 274, 241, 268,\n",
      "       113, 223, 127,  21, 111,  70, 163, 179, 126, 212, 287, 275, 237,\n",
      "       184, 279, 231, 244, 247, 122, 149, 223, 176,  76,  42,  45,  18,\n",
      "       288, 255, 249, 202, 273, 189, 235, 135, 243, 191,  63, 168, 116,\n",
      "        14,  75, 204, 271, 259, 228, 218, 262, 236, 195,  16, 174, 182,\n",
      "       195, 101,  50,  66,  55,  24, 230, 239, 257, 191, 206, 254, 246,\n",
      "       195, 149,  36, 176, 130,  77,  52, 189,  71, 260, 277, 229, 145,\n",
      "       225, 206, 130, 181, 122, 125, 100, 158, 166, 106,   2,  59, 276,\n",
      "       283, 265, 157, 256, 221,  92, 238, 111, 182, 191, 101, 139,  80,\n",
      "        66, 134, 297, 266, 267, 144, 149, 281, 168, 158, 127, 140, 195,\n",
      "       135,   6,  17, 195, 168, 284, 248, 211,  20, 239, 272, 217, 187,\n",
      "       226, 158, 195, 208,  21,  24,  92, 176])}\n",
      "\n",
      "Resultados para Normal:\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('classifier',\n",
      "                                        RandomForestClassifier())]),\n",
      "             param_grid={'classifier__max_depth': range(1, 21),\n",
      "                         'classifier__min_samples_leaf': [1, 2, 5, 10],\n",
      "                         'classifier__min_samples_split': [2, 5, 10, 20]},\n",
      "             scoring='accuracy')\n",
      "Accuracy: 0.8391959798994975\n",
      "Precision: 0.963855421686747\n",
      "Recall: 0.5673758865248227\n",
      "F1 Score: 0.7142857142857144\n",
      "ROC AUC Score: 0.777851367386925\n",
      "Predictions: [0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\n",
      "Resultados para Balanced:\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('classifier',\n",
      "                                        RandomForestClassifier(class_weight='balanced'))]),\n",
      "             param_grid={'classifier__max_depth': range(1, 21),\n",
      "                         'classifier__min_samples_leaf': [1, 2, 5, 10],\n",
      "                         'classifier__min_samples_split': [2, 5, 10, 20]},\n",
      "             scoring='accuracy')\n",
      "Accuracy: 0.8366834170854272\n",
      "Precision: 0.9418604651162791\n",
      "Recall: 0.574468085106383\n",
      "F1 Score: 0.7136563876651982\n",
      "ROC AUC Score: 0.7775064160940475\n",
      "Predictions: [0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\n",
      "Resultados para OverSampler:\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('sampler', RandomOverSampler()),\n",
      "                                       ('classifier',\n",
      "                                        RandomForestClassifier())]),\n",
      "             param_grid={'classifier__max_depth': range(1, 21),\n",
      "                         'classifier__min_samples_leaf': [1, 2, 5, 10],\n",
      "                         'classifier__min_samples_split': [2, 5, 10, 20]},\n",
      "             scoring='accuracy')\n",
      "Accuracy: 0.8391959798994975\n",
      "Precision: 0.963855421686747\n",
      "Recall: 0.5673758865248227\n",
      "F1 Score: 0.7142857142857144\n",
      "ROC AUC Score: 0.777851367386925\n",
      "Predictions: [0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\n",
      "Resultados para UnderSampler:\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('sampler', RandomUnderSampler()),\n",
      "                                       ('classifier',\n",
      "                                        RandomForestClassifier())]),\n",
      "             param_grid={'classifier__max_depth': range(1, 21),\n",
      "                         'classifier__min_samples_leaf': [1, 2, 5, 10],\n",
      "                         'classifier__min_samples_split': [2, 5, 10, 20]},\n",
      "             scoring='accuracy')\n",
      "Accuracy: 0.8190954773869347\n",
      "Precision: 0.8791208791208791\n",
      "Recall: 0.5673758865248227\n",
      "F1 Score: 0.6896551724137931\n",
      "ROC AUC Score: 0.7622871650522947\n",
      "Predictions: [0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0\n",
      " 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\n",
      "Resultados para SMOTEENN:\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('sampler', SMOTEENN()),\n",
      "                                       ('classifier',\n",
      "                                        RandomForestClassifier())]),\n",
      "             param_grid={'classifier__max_depth': range(1, 21),\n",
      "                         'classifier__min_samples_leaf': [1, 2, 5, 10],\n",
      "                         'classifier__min_samples_split': [2, 5, 10, 20]},\n",
      "             scoring='accuracy')\n",
      "Accuracy: 0.8090452261306532\n",
      "Precision: 0.8155339805825242\n",
      "Recall: 0.5957446808510638\n",
      "F1 Score: 0.6885245901639344\n",
      "ROC AUC Score: 0.760907359880785\n",
      "Predictions: [0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 1 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 0 0 1 1 1 1 0 1 1 0 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier()\n",
    "random_forest_balanceado = RandomForestClassifier(class_weight='balanced')\n",
    "grid_parametros = {'classifier__max_depth': range(1, 21), \n",
    "                   'classifier__min_samples_leaf': [1, 2, 5, 10],\n",
    "                   'classifier__min_samples_split': [2, 5, 10, 20]}\n",
    "\n",
    "\n",
    "oversampler = RandomOverSampler()\n",
    "undersampler = RandomUnderSampler()\n",
    "combinado = SMOTEENN()\n",
    "\n",
    "\n",
    "normal_pipeline = Pipeline([('classifier', random_forest)])\n",
    "balanceado_pipeline = Pipeline([('classifier', random_forest_balanceado)])\n",
    "over_pipeline = ImbPipeline([('sampler', oversampler), ('classifier', random_forest)])\n",
    "under_pipeline = ImbPipeline([('sampler', undersampler), ('classifier', random_forest)])\n",
    "combinado_pipeline = ImbPipeline([('sampler', combinado), ('classifier', random_forest)])\n",
    "\n",
    "\n",
    "resultados = {}\n",
    "\n",
    "\n",
    "for nombre, pipeline in [('Normal', normal_pipeline), ('Balanced', balanceado_pipeline), ('OverSampler', over_pipeline), ('UnderSampler', under_pipeline), ('SMOTEENN', combinado_pipeline)]:\n",
    "    grid_search = GridSearchCV(pipeline, grid_parametros, cv=10, scoring='accuracy')\n",
    "    grid_search.fit(X_train, Y_train)\n",
    "\n",
    "    \n",
    "    print(f\"Resultados para {nombre}:\")\n",
    "    print(grid_search.cv_results_)\n",
    "\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "    Y_pred = best_estimator.predict(X_test)\n",
    "\n",
    "    resultados[nombre] = {\"GridSearchModel\": grid_search,\n",
    "                     \"Accuracy\": accuracy_score(Y_test, Y_pred),\n",
    "                     \"Precision\": precision_score(Y_test, Y_pred),\n",
    "                     \"Recall\": recall_score(Y_test, Y_pred),\n",
    "                     \"F1 Score\": f1_score(Y_test, Y_pred),\n",
    "                     \"ROC AUC Score\": roc_auc_score(Y_test, Y_pred),\n",
    "                     \"Predictions\": Y_pred}\n",
    "\n",
    "\n",
    "for nombre, metricas in resultados.items():\n",
    "    print(f\"\\nResultados para {nombre}:\")\n",
    "    for metrica, value in metricas.items():\n",
    "        print(f\"{metrica}: {value}\")\n",
    "\n",
    "for nombre, metricas in resultados.items():\n",
    "    with open(f\"Modelos/Random_Forest_{nombre}_mejor_modelo.pkl\", \"wb\") as f:\n",
    "        pickle.dump(metricas[\"GridSearchModel\"].best_estimator_, f)\n",
    "    \n",
    "    with open(f\"Resultados/Random_Forest_{nombre}_resultados.txt\", \"w\") as f:\n",
    "        for metrica, value in metricas.items():\n",
    "            if metrica != \"Predictions\": \n",
    "                f.write(f\"{metrica}: {value}\\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para Normal:\n",
      "{'mean_fit_time': array([1.63156986e-02, 3.02765131e-02, 1.53790712e-02, 3.37106466e-02,\n",
      "       1.98123217e-02, 3.11067820e-02, 1.94934130e-02, 3.23125839e-02,\n",
      "       4.85176325e-02, 5.11454105e-02, 4.81693029e-02, 5.15579462e-02,\n",
      "       2.71602983e+01, 2.05849218e-01, 3.14152871e+01, 1.97395778e-01]), 'std_fit_time': array([8.78299117e-04, 6.54580868e-04, 5.61611724e-04, 6.19448658e-03,\n",
      "       8.55400466e-04, 4.55608997e-04, 5.85712215e-04, 1.80216157e-03,\n",
      "       1.75563844e-03, 2.09936198e-03, 1.58575873e-03, 2.68284248e-03,\n",
      "       5.91996199e+00, 5.78934533e-02, 6.39876023e+00, 3.48418326e-02]), 'mean_score_time': array([0.0024955 , 0.00776541, 0.00202644, 0.00869548, 0.00216644,\n",
      "       0.00670841, 0.00216966, 0.0072448 , 0.00249259, 0.00653892,\n",
      "       0.00185859, 0.0062995 , 0.00218112, 0.00746369, 0.00260665,\n",
      "       0.00721769]), 'std_score_time': array([4.62204907e-04, 4.07458081e-04, 7.53914269e-05, 1.61854361e-03,\n",
      "       2.80422943e-04, 2.68302872e-04, 5.23073419e-04, 1.42944286e-03,\n",
      "       4.48158988e-04, 4.57929179e-04, 3.86729976e-04, 4.78801769e-04,\n",
      "       3.43541864e-04, 1.83275908e-03, 5.19814941e-04, 6.34776093e-04]), 'param_classifier__C': masked_array(data=[0.1, 0.1, 0.1, 0.1, 1, 1, 1, 1, 10, 10, 10, 10, 100,\n",
      "                   100, 100, 100],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_classifier__gamma': masked_array(data=['scale', 'scale', 'auto', 'auto', 'scale', 'scale',\n",
      "                   'auto', 'auto', 'scale', 'scale', 'auto', 'auto',\n",
      "                   'scale', 'scale', 'auto', 'auto'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_classifier__kernel': masked_array(data=['linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf',\n",
      "                   'linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf',\n",
      "                   'linear', 'rbf', 'linear', 'rbf'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'classifier__C': 0.1, 'classifier__gamma': 'scale', 'classifier__kernel': 'linear'}, {'classifier__C': 0.1, 'classifier__gamma': 'scale', 'classifier__kernel': 'rbf'}, {'classifier__C': 0.1, 'classifier__gamma': 'auto', 'classifier__kernel': 'linear'}, {'classifier__C': 0.1, 'classifier__gamma': 'auto', 'classifier__kernel': 'rbf'}, {'classifier__C': 1, 'classifier__gamma': 'scale', 'classifier__kernel': 'linear'}, {'classifier__C': 1, 'classifier__gamma': 'scale', 'classifier__kernel': 'rbf'}, {'classifier__C': 1, 'classifier__gamma': 'auto', 'classifier__kernel': 'linear'}, {'classifier__C': 1, 'classifier__gamma': 'auto', 'classifier__kernel': 'rbf'}, {'classifier__C': 10, 'classifier__gamma': 'scale', 'classifier__kernel': 'linear'}, {'classifier__C': 10, 'classifier__gamma': 'scale', 'classifier__kernel': 'rbf'}, {'classifier__C': 10, 'classifier__gamma': 'auto', 'classifier__kernel': 'linear'}, {'classifier__C': 10, 'classifier__gamma': 'auto', 'classifier__kernel': 'rbf'}, {'classifier__C': 100, 'classifier__gamma': 'scale', 'classifier__kernel': 'linear'}, {'classifier__C': 100, 'classifier__gamma': 'scale', 'classifier__kernel': 'rbf'}, {'classifier__C': 100, 'classifier__gamma': 'auto', 'classifier__kernel': 'linear'}, {'classifier__C': 100, 'classifier__gamma': 'auto', 'classifier__kernel': 'rbf'}], 'split0_test_score': array([0.71069182, 0.74213836, 0.71069182, 0.74213836, 0.71069182,\n",
      "       0.79245283, 0.71069182, 0.79245283, 0.71069182, 0.79874214,\n",
      "       0.71069182, 0.79874214, 0.71069182, 0.78616352, 0.71069182,\n",
      "       0.78616352]), 'split1_test_score': array([0.80503145, 0.81761006, 0.80503145, 0.81761006, 0.80503145,\n",
      "       0.86792453, 0.80503145, 0.86792453, 0.80503145, 0.87421384,\n",
      "       0.80503145, 0.87421384, 0.80503145, 0.8427673 , 0.80503145,\n",
      "       0.8427673 ]), 'split2_test_score': array([0.79245283, 0.81761006, 0.79245283, 0.81761006, 0.79245283,\n",
      "       0.79874214, 0.79245283, 0.79874214, 0.79245283, 0.81132075,\n",
      "       0.79245283, 0.81132075, 0.79245283, 0.81132075, 0.79245283,\n",
      "       0.81132075]), 'split3_test_score': array([0.7672956 , 0.79245283, 0.7672956 , 0.79245283, 0.7672956 ,\n",
      "       0.80503145, 0.7672956 , 0.80503145, 0.7672956 , 0.80503145,\n",
      "       0.7672956 , 0.80503145, 0.7672956 , 0.78616352, 0.7672956 ,\n",
      "       0.78616352]), 'split4_test_score': array([0.71698113, 0.73584906, 0.71698113, 0.73584906, 0.71698113,\n",
      "       0.76100629, 0.71698113, 0.76100629, 0.71698113, 0.77358491,\n",
      "       0.71698113, 0.77358491, 0.71698113, 0.79874214, 0.71698113,\n",
      "       0.79874214]), 'split5_test_score': array([0.73584906, 0.74842767, 0.73584906, 0.74842767, 0.73584906,\n",
      "       0.81132075, 0.73584906, 0.81132075, 0.73584906, 0.79874214,\n",
      "       0.73584906, 0.79874214, 0.73584906, 0.7672956 , 0.73584906,\n",
      "       0.7672956 ]), 'split6_test_score': array([0.76100629, 0.77987421, 0.76100629, 0.77987421, 0.76100629,\n",
      "       0.81132075, 0.76100629, 0.81132075, 0.76100629, 0.81761006,\n",
      "       0.76100629, 0.81761006, 0.76100629, 0.80503145, 0.76100629,\n",
      "       0.80503145]), 'split7_test_score': array([0.74842767, 0.77987421, 0.74842767, 0.77987421, 0.74842767,\n",
      "       0.79245283, 0.74842767, 0.79245283, 0.74842767, 0.79874214,\n",
      "       0.74842767, 0.79874214, 0.74842767, 0.78616352, 0.74842767,\n",
      "       0.78616352]), 'split8_test_score': array([0.74842767, 0.7672956 , 0.74842767, 0.7672956 , 0.74842767,\n",
      "       0.81132075, 0.74842767, 0.81132075, 0.74842767, 0.82389937,\n",
      "       0.74842767, 0.82389937, 0.74842767, 0.80503145, 0.74842767,\n",
      "       0.80503145]), 'split9_test_score': array([0.74050633, 0.80379747, 0.74050633, 0.80379747, 0.74050633,\n",
      "       0.84177215, 0.74050633, 0.84177215, 0.74050633, 0.85443038,\n",
      "       0.74050633, 0.85443038, 0.74050633, 0.82278481, 0.74050633,\n",
      "       0.82278481]), 'mean_test_score': array([0.75266699, 0.77849295, 0.75266699, 0.77849295, 0.75266699,\n",
      "       0.80933445, 0.75266699, 0.80933445, 0.75266699, 0.81563172,\n",
      "       0.75266699, 0.81563172, 0.75266699, 0.80114641, 0.75266699,\n",
      "       0.80114641]), 'std_test_score': array([0.02847903, 0.02840558, 0.02847903, 0.02840558, 0.02847903,\n",
      "       0.02744657, 0.02847903, 0.02744657, 0.02847903, 0.02786418,\n",
      "       0.02847903, 0.02786418, 0.02847903, 0.02039446, 0.02847903,\n",
      "       0.02039446]), 'rank_test_score': array([9, 7, 9, 7, 9, 3, 9, 3, 9, 1, 9, 1, 9, 5, 9, 5])}\n",
      "Resultados para Balanced:\n",
      "{'mean_fit_time': array([0.03402493, 0.04710684, 0.03649962, 0.04748178, 0.04474535,\n",
      "       0.04928713, 0.04416962, 0.04275353, 0.12989929, 0.06165307,\n",
      "       0.12568488, 0.05908186, 3.28610926, 0.15008402, 3.27946599,\n",
      "       0.14810648]), 'std_fit_time': array([2.49924947e-03, 2.21292655e-03, 5.87391863e-03, 1.15515188e-03,\n",
      "       4.78925028e-03, 5.18869065e-03, 4.37142782e-03, 2.58062930e-03,\n",
      "       1.83116505e-02, 5.01626268e-03, 1.98298210e-02, 3.39079170e-03,\n",
      "       2.87687599e+00, 1.85096776e-02, 2.87292422e+00, 1.93712612e-02]), 'mean_score_time': array([0.00340958, 0.01069274, 0.00316675, 0.0112175 , 0.00286252,\n",
      "       0.01084621, 0.00288312, 0.0091166 , 0.00293519, 0.0080281 ,\n",
      "       0.00299764, 0.00873911, 0.00289068, 0.0083164 , 0.00330787,\n",
      "       0.00844848]), 'std_score_time': array([0.00072019, 0.00059064, 0.00064965, 0.00110501, 0.00089262,\n",
      "       0.00261941, 0.00092007, 0.00061632, 0.00074595, 0.00070223,\n",
      "       0.00069328, 0.0009203 , 0.00103435, 0.00083273, 0.00103365,\n",
      "       0.00071295]), 'param_classifier__C': masked_array(data=[0.1, 0.1, 0.1, 0.1, 1, 1, 1, 1, 10, 10, 10, 10, 100,\n",
      "                   100, 100, 100],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_classifier__gamma': masked_array(data=['scale', 'scale', 'auto', 'auto', 'scale', 'scale',\n",
      "                   'auto', 'auto', 'scale', 'scale', 'auto', 'auto',\n",
      "                   'scale', 'scale', 'auto', 'auto'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_classifier__kernel': masked_array(data=['linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf',\n",
      "                   'linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf',\n",
      "                   'linear', 'rbf', 'linear', 'rbf'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'classifier__C': 0.1, 'classifier__gamma': 'scale', 'classifier__kernel': 'linear'}, {'classifier__C': 0.1, 'classifier__gamma': 'scale', 'classifier__kernel': 'rbf'}, {'classifier__C': 0.1, 'classifier__gamma': 'auto', 'classifier__kernel': 'linear'}, {'classifier__C': 0.1, 'classifier__gamma': 'auto', 'classifier__kernel': 'rbf'}, {'classifier__C': 1, 'classifier__gamma': 'scale', 'classifier__kernel': 'linear'}, {'classifier__C': 1, 'classifier__gamma': 'scale', 'classifier__kernel': 'rbf'}, {'classifier__C': 1, 'classifier__gamma': 'auto', 'classifier__kernel': 'linear'}, {'classifier__C': 1, 'classifier__gamma': 'auto', 'classifier__kernel': 'rbf'}, {'classifier__C': 10, 'classifier__gamma': 'scale', 'classifier__kernel': 'linear'}, {'classifier__C': 10, 'classifier__gamma': 'scale', 'classifier__kernel': 'rbf'}, {'classifier__C': 10, 'classifier__gamma': 'auto', 'classifier__kernel': 'linear'}, {'classifier__C': 10, 'classifier__gamma': 'auto', 'classifier__kernel': 'rbf'}, {'classifier__C': 100, 'classifier__gamma': 'scale', 'classifier__kernel': 'linear'}, {'classifier__C': 100, 'classifier__gamma': 'scale', 'classifier__kernel': 'rbf'}, {'classifier__C': 100, 'classifier__gamma': 'auto', 'classifier__kernel': 'linear'}, {'classifier__C': 100, 'classifier__gamma': 'auto', 'classifier__kernel': 'rbf'}], 'split0_test_score': array([0.71069182, 0.77987421, 0.71069182, 0.77987421, 0.71069182,\n",
      "       0.77358491, 0.71069182, 0.77358491, 0.71069182, 0.79874214,\n",
      "       0.71069182, 0.79874214, 0.71069182, 0.75471698, 0.71069182,\n",
      "       0.75471698]), 'split1_test_score': array([0.80503145, 0.86792453, 0.80503145, 0.86792453, 0.82389937,\n",
      "       0.87421384, 0.82389937, 0.87421384, 0.82389937, 0.81761006,\n",
      "       0.82389937, 0.81761006, 0.82389937, 0.83647799, 0.82389937,\n",
      "       0.83647799]), 'split2_test_score': array([0.77358491, 0.77358491, 0.77358491, 0.77358491, 0.77987421,\n",
      "       0.77358491, 0.77987421, 0.77358491, 0.77987421, 0.78616352,\n",
      "       0.77987421, 0.78616352, 0.77987421, 0.80503145, 0.77987421,\n",
      "       0.80503145]), 'split3_test_score': array([0.76100629, 0.78616352, 0.76100629, 0.78616352, 0.76100629,\n",
      "       0.77358491, 0.76100629, 0.77358491, 0.76100629, 0.7672956 ,\n",
      "       0.76100629, 0.7672956 , 0.76100629, 0.7672956 , 0.76100629,\n",
      "       0.7672956 ]), 'split4_test_score': array([0.72327044, 0.75471698, 0.72327044, 0.75471698, 0.72955975,\n",
      "       0.74842767, 0.72955975, 0.74842767, 0.72955975, 0.76100629,\n",
      "       0.72955975, 0.76100629, 0.72955975, 0.78616352, 0.72955975,\n",
      "       0.78616352]), 'split5_test_score': array([0.73584906, 0.77358491, 0.73584906, 0.77358491, 0.73584906,\n",
      "       0.79245283, 0.73584906, 0.79245283, 0.73584906, 0.79874214,\n",
      "       0.73584906, 0.79874214, 0.73584906, 0.77358491, 0.73584906,\n",
      "       0.77358491]), 'split6_test_score': array([0.75471698, 0.82389937, 0.75471698, 0.82389937, 0.75471698,\n",
      "       0.81132075, 0.75471698, 0.81132075, 0.75471698, 0.77987421,\n",
      "       0.75471698, 0.77987421, 0.75471698, 0.7672956 , 0.75471698,\n",
      "       0.7672956 ]), 'split7_test_score': array([0.74842767, 0.77358491, 0.74842767, 0.77358491, 0.74842767,\n",
      "       0.79874214, 0.74842767, 0.79874214, 0.74842767, 0.76100629,\n",
      "       0.74842767, 0.76100629, 0.74842767, 0.77358491, 0.74842767,\n",
      "       0.77358491]), 'split8_test_score': array([0.74842767, 0.77358491, 0.74842767, 0.77358491, 0.74842767,\n",
      "       0.81761006, 0.74842767, 0.81761006, 0.74842767, 0.81761006,\n",
      "       0.74842767, 0.81761006, 0.74842767, 0.79245283, 0.74842767,\n",
      "       0.79245283]), 'split9_test_score': array([0.74050633, 0.81012658, 0.74050633, 0.81012658, 0.74050633,\n",
      "       0.8164557 , 0.74050633, 0.8164557 , 0.74050633, 0.81012658,\n",
      "       0.74050633, 0.81012658, 0.74050633, 0.78481013, 0.74050633,\n",
      "       0.78481013]), 'mean_test_score': array([0.75015126, 0.79170448, 0.75015126, 0.79170448, 0.75329592,\n",
      "       0.79799777, 0.75329592, 0.79799777, 0.75329592, 0.78981769,\n",
      "       0.75329592, 0.78981769, 0.75329592, 0.78414139, 0.75329592,\n",
      "       0.78414139]), 'std_test_score': array([0.0250655 , 0.03168184, 0.0250655 , 0.03168184, 0.02940511,\n",
      "       0.03314843, 0.02940511, 0.03314843, 0.02940511, 0.02096721,\n",
      "       0.02940511, 0.02096721, 0.02940511, 0.02214806, 0.02940511,\n",
      "       0.02214806]), 'rank_test_score': array([15,  3, 15,  3,  9,  1,  9,  1,  9,  5,  9,  5,  9,  7,  9,  7])}\n",
      "Resultados para OverSampler:\n",
      "{'mean_fit_time': array([0.0512944 , 0.06832542, 0.0456641 , 0.06627228, 0.06706035,\n",
      "       0.06521144, 0.07211971, 0.06475732, 0.20575633, 0.08942482,\n",
      "       0.20032938, 0.08775928, 6.96003633, 0.19432795, 3.6062077 ,\n",
      "       0.21858571]), 'std_fit_time': array([8.48029552e-03, 4.59980261e-03, 2.35081696e-03, 2.09906309e-03,\n",
      "       8.57290181e-03, 3.53476509e-03, 5.67126035e-03, 2.39612385e-03,\n",
      "       2.35893102e-02, 3.94408165e-03, 2.82109660e-02, 2.64367639e-03,\n",
      "       7.87550919e+00, 1.70109837e-02, 3.47759191e+00, 2.77125360e-02]), 'mean_score_time': array([0.00342295, 0.0132206 , 0.00303147, 0.01267557, 0.0034085 ,\n",
      "       0.01107385, 0.00324519, 0.01144016, 0.00354555, 0.01096456,\n",
      "       0.00383389, 0.01026998, 0.00347815, 0.01003277, 0.00369449,\n",
      "       0.01072536]), 'std_score_time': array([0.00061392, 0.00194262, 0.00058684, 0.00063568, 0.0006937 ,\n",
      "       0.00113191, 0.00070445, 0.00075663, 0.00079882, 0.00073534,\n",
      "       0.00086263, 0.00069839, 0.00053274, 0.0010297 , 0.00068708,\n",
      "       0.00143869]), 'param_classifier__C': masked_array(data=[0.1, 0.1, 0.1, 0.1, 1, 1, 1, 1, 10, 10, 10, 10, 100,\n",
      "                   100, 100, 100],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_classifier__gamma': masked_array(data=['scale', 'scale', 'auto', 'auto', 'scale', 'scale',\n",
      "                   'auto', 'auto', 'scale', 'scale', 'auto', 'auto',\n",
      "                   'scale', 'scale', 'auto', 'auto'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_classifier__kernel': masked_array(data=['linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf',\n",
      "                   'linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf',\n",
      "                   'linear', 'rbf', 'linear', 'rbf'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'classifier__C': 0.1, 'classifier__gamma': 'scale', 'classifier__kernel': 'linear'}, {'classifier__C': 0.1, 'classifier__gamma': 'scale', 'classifier__kernel': 'rbf'}, {'classifier__C': 0.1, 'classifier__gamma': 'auto', 'classifier__kernel': 'linear'}, {'classifier__C': 0.1, 'classifier__gamma': 'auto', 'classifier__kernel': 'rbf'}, {'classifier__C': 1, 'classifier__gamma': 'scale', 'classifier__kernel': 'linear'}, {'classifier__C': 1, 'classifier__gamma': 'scale', 'classifier__kernel': 'rbf'}, {'classifier__C': 1, 'classifier__gamma': 'auto', 'classifier__kernel': 'linear'}, {'classifier__C': 1, 'classifier__gamma': 'auto', 'classifier__kernel': 'rbf'}, {'classifier__C': 10, 'classifier__gamma': 'scale', 'classifier__kernel': 'linear'}, {'classifier__C': 10, 'classifier__gamma': 'scale', 'classifier__kernel': 'rbf'}, {'classifier__C': 10, 'classifier__gamma': 'auto', 'classifier__kernel': 'linear'}, {'classifier__C': 10, 'classifier__gamma': 'auto', 'classifier__kernel': 'rbf'}, {'classifier__C': 100, 'classifier__gamma': 'scale', 'classifier__kernel': 'linear'}, {'classifier__C': 100, 'classifier__gamma': 'scale', 'classifier__kernel': 'rbf'}, {'classifier__C': 100, 'classifier__gamma': 'auto', 'classifier__kernel': 'linear'}, {'classifier__C': 100, 'classifier__gamma': 'auto', 'classifier__kernel': 'rbf'}], 'split0_test_score': array([0.73584906, 0.74842767, 0.71069182, 0.77987421, 0.71069182,\n",
      "       0.78616352, 0.73584906, 0.79245283, 0.71069182, 0.77987421,\n",
      "       0.73584906, 0.80503145, 0.71069182, 0.74842767, 0.71698113,\n",
      "       0.7672956 ]), 'split1_test_score': array([0.80503145, 0.87421384, 0.78616352, 0.86792453, 0.77358491,\n",
      "       0.87421384, 0.80503145, 0.86792453, 0.80503145, 0.86163522,\n",
      "       0.82389937, 0.8490566 , 0.82389937, 0.82389937, 0.83018868,\n",
      "       0.82389937]), 'split2_test_score': array([0.77987421, 0.77358491, 0.7672956 , 0.7672956 , 0.77358491,\n",
      "       0.77987421, 0.77358491, 0.78616352, 0.74842767, 0.78616352,\n",
      "       0.77358491, 0.77358491, 0.7672956 , 0.78616352, 0.79245283,\n",
      "       0.81132075]), 'split3_test_score': array([0.75471698, 0.78616352, 0.74213836, 0.78616352, 0.73584906,\n",
      "       0.76100629, 0.75471698, 0.77987421, 0.77358491, 0.77358491,\n",
      "       0.72327044, 0.77358491, 0.76100629, 0.74213836, 0.7672956 ,\n",
      "       0.7672956 ]), 'split4_test_score': array([0.72327044, 0.74842767, 0.71698113, 0.73584906, 0.71698113,\n",
      "       0.74842767, 0.71069182, 0.74842767, 0.72327044, 0.76100629,\n",
      "       0.69811321, 0.7672956 , 0.71698113, 0.78616352, 0.71698113,\n",
      "       0.78616352]), 'split5_test_score': array([0.73584906, 0.77358491, 0.73584906, 0.77358491, 0.67924528,\n",
      "       0.78616352, 0.67924528, 0.79245283, 0.73584906, 0.77987421,\n",
      "       0.73584906, 0.79874214, 0.73584906, 0.74842767, 0.73584906,\n",
      "       0.77358491]), 'split6_test_score': array([0.75471698, 0.81132075, 0.75471698, 0.83018868, 0.76100629,\n",
      "       0.80503145, 0.76100629, 0.79874214, 0.77358491, 0.7672956 ,\n",
      "       0.76100629, 0.77987421, 0.74213836, 0.74842767, 0.74842767,\n",
      "       0.75471698]), 'split7_test_score': array([0.77987421, 0.77358491, 0.74842767, 0.77987421, 0.74842767,\n",
      "       0.77358491, 0.74842767, 0.78616352, 0.76100629, 0.76100629,\n",
      "       0.74842767, 0.80503145, 0.74842767, 0.76100629, 0.72327044,\n",
      "       0.77987421]), 'split8_test_score': array([0.72327044, 0.77358491, 0.74842767, 0.77358491, 0.74842767,\n",
      "       0.82389937, 0.74842767, 0.82389937, 0.74842767, 0.78616352,\n",
      "       0.74842767, 0.80503145, 0.72955975, 0.79245283, 0.74842767,\n",
      "       0.7672956 ]), 'split9_test_score': array([0.77848101, 0.80379747, 0.74050633, 0.80379747, 0.74050633,\n",
      "       0.81012658, 0.77848101, 0.82278481, 0.74050633, 0.81012658,\n",
      "       0.74050633, 0.81012658, 0.74050633, 0.79113924, 0.74050633,\n",
      "       0.79746835]), 'mean_test_score': array([0.75709338, 0.78666906, 0.74511982, 0.78981371, 0.73883051,\n",
      "       0.79484914, 0.74954621, 0.79988854, 0.75203805, 0.78667304,\n",
      "       0.7488934 , 0.79673593, 0.74763554, 0.77282462, 0.75203805,\n",
      "       0.78289149]), 'std_test_score': array([0.02644871, 0.03489272, 0.02093689, 0.03476189, 0.02814781,\n",
      "       0.03406954, 0.03360619, 0.0304419 , 0.02602976, 0.02850739,\n",
      "       0.03166787, 0.02313055, 0.03038639, 0.02559712, 0.03417653,\n",
      "       0.02081412]), 'rank_test_score': array([ 9,  6, 15,  4, 16,  3, 12,  1, 10,  5, 13,  2, 14,  8, 10,  7])}\n",
      "Resultados para UnderSampler:\n",
      "{'mean_fit_time': array([0.01634963, 0.02367344, 0.01530118, 0.02269416, 0.02370479,\n",
      "       0.0221597 , 0.0240515 , 0.02246342, 0.06719234, 0.03064942,\n",
      "       0.06361752, 0.03008997, 0.57343349, 0.06810861, 0.72329547,\n",
      "       0.06616118]), 'std_fit_time': array([0.00231978, 0.00167769, 0.00110845, 0.00112014, 0.00308935,\n",
      "       0.00143078, 0.00293521, 0.00166687, 0.00485542, 0.00180637,\n",
      "       0.00895693, 0.00190443, 0.32933519, 0.00822142, 0.36944732,\n",
      "       0.00798327]), 'mean_score_time': array([0.00243154, 0.0081084 , 0.00237284, 0.00844049, 0.00249479,\n",
      "       0.00680039, 0.00230968, 0.00708158, 0.00238454, 0.00618188,\n",
      "       0.0023381 , 0.00683248, 0.00249066, 0.00637155, 0.00238509,\n",
      "       0.00669827]), 'std_score_time': array([0.00031821, 0.00078616, 0.000556  , 0.00123274, 0.00095162,\n",
      "       0.00053855, 0.00048742, 0.00084462, 0.00048267, 0.0006734 ,\n",
      "       0.00064587, 0.00049997, 0.00072798, 0.00062211, 0.00044952,\n",
      "       0.00065686]), 'param_classifier__C': masked_array(data=[0.1, 0.1, 0.1, 0.1, 1, 1, 1, 1, 10, 10, 10, 10, 100,\n",
      "                   100, 100, 100],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_classifier__gamma': masked_array(data=['scale', 'scale', 'auto', 'auto', 'scale', 'scale',\n",
      "                   'auto', 'auto', 'scale', 'scale', 'auto', 'auto',\n",
      "                   'scale', 'scale', 'auto', 'auto'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_classifier__kernel': masked_array(data=['linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf',\n",
      "                   'linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf',\n",
      "                   'linear', 'rbf', 'linear', 'rbf'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'classifier__C': 0.1, 'classifier__gamma': 'scale', 'classifier__kernel': 'linear'}, {'classifier__C': 0.1, 'classifier__gamma': 'scale', 'classifier__kernel': 'rbf'}, {'classifier__C': 0.1, 'classifier__gamma': 'auto', 'classifier__kernel': 'linear'}, {'classifier__C': 0.1, 'classifier__gamma': 'auto', 'classifier__kernel': 'rbf'}, {'classifier__C': 1, 'classifier__gamma': 'scale', 'classifier__kernel': 'linear'}, {'classifier__C': 1, 'classifier__gamma': 'scale', 'classifier__kernel': 'rbf'}, {'classifier__C': 1, 'classifier__gamma': 'auto', 'classifier__kernel': 'linear'}, {'classifier__C': 1, 'classifier__gamma': 'auto', 'classifier__kernel': 'rbf'}, {'classifier__C': 10, 'classifier__gamma': 'scale', 'classifier__kernel': 'linear'}, {'classifier__C': 10, 'classifier__gamma': 'scale', 'classifier__kernel': 'rbf'}, {'classifier__C': 10, 'classifier__gamma': 'auto', 'classifier__kernel': 'linear'}, {'classifier__C': 10, 'classifier__gamma': 'auto', 'classifier__kernel': 'rbf'}, {'classifier__C': 100, 'classifier__gamma': 'scale', 'classifier__kernel': 'linear'}, {'classifier__C': 100, 'classifier__gamma': 'scale', 'classifier__kernel': 'rbf'}, {'classifier__C': 100, 'classifier__gamma': 'auto', 'classifier__kernel': 'linear'}, {'classifier__C': 100, 'classifier__gamma': 'auto', 'classifier__kernel': 'rbf'}], 'split0_test_score': array([0.71069182, 0.76100629, 0.71069182, 0.76100629, 0.72327044,\n",
      "       0.79245283, 0.71069182, 0.77358491, 0.71069182, 0.7672956 ,\n",
      "       0.71069182, 0.7672956 , 0.71069182, 0.75471698, 0.73584906,\n",
      "       0.76100629]), 'split1_test_score': array([0.79874214, 0.86163522, 0.80503145, 0.85534591, 0.80503145,\n",
      "       0.8427673 , 0.81132075, 0.87421384, 0.80503145, 0.8427673 ,\n",
      "       0.79245283, 0.85534591, 0.78616352, 0.83018868, 0.81761006,\n",
      "       0.81761006]), 'split2_test_score': array([0.76100629, 0.79245283, 0.77987421, 0.77987421, 0.77358491,\n",
      "       0.7672956 , 0.77358491, 0.74842767, 0.76100629, 0.77358491,\n",
      "       0.7672956 , 0.7672956 , 0.79245283, 0.80503145, 0.79245283,\n",
      "       0.75471698]), 'split3_test_score': array([0.77358491, 0.77358491, 0.72327044, 0.79874214, 0.77987421,\n",
      "       0.77358491, 0.76100629, 0.7672956 , 0.75471698, 0.76100629,\n",
      "       0.7672956 , 0.77358491, 0.76100629, 0.75471698, 0.71698113,\n",
      "       0.76100629]), 'split4_test_score': array([0.73584906, 0.74213836, 0.71698113, 0.74213836, 0.72327044,\n",
      "       0.74213836, 0.71698113, 0.72327044, 0.73584906, 0.76100629,\n",
      "       0.71069182, 0.74213836, 0.72327044, 0.77358491, 0.71698113,\n",
      "       0.77358491]), 'split5_test_score': array([0.72955975, 0.77358491, 0.67924528, 0.77358491, 0.72327044,\n",
      "       0.78616352, 0.71069182, 0.79874214, 0.71698113, 0.76100629,\n",
      "       0.73584906, 0.77987421, 0.72327044, 0.72327044, 0.67924528,\n",
      "       0.77358491]), 'split6_test_score': array([0.7672956 , 0.81132075, 0.77987421, 0.79874214, 0.76100629,\n",
      "       0.79874214, 0.76100629, 0.81132075, 0.73584906, 0.7672956 ,\n",
      "       0.77358491, 0.77987421, 0.76100629, 0.75471698, 0.75471698,\n",
      "       0.74213836]), 'split7_test_score': array([0.79245283, 0.79245283, 0.74842767, 0.78616352, 0.74842767,\n",
      "       0.79245283, 0.72327044, 0.78616352, 0.74842767, 0.77987421,\n",
      "       0.74842767, 0.7672956 , 0.72327044, 0.77358491, 0.72327044,\n",
      "       0.75471698]), 'split8_test_score': array([0.72955975, 0.76100629, 0.74213836, 0.7672956 , 0.74842767,\n",
      "       0.79874214, 0.74213836, 0.79874214, 0.72327044, 0.82389937,\n",
      "       0.74842767, 0.79245283, 0.72327044, 0.78616352, 0.74842767,\n",
      "       0.79874214]), 'split9_test_score': array([0.74050633, 0.80379747, 0.74050633, 0.8164557 , 0.74050633,\n",
      "       0.82278481, 0.75316456, 0.82278481, 0.76582278, 0.79746835,\n",
      "       0.68987342, 0.79746835, 0.75316456, 0.77848101, 0.68987342,\n",
      "       0.75949367]), 'mean_test_score': array([0.75392485, 0.78729799, 0.74260409, 0.78793488, 0.75266699,\n",
      "       0.79171244, 0.74638564, 0.79045458, 0.74576467, 0.78352042,\n",
      "       0.74445904, 0.78226256, 0.74575671, 0.77344559, 0.7375408 ,\n",
      "       0.76966006]), 'std_test_score': array([0.02769772, 0.03197888, 0.03574477, 0.03018901, 0.0260109 ,\n",
      "       0.02661802, 0.03065114, 0.03968996, 0.02644929, 0.02737582,\n",
      "       0.03091991, 0.02836358, 0.0275414 , 0.028239  , 0.04069695,\n",
      "       0.02152428]), 'rank_test_score': array([ 9,  4, 15,  3, 10,  1, 11,  2, 12,  5, 14,  6, 13,  7, 16,  8])}\n",
      "Resultados para SMOTEENN:\n",
      "{'mean_fit_time': array([0.03140078, 0.03358006, 0.02944667, 0.03838077, 0.03405101,\n",
      "       0.02891383, 0.03363585, 0.02943511, 0.06537504, 0.02981305,\n",
      "       0.0629436 , 0.03135302, 0.28765414, 0.0336777 , 0.2974565 ,\n",
      "       0.03142979]), 'std_fit_time': array([0.00358956, 0.00131298, 0.00156713, 0.00528124, 0.00222493,\n",
      "       0.00086295, 0.00174717, 0.00158276, 0.00777679, 0.00123414,\n",
      "       0.00552636, 0.00249002, 0.04521191, 0.00209304, 0.05796913,\n",
      "       0.00208247]), 'mean_score_time': array([0.00166557, 0.00530598, 0.00167246, 0.00588284, 0.00119786,\n",
      "       0.00336535, 0.00187333, 0.00334806, 0.00160346, 0.00275805,\n",
      "       0.00152762, 0.00275998, 0.00154762, 0.00218379, 0.00148907,\n",
      "       0.00221345]), 'std_score_time': array([0.00045471, 0.00066118, 0.00066777, 0.00130975, 0.00030712,\n",
      "       0.00042835, 0.00027397, 0.00058349, 0.00082417, 0.0008174 ,\n",
      "       0.00048237, 0.00049517, 0.00049229, 0.00071125, 0.00055633,\n",
      "       0.0005822 ]), 'param_classifier__C': masked_array(data=[0.1, 0.1, 0.1, 0.1, 1, 1, 1, 1, 10, 10, 10, 10, 100,\n",
      "                   100, 100, 100],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_classifier__gamma': masked_array(data=['scale', 'scale', 'auto', 'auto', 'scale', 'scale',\n",
      "                   'auto', 'auto', 'scale', 'scale', 'auto', 'auto',\n",
      "                   'scale', 'scale', 'auto', 'auto'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_classifier__kernel': masked_array(data=['linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf',\n",
      "                   'linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf',\n",
      "                   'linear', 'rbf', 'linear', 'rbf'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'classifier__C': 0.1, 'classifier__gamma': 'scale', 'classifier__kernel': 'linear'}, {'classifier__C': 0.1, 'classifier__gamma': 'scale', 'classifier__kernel': 'rbf'}, {'classifier__C': 0.1, 'classifier__gamma': 'auto', 'classifier__kernel': 'linear'}, {'classifier__C': 0.1, 'classifier__gamma': 'auto', 'classifier__kernel': 'rbf'}, {'classifier__C': 1, 'classifier__gamma': 'scale', 'classifier__kernel': 'linear'}, {'classifier__C': 1, 'classifier__gamma': 'scale', 'classifier__kernel': 'rbf'}, {'classifier__C': 1, 'classifier__gamma': 'auto', 'classifier__kernel': 'linear'}, {'classifier__C': 1, 'classifier__gamma': 'auto', 'classifier__kernel': 'rbf'}, {'classifier__C': 10, 'classifier__gamma': 'scale', 'classifier__kernel': 'linear'}, {'classifier__C': 10, 'classifier__gamma': 'scale', 'classifier__kernel': 'rbf'}, {'classifier__C': 10, 'classifier__gamma': 'auto', 'classifier__kernel': 'linear'}, {'classifier__C': 10, 'classifier__gamma': 'auto', 'classifier__kernel': 'rbf'}, {'classifier__C': 100, 'classifier__gamma': 'scale', 'classifier__kernel': 'linear'}, {'classifier__C': 100, 'classifier__gamma': 'scale', 'classifier__kernel': 'rbf'}, {'classifier__C': 100, 'classifier__gamma': 'auto', 'classifier__kernel': 'linear'}, {'classifier__C': 100, 'classifier__gamma': 'auto', 'classifier__kernel': 'rbf'}], 'split0_test_score': array([0.74213836, 0.77358491, 0.74213836, 0.77987421, 0.74213836,\n",
      "       0.7672956 , 0.72955975, 0.7672956 , 0.74213836, 0.72955975,\n",
      "       0.74213836, 0.76100629, 0.74213836, 0.72955975, 0.72327044,\n",
      "       0.74842767]), 'split1_test_score': array([0.79874214, 0.83018868, 0.79245283, 0.83018868, 0.80503145,\n",
      "       0.83018868, 0.81132075, 0.8490566 , 0.77358491, 0.8490566 ,\n",
      "       0.79874214, 0.8427673 , 0.77987421, 0.79874214, 0.80503145,\n",
      "       0.86163522]), 'split2_test_score': array([0.72955975, 0.75471698, 0.71698113, 0.74842767, 0.76100629,\n",
      "       0.77358491, 0.73584906, 0.73584906, 0.72955975, 0.71069182,\n",
      "       0.73584906, 0.72955975, 0.72327044, 0.76100629, 0.70440252,\n",
      "       0.75471698]), 'split3_test_score': array([0.72327044, 0.77358491, 0.73584906, 0.77358491, 0.70440252,\n",
      "       0.77358491, 0.73584906, 0.74213836, 0.73584906, 0.76100629,\n",
      "       0.72955975, 0.74213836, 0.73584906, 0.74213836, 0.73584906,\n",
      "       0.74213836]), 'split4_test_score': array([0.71698113, 0.72327044, 0.71698113, 0.71069182, 0.69811321,\n",
      "       0.74213836, 0.71069182, 0.73584906, 0.69811321, 0.76100629,\n",
      "       0.68553459, 0.72327044, 0.71698113, 0.71069182, 0.71069182,\n",
      "       0.74213836]), 'split5_test_score': array([0.72327044, 0.7672956 , 0.72955975, 0.74842767, 0.72955975,\n",
      "       0.77358491, 0.74213836, 0.75471698, 0.69811321, 0.74842767,\n",
      "       0.71698113, 0.75471698, 0.71698113, 0.71698113, 0.72955975,\n",
      "       0.71698113]), 'split6_test_score': array([0.73584906, 0.79245283, 0.77358491, 0.79245283, 0.7672956 ,\n",
      "       0.77358491, 0.75471698, 0.76100629, 0.74842767, 0.83018868,\n",
      "       0.72955975, 0.79245283, 0.71069182, 0.78616352, 0.73584906,\n",
      "       0.81132075]), 'split7_test_score': array([0.75471698, 0.77358491, 0.72955975, 0.7672956 , 0.71698113,\n",
      "       0.74842767, 0.73584906, 0.77358491, 0.71069182, 0.73584906,\n",
      "       0.74213836, 0.76100629, 0.72955975, 0.69811321, 0.74213836,\n",
      "       0.72955975]), 'split8_test_score': array([0.72327044, 0.75471698, 0.71069182, 0.75471698, 0.69811321,\n",
      "       0.79874214, 0.72327044, 0.77358491, 0.70440252, 0.77987421,\n",
      "       0.70440252, 0.77987421, 0.71069182, 0.81761006, 0.71698113,\n",
      "       0.74213836]), 'split9_test_score': array([0.71518987, 0.76582278, 0.75316456, 0.77848101, 0.7278481 ,\n",
      "       0.79746835, 0.70253165, 0.77848101, 0.74050633, 0.77848101,\n",
      "       0.73417722, 0.77848101, 0.74050633, 0.74683544, 0.74683544,\n",
      "       0.78481013]), 'mean_test_score': array([0.73629886, 0.7709219 , 0.74009633, 0.76841414, 0.73504896,\n",
      "       0.77786004, 0.73817769, 0.76715628, 0.72813868, 0.76841414,\n",
      "       0.73190829, 0.76652735, 0.73065441, 0.75078417, 0.7350609 ,\n",
      "       0.76338667]), 'std_test_score': array([0.0237615 , 0.0261389 , 0.02492181, 0.02995498, 0.03276823,\n",
      "       0.02426077, 0.02824539, 0.03114053, 0.023576  , 0.04118641,\n",
      "       0.02799587, 0.03292222, 0.01976149, 0.03766556, 0.02667545,\n",
      "       0.041666  ]), 'rank_test_score': array([11,  2,  9,  3, 13,  1, 10,  5, 16,  3, 14,  6, 15,  8, 12,  7])}\n",
      "\n",
      "Resultados para Normal:\n",
      "GridSearchModel: GridSearchCV(cv=10, estimator=Pipeline(steps=[('classifier', SVC())]),\n",
      "             param_grid={'classifier__C': [0.1, 1, 10, 100],\n",
      "                         'classifier__gamma': ['scale', 'auto'],\n",
      "                         'classifier__kernel': ['linear', 'rbf']},\n",
      "             scoring='accuracy')\n",
      "Accuracy: 0.8065326633165829\n",
      "Precision: 0.872093023255814\n",
      "Recall: 0.5319148936170213\n",
      "F1 Score: 0.6607929515418502\n",
      "ROC AUC Score: 0.7445566685983939\n",
      "Predictions: [0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "\n",
      "Resultados para Balanced:\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('classifier',\n",
      "                                        SVC(class_weight='balanced'))]),\n",
      "             param_grid={'classifier__C': [0.1, 1, 10, 100],\n",
      "                         'classifier__gamma': ['scale', 'auto'],\n",
      "                         'classifier__kernel': ['linear', 'rbf']},\n",
      "             scoring='accuracy')\n",
      "Accuracy: 0.7839195979899497\n",
      "Precision: 0.7522935779816514\n",
      "Recall: 0.5815602836879432\n",
      "F1 Score: 0.6559999999999999\n",
      "ROC AUC Score: 0.7382509589645943\n",
      "Predictions: [0 1 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 1 1 1 1 0 0 1 0 0 1 0 0 1 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 0 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\n",
      "Resultados para OverSampler:\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('sampler', RandomOverSampler()),\n",
      "                                       ('classifier', SVC())]),\n",
      "             param_grid={'classifier__C': [0.1, 1, 10, 100],\n",
      "                         'classifier__gamma': ['scale', 'auto'],\n",
      "                         'classifier__kernel': ['linear', 'rbf']},\n",
      "             scoring='accuracy')\n",
      "Accuracy: 0.7839195979899497\n",
      "Precision: 0.7522935779816514\n",
      "Recall: 0.5815602836879432\n",
      "F1 Score: 0.6559999999999999\n",
      "ROC AUC Score: 0.7382509589645943\n",
      "Predictions: [0 1 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 1 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 0 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\n",
      "Resultados para UnderSampler:\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('sampler', RandomUnderSampler()),\n",
      "                                       ('classifier', SVC())]),\n",
      "             param_grid={'classifier__C': [0.1, 1, 10, 100],\n",
      "                         'classifier__gamma': ['scale', 'auto'],\n",
      "                         'classifier__kernel': ['linear', 'rbf']},\n",
      "             scoring='accuracy')\n",
      "Accuracy: 0.7939698492462312\n",
      "Precision: 0.7657657657657657\n",
      "Recall: 0.6028368794326241\n",
      "F1 Score: 0.6746031746031745\n",
      "ROC AUC Score: 0.7508347821287634\n",
      "Predictions: [0 1 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 1 1 1 1 0 0 1 0 0 1 0 0 1 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\n",
      "Resultados para SMOTEENN:\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('sampler', SMOTEENN()),\n",
      "                                       ('classifier', SVC())]),\n",
      "             param_grid={'classifier__C': [0.1, 1, 10, 100],\n",
      "                         'classifier__gamma': ['scale', 'auto'],\n",
      "                         'classifier__kernel': ['linear', 'rbf']},\n",
      "             scoring='accuracy')\n",
      "Accuracy: 0.7814070351758794\n",
      "Precision: 0.7410714285714286\n",
      "Recall: 0.5886524822695035\n",
      "F1 Score: 0.6561264822134388\n",
      "ROC AUC Score: 0.7379060076717168\n",
      "Predictions: [0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 1 1 1 1 1 0 1 1 0 0 1 0 0 1 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC()\n",
    "svm_balanceado = SVC(class_weight='balanced')\n",
    "grid_parametros = {'classifier__C': [0.1, 1, 10, 100],\n",
    "                   'classifier__kernel': ['linear', 'rbf'],\n",
    "                   'classifier__gamma': ['scale', 'auto']}\n",
    "\n",
    "oversampler = RandomOverSampler()\n",
    "undersampler = RandomUnderSampler()\n",
    "combinado = SMOTEENN()\n",
    "\n",
    "normal_pipeline = Pipeline([('classifier', svm)])\n",
    "balanceado_pipeline = Pipeline([('classifier', svm_balanceado)])\n",
    "over_pipeline = ImbPipeline([('sampler', oversampler), ('classifier', svm)])\n",
    "under_pipeline = ImbPipeline([('sampler', undersampler), ('classifier', svm)])\n",
    "combinado_pipeline = ImbPipeline([('sampler', combinado), ('classifier', svm)])\n",
    "\n",
    "resultados = {}\n",
    "\n",
    "for nombre, pipeline in [('Normal', normal_pipeline), ('Balanced', balanceado_pipeline), ('OverSampler', over_pipeline), ('UnderSampler', under_pipeline), ('SMOTEENN', combinado_pipeline)]:\n",
    "    grid_search = GridSearchCV(pipeline, grid_parametros, cv=10, scoring='accuracy')\n",
    "    grid_search.fit(X_train, Y_train)\n",
    "\n",
    "    print(f\"Resultados para {nombre}:\")\n",
    "    print(grid_search.cv_results_)\n",
    "\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "    Y_pred = best_estimator.predict(X_test)\n",
    "\n",
    "    resultados[nombre] = {\"GridSearchModel\": grid_search,\n",
    "                     \"Accuracy\": accuracy_score(Y_test, Y_pred),\n",
    "                     \"Precision\": precision_score(Y_test, Y_pred),\n",
    "                     \"Recall\": recall_score(Y_test, Y_pred),\n",
    "                     \"F1 Score\": f1_score(Y_test, Y_pred),\n",
    "                     \"ROC AUC Score\": roc_auc_score(Y_test, Y_pred),\n",
    "                     \"Predictions\": Y_pred}\n",
    "\n",
    "\n",
    "for nombre, metricas in resultados.items():\n",
    "    print(f\"\\nResultados para {nombre}:\")\n",
    "    for metrica, value in metricas.items():\n",
    "        print(f\"{metrica}: {value}\")\n",
    "\n",
    "for nombre, metricas in resultados.items():\n",
    "    with open(f\"Modelos/SVC_{nombre}_mejor_modelo.pkl\", \"wb\") as f:\n",
    "        pickle.dump(metricas[\"GridSearchModel\"].best_estimator_, f)\n",
    "    \n",
    "    with open(f\"Resultados/SVC_{nombre}_resultados.txt\", \"w\") as f:\n",
    "        for metrica, value in metricas.items():\n",
    "            if metrica != \"Predictions\": \n",
    "                f.write(f\"{metrica}: {value}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging, Boosting, Adaboost, Xgboost, Stacking y Voting\n",
    "\n",
    "Importo varios modelos de clasificación, como Gradient Boosting, AdaBoost, XGBoost, Stacking y Voting, así como otros clasificadores básicos como SVC, Regresión Logística, KNeighbors y Árbol de Decisión (estos últimos para stacking y voting, el resto de modelos se basan en arboles de decisiones). \n",
    "\n",
    "Luego, creo instancias de estos modelos y muestras, para posteriormente crear un diccionario llamado ensemble_modelos, que contiene cada modelo de ensamblado con sus respectivos hiperparámetros. Después, itero con bucles cada modelo y técnica de muestreo, aplicándolos en un pipeline y utilizando GridSearchCV para encontrar la mejor combinación de hiperparámetros.\n",
    "\n",
    "Entreno y evalúo cada modelo con diferentes técnicas de muestreo y guardo los resultados en el diccionario. Finalmente, imprimo los resultados en la pantalla y los guardo en archivos para su posterior análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados para Bagging (Normal):\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('classifier',\n",
      "                                        BaggingClassifier(estimator=DecisionTreeClassifier()))]),\n",
      "             param_grid={'classifier__estimator__max_depth': [None, 3, 5, 10],\n",
      "                         'classifier__n_estimators': [10, 50, 100]},\n",
      "             scoring='accuracy')\n",
      "Accuracy: 0.8442211055276382\n",
      "Precision: 0.9876543209876543\n",
      "Recall: 0.5673758865248227\n",
      "F1 Score: 0.7207207207207208\n",
      "ROC AUC Score: 0.7817424179705825\n",
      "Predictions: [0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\n",
      "Resultados para Bagging (OverSampler):\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('sampler', SMOTE()),\n",
      "                                       ('classifier',\n",
      "                                        BaggingClassifier(estimator=DecisionTreeClassifier()))]),\n",
      "             param_grid={'classifier__estimator__max_depth': [None, 3, 5, 10],\n",
      "                         'classifier__n_estimators': [10, 50, 100]},\n",
      "             scoring='accuracy')\n",
      "Accuracy: 0.8442211055276382\n",
      "Precision: 0.9876543209876543\n",
      "Recall: 0.5673758865248227\n",
      "F1 Score: 0.7207207207207208\n",
      "ROC AUC Score: 0.7817424179705825\n",
      "Predictions: [0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\n",
      "Resultados para Bagging (UnderSampler):\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('sampler', RandomUnderSampler()),\n",
      "                                       ('classifier',\n",
      "                                        BaggingClassifier(estimator=DecisionTreeClassifier()))]),\n",
      "             param_grid={'classifier__estimator__max_depth': [None, 3, 5, 10],\n",
      "                         'classifier__n_estimators': [10, 50, 100]},\n",
      "             scoring='accuracy')\n",
      "Accuracy: 0.8417085427135679\n",
      "Precision: 0.975609756097561\n",
      "Recall: 0.5673758865248227\n",
      "F1 Score: 0.7174887892376682\n",
      "ROC AUC Score: 0.7797968926787537\n",
      "Predictions: [0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\n",
      "Resultados para Bagging (SMOTEENN):\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('sampler', SMOTEENN()),\n",
      "                                       ('classifier',\n",
      "                                        BaggingClassifier(estimator=DecisionTreeClassifier()))]),\n",
      "             param_grid={'classifier__estimator__max_depth': [None, 3, 5, 10],\n",
      "                         'classifier__n_estimators': [10, 50, 100]},\n",
      "             scoring='accuracy')\n",
      "Accuracy: 0.8065326633165829\n",
      "Precision: 0.82\n",
      "Recall: 0.5815602836879432\n",
      "F1 Score: 0.6804979253112032\n",
      "ROC AUC Score: 0.7557606865910533\n",
      "Predictions: [0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 1 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0\n",
      " 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 1\n",
      " 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\n",
      "Resultados para Boosting (Gradient Boosting) (Normal):\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('classifier',\n",
      "                                        GradientBoostingClassifier())]),\n",
      "             param_grid={'classifier__learning_rate': [0.1, 0.01, 0.001],\n",
      "                         'classifier__max_depth': [3, 5, 10, 15],\n",
      "                         'classifier__n_estimators': [100, 200, 300, 400]},\n",
      "             scoring='accuracy')\n",
      "Accuracy: 0.8417085427135679\n",
      "Precision: 0.975609756097561\n",
      "Recall: 0.5673758865248227\n",
      "F1 Score: 0.7174887892376682\n",
      "ROC AUC Score: 0.7797968926787537\n",
      "Predictions: [0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 1 1 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\n",
      "Resultados para Boosting (Gradient Boosting) (OverSampler):\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('sampler', SMOTE()),\n",
      "                                       ('classifier',\n",
      "                                        GradientBoostingClassifier())]),\n",
      "             param_grid={'classifier__learning_rate': [0.1, 0.01, 0.001],\n",
      "                         'classifier__max_depth': [3, 5, 10, 15],\n",
      "                         'classifier__n_estimators': [100, 200, 300, 400]},\n",
      "             scoring='accuracy')\n",
      "Accuracy: 0.8442211055276382\n",
      "Precision: 0.9876543209876543\n",
      "Recall: 0.5673758865248227\n",
      "F1 Score: 0.7207207207207208\n",
      "ROC AUC Score: 0.7817424179705825\n",
      "Predictions: [0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\n",
      "Resultados para Boosting (Gradient Boosting) (UnderSampler):\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('sampler', RandomUnderSampler()),\n",
      "                                       ('classifier',\n",
      "                                        GradientBoostingClassifier())]),\n",
      "             param_grid={'classifier__learning_rate': [0.1, 0.01, 0.001],\n",
      "                         'classifier__max_depth': [3, 5, 10, 15],\n",
      "                         'classifier__n_estimators': [100, 200, 300, 400]},\n",
      "             scoring='accuracy')\n",
      "Accuracy: 0.8442211055276382\n",
      "Precision: 0.9876543209876543\n",
      "Recall: 0.5673758865248227\n",
      "F1 Score: 0.7207207207207208\n",
      "ROC AUC Score: 0.7817424179705825\n",
      "Predictions: [0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\n",
      "Resultados para Boosting (Gradient Boosting) (SMOTEENN):\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('sampler', SMOTEENN()),\n",
      "                                       ('classifier',\n",
      "                                        GradientBoostingClassifier())]),\n",
      "             param_grid={'classifier__learning_rate': [0.1, 0.01, 0.001],\n",
      "                         'classifier__max_depth': [3, 5, 10, 15],\n",
      "                         'classifier__n_estimators': [100, 200, 300, 400]},\n",
      "             scoring='accuracy')\n",
      "Accuracy: 0.8065326633165829\n",
      "Precision: 0.82\n",
      "Recall: 0.5815602836879432\n",
      "F1 Score: 0.6804979253112032\n",
      "ROC AUC Score: 0.7557606865910533\n",
      "Predictions: [0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 1 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0\n",
      " 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 1\n",
      " 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\n",
      "Resultados para AdaBoost (Normal):\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('classifier', AdaBoostClassifier())]),\n",
      "             param_grid={'classifier__learning_rate': [1.0, 0.5, 0.1],\n",
      "                         'classifier__n_estimators': [50, 100, 150]},\n",
      "             scoring='accuracy')\n",
      "Accuracy: 0.8341708542713567\n",
      "Precision: 0.987012987012987\n",
      "Recall: 0.5390070921985816\n",
      "F1 Score: 0.6972477064220183\n",
      "ROC AUC Score: 0.7675580208074619\n",
      "Predictions: [0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\n",
      "Resultados para AdaBoost (OverSampler):\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('sampler', SMOTE()),\n",
      "                                       ('classifier', AdaBoostClassifier())]),\n",
      "             param_grid={'classifier__learning_rate': [1.0, 0.5, 0.1],\n",
      "                         'classifier__n_estimators': [50, 100, 150]},\n",
      "             scoring='accuracy')\n",
      "Accuracy: 0.8291457286432161\n",
      "Precision: 0.9101123595505618\n",
      "Recall: 0.574468085106383\n",
      "F1 Score: 0.7043478260869566\n",
      "ROC AUC Score: 0.7716698402185611\n",
      "Predictions: [0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\n",
      "Resultados para AdaBoost (UnderSampler):\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('sampler', RandomUnderSampler()),\n",
      "                                       ('classifier', AdaBoostClassifier())]),\n",
      "             param_grid={'classifier__learning_rate': [1.0, 0.5, 0.1],\n",
      "                         'classifier__n_estimators': [50, 100, 150]},\n",
      "             scoring='accuracy')\n",
      "Accuracy: 0.8241206030150754\n",
      "Precision: 0.8736842105263158\n",
      "Recall: 0.5886524822695035\n",
      "F1 Score: 0.7033898305084745\n",
      "ROC AUC Score: 0.7709799376328061\n",
      "Predictions: [0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 1 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 1\n",
      " 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\n",
      "Resultados para AdaBoost (SMOTEENN):\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('sampler', SMOTEENN()),\n",
      "                                       ('classifier', AdaBoostClassifier())]),\n",
      "             param_grid={'classifier__learning_rate': [1.0, 0.5, 0.1],\n",
      "                         'classifier__n_estimators': [50, 100, 150]},\n",
      "             scoring='accuracy')\n",
      "Accuracy: 0.7914572864321608\n",
      "Precision: 0.7589285714285714\n",
      "Recall: 0.6028368794326241\n",
      "F1 Score: 0.6719367588932805\n",
      "ROC AUC Score: 0.7488892568369346\n",
      "Predictions: [0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1\n",
      " 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 1 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1\n",
      " 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 1\n",
      " 0 0 0 1 1 1 1 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 1 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0]\n",
      "\n",
      "Resultados para XGBoost (Normal):\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('classifier',\n",
      "                                        XGBClassifier(base_score=None,\n",
      "                                                      booster=None,\n",
      "                                                      callbacks=None,\n",
      "                                                      colsample_bylevel=None,\n",
      "                                                      colsample_bynode=None,\n",
      "                                                      colsample_bytree=None,\n",
      "                                                      early_stopping_rounds=None,\n",
      "                                                      enable_categorical=False,\n",
      "                                                      eval_metric=None,\n",
      "                                                      feature_types=None,\n",
      "                                                      gamma=None, gpu_id=None,\n",
      "                                                      grow_policy=None,\n",
      "                                                      importance_type=None,\n",
      "                                                      interaction_const...\n",
      "                                                      max_delta_step=None,\n",
      "                                                      max_depth=None,\n",
      "                                                      max_leaves=None,\n",
      "                                                      min_child_weight=None,\n",
      "                                                      missing=nan,\n",
      "                                                      monotone_constraints=None,\n",
      "                                                      n_estimators=100,\n",
      "                                                      n_jobs=None,\n",
      "                                                      num_parallel_tree=None,\n",
      "                                                      predictor=None,\n",
      "                                                      random_state=None, ...))]),\n",
      "             param_grid={'classifier__learning_rate': [0.1, 0.01, 0.001],\n",
      "                         'classifier__max_depth': [3, 5, 10, 15],\n",
      "                         'classifier__n_estimators': [100, 200, 300, 400]},\n",
      "             scoring='accuracy')\n",
      "Accuracy: 0.8442211055276382\n",
      "Precision: 0.9876543209876543\n",
      "Recall: 0.5673758865248227\n",
      "F1 Score: 0.7207207207207208\n",
      "ROC AUC Score: 0.7817424179705825\n",
      "Predictions: [0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\n",
      "Resultados para XGBoost (OverSampler):\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('sampler', SMOTE()),\n",
      "                                       ('classifier',\n",
      "                                        XGBClassifier(base_score=None,\n",
      "                                                      booster=None,\n",
      "                                                      callbacks=None,\n",
      "                                                      colsample_bylevel=None,\n",
      "                                                      colsample_bynode=None,\n",
      "                                                      colsample_bytree=None,\n",
      "                                                      early_stopping_rounds=None,\n",
      "                                                      enable_categorical=False,\n",
      "                                                      eval_metric=None,\n",
      "                                                      feature_types=None,\n",
      "                                                      gamma=None, gpu_id=None,\n",
      "                                                      grow_policy=None,\n",
      "                                                      importance_type=No...\n",
      "                                                      max_delta_step=None,\n",
      "                                                      max_depth=None,\n",
      "                                                      max_leaves=None,\n",
      "                                                      min_child_weight=None,\n",
      "                                                      missing=nan,\n",
      "                                                      monotone_constraints=None,\n",
      "                                                      n_estimators=100,\n",
      "                                                      n_jobs=None,\n",
      "                                                      num_parallel_tree=None,\n",
      "                                                      predictor=None,\n",
      "                                                      random_state=None, ...))]),\n",
      "             param_grid={'classifier__learning_rate': [0.1, 0.01, 0.001],\n",
      "                         'classifier__max_depth': [3, 5, 10, 15],\n",
      "                         'classifier__n_estimators': [100, 200, 300, 400]},\n",
      "             scoring='accuracy')\n",
      "Accuracy: 0.8442211055276382\n",
      "Precision: 0.9876543209876543\n",
      "Recall: 0.5673758865248227\n",
      "F1 Score: 0.7207207207207208\n",
      "ROC AUC Score: 0.7817424179705825\n",
      "Predictions: [0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\n",
      "Resultados para XGBoost (UnderSampler):\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('sampler', RandomUnderSampler()),\n",
      "                                       ('classifier',\n",
      "                                        XGBClassifier(base_score=None,\n",
      "                                                      booster=None,\n",
      "                                                      callbacks=None,\n",
      "                                                      colsample_bylevel=None,\n",
      "                                                      colsample_bynode=None,\n",
      "                                                      colsample_bytree=None,\n",
      "                                                      early_stopping_rounds=None,\n",
      "                                                      enable_categorical=False,\n",
      "                                                      eval_metric=None,\n",
      "                                                      feature_types=None,\n",
      "                                                      gamma=None, gpu_id=None,\n",
      "                                                      grow_policy=None,\n",
      "                                                      impor...\n",
      "                                                      max_delta_step=None,\n",
      "                                                      max_depth=None,\n",
      "                                                      max_leaves=None,\n",
      "                                                      min_child_weight=None,\n",
      "                                                      missing=nan,\n",
      "                                                      monotone_constraints=None,\n",
      "                                                      n_estimators=100,\n",
      "                                                      n_jobs=None,\n",
      "                                                      num_parallel_tree=None,\n",
      "                                                      predictor=None,\n",
      "                                                      random_state=None, ...))]),\n",
      "             param_grid={'classifier__learning_rate': [0.1, 0.01, 0.001],\n",
      "                         'classifier__max_depth': [3, 5, 10, 15],\n",
      "                         'classifier__n_estimators': [100, 200, 300, 400]},\n",
      "             scoring='accuracy')\n",
      "Accuracy: 0.8442211055276382\n",
      "Precision: 0.9876543209876543\n",
      "Recall: 0.5673758865248227\n",
      "F1 Score: 0.7207207207207208\n",
      "ROC AUC Score: 0.7817424179705825\n",
      "Predictions: [0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\n",
      "Resultados para XGBoost (SMOTEENN):\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('sampler', SMOTEENN()),\n",
      "                                       ('classifier',\n",
      "                                        XGBClassifier(base_score=None,\n",
      "                                                      booster=None,\n",
      "                                                      callbacks=None,\n",
      "                                                      colsample_bylevel=None,\n",
      "                                                      colsample_bynode=None,\n",
      "                                                      colsample_bytree=None,\n",
      "                                                      early_stopping_rounds=None,\n",
      "                                                      enable_categorical=False,\n",
      "                                                      eval_metric=None,\n",
      "                                                      feature_types=None,\n",
      "                                                      gamma=None, gpu_id=None,\n",
      "                                                      grow_policy=None,\n",
      "                                                      importance_type...\n",
      "                                                      max_delta_step=None,\n",
      "                                                      max_depth=None,\n",
      "                                                      max_leaves=None,\n",
      "                                                      min_child_weight=None,\n",
      "                                                      missing=nan,\n",
      "                                                      monotone_constraints=None,\n",
      "                                                      n_estimators=100,\n",
      "                                                      n_jobs=None,\n",
      "                                                      num_parallel_tree=None,\n",
      "                                                      predictor=None,\n",
      "                                                      random_state=None, ...))]),\n",
      "             param_grid={'classifier__learning_rate': [0.1, 0.01, 0.001],\n",
      "                         'classifier__max_depth': [3, 5, 10, 15],\n",
      "                         'classifier__n_estimators': [100, 200, 300, 400]},\n",
      "             scoring='accuracy')\n",
      "Accuracy: 0.8442211055276382\n",
      "Precision: 0.9876543209876543\n",
      "Recall: 0.5673758865248227\n",
      "F1 Score: 0.7207207207207208\n",
      "ROC AUC Score: 0.7817424179705825\n",
      "Predictions: [0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\n",
      "Resultados para Stacking (Normal):\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('classifier',\n",
      "                                        StackingClassifier(cv=10,\n",
      "                                                           estimators=[('svc',\n",
      "                                                                        SVC(probability=True)),\n",
      "                                                                       ('log_reg',\n",
      "                                                                        LogisticRegression()),\n",
      "                                                                       ('knn',\n",
      "                                                                        KNeighborsClassifier()),\n",
      "                                                                       ('decision_tree',\n",
      "                                                                        DecisionTreeClassifier())],\n",
      "                                                           final_estimator=LogisticRegression()))]),\n",
      "             param_grid={}, scoring='accuracy')\n",
      "Accuracy: 0.8015075376884422\n",
      "Precision: 0.8369565217391305\n",
      "Recall: 0.5460992907801419\n",
      "F1 Score: 0.6609442060085837\n",
      "ROC AUC Score: 0.743866766012639\n",
      "Predictions: [0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 1 0 1 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 1 1 1 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\n",
      "Resultados para Stacking (OverSampler):\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('sampler', SMOTE()),\n",
      "                                       ('classifier',\n",
      "                                        StackingClassifier(cv=10,\n",
      "                                                           estimators=[('svc',\n",
      "                                                                        SVC(probability=True)),\n",
      "                                                                       ('log_reg',\n",
      "                                                                        LogisticRegression()),\n",
      "                                                                       ('knn',\n",
      "                                                                        KNeighborsClassifier()),\n",
      "                                                                       ('decision_tree',\n",
      "                                                                        DecisionTreeClassifier())],\n",
      "                                                           final_estimator=LogisticRegression()))]),\n",
      "             param_grid={}, scoring='accuracy')\n",
      "Accuracy: 0.7839195979899497\n",
      "Precision: 0.7165354330708661\n",
      "Recall: 0.6453900709219859\n",
      "F1 Score: 0.6791044776119403\n",
      "ROC AUC Score: 0.7526561249551564\n",
      "Predictions: [0 1 1 0 1 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 1 1 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0\n",
      " 1 0 1 1 0 1 1 0 0 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 1 0 1 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0\n",
      " 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 1 1 0 1 0 0 1 1 1 0 0 0 0 1 0\n",
      " 0 0 1 1 1 1 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 0 1 0 0 0 1\n",
      " 0 0 0 0 0 1 1 0 1 0 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 1 1 0]\n",
      "\n",
      "Resultados para Stacking (UnderSampler):\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('sampler', RandomUnderSampler()),\n",
      "                                       ('classifier',\n",
      "                                        StackingClassifier(cv=10,\n",
      "                                                           estimators=[('svc',\n",
      "                                                                        SVC(probability=True)),\n",
      "                                                                       ('log_reg',\n",
      "                                                                        LogisticRegression()),\n",
      "                                                                       ('knn',\n",
      "                                                                        KNeighborsClassifier()),\n",
      "                                                                       ('decision_tree',\n",
      "                                                                        DecisionTreeClassifier())],\n",
      "                                                           final_estimator=LogisticRegression()))]),\n",
      "             param_grid={}, scoring='accuracy')\n",
      "Accuracy: 0.7537688442211056\n",
      "Precision: 0.6641221374045801\n",
      "Recall: 0.6170212765957447\n",
      "F1 Score: 0.6397058823529412\n",
      "ROC AUC Score: 0.7229075254574054\n",
      "Predictions: [0 1 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 1 1 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 1 1 0\n",
      " 0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 1 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 0 0 0 1 0 1 0 1 1 1 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1\n",
      " 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 0 0 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 0 1 1 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\n",
      "Resultados para Stacking (SMOTEENN):\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('sampler', SMOTEENN()),\n",
      "                                       ('classifier',\n",
      "                                        StackingClassifier(cv=10,\n",
      "                                                           estimators=[('svc',\n",
      "                                                                        SVC(probability=True)),\n",
      "                                                                       ('log_reg',\n",
      "                                                                        LogisticRegression()),\n",
      "                                                                       ('knn',\n",
      "                                                                        KNeighborsClassifier()),\n",
      "                                                                       ('decision_tree',\n",
      "                                                                        DecisionTreeClassifier())],\n",
      "                                                           final_estimator=LogisticRegression()))]),\n",
      "             param_grid={}, scoring='accuracy')\n",
      "Accuracy: 0.7688442211055276\n",
      "Precision: 0.696\n",
      "Recall: 0.6170212765957447\n",
      "F1 Score: 0.6541353383458647\n",
      "ROC AUC Score: 0.7345806772083782\n",
      "Predictions: [0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 0 0 0 0 1\n",
      " 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0\n",
      " 0 0 0 1 1 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 1 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 1 1 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 0 1 0\n",
      " 0 0 0 1 1 1 1 0 0 1 0 0 1 0 0 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 1\n",
      " 0 0 0 1 0 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\n",
      "Resultados para Voting (Normal):\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('classifier',\n",
      "                                        VotingClassifier(estimators=[('svc',\n",
      "                                                                      SVC(probability=True)),\n",
      "                                                                     ('log_reg',\n",
      "                                                                      LogisticRegression()),\n",
      "                                                                     ('knn',\n",
      "                                                                      KNeighborsClassifier()),\n",
      "                                                                     ('decision_tree',\n",
      "                                                                      DecisionTreeClassifier())],\n",
      "                                                         voting='soft'))]),\n",
      "             param_grid={}, scoring='accuracy')\n",
      "Accuracy: 0.8015075376884422\n",
      "Precision: 0.8297872340425532\n",
      "Recall: 0.5531914893617021\n",
      "F1 Score: 0.6638297872340426\n",
      "ROC AUC Score: 0.7454673400115904\n",
      "Predictions: [0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 1 0 1 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "\n",
      "Resultados para Voting (OverSampler):\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('sampler', SMOTE()),\n",
      "                                       ('classifier',\n",
      "                                        VotingClassifier(estimators=[('svc',\n",
      "                                                                      SVC(probability=True)),\n",
      "                                                                     ('log_reg',\n",
      "                                                                      LogisticRegression()),\n",
      "                                                                     ('knn',\n",
      "                                                                      KNeighborsClassifier()),\n",
      "                                                                     ('decision_tree',\n",
      "                                                                      DecisionTreeClassifier())],\n",
      "                                                         voting='soft'))]),\n",
      "             param_grid={}, scoring='accuracy')\n",
      "Accuracy: 0.7763819095477387\n",
      "Precision: 0.7063492063492064\n",
      "Recall: 0.6312056737588653\n",
      "F1 Score: 0.6666666666666667\n",
      "ROC AUC Score: 0.7436184010817672\n",
      "Predictions: [0 1 1 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 1 1 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 1\n",
      " 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 1 0 1 1 0\n",
      " 1 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 1 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 1 1 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0\n",
      " 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1 1 1 0 0 0 0 1 1\n",
      " 0 0 0 1 1 1 1 0 0 1 0 0 0 1 1 1 1 0 0 1 0 1 1 0 1 0 1 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0]\n",
      "\n",
      "Resultados para Voting (UnderSampler):\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('sampler', RandomUnderSampler()),\n",
      "                                       ('classifier',\n",
      "                                        VotingClassifier(estimators=[('svc',\n",
      "                                                                      SVC(probability=True)),\n",
      "                                                                     ('log_reg',\n",
      "                                                                      LogisticRegression()),\n",
      "                                                                     ('knn',\n",
      "                                                                      KNeighborsClassifier()),\n",
      "                                                                     ('decision_tree',\n",
      "                                                                      DecisionTreeClassifier())],\n",
      "                                                         voting='soft'))]),\n",
      "             param_grid={}, scoring='accuracy')\n",
      "Accuracy: 0.7613065326633166\n",
      "Precision: 0.6666666666666666\n",
      "Recall: 0.6524822695035462\n",
      "F1 Score: 0.6594982078853048\n",
      "ROC AUC Score: 0.7367469713276485\n",
      "Predictions: [0 1 1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0\n",
      " 0 0 0 1 1 0 0 0 0 1 1 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1\n",
      " 0 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 1 0 0 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 1 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 1 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0\n",
      " 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1\n",
      " 1 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1\n",
      " 0 0 0 1 1 1 1 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 0 1 1 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 0 0 0 1 1 0]\n",
      "\n",
      "Resultados para Voting (SMOTEENN):\n",
      "GridSearchModel: GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('sampler', SMOTEENN()),\n",
      "                                       ('classifier',\n",
      "                                        VotingClassifier(estimators=[('svc',\n",
      "                                                                      SVC(probability=True)),\n",
      "                                                                     ('log_reg',\n",
      "                                                                      LogisticRegression()),\n",
      "                                                                     ('knn',\n",
      "                                                                      KNeighborsClassifier()),\n",
      "                                                                     ('decision_tree',\n",
      "                                                                      DecisionTreeClassifier())],\n",
      "                                                         voting='soft'))]),\n",
      "             param_grid={}, scoring='accuracy')\n",
      "Accuracy: 0.7763819095477387\n",
      "Precision: 0.7131147540983607\n",
      "Recall: 0.6170212765957447\n",
      "F1 Score: 0.6615969581749049\n",
      "ROC AUC Score: 0.7404172530838646\n",
      "Predictions: [0 1 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 1 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 1 0 1 0 0 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1\n",
      " 0 0 0 1 1 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 1 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 1 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 0 1 1\n",
      " 0 0 0 1 1 1 1 0 1 1 0 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 1\n",
      " 0 0 0 0 0 1 1 0 1 0 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import (GradientBoostingClassifier, StackingClassifier,\n",
    "                              AdaBoostClassifier, VotingClassifier, BaggingClassifier)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, roc_auc_score)\n",
    "from xgboost import XGBClassifier  \n",
    "\n",
    "\n",
    "oversampler = SMOTE()\n",
    "undersampler = RandomUnderSampler()\n",
    "smoteenn = SMOTEENN()\n",
    "\n",
    "# Modelos de ensemble\n",
    "bagging_modelo = BaggingClassifier(estimator=DecisionTreeClassifier())\n",
    "boosting_modelo = GradientBoostingClassifier()\n",
    "ada_boost_modelo = AdaBoostClassifier()\n",
    "xgboost_modelo = XGBClassifier() \n",
    "\n",
    "#Estimadores para stacking y voting\n",
    "estimators = [\n",
    "    ('svc', SVC(probability=True)),\n",
    "    ('log_reg', LogisticRegression()),\n",
    "    ('knn', KNeighborsClassifier()),\n",
    "    ('decision_tree', DecisionTreeClassifier())\n",
    "]\n",
    "stacking_modelo = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(), cv=10)\n",
    "voting_modelo = VotingClassifier(estimators=estimators, voting='soft')\n",
    "\n",
    "\n",
    "ensemble_modelos = {\n",
    "    'Bagging': (bagging_modelo, {'classifier__n_estimators': [10, 50, 100], 'classifier__estimator__max_depth': [None, 3, 5, 10]}),\n",
    "    'Boosting (Gradient Boosting)': (boosting_modelo, {'classifier__n_estimators': [100, 200, 300, 400], 'classifier__learning_rate': [0.1, 0.01, 0.001], 'classifier__max_depth': [3, 5, 10, 15]}),\n",
    "    'AdaBoost': (ada_boost_modelo, {'classifier__n_estimators': [50, 100, 150], 'classifier__learning_rate': [1.0, 0.5, 0.1]}),\n",
    "    'XGBoost': (xgboost_modelo, {'classifier__n_estimators': [100, 200, 300, 400], 'classifier__learning_rate': [0.1, 0.01, 0.001], 'classifier__max_depth': [3, 5, 10, 15]}), \n",
    "    'Stacking': (stacking_modelo, {}),\n",
    "    'Voting': (voting_modelo, {}),\n",
    "}\n",
    "\n",
    "\n",
    "resultados = {}\n",
    "\n",
    "for ensemble_name, (model, model_param_grid) in ensemble_modelos.items():\n",
    "    for sampling_name, pipeline in [('Normal', Pipeline([('classifier', model)])),\n",
    "                                     ('OverSampler', ImbPipeline([('sampler', oversampler), ('classifier', model)])),\n",
    "                                     ('UnderSampler', ImbPipeline([('sampler', undersampler), ('classifier', model)])),\n",
    "                                     ('SMOTEENN', ImbPipeline([('sampler', smoteenn), ('classifier', model)]))]:\n",
    "        grid_search = GridSearchCV(pipeline, model_param_grid, cv=10, scoring='accuracy')\n",
    "        grid_search.fit(X_train, Y_train)\n",
    "        Y_pred = grid_search.predict(X_test)\n",
    "\n",
    "\n",
    "        nombre = f\"{ensemble_name} ({sampling_name})\"\n",
    "        resultados[nombre] = {\"GridSearchModel\": grid_search,\n",
    "                     \"Accuracy\": accuracy_score(Y_test, Y_pred),\n",
    "                     \"Precision\": precision_score(Y_test, Y_pred),\n",
    "                     \"Recall\": recall_score(Y_test, Y_pred),\n",
    "                     \"F1 Score\": f1_score(Y_test, Y_pred),\n",
    "                     \"ROC AUC Score\": roc_auc_score(Y_test, Y_pred),\n",
    "                     \"Predictions\": Y_pred}\n",
    "\n",
    "\n",
    "for nombre, metrics in resultados.items():\n",
    "    print(f\"\\nResultados para {nombre}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value}\")\n",
    "\n",
    "for nombre, metricas in resultados.items():\n",
    "    with open(f\"Modelos/Ensemble_{nombre}_mejor_modelo.pkl\", \"wb\") as f:\n",
    "        pickle.dump(metricas[\"GridSearchModel\"].best_estimator_, f)\n",
    "    \n",
    "    with open(\"Resultados/resultados.txt\", \"w\") as f:\n",
    "        for nombre, metrics in resultados.items():\n",
    "            f.write(f\"\\nResultados para{nombre}:\\n\")\n",
    "            for metric, value in metrics.items():\n",
    "                f.write(f\"{metric}: {value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89       257\n",
      "           1       0.99      0.57      0.72       141\n",
      "\n",
      "    accuracy                           0.84       398\n",
      "   macro avg       0.90      0.78      0.81       398\n",
      "weighted avg       0.87      0.84      0.83       398\n",
      "\n",
      "[0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "with open('modelos/DecisionTree_Balanced_mejor_modelo.pkl', 'rb') as file:\n",
    "    modelo = pickle.load(file)\n",
    "\n",
    "\n",
    "y_pred = modelo.predict(X_test)\n",
    "print('DecisionTree:\\n', classification_report(Y_test, y_pred))\n",
    "\n",
    "print(y_pred)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmante rescato los mejores modelos y creo las matrices de confusión para tener una mejor visión de sus predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Didac\\AppData\\Local\\Temp\\ipykernel_8236\\1495810682.py:22: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  cbar.ax.set_yticklabels(cbar.ax.get_yticklabels(), color='white')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, '0'), Text(0, 1.5, '1')]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "conf_mat = confusion_matrix(Y_test, y_pred)\n",
    "\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"deep\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.gcf().set_facecolor('#333333')\n",
    "\n",
    "\n",
    "ax = sns.heatmap(conf_mat, annot=True, fmt='d', cmap=\"crest\", cbar=True,\n",
    "                 cbar_kws={ \"orientation\": \"vertical\",\n",
    "                           \"shrink\": 0.5, \"format\": \"%.0f\", \"extend\": \"neither\", \"extendfrac\": None,\n",
    "                           \"extendrect\": False, \"drawedges\": False}, linewidths=1, linecolor='white',\n",
    "                 square=True, annot_kws={\"color\": \"white\", \"fontweight\": \"bold\",\"fontsize\": 13})\n",
    "\n",
    "\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(color='white', labelsize=10)\n",
    "cbar.ax.set_yticklabels(cbar.ax.get_yticklabels(), color='white')\n",
    "\n",
    "\n",
    "\n",
    "ax.set_xlabel(\"Predicción\", color='white', fontsize=12)\n",
    "ax.set_ylabel(\"Realidad\", color='white', fontsize=12)\n",
    "\n",
    "labels_x = ax.get_xticklabels()\n",
    "labels_y = ax.get_yticklabels()\n",
    "ax.set_xticklabels(labels_x, fontsize=12, color='white')\n",
    "ax.set_yticklabels(labels_y, fontsize=12, color='white')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.86       257\n",
      "           1       0.82      0.60      0.69       141\n",
      "\n",
      "    accuracy                           0.81       398\n",
      "   macro avg       0.81      0.76      0.78       398\n",
      "weighted avg       0.81      0.81      0.80       398\n",
      "\n",
      "[0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 1 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 0 1 0\n",
      " 0 0 0 1 1 1 1 0 1 1 0 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "with open('modelos/Random_Forest_SMOTEENN_mejor_modelo.pkl', 'rb') as file:\n",
    "    modelo = pickle.load(file)\n",
    "\n",
    "\n",
    "y_pred = modelo.predict(X_test)\n",
    "print('DecisionTree:\\n', classification_report(Y_test, y_pred))\n",
    "\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Didac\\AppData\\Local\\Temp\\ipykernel_8236\\3572472372.py:22: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  cbar.ax.set_yticklabels(cbar.ax.get_yticklabels(), color='white')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, '0'), Text(0, 1.5, '1')]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "conf_mat = confusion_matrix(Y_test, y_pred)\n",
    "\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"deep\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.gcf().set_facecolor('#333333')\n",
    "\n",
    "\n",
    "ax = sns.heatmap(conf_mat, annot=True, fmt='d', cmap=\"crest\", cbar=True,\n",
    "                 cbar_kws={ \"orientation\": \"vertical\",\n",
    "                           \"shrink\": 0.5, \"format\": \"%.0f\", \"extend\": \"neither\", \"extendfrac\": None,\n",
    "                           \"extendrect\": False, \"drawedges\": False}, linewidths=1, linecolor='white',\n",
    "                 square=True, annot_kws={\"color\": \"white\", \"fontweight\": \"bold\",\"fontsize\": 13})\n",
    "\n",
    "\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(color='white', labelsize=10)\n",
    "cbar.ax.set_yticklabels(cbar.ax.get_yticklabels(), color='white')\n",
    "\n",
    "\n",
    "\n",
    "ax.set_xlabel(\"Predicción\", color='white', fontsize=12)\n",
    "ax.set_ylabel(\"Realidad\", color='white', fontsize=12)\n",
    "\n",
    "labels_x = ax.get_xticklabels()\n",
    "labels_y = ax.get_yticklabels()\n",
    "ax.set_xticklabels(labels_x, fontsize=12, color='white')\n",
    "ax.set_yticklabels(labels_y, fontsize=12, color='white')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "El modelo Decision Tree Balanced Accuracy: 0.8442 , Precision: 0.9877, Recall: 0.5674, F1 Score 0.7207 y ROC AUC 0.7817 muestra un rendimiento muy bueno en términos de precisión, pero el recall es bastante bajo, lo que indica que el modelo no es eficiente al identificar a todos los clientes que realmente comprarán el seguro. En este caso, el modelo está perdiendo alrededor del 40% de la clase más importante, la clase 1 (Sí compran el seguro).\n",
    "\n",
    "Esto me hace pensar que para el caso de estudio sería mejor, el modelo Random Forest SMOTEENN Accuracy: 0.8090 , Precision: 0.8155, Recall: 0.5957, F1 Score 0.6885 y ROC AUC 0.7609. Este modelo sacrifica algo de precisión para mejorar el recall, lo que significa que el modelo es más eficiente al identificar la clase más importante. \n",
    "\n",
    "En conclusión, es fundamental tener en cuenta los objetivos del negocio al seleccionar el modelo, entiendo que en este caso es muy importante identificar a una mayor proporción de clientes que comprarán el seguro, ya que si el proyecto se pusiera en práctica esta diferencia podria significar una gran cantidad de potenciales futuros clientes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "travel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
